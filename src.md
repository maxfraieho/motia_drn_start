# ÐšÐ¾Ð´ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ: src

**Ð—Ð³ÐµÐ½ÐµÑ€Ð¾Ð²Ð°Ð½Ð¾:** 2025-09-21 07:24:58
**Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ:** `/home/vokov/claude-notifer-and-bot/src`

---

## Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ

```
â”œâ”€â”€ bot/
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auto_responder.py
â”‚   â”‚   â”œâ”€â”€ availability_monitor.py
â”‚   â”‚   â”œâ”€â”€ conversation_mode.py
â”‚   â”‚   â”œâ”€â”€ demo_dracon_system.py
â”‚   â”‚   â”œâ”€â”€ dnd_prompt_manager.py
â”‚   â”‚   â”œâ”€â”€ dracon_enhanced.py
â”‚   â”‚   â”œâ”€â”€ dracon_generator.py
â”‚   â”‚   â”œâ”€â”€ dracon_parser.py
â”‚   â”‚   â””â”€â”€ dracon_renderer.py
â”‚   â”‚   â””â”€â”€ ... Ñ‚Ð° Ñ‰Ðµ 14 Ñ„Ð°Ð¹Ð»Ñ–Ð²
â”‚   â”œâ”€â”€ handlers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ callback.py
â”‚   â”‚   â”œâ”€â”€ command.py
â”‚   â”‚   â”œâ”€â”€ dnd_prompts.py
â”‚   â”‚   â”œâ”€â”€ image_command.py
â”‚   â”‚   â”œâ”€â”€ mcp_callbacks.py
â”‚   â”‚   â”œâ”€â”€ mcp_commands.py
â”‚   â”‚   â”œâ”€â”€ message.py
â”‚   â”‚   â”œâ”€â”€ scheduled_prompts_handler.py
â”‚   â”‚   â””â”€â”€ task_commands.py
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ claude_availability.py
â”‚   â”‚   â”œâ”€â”€ rate_limit.py
â”‚   â”‚   â””â”€â”€ security.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ error_handler.py
â”‚   â”‚   â””â”€â”€ formatting.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ core.py
â”œâ”€â”€ claude/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”œâ”€â”€ facade.py
â”‚   â”œâ”€â”€ facade.py.backup
â”‚   â”œâ”€â”€ integration.py
â”‚   â”œâ”€â”€ monitor.py
â”‚   â”œâ”€â”€ parser.py
â”‚   â”œâ”€â”€ sdk_integration.py
â”‚   â””â”€â”€ session.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ environments.py
â”‚   â”œâ”€â”€ features.py
â”‚   â”œâ”€â”€ loader.py
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ localization/
â”‚   â”œâ”€â”€ translations/
â”‚   â”‚   â”œâ”€â”€ en.json
â”‚   â”‚   â””â”€â”€ uk.json
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ helpers.py
â”‚   â”œâ”€â”€ manager.py
â”‚   â”œâ”€â”€ storage.py
â”‚   â””â”€â”€ util.py
â”œâ”€â”€ mcp/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ claude_integration.py
â”‚   â”œâ”€â”€ context_handler.py
â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”œâ”€â”€ manager.py
â”‚   â””â”€â”€ server_configs.py
â”œâ”€â”€ security/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audit.py
â”‚   â”œâ”€â”€ auth.py
â”‚   â”œâ”€â”€ rate_limiter.py
â”‚   â””â”€â”€ validators.py
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ facade.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ repositories.py
â”‚   â””â”€â”€ session_storage.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ constants.py
â”œâ”€â”€ __init__.py
â”œâ”€â”€ exceptions.py
â”œâ”€â”€ main.py
â”œâ”€â”€ run_md_service.sh
â””â”€â”€ src.md
```

---

## Ð¤Ð°Ð¹Ð»Ð¸ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ

### exceptions.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 1,887 Ð±Ð°Ð¹Ñ‚

```python
"""Custom exceptions for Claude Code Telegram Bot."""


class ClaudeCodeTelegramError(Exception):
    """Base exception for Claude Code Telegram Bot."""

    pass


class ConfigurationError(ClaudeCodeTelegramError):
    """Configuration-related errors."""

    pass


class MissingConfigError(ConfigurationError):
    """Required configuration is missing."""

    pass


class InvalidConfigError(ConfigurationError):
    """Configuration is invalid."""

    pass


class SecurityError(ClaudeCodeTelegramError):
    """Security-related errors."""

    pass


class AuthenticationError(SecurityError):
    """Authentication failed."""

    pass


class AuthorizationError(SecurityError):
    """Authorization failed."""

    pass


class DirectoryTraversalError(SecurityError):
    """Directory traversal attempt detected."""

    pass


class ClaudeError(ClaudeCodeTelegramError):
    """Claude Code-related errors."""

    pass


class ClaudeTimeoutError(ClaudeError):
    """Claude Code operation timed out."""

    pass


class ClaudeProcessError(ClaudeError):
    """Claude Code process execution failed."""

    pass


class ClaudeParsingError(ClaudeError):
    """Failed to parse Claude Code output."""

    pass


class StorageError(ClaudeCodeTelegramError):
    """Storage-related errors."""

    pass


class DatabaseConnectionError(StorageError):
    """Database connection failed."""

    pass


class DataIntegrityError(StorageError):
    """Data integrity check failed."""

    pass


class TelegramError(ClaudeCodeTelegramError):
    """Telegram API-related errors."""

    pass


class MessageTooLongError(TelegramError):
    """Message exceeds Telegram's length limit."""

    pass


class RateLimitError(TelegramError):
    """Rate limit exceeded."""

    pass


class RateLimitExceeded(RateLimitError):
    """Rate limit exceeded (alias for compatibility)."""

    pass

```

### __init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 1,234 Ð±Ð°Ð¹Ñ‚

```python
"""Claude Code Telegram Bot.

A Telegram bot that provides remote access to Claude Code CLI, allowing developers
to interact with their projects from anywhere through a secure, terminal-like
interface within Telegram.

Features:
- Environment-based configuration with Pydantic validation
- Feature flags for dynamic functionality control
- Comprehensive security framework (planned)
- Session persistence and state management (planned)
- Real-time Claude Code integration (planned)

Current Implementation Status:
- âœ… Project Structure & Configuration System (Complete)
- ðŸš§ Authentication & Security Framework (TODO-3)
- ðŸš§ Telegram Bot Core (TODO-4)
- ðŸš§ Claude Code Integration (TODO-5)
- ðŸš§ Storage Layer (TODO-6)
"""

__version__ = "0.1.0"
__author__ = "Richard Atkinson"
__email__ = "richardatk01@gmail.com"
__license__ = "MIT"
__homepage__ = "https://github.com/richardatkinson/claude-code-telegram"

# Development status indicators
__status__ = "Alpha"
__implementation_phase__ = "TODO-3 Complete"

# Completed components
__completed_todos__ = [
    "TODO-1: Project Structure",
    "TODO-2: Configuration Management",
    "TODO-3: Authentication & Security Framework",
]
__next_todo__ = "TODO-4: Telegram Bot Core"

```

### run_md_service.sh

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 3,366 Ð±Ð°Ð¹Ñ‚

```bash
#!/bin/bash

# ===================================================================
# MD TO EMBEDDINGS SERVICE v4.0 - Simple Reliable Launcher (Linux)
# ===================================================================

set -e  # Exit on any error

# Set UTF-8 encoding
export LC_ALL=C.UTF-8
export LANG=C.UTF-8

# Color codes for output
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Script configuration
PYTHON_SCRIPT="md_to_embeddings_service_v4.py"

# Function to print colored output
print_header() {
    echo -e "${BLUE}===================================================================${NC}"
    echo -e "${BLUE}                MD TO EMBEDDINGS SERVICE v4.0${NC}"
    echo -e "${BLUE}===================================================================${NC}"
    echo -e "${YELLOW}Working directory: $(pwd)${NC}"
    echo -e "${BLUE}===================================================================${NC}"
    echo
}

print_error() {
    echo -e "${RED}ERROR: $1${NC}"
}

print_success() {
    echo -e "${GREEN}$1${NC}"
}

print_info() {
    echo -e "${YELLOW}$1${NC}"
}

# Change to script directory
cd "$(dirname "$0")"

# Clear terminal and show header
clear
print_header

# [1/2] Check Python installation
echo "[1/2] Checking Python..."

if command -v python3 &> /dev/null; then
    print_success "Python3 found"
    python3 --version
    PY_CMD="python3"
elif command -v python &> /dev/null; then
    print_success "Python found"
    python --version
    PY_CMD="python"
else
    echo
    print_error "Python not found!"
    echo
    echo "Please install Python3 using:"
    echo "  - Ubuntu/Debian: sudo apt install python3 python3-pip"
    echo "  - CentOS/RHEL: sudo yum install python3 python3-pip"
    echo "  - Fedora: sudo dnf install python3 python3-pip"
    echo "  - Arch: sudo pacman -S python python-pip"
    echo
    exit 1
fi

print_success "Python check completed successfully"
echo

# [2/2] Check main script exists
echo "[2/2] Checking main script..."
if [[ -f "$PYTHON_SCRIPT" ]]; then
    print_success "Main script found: $PYTHON_SCRIPT"
else
    echo
    print_error "$PYTHON_SCRIPT not found!"
    echo "Please make sure the file exists in the current directory."
    echo
    exit 1
fi
echo

# Launch service
echo -e "${BLUE}===================================================================${NC}"
echo -e "${BLUE}Launching MD to Embeddings Service v4.0...${NC}"
echo -e "${BLUE}===================================================================${NC}"
echo
echo "MENU OPTIONS:"
echo "  1. Deploy project template (first run)"
echo "  2. Convert DRAKON schemas"
echo "  3. Create .md file (WITHOUT service files)"
echo "  4. Copy .md to Dropbox"
echo "  5. Exit"
echo
echo -e "${BLUE}===================================================================${NC}"
echo

# Execute the Python script
$PY_CMD "$PYTHON_SCRIPT"
EXIT_CODE=$?

echo
echo -e "${BLUE}===================================================================${NC}"
if [[ $EXIT_CODE -eq 0 ]]; then
    print_success "Service completed successfully"
else
    print_error "Service exited with code: $EXIT_CODE"
fi
echo -e "${BLUE}===================================================================${NC}"
echo

# Wait for user input (Linux equivalent of pause)
read -p "Press Enter to continue..." -r
exit $EXIT_CODE

```

### main.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 12,084 Ð±Ð°Ð¹Ñ‚

```python
"""Main entry point for Claude Code Telegram Bot."""

import argparse
import asyncio
import logging
import os
import signal
import sys
from pathlib import Path
from typing import Any, Dict

import structlog

from src import __version__
from src.bot.core import ClaudeCodeBot
from src.claude.facade import ClaudeIntegration
from src.claude import (
    ClaudeProcessManager,
    SessionManager,
    ToolMonitor,
)
# Temporarily disable SDK integration
# from src.claude.sdk_integration import ClaudeSDKManager
from src.config.features import FeatureFlags
from src.config.loader import load_config
from src.config.settings import Settings
from src.exceptions import ConfigurationError
from src.security.audit import AuditLogger, InMemoryAuditStorage
from src.security.auth import (
    AuthenticationManager,
    InMemoryTokenStorage,
    TokenAuthProvider,
    WhitelistAuthProvider,
)
from src.security.rate_limiter import RateLimiter
from src.security.validators import SecurityValidator
from src.storage.facade import Storage
from src.storage.session_storage import SQLiteSessionStorage
from src.localization import LocalizationManager, UserLanguageStorage
from src.mcp.manager import MCPManager
from src.mcp.context_handler import MCPContextHandler


def setup_logging(debug: bool = False) -> None:
    """Configure structured logging."""
    level = logging.DEBUG if debug else logging.INFO

    # Clear any existing handlers to prevent duplication
    root_logger = logging.getLogger()
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # Configure standard logging with single handler
    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(logging.Formatter("%(message)s"))
    
    logging.basicConfig(
        level=level,
        handlers=[handler],
        force=True,
    )

    # Configure structlog
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            (
                structlog.dev.ConsoleRenderer(colors=True)
                if debug
                else structlog.processors.JSONRenderer()
            ),
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )


def acquire_bot_lock() -> None:
    """Ensure only one bot instance is running."""
    lock_file = Path("/tmp/claude_bot.lock")

    if lock_file.exists():
        try:
            with open(lock_file, "r") as f:
                old_pid = int(f.read().strip())

            # Check if process is still running
            try:
                os.kill(old_pid, 0)  # Signal 0 just checks if process exists
                print(f"âŒ Bot already running with PID {old_pid}")
                print("Stop the existing instance first or wait for it to finish.")
                sys.exit(1)
            except OSError:
                # Process doesn't exist, remove stale lock file
                lock_file.unlink()
        except (ValueError, FileNotFoundError):
            # Invalid or missing lock file, remove it
            lock_file.unlink(missing_ok=True)

    # Create new lock file with current PID
    with open(lock_file, "w") as f:
        f.write(str(os.getpid()))

    # Register cleanup function
    def cleanup_lock():
        lock_file.unlink(missing_ok=True)

    import atexit
    atexit.register(cleanup_lock)


def parse_args() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Claude Code Telegram Bot",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    parser.add_argument(
        "--version", action="version", version=f"Claude Code Telegram Bot {__version__}"
    )

    parser.add_argument("--debug", action="store_true", help="Enable debug logging")

    parser.add_argument("--config-file", type=Path, help="Path to configuration file")

    return parser.parse_args()


async def create_application(config: Settings) -> Dict[str, Any]:
    """Create and configure the application components."""
    logger = structlog.get_logger()
    logger.info("Creating application components")

    # Initialize storage system
    storage = Storage(config.database_url)
    await storage.initialize()

    # Create security components
    providers = []

    # Add whitelist provider if users are configured
    # if config.allowed_users:
    #     providers.append(WhitelistAuthProvider(config.allowed_users))

    # Add token provider if enabled
    if config.enable_token_auth:
        token_storage = InMemoryTokenStorage()  # TODO: Use database storage
        providers.append(TokenAuthProvider(config.auth_token_secret, token_storage))

    # Fall back to allowing all users in development mode
    if not providers and config.development_mode:
        logger.warning(
            "No auth providers configured - creating development-only allow-all provider"
        )
        providers.append(WhitelistAuthProvider([], allow_all_dev=True))
    elif not providers:
        raise ConfigurationError("No authentication providers configured")

    auth_manager = AuthenticationManager(providers)
    security_validator = SecurityValidator(
        config.approved_directory, 
        flexible_mode=getattr(config, 'security_flexible_mode', False)
    )
    rate_limiter = RateLimiter(config)

    # Create audit storage and logger
    audit_storage = InMemoryAuditStorage()  # TODO: Use database storage in production
    audit_logger = AuditLogger(audit_storage)

    # Create Claude integration components with persistent storage
    session_storage = SQLiteSessionStorage(storage.db_manager)
    session_manager = SessionManager(config, session_storage)
    tool_monitor = ToolMonitor(config, security_validator)

    # Create Claude manager based on configuration
    if config.use_sdk:
        logger.info("Using Claude Python SDK integration")
        # Temporarily disable SDK integration
        # sdk_manager = ClaudeSDKManager(config)
        sdk_manager = None
        process_manager = None
    else:
        logger.info("Using Claude CLI subprocess integration")
        process_manager = ClaudeProcessManager(config)
        sdk_manager = None

    # Create main Claude integration facade
    claude_integration = ClaudeIntegration(
        config=config,
        process_manager=process_manager,
        sdk_manager=sdk_manager,
        session_manager=session_manager,
        tool_monitor=tool_monitor,
    )

    # Create localization components
    localization_manager = None
    user_language_storage = None
    
    if config.enable_localization:
        logger.info("Initializing localization system")
        localization_manager = LocalizationManager()
        user_language_storage = UserLanguageStorage(storage)
        logger.info("Localization system initialized", 
                   available_languages=list(localization_manager.get_available_languages().keys()))

    # Create image processing components
    if config.enable_image_processing:
        logger.info("Initializing image processing system")
        from src.bot.features.image_processor import ImageProcessor
        from src.bot.handlers.image_command import ImageCommandHandler
        
        image_processor = ImageProcessor(config, security_validator)
        image_command_handler = ImageCommandHandler(config, image_processor)
        logger.info("Image processing system initialized")
    else:
        image_command_handler = None

    # Create MCP components
    logger.info("Initializing MCP management system")
    mcp_manager = MCPManager(config, storage)
    
    # Create MCP context handler
    mcp_context_handler = MCPContextHandler(
        mcp_manager=mcp_manager,
        claude_integration=claude_integration,
        storage=storage
    )
    logger.info("MCP system initialized")

    # Create bot with all dependencies
    dependencies = {
        "auth_manager": auth_manager,
        "security_validator": security_validator,
        "rate_limiter": rate_limiter,
        "audit_logger": audit_logger,
        "claude_integration": claude_integration,
        "storage": storage,
        "localization": localization_manager,
        "user_language_storage": user_language_storage,
        "mcp_manager": mcp_manager,
        "mcp_context_handler": mcp_context_handler,
        "image_command_handler": image_command_handler,
    }

    bot = ClaudeCodeBot(config, dependencies)

    logger.info("Application components created successfully")

    return {
        "bot": bot,
        "claude_integration": claude_integration,
        "storage": storage,
        "config": config,
    }


async def run_application(app: Dict[str, Any]) -> None:
    """Run the application with graceful shutdown handling."""
    logger = structlog.get_logger()
    bot: ClaudeCodeBot = app["bot"]
    claude_integration: ClaudeIntegration = app["claude_integration"]
    storage: Storage = app["storage"]

    # Set up signal handlers for graceful shutdown
    shutdown_event = asyncio.Event()

    def signal_handler(signum, frame):
        logger.info("Shutdown signal received", signal=signum)
        shutdown_event.set()

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    try:
        # Start the bot
        logger.info("Starting Claude Code Telegram Bot")

        # Run bot in background task
        bot_task = asyncio.create_task(bot.start())
        shutdown_task = asyncio.create_task(shutdown_event.wait())

        # Wait for either bot completion or shutdown signal
        done, pending = await asyncio.wait(
            [bot_task, shutdown_task], return_when=asyncio.FIRST_COMPLETED
        )

        # Cancel remaining tasks
        for task in pending:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass

    except Exception as e:
        logger.error("Application error", error=str(e))
        raise
    finally:
        # Graceful shutdown
        logger.info("Shutting down application")

        try:
            await bot.stop()
            await claude_integration.shutdown()
            await storage.close()
        except Exception as e:
            logger.error("Error during shutdown", error=str(e))

        logger.info("Application shutdown complete")


async def main() -> None:
    """Main application entry point."""
    args = parse_args()

    # Acquire process lock to prevent multiple instances
    acquire_bot_lock()

    setup_logging(debug=args.debug)

    logger = structlog.get_logger()
    logger.info("Starting Claude Code Telegram Bot", version=__version__)

    try:
        # Load configuration
        from src.config import FeatureFlags, load_config

        config = load_config(config_file=args.config_file)
        features = FeatureFlags(config)

        logger.info(
            "Configuration loaded",
            environment="production" if config.is_production else "development",
            enabled_features=features.get_enabled_features(),
            debug=config.debug,
        )

        # Initialize bot and Claude integration
        app = await create_application(config)
        await run_application(app)

    except ConfigurationError as e:
        logger.error("Configuration error", error=str(e))
        sys.exit(1)
    except Exception as e:
        logger.exception("Unexpected error", error=str(e))
        sys.exit(1)


def run() -> None:
    """Synchronous entry point for setuptools."""
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nShutdown requested by user")
        sys.exit(0)


if __name__ == "__main__":
    run()

```

### mcp/claude_integration.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 9,196 Ð±Ð°Ð¹Ñ‚

```python
"""Claude CLI Integration with MCP Support.

Extends the existing Claude integration to support MCP server context execution.
"""

import asyncio
import json
import os
import subprocess
from typing import Any, Dict, Optional

import structlog

from ..claude.integration import ClaudeIntegration, ClaudeResponse
from ..exceptions import ClaudeProcessError

logger = structlog.get_logger()


class ClaudeMCPIntegration(ClaudeIntegration):
    """Extended Claude integration with MCP support."""

    async def run_command_with_mcp(self, prompt: str, working_directory: str,
                                 user_id: int, mcp_server: str,
                                 session_id: Optional[str] = None) -> ClaudeResponse:
        """Run Claude command with specific MCP server context."""

        logger.info("Running Claude command with MCP context", 
                   user_id=user_id, mcp_server=mcp_server, 
                   working_directory=working_directory)

        # Build Claude CLI command with MCP context
        cmd = [self.claude_cli_path or "claude"]

        # Add session handling
        if session_id:
            cmd.extend(["--session", session_id])

        # Add working directory
        if working_directory and working_directory != str(self.config.approved_directory):
            cmd.extend(["--directory", working_directory])

        # Add MCP server specification (if Claude CLI supports it)
        # Note: This depends on Claude CLI MCP implementation
        # cmd.extend(["--mcp-server", mcp_server])

        # Add prompt
        if prompt.strip():
            cmd.append(prompt)
        else:
            cmd.append("--continue")  # Continue previous conversation

        try:
            result = await self._execute_claude_command(cmd, working_directory, user_id)

            # Parse the response
            response = self._parse_claude_output(result.stdout, result.stderr, result.returncode)

            # Log MCP usage
            if hasattr(self, 'mcp_manager') and self.mcp_manager:
                success = not response.is_error
                await self.mcp_manager.log_usage(
                    user_id=user_id,
                    server_name=mcp_server,
                    query=prompt,
                    success=success,
                    response_time=response.duration_ms,
                    error_message=response.error_type if response.is_error else None,
                    cost=response.cost,
                    session_id=response.session_id
                )

            return response

        except Exception as e:
            logger.error("MCP command execution failed", 
                        user_id=user_id, mcp_server=mcp_server, error=str(e))
            raise ClaudeProcessError(f"MCP command failed: {str(e)}")

    async def list_mcp_servers(self, user_id: int) -> Dict[str, Any]:
        """List available MCP servers via Claude CLI."""
        try:
            cmd = [self.claude_cli_path or "claude", "mcp", "list"]
            result = await self._execute_claude_command(cmd, None, user_id)

            if result.returncode == 0:
                # Parse MCP server list from output
                output = result.stdout.decode('utf-8', errors='ignore')
                return self._parse_mcp_list_output(output)
            else:
                error_msg = result.stderr.decode('utf-8', errors='ignore')
                logger.error("Failed to list MCP servers", 
                           user_id=user_id, error=error_msg)
                return {"servers": [], "error": error_msg}

        except Exception as e:
            logger.error("Error listing MCP servers", user_id=user_id, error=str(e))
            return {"servers": [], "error": str(e)}

    async def add_mcp_server(self, user_id: int, server_name: str, 
                           command: str, args: list, env: Dict[str, str]) -> bool:
        """Add MCP server via Claude CLI."""
        try:
            # Build Claude MCP add command
            cmd = [self.claude_cli_path or "claude", "mcp", "add", server_name]

            # Add environment variables
            for key, value in env.items():
                cmd.extend(["--env", f"{key}={value}"])

            # Add command separator
            cmd.append("--")

            # Add server command and args
            cmd.append(command)
            cmd.extend(args)

            result = await self._execute_claude_command(cmd, None, user_id)

            if result.returncode == 0:
                logger.info("Successfully added MCP server", 
                           server_name=server_name, user_id=user_id)
                return True
            else:
                error_msg = result.stderr.decode('utf-8', errors='ignore')
                logger.error("Failed to add MCP server", 
                           server_name=server_name, user_id=user_id, error=error_msg)
                return False

        except Exception as e:
            logger.error("Error adding MCP server", 
                        server_name=server_name, user_id=user_id, error=str(e))
            return False

    async def remove_mcp_server(self, user_id: int, server_name: str) -> bool:
        """Remove MCP server via Claude CLI."""
        try:
            cmd = [self.claude_cli_path or "claude", "mcp", "remove", server_name]
            result = await self._execute_claude_command(cmd, None, user_id)

            if result.returncode == 0:
                logger.info("Successfully removed MCP server", 
                           server_name=server_name, user_id=user_id)
                return True
            else:
                error_msg = result.stderr.decode('utf-8', errors='ignore')
                logger.warning("Failed to remove MCP server", 
                             server_name=server_name, user_id=user_id, error=error_msg)
                return False

        except Exception as e:
            logger.error("Error removing MCP server", 
                        server_name=server_name, user_id=user_id, error=str(e))
            return False

    def _parse_mcp_list_output(self, output: str) -> Dict[str, Any]:
        """Parse MCP server list output from Claude CLI."""
        servers = []
        lines = output.strip().split('\n')

        current_server = None
        for line in lines:
            line = line.strip()
            if not line:
                continue

            # Look for server entries (this is a simplified parser)
            if line.startswith('âœ“') or line.startswith('âœ—') or line.startswith('â—‹'):
                # Server status line
                parts = line.split()
                if len(parts) >= 2:
                    status_char = parts[0]
                    server_name = parts[1]

                    status = "active" if status_char == "âœ“" else ("error" if status_char == "âœ—" else "inactive")

                    current_server = {
                        "name": server_name,
                        "status": status,
                        "details": " ".join(parts[2:]) if len(parts) > 2 else ""
                    }
                    servers.append(current_server)
            elif current_server and line.startswith(' '):
                # Additional server details
                if 'details' not in current_server:
                    current_server['details'] = ''
                current_server['details'] += ' ' + line.strip()

        return {
            "servers": servers,
            "raw_output": output
        }

    async def check_mcp_server_status(self, user_id: int, server_name: str) -> Dict[str, Any]:
        """Check status of specific MCP server."""
        try:
            # Use the list command and filter for our server
            mcp_list = await self.list_mcp_servers(user_id)

            if "error" in mcp_list:
                return {"status": "error", "error": mcp_list["error"]}

            # Find our server in the list
            for server in mcp_list.get("servers", []):
                if server["name"] == server_name:
                    return {
                        "status": server["status"],
                        "details": server.get("details", ""),
                        "found": True
                    }

            return {"status": "not_found", "found": False}

        except Exception as e:
            logger.error("Error checking MCP server status", 
                        server_name=server_name, user_id=user_id, error=str(e))
            return {"status": "error", "error": str(e)}


# Factory function to create the enhanced Claude integration
def create_claude_mcp_integration(config, process_manager=None, sdk_manager=None, 
                                session_manager=None, tool_monitor=None, mcp_manager=None):
    """Create Claude integration with MCP support."""
    integration = ClaudeMCPIntegration(
        config=config,
        process_manager=process_manager,
        sdk_manager=sdk_manager,
        session_manager=session_manager,
        tool_monitor=tool_monitor
    )

    # Attach MCP manager for usage logging
    integration.mcp_manager = mcp_manager

    return integration

```

### mcp/exceptions.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 681 Ð±Ð°Ð¹Ñ‚

```python
"""MCP-specific exceptions for error handling."""

from ..exceptions import ClaudeCodeTelegramError


class MCPError(ClaudeCodeTelegramError):
    """Base MCP-related error."""
    pass


class MCPValidationError(MCPError):
    """MCP validation error."""
    pass


class MCPServerNotFoundError(MCPError):
    """MCP server not found error."""
    pass


class MCPContextError(MCPError):
    """MCP context-related error."""
    pass


class MCPConnectionError(MCPError):
    """MCP connection error."""
    pass


class MCPCommandError(MCPError):
    """MCP command execution error."""
    pass


class MCPConfigurationError(MCPError):
    """MCP configuration error."""
    pass

```

### mcp/context_handler.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 12,431 Ð±Ð°Ð¹Ñ‚

```python
"""MCP Context Handler.

Handles active context selection and contextual query execution.
"""

import asyncio
import json
import time
from datetime import datetime
from typing import Any, Dict, List, Optional

import structlog

from src.claude.facade import ClaudeIntegration
from src.claude.integration import ClaudeResponse
from src.storage.facade import Storage
from .exceptions import MCPContextError, MCPServerNotFoundError
from .manager import MCPManager

logger = structlog.get_logger()


class MCPContextHandler:
    """Handles MCP context selection and execution."""

    def __init__(self, mcp_manager: MCPManager, claude_integration: ClaudeIntegration, storage: Storage):
        """Initialize context handler."""
        self.mcp_manager = mcp_manager
        self.claude_integration = claude_integration
        self.storage = storage

    async def get_active_context(self, user_id: int) -> Optional[Dict[str, Any]]:
        """Get user's active MCP context."""
        try:
            async with self.storage.db_manager.get_connection() as conn:
                cursor = await conn.execute("""
                    SELECT ac.selected_server, ac.context_settings, ac.selected_at,
                           s.server_type, s.status, t.display_name
                    FROM user_active_context ac
                    LEFT JOIN user_mcp_servers s ON ac.user_id = s.user_id 
                                                 AND ac.selected_server = s.server_name
                    LEFT JOIN mcp_server_templates t ON s.server_type = t.server_type
                    WHERE ac.user_id = %s
                """, (user_id,))

                row = await cursor.fetchone()
                if row:
                    context = dict(row)
                    if context['context_settings']:
                        context['context_settings'] = json.loads(context['context_settings'])
                    return context

                return None

        except Exception as e:
            logger.error("Failed to get active context", user_id=user_id, error=str(e))
            return None

    async def set_active_context(self, user_id: int, server_name: str, 
                               context_settings: Optional[Dict[str, Any]] = None) -> bool:
        """Set user's active MCP context."""
        try:
            # Verify server exists and is enabled
            servers = await self.mcp_manager.get_user_servers(user_id)
            server = next((s for s in servers if s['server_name'] == server_name), None)

            if not server:
                raise MCPServerNotFoundError(f"Server '{server_name}' not found")

            if not server['is_enabled']:
                raise MCPContextError(f"Server '{server_name}' is disabled")

            # Set active context
            async with self.storage.db_manager.get_connection() as conn:
                await conn.execute("""
                    INSERT INTO user_active_context (user_id, selected_server, context_settings)
                    VALUES (%s, %s, %s)
                    ON CONFLICT (user_id) 
                    DO UPDATE SET 
                        selected_server = EXCLUDED.selected_server,
                        context_settings = EXCLUDED.context_settings,
                        selected_at = CURRENT_TIMESTAMP
                """, (user_id, server_name, json.dumps(context_settings or {})))
                await conn.commit()

            logger.info("Active MCP context set", 
                       user_id=user_id, server_name=server_name)
            return True

        except Exception as e:
            logger.error("Failed to set active context", 
                        user_id=user_id, server_name=server_name, error=str(e))
            raise MCPContextError(f"Failed to set context: {str(e)}")

    async def clear_active_context(self, user_id: int) -> bool:
        """Clear user's active MCP context."""
        try:
            async with self.storage.db_manager.get_connection() as conn:
                cursor = await conn.execute("""
                    DELETE FROM user_active_context WHERE user_id = %s
                """, (user_id,))
                await conn.commit()

                logger.info("Active MCP context cleared", 
                           user_id=user_id, affected_rows=cursor.rowcount)
                return cursor.rowcount > 0

        except Exception as e:
            logger.error("Failed to clear active context", user_id=user_id, error=str(e))
            return False

    async def execute_contextual_query(self, user_id: int, query: str,
                                     working_directory: Optional[str] = None,
                                     session_id: Optional[str] = None) -> ClaudeResponse:
        """Execute query with active MCP context."""
        start_time = time.time()

        # Get active context
        context = await self.get_active_context(user_id)
        if not context or not context['selected_server']:
            raise MCPContextError("No active MCP context set. Use /mcpselect first.")

        server_name = context['selected_server']

        try:
            # Check server status
            status = await self.mcp_manager.get_server_status(user_id, server_name)
            if status.status != "active":
                raise MCPContextError(f"Server '{server_name}' is not active (status: {status.status})")

            # Prepare contextual prompt
            contextual_prompt = self._prepare_contextual_prompt(query, context)

            # Execute with Claude CLI using the active MCP server
            response = await self.claude_integration.run_command_with_mcp(
                prompt=contextual_prompt,
                working_directory=working_directory,
                user_id=user_id,
                session_id=session_id,
                mcp_server=server_name
            )

            # Log successful usage
            response_time = int((time.time() - start_time) * 1000)
            await self.mcp_manager.log_usage(
                user_id=user_id,
                server_name=server_name,
                query=query,
                success=True,
                response_time=response_time,
                cost=response.cost,
                session_id=response.session_id
            )

            return response

        except Exception as e:
            # Log failed usage
            response_time = int((time.time() - start_time) * 1000)
            await self.mcp_manager.log_usage(
                user_id=user_id,
                server_name=server_name,
                query=query,
                success=False,
                response_time=response_time,
                error_message=str(e),
                session_id=session_id
            )

            logger.error("MCP contextual query failed", 
                        user_id=user_id, server_name=server_name, 
                        query=query[:100], error=str(e))
            raise

    def _prepare_contextual_prompt(self, query: str, context: Dict[str, Any]) -> str:
        """Prepare prompt with MCP context information."""
        server_name = context['selected_server']
        server_type = context.get('server_type', 'unknown')
        display_name = context.get('display_name', server_name)

        # Base contextual prompt
        contextual_prompt = f"""You have access to {display_name} ({server_type}) MCP server tools.

User Query: {query}

Please use the appropriate MCP tools from the {server_name} server to answer this query. 
Be specific and provide detailed results when possible."""

        # Add server-specific context hints
        if server_type == 'github':
            contextual_prompt += "\n\nFor GitHub queries, you can access repositories, issues, pull requests, commits, and other GitHub resources."
        elif server_type == 'filesystem':
            contextual_prompt += "\n\nFor filesystem queries, you can read, write, and manage files in the allowed directories."
        elif server_type in ['postgres', 'sqlite']:
            contextual_prompt += "\n\nFor database queries, you can execute SELECT statements and analyze data. Be careful with data modifications."
        elif server_type == 'git':
            contextual_prompt += "\n\nFor git queries, you can check repository status, history, branches, and perform git operations."
        elif server_type == 'playwright':
            contextual_prompt += "\n\nFor web automation queries, you can browse websites, extract data, and interact with web pages."

        return contextual_prompt

    async def get_context_suggestions(self, user_id: int, query: str) -> List[str]:
        """Get context-aware suggestions based on query and available servers."""
        try:
            # Get user's enabled servers
            servers = await self.mcp_manager.get_user_servers(user_id)
            enabled_servers = [s for s in servers if s['is_enabled']]

            if not enabled_servers:
                return ["ÐÐµÐ¼Ð°Ñ” Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¸Ñ… MCP ÑÐµÑ€Ð²ÐµÑ€Ñ–Ð². Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /mcpadd Ð´Ð»Ñ Ð´Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ."]

            suggestions = []
            query_lower = query.lower()

            # Suggest relevant servers based on query content
            for server in enabled_servers:
                server_type = server['server_type']
                server_name = server['server_name']

                if server_type == 'github' and any(word in query_lower for word in 
                    ['github', 'repo', 'repository', 'pull request', 'issue', 'commit']):
                    suggestions.append(f"Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ñ‚Ð¸ {server_name} (GitHub) Ð´Ð»Ñ Ñ†ÑŒÐ¾Ð³Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ")

                elif server_type == 'filesystem' and any(word in query_lower for word in
                    ['file', 'directory', 'read', 'write', 'save', 'Ñ„Ð°Ð¹Ð»', 'Ð¿Ð°Ð¿ÐºÐ°']):
                    suggestions.append(f"Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ñ‚Ð¸ {server_name} (File System) Ð´Ð»Ñ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸ Ð· Ñ„Ð°Ð¹Ð»Ð°Ð¼Ð¸")

                elif server_type in ['postgres', 'sqlite'] and any(word in query_lower for word in
                    ['database', 'query', 'select', 'sql', 'table', 'Ð±Ð´', 'Ð±Ð°Ð·Ð° Ð´Ð°Ð½Ð¸Ñ…']):
                    suggestions.append(f"Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ñ‚Ð¸ {server_name} (Database) Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð² Ð´Ð¾ Ð‘Ð”")

                elif server_type == 'git' and any(word in query_lower for word in
                    ['git', 'branch', 'merge', 'commit', 'status']):
                    suggestions.append(f"Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ñ‚Ð¸ {server_name} (Git) Ð´Ð»Ñ git Ð¾Ð¿ÐµÑ€Ð°Ñ†Ñ–Ð¹")

                elif server_type == 'playwright' and any(word in query_lower for word in
                    ['web', 'browser', 'scrape', 'webpage', 'site', 'ÑÐ°Ð¹Ñ‚']):
                    suggestions.append(f"Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ñ‚Ð¸ {server_name} (Web Automation) Ð´Ð»Ñ Ð²ÐµÐ±-Ð·Ð°Ð´Ð°Ñ‡")

            # If no specific suggestions, show general options
            if not suggestions:
                for server in enabled_servers[:3]:  # Show top 3 servers
                    suggestions.append(f"Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ²Ð°Ñ‚Ð¸ Ð· {server['server_name']} ({server.get('display_name', server['server_type'])})")

            return suggestions

        except Exception as e:
            logger.error("Failed to get context suggestions", user_id=user_id, error=str(e))
            return ["ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð½Ñ– Ð¿Ñ€Ð¾Ð¿Ð¾Ð·Ð¸Ñ†Ñ–Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ"]

    async def get_context_summary(self, user_id: int) -> Dict[str, Any]:
        """Get summary of user's MCP context and usage."""
        try:
            # Get active context
            active_context = await self.get_active_context(user_id)

            # Get all user servers
            servers = await self.mcp_manager.get_user_servers(user_id)

            # Get usage stats
            usage_stats = await self.mcp_manager.get_usage_stats(user_id, days=7)

            return {
                "active_context": active_context,
                "total_servers": len(servers),
                "enabled_servers": len([s for s in servers if s['is_enabled']]),
                "server_types": list(set(s['server_type'] for s in servers)),
                "recent_usage": usage_stats
            }

        except Exception as e:
            logger.error("Failed to get context summary", user_id=user_id, error=str(e))
            return {}

```

### mcp/__init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 935 Ð±Ð°Ð¹Ñ‚

```python
"""MCP (Model Context Protocol) Management Module.

This module provides comprehensive MCP server management capabilities for the Telegram bot,
including server configuration, context handling, and Claude CLI integration.

Components:
- MCPManager: Core server management
- MCPContextHandler: Context selection and query execution  
- ServerConfigRegistry: Predefined server templates
- Exception handling and validation
"""

from .context_handler import MCPContextHandler
from .exceptions import (
    MCPContextError,
    MCPError,
    MCPServerNotFoundError,
    MCPValidationError,
)
from .manager import MCPManager, MCPServerConfig, MCPServerStatus
from .server_configs import server_config_registry

__all__ = [
    "MCPManager",
    "MCPContextHandler", 
    "MCPServerConfig",
    "MCPServerStatus",
    "server_config_registry",
    "MCPError",
    "MCPValidationError",
    "MCPServerNotFoundError", 
    "MCPContextError",
]

```

### mcp/manager.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 20,120 Ð±Ð°Ð¹Ñ‚

```python
"""MCP Server Management System.

Core component for managing Model Context Protocol servers in the Telegram bot.
Handles server configuration, status monitoring, and Claude CLI integration.
"""

import asyncio
import json
import os
import subprocess
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import structlog
from pydantic import BaseModel, Field

from ..config.settings import Settings
from ..storage.facade import Storage
from .exceptions import MCPError, MCPServerNotFoundError, MCPValidationError

logger = structlog.get_logger()


class MCPServerConfig(BaseModel):
    """MCP server configuration model."""

    name: str
    server_type: str
    command: str
    args: List[str] = Field(default_factory=list)
    env: Dict[str, str] = Field(default_factory=dict)
    config: Dict[str, Any] = Field(default_factory=dict)
    is_enabled: bool = True


class MCPServerStatus(BaseModel):
    """MCP server status model."""

    name: str
    status: str  # inactive, active, error, connecting
    last_check: Optional[datetime] = None
    error_message: Optional[str] = None
    response_time: Optional[int] = None


class MCPManager:
    """Main MCP server management class."""

    def __init__(self, settings: Settings, storage: Storage):
        """Initialize MCP manager."""
        self.settings = settings
        self.storage = storage
        self.claude_cli_path = settings.claude_cli_path or "claude"
        self._status_cache: Dict[str, MCPServerStatus] = {}
        self._cache_timeout = 300  # 5 minutes

    async def get_server_templates(self) -> List[Dict[str, Any]]:
        """Get available MCP server templates."""
        try:
            async with self.storage.db_manager.get_connection() as conn:
                cursor = await conn.execute("""
                    SELECT server_type, display_name, description, config_schema, 
                           setup_instructions, command_template, args_template, env_template
                    FROM mcp_server_templates 
                    WHERE is_active = true
                    ORDER BY display_name
                """)
                rows = await cursor.fetchall()

                templates = []
                for row in rows:
                    template = dict(row)
                    # Parse JSON fields
                    for field in ['config_schema', 'args_template', 'env_template']:
                        if template[field]:
                            template[field] = json.loads(template[field])
                    templates.append(template)

                return templates

        except Exception as e:
            logger.error("Failed to get server templates", error=str(e))
            return []

    async def get_user_servers(self, user_id: int) -> List[Dict[str, Any]]:
        """Get user's MCP servers."""
        try:
            async with self.storage.db_manager.get_connection() as conn:
                cursor = await conn.execute("""
                    SELECT s.*, t.display_name, t.description
                    FROM user_mcp_servers s
                    LEFT JOIN mcp_server_templates t ON s.server_type = t.server_type
                    WHERE s.user_id = %s
                    ORDER BY s.server_name
                """, (user_id,))
                rows = await cursor.fetchall()

                servers = []
                for row in rows:
                    server = dict(row)
                    # Parse JSON fields
                    for field in ['server_args', 'server_env', 'config']:
                        if server[field]:
                            server[field] = json.loads(server[field])
                    servers.append(server)

                return servers

        except Exception as e:
            logger.error("Failed to get user servers", user_id=user_id, error=str(e))
            return []

    async def add_server(self, user_id: int, config: MCPServerConfig) -> bool:
        """Add a new MCP server for user."""
        try:
            # Validate server name uniqueness
            existing_servers = await self.get_user_servers(user_id)
            if any(s['server_name'] == config.name for s in existing_servers):
                raise MCPValidationError(f"Server '{config.name}' already exists")

            # Insert server into database
            async with self.storage.db_manager.get_connection() as conn:
                await conn.execute("""
                    INSERT INTO user_mcp_servers 
                    (user_id, server_name, server_type, server_command, server_args, 
                     server_env, config, is_enabled)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    user_id,
                    config.name,
                    config.server_type,
                    config.command,
                    json.dumps(config.args),
                    json.dumps(config.env),
                    json.dumps(config.config),
                    config.is_enabled
                ))
                await conn.commit()

            # Add server to Claude CLI
            if config.is_enabled:
                success = await self._add_to_claude_cli(user_id, config)
                if not success:
                    logger.warning("Server added to database but failed to add to Claude CLI", 
                                 server_name=config.name)

            logger.info("MCP server added successfully", 
                       user_id=user_id, server_name=config.name)
            return True

        except Exception as e:
            logger.error("Failed to add MCP server", 
                        user_id=user_id, server_name=config.name, error=str(e))
            raise MCPError(f"Failed to add server: {str(e)}")

    async def remove_server(self, user_id: int, server_name: str) -> bool:
        """Remove an MCP server."""
        try:
            # Remove from Claude CLI first
            await self._remove_from_claude_cli(user_id, server_name)

            # Remove from database
            async with self.storage.db_manager.get_connection() as conn:
                cursor = await conn.execute("""
                    DELETE FROM user_mcp_servers 
                    WHERE user_id = %s AND server_name = %s
                """, (user_id, server_name))

                if cursor.rowcount == 0:
                    raise MCPServerNotFoundError(f"Server '{server_name}' not found")

                await conn.commit()

            # Clear cache
            cache_key = f"{user_id}:{server_name}"
            self._status_cache.pop(cache_key, None)

            logger.info("MCP server removed successfully", 
                       user_id=user_id, server_name=server_name)
            return True

        except Exception as e:
            logger.error("Failed to remove MCP server", 
                        user_id=user_id, server_name=server_name, error=str(e))
            raise MCPError(f"Failed to remove server: {str(e)}")

    async def enable_server(self, user_id: int, server_name: str) -> bool:
        """Enable an MCP server."""
        try:
            # Get server config
            servers = await self.get_user_servers(user_id)
            server = next((s for s in servers if s['server_name'] == server_name), None)
            if not server:
                raise MCPServerNotFoundError(f"Server '{server_name}' not found")

            # Create config object
            config = MCPServerConfig(
                name=server['server_name'],
                server_type=server['server_type'],
                command=server['server_command'],
                args=server['server_args'] or [],
                env=server['server_env'] or {},
                config=server['config'] or {}
            )

            # Add to Claude CLI
            success = await self._add_to_claude_cli(user_id, config)
            if success:
                # Update database
                async with self.storage.db_manager.get_connection() as conn:
                    await conn.execute("""
                        UPDATE user_mcp_servers 
                        SET is_enabled = true, status = 'active', updated_at = CURRENT_TIMESTAMP
                        WHERE user_id = %s AND server_name = %s
                    """, (user_id, server_name))
                    await conn.commit()

                logger.info("MCP server enabled successfully", 
                           user_id=user_id, server_name=server_name)
                return True
            else:
                raise MCPError("Failed to add server to Claude CLI")

        except Exception as e:
            logger.error("Failed to enable MCP server", 
                        user_id=user_id, server_name=server_name, error=str(e))
            raise MCPError(f"Failed to enable server: {str(e)}")

    async def disable_server(self, user_id: int, server_name: str) -> bool:
        """Disable an MCP server."""
        try:
            # Remove from Claude CLI
            await self._remove_from_claude_cli(user_id, server_name)

            # Update database
            async with self.storage.db_manager.get_connection() as conn:
                cursor = await conn.execute("""
                    UPDATE user_mcp_servers 
                    SET is_enabled = false, status = 'inactive', updated_at = CURRENT_TIMESTAMP
                    WHERE user_id = %s AND server_name = %s
                """, (user_id, server_name))

                if cursor.rowcount == 0:
                    raise MCPServerNotFoundError(f"Server '{server_name}' not found")

                await conn.commit()

            # Clear cache
            cache_key = f"{user_id}:{server_name}"
            self._status_cache.pop(cache_key, None)

            logger.info("MCP server disabled successfully", 
                       user_id=user_id, server_name=server_name)
            return True

        except Exception as e:
            logger.error("Failed to disable MCP server", 
                        user_id=user_id, server_name=server_name, error=str(e))
            raise MCPError(f"Failed to disable server: {str(e)}")

    async def get_server_status(self, user_id: int, server_name: str) -> MCPServerStatus:
        """Get status of an MCP server."""
        cache_key = f"{user_id}:{server_name}"

        # Check cache
        if cache_key in self._status_cache:
            cached_status = self._status_cache[cache_key]
            if cached_status.last_check and \
               (datetime.utcnow() - cached_status.last_check).seconds < self._cache_timeout:
                return cached_status

        # Check actual status
        status = await self._check_server_status(user_id, server_name)

        # Update cache
        self._status_cache[cache_key] = status

        # Update database
        try:
            async with self.storage.db_manager.get_connection() as conn:
                await conn.execute("""
                    UPDATE user_mcp_servers 
                    SET status = %s, last_status_check = CURRENT_TIMESTAMP, 
                        error_message = %s, updated_at = CURRENT_TIMESTAMP
                    WHERE user_id = %s AND server_name = %s
                """, (status.status, status.error_message, user_id, server_name))
                await conn.commit()
        except Exception as e:
            logger.error("Failed to update server status in database", error=str(e))

        return status

    async def _check_server_status(self, user_id: int, server_name: str) -> MCPServerStatus:
        """Check actual server status via Claude CLI."""
        try:
            start_time = time.time()

            # Use Claude CLI to list servers and check if ours is there
            result = await self._run_claude_command(user_id, ["mcp", "list"])

            response_time = int((time.time() - start_time) * 1000)

            if result.returncode == 0:
                # Parse output to check if our server is listed and active
                output = result.stdout.decode('utf-8', errors='ignore')

                # Simple check - look for server name in output
                if server_name in output and "active" in output.lower():
                    return MCPServerStatus(
                        name=server_name,
                        status="active",
                        last_check=datetime.utcnow(),
                        response_time=response_time
                    )
                else:
                    return MCPServerStatus(
                        name=server_name,
                        status="inactive",
                        last_check=datetime.utcnow(),
                        response_time=response_time
                    )
            else:
                error_msg = result.stderr.decode('utf-8', errors='ignore')
                return MCPServerStatus(
                    name=server_name,
                    status="error",
                    last_check=datetime.utcnow(),
                    error_message=error_msg,
                    response_time=response_time
                )

        except Exception as e:
            return MCPServerStatus(
                name=server_name,
                status="error",
                last_check=datetime.utcnow(),
                error_message=str(e)
            )

    async def _add_to_claude_cli(self, user_id: int, config: MCPServerConfig) -> bool:
        """Add server to Claude CLI configuration."""
        try:
            # Build Claude MCP add command
            cmd = ["mcp", "add", config.name]

            # Add environment variables
            for key, value in config.env.items():
                cmd.extend(["--env", f"{key}={value}"])

            # Add command separator
            cmd.append("--")

            # Add server command and args
            cmd.append(config.command)
            cmd.extend(config.args)

            result = await self._run_claude_command(user_id, cmd)

            if result.returncode == 0:
                logger.info("Successfully added server to Claude CLI", 
                           server_name=config.name, user_id=user_id)
                return True
            else:
                error_msg = result.stderr.decode('utf-8', errors='ignore')
                logger.error("Failed to add server to Claude CLI", 
                           server_name=config.name, user_id=user_id, error=error_msg)
                return False

        except Exception as e:
            logger.error("Exception adding server to Claude CLI", 
                        server_name=config.name, user_id=user_id, error=str(e))
            return False

    async def _remove_from_claude_cli(self, user_id: int, server_name: str) -> bool:
        """Remove server from Claude CLI configuration."""
        try:
            cmd = ["mcp", "remove", server_name]
            result = await self._run_claude_command(user_id, cmd)

            if result.returncode == 0:
                logger.info("Successfully removed server from Claude CLI", 
                           server_name=server_name, user_id=user_id)
                return True
            else:
                error_msg = result.stderr.decode('utf-8', errors='ignore')
                logger.warning("Failed to remove server from Claude CLI", 
                             server_name=server_name, user_id=user_id, error=error_msg)
                return False

        except Exception as e:
            logger.error("Exception removing server from Claude CLI", 
                        server_name=server_name, user_id=user_id, error=str(e))
            return False

    async def _run_claude_command(self, user_id: int, cmd: List[str]) -> subprocess.CompletedProcess:
        """Run Claude CLI command with user-specific environment."""
        try:
            # Prepare environment
            env = os.environ.copy()

            # Add user-specific paths or settings if needed
            # For now, we'll use the standard Claude CLI path

            # Build full command
            full_cmd = [self.claude_cli_path] + cmd

            # Run command with timeout
            result = await asyncio.wait_for(
                asyncio.create_subprocess_exec(
                    *full_cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE,
                    env=env
                ),
                timeout=30.0
            )

            stdout, stderr = await result.communicate()

            return subprocess.CompletedProcess(
                args=full_cmd,
                returncode=result.returncode,
                stdout=stdout,
                stderr=stderr
            )

        except asyncio.TimeoutError:
            logger.error("Claude CLI command timed out", cmd=cmd, user_id=user_id)
            raise MCPError("Command timed out")
        except Exception as e:
            logger.error("Failed to run Claude CLI command", 
                        cmd=cmd, user_id=user_id, error=str(e))
            raise MCPError(f"Command failed: {str(e)}")

    async def log_usage(self, user_id: int, server_name: str, query: str, 
                       success: bool, response_time: Optional[int] = None,
                       error_message: Optional[str] = None, cost: float = 0.0,
                       session_id: Optional[str] = None) -> None:
        """Log MCP server usage."""
        try:
            async with self.storage.db_manager.get_connection() as conn:
                await conn.execute("""
                    INSERT INTO mcp_usage_log 
                    (user_id, server_name, query, response_time, success, 
                     error_message, cost, session_id)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                """, (user_id, server_name, query, response_time, success, 
                     error_message, cost, session_id))
                await conn.commit()

        except Exception as e:
            logger.error("Failed to log MCP usage", error=str(e))

    async def get_usage_stats(self, user_id: int, days: int = 30) -> Dict[str, Any]:
        """Get usage statistics for user."""
        try:
            async with self.storage.db_manager.get_connection() as conn:
                # Total usage stats
                cursor = await conn.execute("""
                    SELECT 
                        COUNT(*) as total_queries,
                        COUNT(DISTINCT server_name) as servers_used,
                        SUM(CASE WHEN success THEN 1 ELSE 0 END) as successful_queries,
                        AVG(response_time) as avg_response_time,
                        SUM(cost) as total_cost
                    FROM mcp_usage_log
                    WHERE user_id = %s 
                      AND created_at >= CURRENT_TIMESTAMP - INTERVAL '%s days'
                """, (user_id, days))

                stats = dict(await cursor.fetchone())

                # Server-specific stats
                cursor = await conn.execute("""
                    SELECT 
                        server_name,
                        COUNT(*) as query_count,
                        AVG(response_time) as avg_response_time,
                        SUM(cost) as total_cost
                    FROM mcp_usage_log
                    WHERE user_id = %s 
                      AND created_at >= CURRENT_TIMESTAMP - INTERVAL '%s days'
                    GROUP BY server_name
                    ORDER BY query_count DESC
                """, (user_id, days))

                server_stats = [dict(row) for row in await cursor.fetchall()]

                return {
                    "overall": stats,
                    "by_server": server_stats,
                    "period_days": days
                }

        except Exception as e:
            logger.error("Failed to get usage stats", user_id=user_id, error=str(e))
            return {"overall": {}, "by_server": [], "period_days": days}

```

### mcp/server_configs.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 18,508 Ð±Ð°Ð¹Ñ‚

```python
"""MCP Server Configuration Templates.

Predefined configurations for popular MCP servers with setup wizards.
"""

import json
from typing import Any, Dict, List, Optional, Tuple

import structlog

from .exceptions import MCPValidationError

logger = structlog.get_logger()


class ServerConfigTemplate:
    """Base class for MCP server configuration templates."""

    def __init__(self, server_type: str, display_name: str, description: str):
        self.server_type = server_type
        self.display_name = display_name
        self.description = description

    def get_setup_steps(self) -> List[Dict[str, Any]]:
        """Get interactive setup steps."""
        raise NotImplementedError

    def validate_config(self, config: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
        """Validate configuration parameters."""
        raise NotImplementedError

    def build_server_config(self, user_inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Build final server configuration from user inputs."""
        raise NotImplementedError


class GitHubServerTemplate(ServerConfigTemplate):
    """GitHub MCP server template."""

    def __init__(self):
        super().__init__(
            server_type="github",
            display_name="ðŸ™ GitHub Integration",
            description="Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ð´Ð¾ GitHub Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ñ—Ð², issues, pull requests Ñ‚Ð° Ñ–Ð½ÑˆÐ¾Ð³Ð¾"
        )

    def get_setup_steps(self) -> List[Dict[str, Any]]:
        """Get GitHub setup steps."""
        return [
            {
                "step": 1,
                "title": "GitHub Personal Access Token",
                "description": "Ð’Ð°Ð¼ Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±ÐµÐ½ GitHub Personal Access Token Ð´Ð»Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ñƒ Ð´Ð¾ API",
                "input_type": "password",
                "input_key": "github_token",
                "placeholder": "ghp_xxxxxxxxxxxxxxxxxx",
                "validation": "required",
                "help_text": (
                    "Ð¯Ðº Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ñ‚Ð¾ÐºÐµÐ½:\n"
                    "1. ÐŸÐµÑ€ÐµÐ¹Ð´Ñ–Ñ‚ÑŒ Ð´Ð¾ GitHub.com\n"
                    "2. Settings â†’ Developer settings â†’ Personal access tokens â†’ Tokens (classic)\n"
                    "3. Generate new token (classic)\n"
                    "4. Ð’Ð¸Ð±ÐµÑ€Ñ–Ñ‚ÑŒ scopes: repo, read:user\n"
                    "5. Ð¡ÐºÐ¾Ð¿Ñ–ÑŽÐ¹Ñ‚Ðµ Ð·Ð³ÐµÐ½ÐµÑ€Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ‚Ð¾ÐºÐµÐ½"
                )
            },
            {
                "step": 2,
                "title": "ÐÐ°Ð·Ð²Ð° ÑÐµÑ€Ð²ÐµÑ€Ð°",
                "description": "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ð´Ð»Ñ Ñ†ÑŒÐ¾Ð³Ð¾ MCP ÑÐµÑ€Ð²ÐµÑ€Ð°",
                "input_type": "text",
                "input_key": "server_name",
                "placeholder": "github-main",
                "validation": "required",
                "default": "github"
            }
        ]

    def validate_config(self, config: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
        """Validate GitHub configuration."""
        if not config.get("github_token"):
            return False, "GitHub Ñ‚Ð¾ÐºÐµÐ½ Ñ” Ð¾Ð±Ð¾Ð²'ÑÐ·ÐºÐ¾Ð²Ð¸Ð¼"

        token = config["github_token"].strip()
        if not token.startswith("ghp_") and not token.startswith("github_pat_") and not token.startswith("gho_"):
            return False, "ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ GitHub Ñ‚Ð¾ÐºÐµÐ½Ñƒ"

        if len(token) < 20:
            return False, "GitHub Ñ‚Ð¾ÐºÐµÐ½ Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹"

        return True, None

    def build_server_config(self, user_inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Build GitHub server configuration."""
        return {
            "name": user_inputs.get("server_name", "github"),
            "server_type": "github",
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-github"],
            "env": {
                "GITHUB_PERSONAL_ACCESS_TOKEN": user_inputs["github_token"]
            },
            "config": {
                "github_token": user_inputs["github_token"]  # Store for reference
            }
        }


class FilesystemServerTemplate(ServerConfigTemplate):
    """Filesystem MCP server template."""

    def __init__(self):
        super().__init__(
            server_type="filesystem",
            display_name="ðŸ“ File System Access",
            description="Ð§Ð¸Ñ‚Ð°Ð½Ð½Ñ Ñ‚Ð° Ð·Ð°Ð¿Ð¸Ñ Ñ„Ð°Ð¹Ð»Ñ–Ð² Ñƒ Ð²ÐºÐ°Ð·Ð°Ð½Ð¸Ñ… Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑÑ…"
        )

    def get_setup_steps(self) -> List[Dict[str, Any]]:
        """Get filesystem setup steps."""
        return [
            {
                "step": 1,
                "title": "Ð”Ð¾Ð·Ð²Ð¾Ð»ÐµÐ½Ð° Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ",
                "description": "Ð’ÐºÐ°Ð¶Ñ–Ñ‚ÑŒ ÑˆÐ»ÑÑ… Ð´Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—, Ð´Ðµ Claude Ð¼Ð¾Ð¶Ðµ Ð¿Ñ€Ð°Ñ†ÑŽÐ²Ð°Ñ‚Ð¸ Ð· Ñ„Ð°Ð¹Ð»Ð°Ð¼Ð¸",
                "input_type": "text",
                "input_key": "allowed_path",
                "placeholder": "/home/user/projects",
                "validation": "required",
                "help_text": (
                    "Ð’Ð°Ð¶Ð»Ð¸Ð²Ð¾:\n"
                    "â€¢ Ð’ÐºÐ°Ð¶Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ð½Ð¸Ð¹ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð¸Ð¹ ÑˆÐ»ÑÑ…\n"
                    "â€¢ ÐŸÐµÑ€ÐµÐºÐ¾Ð½Ð°Ð¹Ñ‚ÐµÑÑ, Ñ‰Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ Ñ–ÑÐ½ÑƒÑ”\n"
                    "â€¢ Claude Ð¼Ð°Ñ‚Ð¸Ð¼Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ñ‚Ñ–Ð»ÑŒÐºÐ¸ Ð´Ð¾ Ñ†Ñ–Ñ”Ñ— Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—\n"
                    "â€¢ ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´: /home/username/my-project"
                )
            },
            {
                "step": 2,
                "title": "ÐÐ°Ð·Ð²Ð° ÑÐµÑ€Ð²ÐµÑ€Ð°",
                "description": "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ð´Ð»Ñ Ñ†ÑŒÐ¾Ð³Ð¾ MCP ÑÐµÑ€Ð²ÐµÑ€Ð°",
                "input_type": "text",
                "input_key": "server_name",
                "placeholder": "filesystem-project",
                "validation": "required",
                "default": "filesystem"
            }
        ]

    def validate_config(self, config: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
        """Validate filesystem configuration."""
        allowed_path = config.get("allowed_path", "").strip()
        if not allowed_path:
            return False, "Ð¨Ð»ÑÑ… Ð´Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ— Ñ” Ð¾Ð±Ð¾Ð²'ÑÐ·ÐºÐ¾Ð²Ð¸Ð¼"

        if not allowed_path.startswith("/"):
            return False, "Ð¨Ð»ÑÑ… Ð¿Ð¾Ð²Ð¸Ð½ÐµÐ½ Ð±ÑƒÑ‚Ð¸ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð¸Ð¼ (Ð¿Ð¾Ñ‡Ð¸Ð½Ð°Ñ‚Ð¸ÑÑ Ð· /)"

        # Basic path validation
        if ".." in allowed_path:
            return False, "Ð¨Ð»ÑÑ… Ð½Ðµ Ð¼Ð¾Ð¶Ðµ Ð¼Ñ–ÑÑ‚Ð¸Ñ‚Ð¸ '..' Ð´Ð»Ñ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸"

        return True, None

    def build_server_config(self, user_inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Build filesystem server configuration."""
        return {
            "name": user_inputs.get("server_name", "filesystem"),
            "server_type": "filesystem",
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-filesystem", user_inputs["allowed_path"]],
            "env": {},
            "config": {
                "allowed_path": user_inputs["allowed_path"]
            }
        }


class PostgresServerTemplate(ServerConfigTemplate):
    """PostgreSQL MCP server template."""

    def __init__(self):
        super().__init__(
            server_type="postgres",
            display_name="ðŸ˜ PostgreSQL Database",
            description="Ð—Ð°Ð¿Ð¸Ñ‚Ð¸ Ñ‚Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ PostgreSQL Ð±Ð°Ð·Ð°Ð¼Ð¸ Ð´Ð°Ð½Ð¸Ñ…"
        )

    def get_setup_steps(self) -> List[Dict[str, Any]]:
        """Get PostgreSQL setup steps."""
        return [
            {
                "step": 1,
                "title": "Connection String",
                "description": "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ñ€ÑÐ´Ð¾Ðº Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ Ð´Ð¾ PostgreSQL Ð±Ð°Ð·Ð¸ Ð´Ð°Ð½Ð¸Ñ…",
                "input_type": "password",
                "input_key": "connection_string",
                "placeholder": "postgresql://user:password@localhost:5432/dbname",
                "validation": "required",
                "help_text": (
                    "Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚: postgresql://username:password@host:port/database\n\n"
                    "ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸:\n"
                    "â€¢ postgresql://user:pass@localhost:5432/mydb\n"
                    "â€¢ postgresql://user:pass@host.com:5432/prod_db\n\n"
                    "ÐŸÐµÑ€ÐµÐºÐ¾Ð½Ð°Ð¹Ñ‚ÐµÑÑ, Ñ‰Ð¾ Ð±Ð°Ð·Ð° Ð´Ð°Ð½Ð¸Ñ… Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð° Ñ‚Ð° ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡ Ð¼Ð°Ñ” Ð½ÐµÐ¾Ð±Ñ…Ñ–Ð´Ð½Ñ– Ð¿Ñ€Ð°Ð²Ð°"
                )
            },
            {
                "step": 2,
                "title": "ÐÐ°Ð·Ð²Ð° ÑÐµÑ€Ð²ÐµÑ€Ð°",
                "description": "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ð´Ð»Ñ Ñ†ÑŒÐ¾Ð³Ð¾ MCP ÑÐµÑ€Ð²ÐµÑ€Ð°",
                "input_type": "text",
                "input_key": "server_name",
                "placeholder": "postgres-main",
                "validation": "required",
                "default": "postgres"
            }
        ]

    def validate_config(self, config: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
        """Validate PostgreSQL configuration."""
        connection_string = config.get("connection_string", "").strip()
        if not connection_string:
            return False, "Connection string Ñ” Ð¾Ð±Ð¾Ð²'ÑÐ·ÐºÐ¾Ð²Ð¸Ð¼"

        if not connection_string.startswith("postgresql://"):
            return False, "Connection string Ð¿Ð¾Ð²Ð¸Ð½ÐµÐ½ Ð¿Ð¾Ñ‡Ð¸Ð½Ð°Ñ‚Ð¸ÑÑ Ð· postgresql://"

        # Basic format validation
        if "@" not in connection_string or "/" not in connection_string:
            return False, "ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ connection string"

        return True, None

    def build_server_config(self, user_inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Build PostgreSQL server configuration."""
        return {
            "name": user_inputs.get("server_name", "postgres"),
            "server_type": "postgres",
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-postgres", user_inputs["connection_string"]],
            "env": {},
            "config": {
                "connection_string": user_inputs["connection_string"]
            }
        }


class SQLiteServerTemplate(ServerConfigTemplate):
    """SQLite MCP server template."""

    def __init__(self):
        super().__init__(
            server_type="sqlite",
            display_name="ðŸ’¾ SQLite Database",
            description="Ð—Ð°Ð¿Ð¸Ñ‚Ð¸ Ñ‚Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ SQLite Ð±Ð°Ð·Ð°Ð¼Ð¸ Ð´Ð°Ð½Ð¸Ñ…"
        )

    def get_setup_steps(self) -> List[Dict[str, Any]]:
        """Get SQLite setup steps."""
        return [
            {
                "step": 1,
                "title": "Ð¨Ð»ÑÑ… Ð´Ð¾ Ð‘Ð” Ñ„Ð°Ð¹Ð»Ñƒ",
                "description": "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ð½Ð¸Ð¹ ÑˆÐ»ÑÑ… Ð´Ð¾ SQLite Ñ„Ð°Ð¹Ð»Ñƒ Ð±Ð°Ð·Ð¸ Ð´Ð°Ð½Ð¸Ñ…",
                "input_type": "text",
                "input_key": "database_path",
                "placeholder": "/path/to/database.db",
                "validation": "required",
                "help_text": (
                    "Ð’ÐºÐ°Ð¶Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ð½Ð¸Ð¹ ÑˆÐ»ÑÑ… Ð´Ð¾ .db Ñ„Ð°Ð¹Ð»Ñƒ:\n"
                    "â€¢ /home/user/data/app.db\n"
                    "â€¢ /var/lib/myapp/database.sqlite\n\n"
                    "Ð¤Ð°Ð¹Ð» Ð¿Ð¾Ð²Ð¸Ð½ÐµÐ½ Ñ–ÑÐ½ÑƒÐ²Ð°Ñ‚Ð¸ Ñ‚Ð° Ð±ÑƒÑ‚Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¼ Ð´Ð»Ñ Ñ‡Ð¸Ñ‚Ð°Ð½Ð½Ñ"
                )
            },
            {
                "step": 2,
                "title": "ÐÐ°Ð·Ð²Ð° ÑÐµÑ€Ð²ÐµÑ€Ð°",
                "description": "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ð´Ð»Ñ Ñ†ÑŒÐ¾Ð³Ð¾ MCP ÑÐµÑ€Ð²ÐµÑ€Ð°",
                "input_type": "text",
                "input_key": "server_name",
                "placeholder": "sqlite-app",
                "validation": "required",
                "default": "sqlite"
            }
        ]

    def validate_config(self, config: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
        """Validate SQLite configuration."""
        database_path = config.get("database_path", "").strip()
        if not database_path:
            return False, "Ð¨Ð»ÑÑ… Ð´Ð¾ Ð±Ð°Ð·Ð¸ Ð´Ð°Ð½Ð¸Ñ… Ñ” Ð¾Ð±Ð¾Ð²'ÑÐ·ÐºÐ¾Ð²Ð¸Ð¼"

        if not database_path.startswith("/"):
            return False, "Ð¨Ð»ÑÑ… Ð¿Ð¾Ð²Ð¸Ð½ÐµÐ½ Ð±ÑƒÑ‚Ð¸ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð¸Ð¼ (Ð¿Ð¾Ñ‡Ð¸Ð½Ð°Ñ‚Ð¸ÑÑ Ð· /)"

        if not (database_path.endswith(".db") or database_path.endswith(".sqlite") or 
                database_path.endswith(".sqlite3")):
            return False, "Ð¤Ð°Ð¹Ð» Ð¿Ð¾Ð²Ð¸Ð½ÐµÐ½ Ð¼Ð°Ñ‚Ð¸ Ñ€Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ .db, .sqlite Ð°Ð±Ð¾ .sqlite3"

        return True, None

    def build_server_config(self, user_inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Build SQLite server configuration."""
        return {
            "name": user_inputs.get("server_name", "sqlite"),
            "server_type": "sqlite",
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-sqlite", user_inputs["database_path"]],
            "env": {},
            "config": {
                "database_path": user_inputs["database_path"]
            }
        }


class GitServerTemplate(ServerConfigTemplate):
    """Git MCP server template."""

    def __init__(self):
        super().__init__(
            server_type="git",
            display_name="ðŸ”§ Git Repository Tools",
            description="Git Ð¾Ð¿ÐµÑ€Ð°Ñ†Ñ–Ñ— Ñ‚Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–ÑÐ¼Ð¸"
        )

    def get_setup_steps(self) -> List[Dict[str, Any]]:
        """Get Git setup steps."""
        return [
            {
                "step": 1,
                "title": "Ð¨Ð»ÑÑ… Ð´Ð¾ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–ÑŽ",
                "description": "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ ÑˆÐ»ÑÑ… Ð´Ð¾ git Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–ÑŽ",
                "input_type": "text",
                "input_key": "repo_path",
                "placeholder": "/path/to/git/repo",
                "validation": "required",
                "help_text": (
                    "Ð’ÐºÐ°Ð¶Ñ–Ñ‚ÑŒ ÑˆÐ»ÑÑ… Ð´Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ— Ð· git Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ñ”Ð¼:\n"
                    "â€¢ /home/user/my-project\n"
                    "â€¢ /var/www/website\n\n"
                    "Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ Ð¿Ð¾Ð²Ð¸Ð½Ð½Ð° Ð¼Ñ–ÑÑ‚Ð¸Ñ‚Ð¸ .git Ð¿Ð°Ð¿ÐºÑƒ"
                )
            },
            {
                "step": 2,
                "title": "ÐÐ°Ð·Ð²Ð° ÑÐµÑ€Ð²ÐµÑ€Ð°",
                "description": "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ð´Ð»Ñ Ñ†ÑŒÐ¾Ð³Ð¾ MCP ÑÐµÑ€Ð²ÐµÑ€Ð°",
                "input_type": "text",
                "input_key": "server_name",
                "placeholder": "git-project",
                "validation": "required",
                "default": "git"
            }
        ]

    def validate_config(self, config: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
        """Validate Git configuration."""
        repo_path = config.get("repo_path", "").strip()
        if not repo_path:
            return False, "Ð¨Ð»ÑÑ… Ð´Ð¾ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–ÑŽ Ñ” Ð¾Ð±Ð¾Ð²'ÑÐ·ÐºÐ¾Ð²Ð¸Ð¼"

        if not repo_path.startswith("/"):
            return False, "Ð¨Ð»ÑÑ… Ð¿Ð¾Ð²Ð¸Ð½ÐµÐ½ Ð±ÑƒÑ‚Ð¸ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð¸Ð¼ (Ð¿Ð¾Ñ‡Ð¸Ð½Ð°Ñ‚Ð¸ÑÑ Ð· /)"

        return True, None

    def build_server_config(self, user_inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Build Git server configuration."""
        return {
            "name": user_inputs.get("server_name", "git"),
            "server_type": "git",
            "command": "uvx",
            "args": ["mcp-server-git", "--repository", user_inputs["repo_path"]],
            "env": {},
            "config": {
                "repo_path": user_inputs["repo_path"]
            }
        }


class PlaywrightServerTemplate(ServerConfigTemplate):
    """Playwright MCP server template."""

    def __init__(self):
        super().__init__(
            server_type="playwright",
            display_name="ðŸŒ Web Automation",
            description="ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð° Ñ‚Ð° Ð²ÐµÐ±-ÑÐºÑ€Ð°Ð¿Ñ–Ð½Ð³"
        )

    def get_setup_steps(self) -> List[Dict[str, Any]]:
        """Get Playwright setup steps."""
        return [
            {
                "step": 1,
                "title": "ÐÐ°Ð·Ð²Ð° ÑÐµÑ€Ð²ÐµÑ€Ð°",
                "description": "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ð´Ð»Ñ Ñ†ÑŒÐ¾Ð³Ð¾ MCP ÑÐµÑ€Ð²ÐµÑ€Ð°",
                "input_type": "text",
                "input_key": "server_name",
                "placeholder": "playwright-web",
                "validation": "required",
                "default": "playwright",
                "help_text": (
                    "Playwright MCP ÑÐµÑ€Ð²ÐµÑ€ Ð½Ðµ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÑ” Ð´Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ð¾Ñ— ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ—.\n"
                    "Ð’Ñ–Ð½ Ð½Ð°Ð´Ð°Ñ” Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð° Ñ‚Ð° Ð²ÐµÐ±-ÑÐºÑ€Ð°Ð¿Ñ–Ð½Ð³Ñƒ."
                )
            }
        ]

    def validate_config(self, config: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
        """Validate Playwright configuration."""
        return True, None  # No special validation needed

    def build_server_config(self, user_inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Build Playwright server configuration."""
        return {
            "name": user_inputs.get("server_name", "playwright"),
            "server_type": "playwright",
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-playwright"],
            "env": {},
            "config": {}
        }


class ServerConfigRegistry:
    """Registry of available MCP server configuration templates."""

    def __init__(self):
        self.templates = {
            "github": GitHubServerTemplate(),
            "filesystem": FilesystemServerTemplate(),
            "postgres": PostgresServerTemplate(),
            "sqlite": SQLiteServerTemplate(),
            "git": GitServerTemplate(),
            "playwright": PlaywrightServerTemplate(),
        }

    def get_template(self, server_type: str) -> Optional[ServerConfigTemplate]:
        """Get template by server type."""
        return self.templates.get(server_type)

    def get_all_templates(self) -> Dict[str, ServerConfigTemplate]:
        """Get all available templates."""
        return self.templates.copy()

    def get_template_list(self) -> List[Dict[str, str]]:
        """Get list of templates for display."""
        return [
            {
                "server_type": server_type,
                "display_name": template.display_name,
                "description": template.description
            }
            for server_type, template in self.templates.items()
        ]


# Global registry instance
server_config_registry = ServerConfigRegistry()

```

### config/__init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 390 Ð±Ð°Ð¹Ñ‚

```python
"""Configuration module."""

from .environments import DevelopmentConfig, ProductionConfig, TestingConfig
from .features import FeatureFlags
from .loader import create_test_config, load_config
from .settings import Settings

__all__ = [
    "Settings",
    "load_config",
    "create_test_config",
    "DevelopmentConfig",
    "ProductionConfig",
    "TestingConfig",
    "FeatureFlags",
]

```

### config/loader.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 6,316 Ð±Ð°Ð¹Ñ‚

```python
"""Configuration loading with environment detection."""

import os
from pathlib import Path
from typing import Any, Optional

import structlog
from dotenv import load_dotenv

from src.exceptions import ConfigurationError, InvalidConfigError

from .environments import DevelopmentConfig, ProductionConfig, TestingConfig
from .settings import Settings

logger = structlog.get_logger()


def load_config(
    env: Optional[str] = None, config_file: Optional[Path] = None
) -> Settings:
    """Load configuration based on environment.

    Args:
        env: Environment name (development, testing, production)
        config_file: Optional path to configuration file

    Returns:
        Configured Settings instance

    Raises:
        ConfigurationError: If configuration is invalid
    """
    # Load .env file explicitly
    env_file = config_file or Path(".env")
    if env_file.exists():
        logger.info("Loading .env file", path=str(env_file))
        load_dotenv(env_file)
    else:
        logger.warning("No .env file found", path=str(env_file))

    # Determine environment
    env = env or os.getenv("ENVIRONMENT", "development")
    logger.info("Loading configuration", environment=env)

    try:
        # Debug: Log key environment variables before Settings creation
        logger.debug(
            "Environment variables check",
            telegram_bot_token_set=bool(os.getenv("TELEGRAM_BOT_TOKEN")),
            telegram_bot_username=os.getenv("TELEGRAM_BOT_USERNAME"),
            approved_directory=os.getenv("APPROVED_DIRECTORY"),
            debug_mode=os.getenv("DEBUG"),
        )

        # Load base settings from environment variables
        # pydantic-settings will automatically read from environment variables
        settings = Settings()  # type: ignore[call-arg]

        # Apply environment-specific overrides
        settings = _apply_environment_overrides(settings, env)

        # Validate configuration
        _validate_config(settings)

        logger.info(
            "Configuration loaded successfully",
            environment=env,
            debug=settings.debug,
            approved_directory=str(settings.approved_directory),
            features_enabled=_get_enabled_features_summary(settings),
        )

        return settings

    except Exception as e:
        logger.error("Failed to load configuration", error=str(e), environment=env)
        raise ConfigurationError(f"Configuration loading failed: {e}") from e


def _apply_environment_overrides(settings: Settings, env: Optional[str]) -> Settings:
    """Apply environment-specific configuration overrides."""
    overrides = {}

    if env == "development":
        overrides = DevelopmentConfig.as_dict()
    elif env == "testing":
        overrides = TestingConfig.as_dict()
    elif env == "production":
        overrides = ProductionConfig.as_dict()
    else:
        logger.warning("Unknown environment, using default settings", environment=env)

    # Apply overrides
    for key, value in overrides.items():
        if hasattr(settings, key):
            setattr(settings, key, value)
            logger.debug(
                "Applied environment override", key=key, value=value, environment=env
            )

    return settings


def _validate_config(settings: Settings) -> None:
    """Perform additional runtime validation."""
    # Check file system permissions
    try:
        if not os.access(settings.approved_directory, os.R_OK | os.X_OK):
            raise InvalidConfigError(
                f"Cannot access approved directory: {settings.approved_directory}"
            )
    except OSError as e:
        raise InvalidConfigError(f"Error accessing approved directory: {e}") from e

    # Validate feature dependencies
    if settings.enable_mcp and not settings.mcp_config_path:
        raise InvalidConfigError("MCP enabled but no config path provided")

    if settings.enable_token_auth and not settings.auth_token_secret:
        raise InvalidConfigError("Token auth enabled but no secret provided")

    # Validate database path for SQLite
    if settings.database_url.startswith("sqlite:///"):
        db_path = settings.database_path
        if db_path:
            # Ensure parent directory exists
            db_path.parent.mkdir(parents=True, exist_ok=True)

    # Validate rate limiting settings
    if settings.rate_limit_requests <= 0:
        raise InvalidConfigError("rate_limit_requests must be positive")

    if settings.rate_limit_window <= 0:
        raise InvalidConfigError("rate_limit_window must be positive")

    if settings.claude_timeout_seconds <= 0:
        raise InvalidConfigError("claude_timeout_seconds must be positive")

    # Validate cost limits
    if settings.claude_max_cost_per_user <= 0:
        raise InvalidConfigError("claude_max_cost_per_user must be positive")


def _get_enabled_features_summary(settings: Settings) -> list[str]:
    """Get a summary of enabled features for logging."""
    features = []
    if settings.enable_mcp:
        features.append("mcp")
    if settings.enable_git_integration:
        features.append("git")
    if settings.enable_file_uploads:
        features.append("file_uploads")
    if settings.enable_quick_actions:
        features.append("quick_actions")
    if settings.enable_token_auth:
        features.append("token_auth")
    if settings.webhook_url:
        features.append("webhook")
    return features


def create_test_config(**overrides: Any) -> Settings:
    """Create configuration for testing with optional overrides.

    Args:
        **overrides: Configuration values to override

    Returns:
        Settings instance configured for testing
    """
    # Start with testing defaults
    test_values = TestingConfig.as_dict()

    # Add required fields for testing
    test_values.update(
        {
            "telegram_bot_token": "test_token_123",
            "telegram_bot_username": "test_bot",
            "approved_directory": "/tmp/test_projects",
        }
    )

    # Apply any overrides
    test_values.update(overrides)

    # Ensure test directory exists
    test_dir = Path(test_values["approved_directory"])
    test_dir.mkdir(parents=True, exist_ok=True)

    # Create settings with test values
    settings = Settings(**test_values)

    return settings

```

### config/settings.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 12,536 Ð±Ð°Ð¹Ñ‚

```python
"""Configuration management using Pydantic Settings.

Features:
- Environment variable loading
- Type validation
- Default values
- Computed properties
- Environment-specific settings
"""

from datetime import time
from pathlib import Path
from typing import Any, List, Optional

from pydantic import BaseModel, Field, SecretStr, field_validator, model_validator
from pydantic_settings import BaseSettings, SettingsConfigDict

from src.utils.constants import (
    DEFAULT_CLAUDE_MAX_COST_PER_USER,
    DEFAULT_CLAUDE_MAX_TURNS,
    DEFAULT_CLAUDE_TIMEOUT_SECONDS,
    DEFAULT_DATABASE_URL,
    DEFAULT_MAX_SESSIONS_PER_USER,
    DEFAULT_RATE_LIMIT_BURST,
    DEFAULT_RATE_LIMIT_REQUESTS,
    DEFAULT_RATE_LIMIT_WINDOW,
    DEFAULT_SESSION_TIMEOUT_HOURS,
)


class ClaudeAvailabilitySettings(BaseSettings):
    """Settings for Claude CLI availability monitoring."""
    
    enabled: bool = Field(default=False, description="Whether Claude CLI availability monitoring is enabled")
    check_interval_seconds: int = Field(default=60, description="Check interval in seconds")
    notify_chat_ids: List[int] = Field(default_factory=list, description="Chat IDs to notify")
    dnd_start: time = Field(default=time(23, 0), description="DND start time (Europe/Kyiv)")
    dnd_end: time = Field(default=time(8, 0), description="DND end time (Europe/Kyiv)")
    debounce_ok_count: int = Field(default=2, description="Number of consecutive OK checks to confirm availability")
    
    model_config = SettingsConfigDict(env_prefix="CLAUDE_AVAILABILITY_")
    
    @field_validator("notify_chat_ids", mode="before")
    @classmethod
    def parse_notify_chat_ids(cls, v: Any) -> List[int]:
        """Parse comma-separated chat IDs."""
        if v is None or v == "":
            return []
        if isinstance(v, str):
            return [int(chat_id.strip()) for chat_id in v.split(",") if chat_id.strip()]
        if isinstance(v, int):
            return [v]
        if isinstance(v, list):
            return v
        return []


class Settings(BaseSettings):
    """Application settings loaded from environment variables."""

    # Bot settings
    telegram_bot_token: SecretStr = Field(
        ..., description="Telegram bot token from BotFather"
    )
    telegram_bot_username: str = Field(..., description="Bot username without @")

    # Security
    approved_directory: Path = Field(..., description="Base directory for projects")
    security_flexible_mode: bool = Field(
        False, description="Allow more flexible file operations within project subdirectories"
    )
    # allowed_users: Optional[List[int]] = Field(
    #     default=None, description="Allowed Telegram user IDs"
    # )
    enable_token_auth: bool = Field(
        False, description="Enable token-based authentication"
    )
    auth_token_secret: Optional[SecretStr] = Field(
        None, description="Secret for auth tokens"
    )

    # Claude settings
    claude_binary_path: Optional[str] = Field(
        None, description="Path to Claude CLI binary (deprecated)"
    )
    claude_cli_path: Optional[str] = Field(
        None, description="Path to Claude CLI executable"
    )
    anthropic_api_key: Optional[SecretStr] = Field(
        None,
        description="Anthropic API key for Claude SDK (optional if logged into Claude CLI)",
    )
    claude_model: str = Field(
        "claude-3-5-sonnet-20241022", description="Claude model to use"
    )
    claude_max_turns: int = Field(
        DEFAULT_CLAUDE_MAX_TURNS, description="Max conversation turns"
    )
    claude_timeout_seconds: int = Field(
        DEFAULT_CLAUDE_TIMEOUT_SECONDS, description="Claude timeout"
    )
    claude_max_cost_per_user: float = Field(
        DEFAULT_CLAUDE_MAX_COST_PER_USER, description="Max cost per user"
    )
    use_sdk: bool = Field(True, description="Use Python SDK instead of CLI subprocess")
    claude_allowed_tools: Optional[List[str]] = Field(
        default=[
            "Read",
            "Write",
            "Edit",
            "Bash",
            "Glob",
            "Grep",
            "LS",
            "Task",
            "MultiEdit",
            "NotebookRead",
            "NotebookEdit",
            "WebFetch",
            "TodoRead",
            "TodoWrite",
            "WebSearch",
        ],
        description="List of allowed Claude tools",
    )
    claude_disallowed_tools: Optional[List[str]] = Field(
        default=["git commit", "git push"],
        description="List of explicitly disallowed Claude tools/commands",
    )

    # Rate limiting
    rate_limit_requests: int = Field(
        DEFAULT_RATE_LIMIT_REQUESTS, description="Requests per window"
    )
    rate_limit_window: int = Field(
        DEFAULT_RATE_LIMIT_WINDOW, description="Rate limit window seconds"
    )
    rate_limit_burst: int = Field(
        DEFAULT_RATE_LIMIT_BURST, description="Burst capacity"
    )

    # Storage
    database_url: str = Field(
        DEFAULT_DATABASE_URL, description="Database connection URL"
    )
    session_timeout_hours: int = Field(
        DEFAULT_SESSION_TIMEOUT_HOURS, description="Session timeout"
    )
    session_timeout_minutes: int = Field(
        default=120,
        description="Session timeout in minutes",
        ge=10,
        le=1440,  # Max 24 hours
    )
    max_sessions_per_user: int = Field(
        DEFAULT_MAX_SESSIONS_PER_USER, description="Max concurrent sessions"
    )

    # Features
    enable_mcp: bool = Field(False, description="Enable Model Context Protocol")
    mcp_config_path: Optional[Path] = Field(
        None, description="MCP configuration file path"
    )
    enable_git_integration: bool = Field(True, description="Enable git commands")
    enable_file_uploads: bool = Field(True, description="Enable file upload handling")
    enable_quick_actions: bool = Field(True, description="Enable quick action buttons")
    claude_availability: ClaudeAvailabilitySettings = Field(default_factory=ClaudeAvailabilitySettings)
    
    # Image processing settings
    enable_image_processing: bool = Field(True, description="Enable image upload and processing")
    image_max_file_size: int = Field(20 * 1024 * 1024, description="Max image file size in bytes (20MB)")
    image_max_batch_size: int = Field(5, description="Max images per batch processing")
    image_session_timeout_minutes: int = Field(5, description="Image session timeout in minutes")
    image_temp_directory: Path = Field(default=Path("/tmp/claude_bot_images"), description="Temp directory for images")
    
    # Image validation settings
    image_max_width: int = Field(4096, description="Maximum image width in pixels")
    image_max_height: int = Field(4096, description="Maximum image height in pixels") 
    image_min_width: int = Field(32, description="Minimum image width in pixels")
    image_min_height: int = Field(32, description="Minimum image height in pixels")
    
    # Image optimization settings
    image_optimization_enabled: bool = Field(True, description="Enable image optimization")
    image_optimization_max_width: int = Field(2048, description="Max width for optimization")
    image_optimization_max_height: int = Field(2048, description="Max height for optimization")
    image_optimization_quality: int = Field(85, description="JPEG quality for optimization (1-100)")
    
    # Claude image integration settings
    claude_supports_images: bool = Field(True, description="Whether Claude CLI supports images")
    claude_image_timeout_seconds: int = Field(600, description="Timeout for image processing with Claude")

    # Monitoring
    log_level: str = Field("INFO", description="Logging level")
    enable_telemetry: bool = Field(False, description="Enable anonymous telemetry")
    sentry_dsn: Optional[str] = Field(None, description="Sentry DSN for error tracking")

    # Development
    debug: bool = Field(False, description="Enable debug mode")
    development_mode: bool = Field(False, description="Enable development features")

    # Webhook settings (optional)
    webhook_url: Optional[str] = Field(None, description="Webhook URL for bot")
    webhook_port: int = Field(8443, description="Webhook port")
    webhook_path: str = Field("/webhook", description="Webhook path")
    
    # âœ… New field: path to target project
    target_project_path: Path = Field(
        default=Path("/app/target_project"),
        description="Path to target project for Claude CLI operations"
    )
    
    # Localization settings
    default_language: str = Field("en", description="Default language code")
    enable_localization: bool = Field(True, description="Enable multi-language support")

    model_config = SettingsConfigDict(
        env_file=".env", env_file_encoding="utf-8", case_sensitive=False, extra="ignore"
    )

    # @field_validator("allowed_users", mode="before")
    # @classmethod
    # def parse_allowed_users(cls, v: Any) -> Optional[List[int]]:
    #     """Parse comma-separated user IDs."""
    #     if v is None:
    #         return None
    #     if isinstance(v, str):
    #         if not v.strip():
    #             return None
    #         return [int(uid.strip()) for uid in v.split(",") if uid.strip()]
    #     if isinstance(v, int):
    #         return [v]  # Convert single int to list
    #     if isinstance(v, list):
    #         return v  # Already a list
    #     # If we can't parse it, return None instead of failing
    #     return None

    @field_validator("approved_directory")
    @classmethod
    def validate_approved_directory(cls, v: Any) -> Path:
        """Ensure approved directory exists and is absolute."""
        if isinstance(v, str):
            v = Path(v)

        path = v.resolve()
        if not path.exists():
            raise ValueError(f"Approved directory does not exist: {path}")
        if not path.is_dir():
            raise ValueError(f"Approved directory is not a directory: {path}")
        return path  # type: ignore[no-any-return]

    @field_validator("mcp_config_path", mode="before")
    @classmethod
    def validate_mcp_config(cls, v: Any, info: Any) -> Optional[Path]:
        """Validate MCP configuration path if MCP is enabled."""
        # Note: In Pydantic v2, we'll need to check enable_mcp after model creation
        if v and isinstance(v, str):
            v = Path(v)
        if v and not v.exists():
            raise ValueError(f"MCP config file does not exist: {v}")
        return v  # type: ignore[no-any-return]

    @field_validator("log_level")
    @classmethod
    def validate_log_level(cls, v: Any) -> str:
        """Validate log level."""
        valid_levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
        if v.upper() not in valid_levels:
            raise ValueError(f"log_level must be one of {valid_levels}")
        return v.upper()  # type: ignore[no-any-return]

    @model_validator(mode="after")
    @classmethod
    def validate_cross_field_dependencies(cls, v):
        """Validate dependencies between fields."""
        # Check auth token requirements
        if v.enable_token_auth and not v.auth_token_secret:
            raise ValueError(
                "auth_token_secret required when enable_token_auth is True"
            )

        # Check MCP requirements
        if v.enable_mcp and not v.mcp_config_path:
            raise ValueError("mcp_config_path required when enable_mcp is True")

        return v

    @property
    def is_production(self) -> bool:
        """Check if running in production mode."""
        return not (self.debug or self.development_mode)

    @property
    def database_path(self) -> Optional[Path]:
        """Extract path from SQLite database URL."""
        if self.database_url.startswith("sqlite:///"):
            db_path = self.database_url.replace("sqlite:///", "")
            return Path(db_path).resolve()
        return None

    @property
    def telegram_token_str(self) -> str:
        """Get Telegram token as string."""
        return self.telegram_bot_token.get_secret_value()

    @property
    def auth_secret_str(self) -> Optional[str]:
        """Get auth token secret as string."""
        if self.auth_token_secret:
            return self.auth_token_secret.get_secret_value()
        return None

    @property
    def anthropic_api_key_str(self) -> Optional[str]:
        """Get Anthropic API key as string."""
        return (
            self.anthropic_api_key.get_secret_value()
            if self.anthropic_api_key
            else None
        )

```

### config/features.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 3,408 Ð±Ð°Ð¹Ñ‚

```python
"""Feature flag management."""

from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from .settings import Settings


class FeatureFlags:
    """Feature flag management system."""

    def __init__(self, settings: "Settings"):
        """Initialize with settings."""
        self.settings = settings

    @property
    def mcp_enabled(self) -> bool:
        """Check if Model Context Protocol is enabled."""
        return self.settings.enable_mcp and self.settings.mcp_config_path is not None

    @property
    def git_enabled(self) -> bool:
        """Check if Git integration is enabled."""
        return self.settings.enable_git_integration

    @property
    def file_uploads_enabled(self) -> bool:
        """Check if file uploads are enabled."""
        return self.settings.enable_file_uploads

    @property
    def quick_actions_enabled(self) -> bool:
        """Check if quick action buttons are enabled."""
        return self.settings.enable_quick_actions

    @property
    def telemetry_enabled(self) -> bool:
        """Check if telemetry is enabled."""
        return self.settings.enable_telemetry

    @property
    def token_auth_enabled(self) -> bool:
        """Check if token-based authentication is enabled."""
        return (
            self.settings.enable_token_auth
            and self.settings.auth_token_secret is not None
        )

    @property
    def webhook_enabled(self) -> bool:
        """Check if webhook mode is enabled."""
        return self.settings.webhook_url is not None

    @property
    def development_features_enabled(self) -> bool:
        """Check if development features are enabled."""
        return self.settings.development_mode

    @property
    def claude_availability_monitor(self) -> bool:
        """Check if Claude CLI availability monitoring is enabled."""
        return self.settings.claude_availability.enabled

    def is_feature_enabled(self, feature_name: str) -> bool:
        """Generic feature check by name."""
        feature_map = {
            "mcp": self.mcp_enabled,
            "git": self.git_enabled,
            "file_uploads": self.file_uploads_enabled,
            "quick_actions": self.quick_actions_enabled,
            "telemetry": self.telemetry_enabled,
            "token_auth": self.token_auth_enabled,
            "webhook": self.webhook_enabled,
            "development": self.development_features_enabled,
            "claude_availability_monitor": self.claude_availability_monitor,
        }
        return feature_map.get(feature_name, False)

    def get_enabled_features(self) -> list[str]:
        """Get list of all enabled features."""
        features = []
        if self.mcp_enabled:
            features.append("mcp")
        if self.git_enabled:
            features.append("git")
        if self.file_uploads_enabled:
            features.append("file_uploads")
        if self.quick_actions_enabled:
            features.append("quick_actions")
        if self.telemetry_enabled:
            features.append("telemetry")
        if self.token_auth_enabled:
            features.append("token_auth")
        if self.webhook_enabled:
            features.append("webhook")
        if self.development_features_enabled:
            features.append("development")
        if self.claude_availability_monitor:
            features.append("claude_availability_monitor")
        return features

```

### config/environments.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 2,275 Ð±Ð°Ð¹Ñ‚

```python
"""Environment-specific configuration overrides."""

from typing import Any, Dict


class DevelopmentConfig:
    """Development environment overrides."""

    debug: bool = True
    development_mode: bool = True
    log_level: str = "DEBUG"
    rate_limit_requests: int = 100  # More lenient for testing
    claude_timeout_seconds: int = 600  # Longer timeout for debugging
    enable_telemetry: bool = False

    @classmethod
    def as_dict(cls) -> Dict[str, Any]:
        """Return config as dictionary."""
        return {
            key: value
            for key, value in cls.__dict__.items()
            if not key.startswith("_")
            and not callable(value)
            and not isinstance(value, classmethod)
        }


class TestingConfig:
    """Testing environment configuration."""

    debug: bool = True
    development_mode: bool = True
    database_url: str = "sqlite:///:memory:"
    approved_directory: str = "/tmp/test_projects"
    enable_telemetry: bool = False
    claude_timeout_seconds: int = 30  # Faster timeout for tests
    rate_limit_requests: int = 1000  # No rate limiting in tests
    session_timeout_hours: int = 1  # Short session timeout for testing

    @classmethod
    def as_dict(cls) -> Dict[str, Any]:
        """Return config as dictionary."""
        return {
            key: value
            for key, value in cls.__dict__.items()
            if not key.startswith("_")
            and not callable(value)
            and not isinstance(value, classmethod)
        }


class ProductionConfig:
    """Production environment configuration."""

    debug: bool = False
    development_mode: bool = False
    log_level: str = "INFO"
    enable_telemetry: bool = True
    # Use stricter defaults for production
    claude_max_cost_per_user: float = 5.0  # Lower cost limit
    rate_limit_requests: int = 5  # Stricter rate limiting
    session_timeout_hours: int = 12  # Shorter session timeout

    @classmethod
    def as_dict(cls) -> Dict[str, Any]:
        """Return config as dictionary."""
        return {
            key: value
            for key, value in cls.__dict__.items()
            if not key.startswith("_")
            and not callable(value)
            and not isinstance(value, classmethod)
        }

```

### claude/exceptions.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 793 Ð±Ð°Ð¹Ñ‚

```python
"""Claude-specific exceptions."""


class ClaudeError(Exception):
    """Base Claude error."""

    pass


class ClaudeTimeoutError(ClaudeError):
    """Operation timed out."""

    pass


class ClaudeProcessError(ClaudeError):
    """Process execution failed."""

    pass


class ClaudeParsingError(ClaudeError):
    """Failed to parse output."""

    pass


class ClaudeSessionError(ClaudeError):
    """Session management error."""

    pass


class ClaudeToolValidationError(ClaudeError):
    """Tool validation failed during Claude execution."""

    def __init__(
        self, message: str, blocked_tools: list = None, allowed_tools: list = None
    ):
        super().__init__(message)
        self.blocked_tools = blocked_tools or []
        self.allowed_tools = allowed_tools or []

```

### claude/__init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 945 Ð±Ð°Ð¹Ñ‚

```python
"""Claude Code integration module."""

from .exceptions import (
    ClaudeError,
    ClaudeParsingError,
    ClaudeProcessError,
    ClaudeSessionError,
    ClaudeTimeoutError,
)
from .facade import ClaudeIntegration
from .integration import ClaudeProcessManager, ClaudeResponse, StreamUpdate
from .monitor import ToolMonitor
from .parser import OutputParser, ResponseFormatter
from .session import (
    ClaudeSession,
    InMemorySessionStorage,
    SessionManager,
    SessionStorage,
)

__all__ = [
    # Exceptions
    "ClaudeError",
    "ClaudeParsingError",
    "ClaudeProcessError",
    "ClaudeSessionError",
    "ClaudeTimeoutError",
    # Main integration
    "ClaudeIntegration",
    # Core components
    "ClaudeProcessManager",
    "ClaudeResponse",
    "StreamUpdate",
    "SessionManager",
    "SessionStorage",
    "InMemorySessionStorage",
    "ClaudeSession",
    "ToolMonitor",
    "OutputParser",
    "ResponseFormatter",
]

```

### claude/sdk_integration.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 15,963 Ð±Ð°Ð¹Ñ‚

```python
"""Claude Code Python SDK integration.

Features:
- Native Claude Code SDK integration
- Async streaming support
- Tool execution management
- Session persistence
"""

import asyncio
import os
import uuid
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, AsyncIterator, Callable, Dict, List, Optional

import structlog
from claude_code_sdk import (
    ClaudeCodeOptions,
    ClaudeSDKError,
    CLIConnectionError,
    CLINotFoundError,
    Message,
    ProcessError,
    query,
)
from claude_code_sdk.types import (
    AssistantMessage,
    ResultMessage,
    TextBlock,
    ToolResultBlock,
    ToolUseBlock,
    UserMessage,
)

from ..config.settings import Settings
from .exceptions import (
    ClaudeParsingError,
    ClaudeProcessError,
    ClaudeTimeoutError,
)

logger = structlog.get_logger()


def find_claude_cli(claude_cli_path: Optional[str] = None) -> Optional[str]:
    """Find Claude CLI in common locations."""
    import glob
    import shutil

    # First check if a specific path was provided via config or env
    if claude_cli_path:
        if os.path.exists(claude_cli_path) and os.access(claude_cli_path, os.X_OK):
            return claude_cli_path

    # Check CLAUDE_CLI_PATH environment variable
    env_path = os.environ.get("CLAUDE_CLI_PATH")
    if env_path and os.path.exists(env_path) and os.access(env_path, os.X_OK):
        return env_path

    # Check if claude is already in PATH
    claude_path = shutil.which("claude")
    if claude_path:
        return claude_path

    # Check common installation locations
    common_paths = [
        # NVM installations
        os.path.expanduser("~/.nvm/versions/node/*/bin/claude"),
        # Direct npm global install
        os.path.expanduser("~/.npm-global/bin/claude"),
        os.path.expanduser("~/node_modules/.bin/claude"),
        # System locations
        "/usr/local/bin/claude",
        "/usr/bin/claude",
        # Windows locations (for cross-platform support)
        os.path.expanduser("~/AppData/Roaming/npm/claude.cmd"),
    ]

    for pattern in common_paths:
        matches = glob.glob(pattern)
        if matches:
            # Return the first match
            return matches[0]

    return None


def update_path_for_claude(claude_cli_path: Optional[str] = None) -> bool:
    """Update PATH to include Claude CLI if found."""
    claude_path = find_claude_cli(claude_cli_path)

    if claude_path:
        # Add the directory containing claude to PATH
        claude_dir = os.path.dirname(claude_path)
        current_path = os.environ.get("PATH", "")

        if claude_dir not in current_path:
            os.environ["PATH"] = f"{claude_dir}:{current_path}"
            logger.info("Updated PATH for Claude CLI", claude_path=claude_path)

        return True

    return False


@dataclass
class ClaudeResponse:
    """Response from Claude Code SDK."""

    content: str
    session_id: str
    cost: float
    duration_ms: int
    num_turns: int
    is_error: bool = False
    error_type: Optional[str] = None
    tools_used: List[Dict[str, Any]] = field(default_factory=list)


@dataclass
class StreamUpdate:
    """Streaming update from Claude SDK."""

    type: str  # 'assistant', 'user', 'system', 'result'
    content: Optional[str] = None
    tool_calls: Optional[List[Dict]] = None
    metadata: Optional[Dict] = None


class ClaudeSDKManager:
    """Manage Claude Code SDK integration."""

    def __init__(self, config: Settings):
        """Initialize SDK manager with configuration."""
        self.config = config
        self.active_sessions: Dict[str, Dict[str, Any]] = {}

        # Try to find and update PATH for Claude CLI
        if not update_path_for_claude(config.claude_cli_path):
            logger.warning(
                "Claude CLI not found in PATH or common locations. "
                "SDK may fail if Claude is not installed or not in PATH."
            )

        # Set up environment for Claude Code SDK if API key is provided
        # If no API key is provided, the SDK will use existing CLI authentication
        if config.anthropic_api_key_str:
            os.environ["ANTHROPIC_API_KEY"] = config.anthropic_api_key_str
            logger.info("Using provided API key for Claude SDK authentication")
        else:
            logger.info("No API key provided, using existing Claude CLI authentication")

    async def execute_command(
        self,
        prompt: str,
        working_directory: Path,
        session_id: Optional[str] = None,
        continue_session: bool = False,
        stream_callback: Optional[Callable[[StreamUpdate], None]] = None,
    ) -> ClaudeResponse:
        """Execute Claude Code command via SDK."""
        start_time = asyncio.get_event_loop().time()

        logger.info(
            "Starting Claude SDK command",
            working_directory=str(working_directory),
            session_id=session_id,
            continue_session=continue_session,
        )

        try:
            # Build Claude Code options
            options = ClaudeCodeOptions(
                max_turns=self.config.claude_max_turns,
                cwd=str(working_directory),
                allowed_tools=self.config.claude_allowed_tools,
            )

            # Collect messages
            messages = []
            cost = 0.0
            tools_used = []

            # Execute with streaming and timeout
            await asyncio.wait_for(
                self._execute_query_with_streaming(
                    prompt, options, messages, stream_callback
                ),
                timeout=self.config.claude_timeout_seconds,
            )

            # Extract cost and tools from result message
            cost = 0.0
            tools_used = []
            for message in messages:
                if isinstance(message, ResultMessage):
                    cost = getattr(message, "total_cost_usd", 0.0) or 0.0
                    tools_used = self._extract_tools_from_messages(messages)
                    break

            # Calculate duration
            duration_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)

            # Get or create session ID
            final_session_id = session_id or str(uuid.uuid4())

            # Update session
            self._update_session(final_session_id, messages)

            return ClaudeResponse(
                content=self._extract_content_from_messages(messages),
                session_id=final_session_id,
                cost=cost,
                duration_ms=duration_ms,
                num_turns=len(
                    [
                        m
                        for m in messages
                        if isinstance(m, (UserMessage, AssistantMessage))
                    ]
                ),
                tools_used=tools_used,
            )

        except asyncio.TimeoutError:
            logger.error(
                "Claude SDK command timed out",
                timeout_seconds=self.config.claude_timeout_seconds,
            )
            raise ClaudeTimeoutError(
                f"Claude SDK timed out after {self.config.claude_timeout_seconds}s"
            )

        except CLINotFoundError as e:
            logger.error("Claude CLI not found", error=str(e))
            error_msg = (
                "Claude Code not found. Please ensure Claude is installed:\n"
                "  npm install -g @anthropic-ai/claude-code\n\n"
                "If already installed, try one of these:\n"
                "  1. Add Claude to your PATH\n"
                "  2. Create a symlink: ln -s $(which claude) /usr/local/bin/claude\n"
                "  3. Set CLAUDE_CLI_PATH environment variable"
            )
            raise ClaudeProcessError(error_msg)

        except ProcessError as e:
            logger.error(
                "Claude process failed",
                error=str(e),
                exit_code=getattr(e, "exit_code", None),
            )
            raise ClaudeProcessError(f"Claude process error: {str(e)}")

        except CLIConnectionError as e:
            logger.error("Claude connection error", error=str(e))
            raise ClaudeProcessError(f"Failed to connect to Claude: {str(e)}")

        except ClaudeSDKError as e:
            logger.error("Claude SDK error", error=str(e))
            raise ClaudeProcessError(f"Claude SDK error: {str(e)}")

        except Exception as e:
            # Handle ExceptionGroup from TaskGroup operations (Python 3.11+)
            if type(e).__name__ == "ExceptionGroup" or hasattr(e, "exceptions"):
                logger.error(
                    "Task group error in Claude SDK",
                    error=str(e),
                    error_type=type(e).__name__,
                    exception_count=len(getattr(e, "exceptions", [])),
                    exceptions=[
                        str(ex) for ex in getattr(e, "exceptions", [])[:3]
                    ],  # Log first 3 exceptions
                )
                # Extract the most relevant exception from the group
                exceptions = getattr(e, "exceptions", [e])
                main_exception = exceptions[0] if exceptions else e
                raise ClaudeProcessError(
                    f"Claude SDK task error: {str(main_exception)}"
                )

            # Check if it's an ExceptionGroup disguised as a regular exception
            elif hasattr(e, "__notes__") and "TaskGroup" in str(e):
                logger.error(
                    "TaskGroup related error in Claude SDK",
                    error=str(e),
                    error_type=type(e).__name__,
                )
                raise ClaudeProcessError(f"Claude SDK task error: {str(e)}")

            else:
                logger.error(
                    "Unexpected error in Claude SDK",
                    error=str(e),
                    error_type=type(e).__name__,
                )
                raise ClaudeProcessError(f"Unexpected error: {str(e)}")

    async def _execute_query_with_streaming(
        self, prompt: str, options, messages: List, stream_callback: Optional[Callable]
    ) -> None:
        """Execute query with streaming and collect messages."""
        try:
            async for message in query(prompt=prompt, options=options):
                messages.append(message)

                # Handle streaming callback
                if stream_callback:
                    try:
                        await self._handle_stream_message(message, stream_callback)
                    except Exception as callback_error:
                        logger.warning(
                            "Stream callback failed",
                            error=str(callback_error),
                            error_type=type(callback_error).__name__,
                        )
                        # Continue processing even if callback fails

        except Exception as e:
            # Handle both ExceptionGroups and regular exceptions
            if type(e).__name__ == "ExceptionGroup" or hasattr(e, "exceptions"):
                logger.error(
                    "TaskGroup error in streaming execution",
                    error=str(e),
                    error_type=type(e).__name__,
                )
            else:
                logger.error(
                    "Error in streaming execution",
                    error=str(e),
                    error_type=type(e).__name__,
                )
            # Re-raise to be handled by the outer try-catch
            raise

    async def _handle_stream_message(
        self, message: Message, stream_callback: Callable[[StreamUpdate], None]
    ) -> None:
        """Handle streaming message from claude-code-sdk."""
        try:
            if isinstance(message, AssistantMessage):
                # Extract content from assistant message
                content = getattr(message, "content", [])
                if content and isinstance(content, list):
                    # Extract text from TextBlock objects
                    text_parts = []
                    for block in content:
                        if hasattr(block, "text"):
                            text_parts.append(block.text)
                    if text_parts:
                        update = StreamUpdate(
                            type="assistant",
                            content="\n".join(text_parts),
                        )
                        await stream_callback(update)
                elif content:
                    # Fallback for non-list content
                    update = StreamUpdate(
                        type="assistant",
                        content=str(content),
                    )
                    await stream_callback(update)

                # Check for tool calls (if available in the message structure)
                # Note: This depends on the actual claude-code-sdk message structure

            elif isinstance(message, UserMessage):
                content = getattr(message, "content", "")
                if content:
                    update = StreamUpdate(
                        type="user",
                        content=content,
                    )
                    await stream_callback(update)

        except Exception as e:
            logger.warning("Stream callback failed", error=str(e))

    def _extract_content_from_messages(self, messages: List[Message]) -> str:
        """Extract content from message list."""
        content_parts = []

        for message in messages:
            if isinstance(message, AssistantMessage):
                content = getattr(message, "content", [])
                if content and isinstance(content, list):
                    # Extract text from TextBlock objects
                    for block in content:
                        if hasattr(block, "text"):
                            content_parts.append(block.text)
                elif content:
                    # Fallback for non-list content
                    content_parts.append(str(content))

        return "\n".join(content_parts)

    def _extract_tools_from_messages(
        self, messages: List[Message]
    ) -> List[Dict[str, Any]]:
        """Extract tools used from message list."""
        tools_used = []
        current_time = asyncio.get_event_loop().time()

        for message in messages:
            if isinstance(message, AssistantMessage):
                content = getattr(message, "content", [])
                if content and isinstance(content, list):
                    for block in content:
                        if isinstance(block, ToolUseBlock):
                            tools_used.append(
                                {
                                    "name": getattr(block, "tool_name", "unknown"),
                                    "timestamp": current_time,
                                    "input": getattr(block, "tool_input", {}),
                                }
                            )

        return tools_used

    def _update_session(self, session_id: str, messages: List[Message]) -> None:
        """Update session data."""
        if session_id not in self.active_sessions:
            self.active_sessions[session_id] = {
                "messages": [],
                "created_at": asyncio.get_event_loop().time(),
            }

        session_data = self.active_sessions[session_id]
        session_data["messages"] = messages
        session_data["last_used"] = asyncio.get_event_loop().time()

    async def kill_all_processes(self) -> None:
        """Kill all active processes (no-op for SDK)."""
        logger.info("Clearing active SDK sessions", count=len(self.active_sessions))
        self.active_sessions.clear()

    def get_active_process_count(self) -> int:
        """Get number of active sessions."""
        return len(self.active_sessions)

```

### claude/monitor.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 7,092 Ð±Ð°Ð¹Ñ‚

```python
"""Monitor Claude's tool usage.

Features:
- Track tool calls
- Security validation
- Usage analytics
"""

from collections import defaultdict
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import structlog

from ..config.settings import Settings
from ..security.validators import SecurityValidator

logger = structlog.get_logger()


class ToolMonitor:
    """Monitor and validate Claude's tool usage."""

    def __init__(
        self, config: Settings, security_validator: Optional[SecurityValidator] = None
    ):
        """Initialize tool monitor."""
        self.config = config
        self.security_validator = security_validator
        self.tool_usage: Dict[str, int] = defaultdict(int)
        self.security_violations: List[Dict[str, Any]] = []
        
        # Enable flexible mode for development environments
        self.flexible_file_operations = getattr(config, 'development_mode', False)

    async def validate_tool_call(
        self,
        tool_name: str,
        tool_input: Dict[str, Any],
        working_directory: Path,
        user_id: int,
    ) -> Tuple[bool, Optional[str]]:
        """Validate tool call before execution."""
        logger.debug(
            "Validating tool call",
            tool_name=tool_name,
            working_directory=str(working_directory),
            user_id=user_id,
        )

        # Check if tool is allowed
        if (
            hasattr(self.config, "claude_allowed_tools")
            and self.config.claude_allowed_tools
        ):
            if tool_name not in self.config.claude_allowed_tools:
                violation = {
                    "type": "disallowed_tool",
                    "tool_name": tool_name,
                    "user_id": user_id,
                    "working_directory": str(working_directory),
                }
                self.security_violations.append(violation)
                logger.warning("Tool not allowed", **violation)
                return False, f"Tool not allowed: {tool_name}"

        # Check if tool is explicitly disallowed
        if (
            hasattr(self.config, "claude_disallowed_tools")
            and self.config.claude_disallowed_tools
        ):
            if tool_name in self.config.claude_disallowed_tools:
                violation = {
                    "type": "explicitly_disallowed_tool",
                    "tool_name": tool_name,
                    "user_id": user_id,
                    "working_directory": str(working_directory),
                }
                self.security_violations.append(violation)
                logger.warning("Tool explicitly disallowed", **violation)
                return False, f"Tool explicitly disallowed: {tool_name}"

        # Validate file operations
        if tool_name in [
            "create_file",
            "edit_file",
            "read_file",
            "Write",
            "Edit",
            "Read",
        ]:
            file_path = tool_input.get("path") or tool_input.get("file_path")
            if not file_path:
                return False, "File path required"

            # Validate path security
            if self.security_validator:
                valid, resolved_path, error = self.security_validator.validate_path(
                    file_path, working_directory
                )

                if not valid:
                    violation = {
                        "type": "invalid_file_path",
                        "tool_name": tool_name,
                        "file_path": file_path,
                        "user_id": user_id,
                        "working_directory": str(working_directory),
                        "error": error,
                    }
                    self.security_violations.append(violation)
                    logger.warning("Invalid file path in tool call", **violation)
                    return False, error

        # Validate shell commands
        if tool_name in ["bash", "shell", "Bash"]:
            command = tool_input.get("command", "")

            # Check for dangerous commands
            dangerous_patterns = [
                "rm -rf",
                "sudo",
                "chmod 777",
                "curl",
                "wget",
                "nc ",
                "netcat",
                ">",
                ">>",
                "|",
                "&",
                ";",
                "$(",
                "`",
            ]

            for pattern in dangerous_patterns:
                if pattern in command.lower():
                    violation = {
                        "type": "dangerous_command",
                        "tool_name": tool_name,
                        "command": command,
                        "pattern": pattern,
                        "user_id": user_id,
                        "working_directory": str(working_directory),
                    }
                    self.security_violations.append(violation)
                    logger.warning("Dangerous command detected", **violation)
                    return False, f"Dangerous command pattern detected: {pattern}"

        # Track usage
        self.tool_usage[tool_name] += 1

        logger.debug("Tool call validated successfully", tool_name=tool_name)
        return True, None

    def get_tool_stats(self) -> Dict[str, Any]:
        """Get tool usage statistics."""
        return {
            "total_calls": sum(self.tool_usage.values()),
            "by_tool": dict(self.tool_usage),
            "unique_tools": len(self.tool_usage),
            "security_violations": len(self.security_violations),
        }

    def get_security_violations(self) -> List[Dict[str, Any]]:
        """Get security violations."""
        return self.security_violations.copy()

    def reset_stats(self) -> None:
        """Reset statistics."""
        self.tool_usage.clear()
        self.security_violations.clear()
        logger.info("Tool monitor statistics reset")

    def get_user_tool_usage(self, user_id: int) -> Dict[str, Any]:
        """Get tool usage for specific user."""
        user_violations = [
            v for v in self.security_violations if v.get("user_id") == user_id
        ]

        return {
            "user_id": user_id,
            "security_violations": len(user_violations),
            "violation_types": list(set(v.get("type") for v in user_violations)),
        }

    def is_tool_allowed(self, tool_name: str) -> bool:
        """Check if tool is allowed without validation."""
        # Check allowed list
        if (
            hasattr(self.config, "claude_allowed_tools")
            and self.config.claude_allowed_tools
        ):
            if tool_name not in self.config.claude_allowed_tools:
                return False

        # Check disallowed list
        if (
            hasattr(self.config, "claude_disallowed_tools")
            and self.config.claude_disallowed_tools
        ):
            if tool_name in self.config.claude_disallowed_tools:
                return False

        return True

```

### claude/facade.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 32,527 Ð±Ð°Ð¹Ñ‚

```python
"""High-level Claude Code integration facade.

Provides simple interface for bot handlers.
"""

from pathlib import Path
from typing import Any, Callable, Dict, List, Optional, Union, TYPE_CHECKING

import structlog

from ..config.settings import Settings
from .exceptions import ClaudeToolValidationError
from .integration import ClaudeProcessManager, ClaudeResponse, StreamUpdate
from .monitor import ToolMonitor
# Temporarily disable SDK integration
# from .sdk_integration import ClaudeSDKManager
from .session import SessionManager

if TYPE_CHECKING:
    from ..bot.features.image_processor import ProcessedImage

logger = structlog.get_logger()


class ClaudeIntegration:
    """Main integration point for Claude Code."""

    def __init__(
        self,
        config: Settings,
        process_manager: Optional[ClaudeProcessManager] = None,
        sdk_manager: Optional[Any] = None,
        session_manager: Optional[SessionManager] = None,
        tool_monitor: Optional[ToolMonitor] = None,
    ):
        """Initialize Claude integration facade."""
        self.config = config

        # Initialize both managers for fallback capability
        # SDK manager temporarily disabled
        self.sdk_manager = None
        logger.debug("SDK manager disabled for CLI-only mode")
        self.process_manager = process_manager or ClaudeProcessManager(config)

        # Use SDK by default if configured
        if config.use_sdk:
            self.manager = self.sdk_manager
        else:
            self.manager = self.process_manager

        self.session_manager = session_manager
        self.tool_monitor = tool_monitor
        self._sdk_failed_count = 0  # Track SDK failures for adaptive fallback

    async def run_command(
        self,
        prompt: str,
        working_directory: Path,
        user_id: int,
        session_id: Optional[str] = None,
        on_stream: Optional[Callable[[StreamUpdate], None]] = None,
    ) -> ClaudeResponse:
        """Run Claude Code command with full integration."""
        # Add Ukrainian language instruction to prompt
        enhanced_prompt = f"""Ð’ÐÐ–Ð›Ð˜Ð’Ðž: Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ Ð¢Ð†Ð›Ð¬ÐšÐ˜ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ Ð¼Ð¾Ð²Ð¾ÑŽ. ÐšÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡ Ð· Ð£ÐºÑ€Ð°Ñ—Ð½Ð¸ Ñ– Ð¾Ñ‡Ñ–ÐºÑƒÑ” Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ.

{prompt}

ÐžÐ‘ÐžÐ’'Ð¯Ð—ÐšÐžÐ’Ðž Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ Ð¼Ð¾Ð²Ð¾ÑŽ!"""
        logger.info(
            "Running Claude command",
            user_id=user_id,
            working_directory=str(working_directory),
            session_id=session_id,
            prompt_length=len(enhanced_prompt),
        )

        # Get or create session
        session = await self.session_manager.get_or_create_session(
            user_id, working_directory, session_id
        )

        # Track streaming updates and validate tool calls
        tools_validated = True
        validation_errors = []
        blocked_tools = set()

        async def stream_handler(update: StreamUpdate):
            nonlocal tools_validated

            # Validate tool calls
            if update.tool_calls:
                for tool_call in update.tool_calls:
                    tool_name = tool_call["name"]
                    valid, error = await self.tool_monitor.validate_tool_call(
                        tool_name,
                        tool_call.get("input", {}),
                        working_directory,
                        user_id,
                    )

                    if not valid:
                        tools_validated = False
                        validation_errors.append(error)

                        # Track blocked tools
                        if "Tool not allowed:" in error:
                            blocked_tools.add(tool_name)

                        logger.error(
                            "Tool validation failed",
                            tool_name=tool_name,
                            error=error,
                            user_id=user_id,
                        )

                        # For critical tools, we should fail fast
                        if tool_name in ["Task", "Read", "Write", "Edit"]:
                            # Create comprehensive error message
                            admin_instructions = self._get_admin_instructions(
                                list(blocked_tools)
                            )
                            error_msg = self._create_tool_error_message(
                                list(blocked_tools),
                                self.config.claude_allowed_tools or [],
                                admin_instructions,
                            )

                            raise ClaudeToolValidationError(
                                error_msg,
                                blocked_tools=list(blocked_tools),
                                allowed_tools=self.config.claude_allowed_tools or [],
                            )

            # Pass to caller's handler
            if on_stream:
                try:
                    await on_stream(update)
                except Exception as e:
                    logger.warning("Stream callback failed", error=str(e))

        # Execute command
        try:
            # Only continue session if it's not a new session
            should_continue = bool(session_id) and not getattr(
                session, "is_new_session", False
            )

            # For new sessions, don't pass the temporary session_id to Claude Code
            claude_session_id = (
                None
                if getattr(session, "is_new_session", False)
                else session.session_id
            )

            response = await self._execute_with_fallback(
                prompt=enhanced_prompt,
                working_directory=working_directory,
                session_id=claude_session_id,
                continue_session=should_continue,
                stream_callback=stream_handler,
            )

            # Check if tool validation failed
            if not tools_validated:
                logger.error(
                    "Command completed but tool validation failed",
                    validation_errors=validation_errors,
                )
                # Mark response as having errors and include validation details
                response.is_error = True
                response.error_type = "tool_validation_failed"

                # Extract blocked tool names for user feedback
                blocked_tools = []
                for error in validation_errors:
                    if "Tool not allowed:" in error:
                        tool_name = error.split("Tool not allowed: ")[1]
                        blocked_tools.append(tool_name)

                # Create user-friendly error message
                if blocked_tools:
                    tool_list = ", ".join(f"`{tool}`" for tool in blocked_tools)
                    response.content = (
                        f"ðŸš« **Tool Access Blocked**\n\n"
                        f"Claude tried to use tools not allowed:\n"
                        f"{tool_list}\n\n"
                        f"**What you can do:**\n"
                        f"â€¢ Contact the administrator to request access to these tools\n"
                        f"â€¢ Try rephrasing your request to use different approaches\n"
                        f"â€¢ Check what tools are currently available with `/status`\n\n"
                        f"**Currently allowed tools:**\n"
                        f"{', '.join(f'`{t}`' for t in self.config.claude_allowed_tools or [])}"
                    )
                else:
                    response.content = (
                        f"ðŸš« **Tool Validation Failed**\n\n"
                        f"Tools failed security validation. Try different approach.\n\n"
                        f"Details: {' | '.join(validation_errors)}"
                    )

            # Update session (this may change the session_id for new sessions)
            old_session_id = session.session_id
            await self.session_manager.update_session(session.session_id, response)

            # For new sessions, get the updated session_id from the session manager
            if hasattr(session, "is_new_session") and response.session_id:
                # The session_id has been updated to Claude's session_id
                final_session_id = response.session_id
            else:
                # Use the original session_id for continuing sessions
                final_session_id = old_session_id

            # Ensure response has the correct session_id
            response.session_id = final_session_id

            logger.info(
                "Claude command completed",
                session_id=response.session_id,
                cost=response.cost,
                duration_ms=response.duration_ms,
                num_turns=response.num_turns,
                is_error=response.is_error,
            )

            return response

        except Exception as e:
            logger.error(
                "Claude command failed",
                error=str(e),
                user_id=user_id,
                session_id=session.session_id,
            )
            raise

    async def run_command_with_images(
        self,
        prompt: str,
        images: List["ProcessedImage"],
        working_directory: Path,
        user_id: int,
        session_id: Optional[str] = None,
        on_stream: Optional[Callable[[StreamUpdate], None]] = None,
    ) -> ClaudeResponse:
        """Run Claude Code command with image attachments."""
        logger.info(
            "Running Claude command with images",
            user_id=user_id,
            working_directory=str(working_directory),
            session_id=session_id,
            prompt_length=len(prompt),
            image_count=len(images),
        )

        if not self.config.claude_supports_images:
            raise ClaudeToolValidationError(
                "Image processing is not enabled for Claude CLI. "
                "Please contact the administrator to enable image support."
            )

        # Always try SDK first for image processing if available
        # Images require visual analysis which CLI cannot do
        if self.sdk_manager:
            try:
                return await self._run_command_with_images_sdk(
                    prompt, images, working_directory, user_id, session_id, on_stream
                )
            except Exception as e:
                logger.warning("SDK image processing failed, will try CLI fallback", error=str(e))
                self._sdk_failed_count += 1

        # CLI fallback (images won't be processed visually, only by filename)
        logger.warning("Using CLI for image processing - images will not be analyzed visually")
        return await self._run_command_with_images_cli(
            prompt, images, working_directory, user_id, session_id, on_stream
        )

    async def _run_command_with_images_sdk(
        self,
        prompt: str,
        images: List["ProcessedImage"],
        working_directory: Path,
        user_id: int,
        session_id: Optional[str] = None,
        on_stream: Optional[Callable[[StreamUpdate], None]] = None,
    ) -> ClaudeResponse:
        """Run command with images using SDK with PROPER image support."""
        import time

        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° API ÐºÐ»ÑŽÑ‡Ð° - ÑÐ¿Ñ€Ð¾Ð±ÑƒÑ”Ð¼Ð¾ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ð· ÐºÐ¾Ð½Ñ„Ñ–Ð³Ñƒ Ð°Ð±Ð¾ Ð· CLI
        api_key = self.config.anthropic_api_key
        if not api_key:
            try:
                # Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÑ”Ð¼Ð¾ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ API ÐºÐ»ÑŽÑ‡ Ñ‡ÐµÑ€ÐµÐ· Claude CLI token
                import subprocess
                result = subprocess.run(
                    ['claude', 'config', 'get', 'api_key'],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                if result.returncode == 0 and result.stdout.strip():
                    api_key = result.stdout.strip()
                    logger.debug("Using API key from Claude CLI config")
            except Exception as e:
                logger.debug("Could not get API key from Claude CLI", error=str(e))

        if not api_key:
            raise ClaudeToolValidationError(
                "ANTHROPIC_API_KEY not configured. "
                "Please set ANTHROPIC_API_KEY environment variable or authenticate Claude CLI"
            )

        try:
            import anthropic
        except ImportError:
            logger.error("anthropic module not available, falling back to CLI")
            raise ClaudeToolValidationError("anthropic module not installed")

        client = anthropic.Anthropic(api_key=api_key)

        # Ð‘ÑƒÐ´ÑƒÑ”Ð¼Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ Ð· Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½ÑÐ¼Ð¸
        content = []

        # Ð”Ð¾Ð´Ð°Ñ”Ð¼Ð¾ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ ÑÐ¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ
        for image in images:
            base64_data = await image.get_base64_data()
            content.append({
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": f"image/{image.format.lower()}",
                    "data": base64_data
                }
            })

        # Ð”Ð¾Ð´Ð°Ñ”Ð¼Ð¾ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¸Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
        content.append({
            "type": "text",
            "text": prompt
        })

        logger.info("Sending images to Claude API", image_count=len(images), user_id=user_id)

        try:
            # ÐŸÑ€ÑÐ¼Ð¸Ð¹ Ð²Ð¸ÐºÐ»Ð¸Ðº Anthropic Messages API
            api_response = client.messages.create(
                model=self.config.claude_model or "claude-3-5-sonnet-20241022",
                max_tokens=4000,
                messages=[{"role": "user", "content": content}]
            )

            # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚ÑƒÑ”Ð¼Ð¾ Ð² ClaudeResponse
            response_text = "".join([
                block.text for block in api_response.content
                if hasattr(block, 'text')
            ])

            response = ClaudeResponse(
                content=response_text,
                session_id=session_id or f"sdk_img_{user_id}_{int(time.time())}",
                success=True,
                working_directory=working_directory
            )

            logger.info("Claude API response received",
                       response_length=len(response_text),
                       session_id=response.session_id)

            # Track image usage
            if response.session_id:
                await self._log_image_usage(user_id, response.session_id, images)

            return response

        except anthropic.APIError as e:
            logger.error("Anthropic API error", error=str(e), user_id=user_id)
            raise ClaudeToolValidationError(f"API error: {str(e)}")
        except Exception as e:
            logger.error("SDK image processing failed", error=str(e), user_id=user_id)
            raise ClaudeToolValidationError(f"Failed to process images: {str(e)}")

    async def _run_command_with_images_cli(
        self,
        prompt: str,
        images: List["ProcessedImage"],
        working_directory: Path,
        user_id: int,
        session_id: Optional[str] = None,
        on_stream: Optional[Callable[[StreamUpdate], None]] = None,
    ) -> ClaudeResponse:
        """Run command with images using CLI (copies images to working directory)."""
        # Copy images to working directory for Claude CLI access
        copied_images = []
        try:
            for i, image in enumerate(images):
                # Create unique filename in working directory
                image_filename = f"uploaded_image_{i+1}_{image.filename}"
                target_path = working_directory / image_filename

                # Copy image file
                import shutil
                shutil.copy2(image.file_path, target_path)
                copied_images.append((target_path, image))
                logger.debug("Copied image for CLI", src=str(image.file_path), dst=str(target_path))

            # Create enhanced prompt with references to copied images
            enhanced_prompt = await self._create_image_prompt_with_paths(prompt, copied_images)

            # Run command with CLI
            response = await self.run_command(
                prompt=enhanced_prompt,
                working_directory=working_directory,
                user_id=user_id,
                session_id=session_id,
                on_stream=on_stream,
            )

            # Track image usage
            if response.session_id:
                await self._log_image_usage(user_id, response.session_id, images)

            return response

        finally:
            # Clean up copied images
            for copied_path, _ in copied_images:
                try:
                    if copied_path.exists():
                        copied_path.unlink()
                        logger.debug("Cleaned up copied image", path=str(copied_path))
                except Exception as e:
                    logger.warning("Failed to cleanup copied image", path=str(copied_path), error=str(e))

    async def _create_image_prompt(
        self, 
        prompt: str, 
        images: List["ProcessedImage"]
    ) -> str:
        """Create enhanced prompt with image context information."""
        if not images:
            return prompt

        image_info = []
        for i, img in enumerate(images, 1):
            info = f"Image {i}: {img.filename} ({img.format}, {img.dimensions[0]}x{img.dimensions[1]}, {img.file_size / 1024:.1f}KB)"
            if img.caption:
                info += f" - Caption: {img.caption}"
            image_info.append(info)

        enhanced_prompt = f"""Ð’ÐÐ–Ð›Ð˜Ð’Ðž: Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ Ð¢Ð†Ð›Ð¬ÐšÐ˜ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ Ð¼Ð¾Ð²Ð¾ÑŽ. ÐšÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡ Ð· Ð£ÐºÑ€Ð°Ñ—Ð½Ð¸ Ñ– Ð¾Ñ‡Ñ–ÐºÑƒÑ” Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ.

{prompt}

Ð¯ Ð½Ð°Ð´Ð°ÑŽ Ñ‚Ð¾Ð±Ñ– {len(images)} Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ:
{chr(10).join(image_info)}

Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ñ†Ñ– Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñ– Ð¼Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ Ð²Ð¸Ñ‰Ðµ. Ð’Ñ€Ð°Ñ…ÑƒÐ¹:
1. Ð—Ð¼Ñ–ÑÑ‚ Ñ– ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÐºÐ¾Ð¶Ð½Ð¾Ð³Ð¾ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ
2. Ð‘ÑƒÐ´ÑŒ-ÑÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚, ÐºÐ¾Ð´ Ð°Ð±Ð¾ ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¸ UI, Ñ‰Ð¾ Ð²Ð¸Ð´Ð¸Ð¼Ñ–
3. Ð¢ÐµÑ…Ð½Ñ–Ñ‡Ð½Ñ– Ð°ÑÐ¿ÐµÐºÑ‚Ð¸, ÑÐºÑ‰Ð¾ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ– (Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð°, Ð´Ñ–Ð°Ð³Ñ€Ð°Ð¼Ð¸, Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¸ ÐºÐ¾Ð´Ñƒ)
4. Ð—Ð²'ÑÐ·ÐºÐ¸ Ð¼Ñ–Ð¶ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½ÑÐ¼Ð¸, ÑÐºÑ‰Ð¾ Ñ—Ñ… ÐºÑ–Ð»ÑŒÐºÐ°
5. ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ– Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ñ– Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ—

ÐŸÑ€Ð¸Ð¼Ñ–Ñ‚ÐºÐ°: Ð¥Ð¾Ñ‡Ð° Ñ Ð½Ðµ Ð¼Ð¾Ð¶Ñƒ Ð±ÐµÐ·Ð¿Ð¾ÑÐµÑ€ÐµÐ´Ð½ÑŒÐ¾ Ð¿Ñ€Ð¸ÐºÑ€Ñ–Ð¿Ð¸Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ Ð´Ð¾ Ñ†ÑŒÐ¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ, Ð±ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð½Ð°Ð´Ð°Ð¹ ÑÐ²Ñ–Ð¹ Ð½Ð°Ð¹ÐºÑ€Ð°Ñ‰Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ñ– Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ— Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– Ð½Ð°Ð´Ð°Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ Ñ– Ð½Ð°Ð·Ð² Ñ„Ð°Ð¹Ð»Ñ–Ð².

ÐžÐ‘ÐžÐ’'Ð¯Ð—ÐšÐžÐ’Ðž Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ Ð¼Ð¾Ð²Ð¾ÑŽ!"""

        return enhanced_prompt

    async def _create_image_prompt_with_paths(
        self,
        prompt: str,
        copied_images: List[tuple]  # (Path, ProcessedImage)
    ) -> str:
        """Create enhanced prompt with image file paths for CLI access."""
        if not copied_images:
            return prompt

        image_info = []
        image_paths = []
        for i, (path, img) in enumerate(copied_images, 1):
            info = f"Image {i}: {path.name} ({img.format}, {img.dimensions[0]}x{img.dimensions[1]}, {img.file_size / 1024:.1f}KB)"
            if img.caption:
                info += f" - Caption: {img.caption}"
            image_info.append(info)
            image_paths.append(str(path.name))

        enhanced_prompt = f"""Ð’ÐÐ–Ð›Ð˜Ð’Ðž: Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ Ð¢Ð†Ð›Ð¬ÐšÐ˜ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ Ð¼Ð¾Ð²Ð¾ÑŽ. ÐšÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡ Ð· Ð£ÐºÑ€Ð°Ñ—Ð½Ð¸ Ñ– Ð¾Ñ‡Ñ–ÐºÑƒÑ” Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ.

{prompt}

Ð¯ Ð½Ð°Ð´Ð°ÑŽ Ñ‚Ð¾Ð±Ñ– {len(copied_images)} Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ. Ð¤Ð°Ð¹Ð»Ð¸ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ð² Ñ€Ð¾Ð±Ð¾Ñ‡Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—:
{chr(10).join(image_info)}

Ð¢Ð¸ Ð¼Ð¾Ð¶ÐµÑˆ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ Read tool Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ´Ñƒ Ñ†Ð¸Ñ… Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ:
{', '.join(image_paths)}

Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ñ†Ñ– Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ Ð² ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñ– Ð¼Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ Ð²Ð¸Ñ‰Ðµ. Ð’Ñ€Ð°Ñ…ÑƒÐ¹:
1. Ð—Ð¼Ñ–ÑÑ‚ Ñ– ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÐºÐ¾Ð¶Ð½Ð¾Ð³Ð¾ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ
2. Ð‘ÑƒÐ´ÑŒ-ÑÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚, ÐºÐ¾Ð´ Ð°Ð±Ð¾ ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¸ UI, Ñ‰Ð¾ Ð²Ð¸Ð´Ð¸Ð¼Ñ–
3. Ð¢ÐµÑ…Ð½Ñ–Ñ‡Ð½Ñ– Ð°ÑÐ¿ÐµÐºÑ‚Ð¸, ÑÐºÑ‰Ð¾ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ– (Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð°, Ð´Ñ–Ð°Ð³Ñ€Ð°Ð¼Ð¸, Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð¸ ÐºÐ¾Ð´Ñƒ)
4. Ð—Ð²'ÑÐ·ÐºÐ¸ Ð¼Ñ–Ð¶ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½ÑÐ¼Ð¸, ÑÐºÑ‰Ð¾ Ñ—Ñ… ÐºÑ–Ð»ÑŒÐºÐ°
5. ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ– Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ñ– Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ—

Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹ Read tool Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ´Ñƒ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ Ñ– Ð½Ð°Ð´Ð°Ð¹ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð·.

ÐžÐ‘ÐžÐ’'Ð¯Ð—ÐšÐžÐ’Ðž Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ Ð¼Ð¾Ð²Ð¾ÑŽ!"""

        return enhanced_prompt

    async def _log_image_usage(
        self, 
        user_id: int, 
        session_id: str, 
        images: List["ProcessedImage"]
    ) -> None:
        """Log image usage for tracking purposes."""
        try:
            total_size = sum(img.file_size for img in images)
            logger.info(
                "Image processing completed",
                user_id=user_id,
                session_id=session_id,
                image_count=len(images),
                total_size_mb=round(total_size / (1024 * 1024), 2),
                formats=[img.format for img in images],
            )
        except Exception as e:
            logger.warning("Failed to log image usage", error=str(e))

    async def _execute_with_fallback(
        self,
        prompt: str,
        working_directory: Path,
        session_id: Optional[str] = None,
        continue_session: bool = False,
        stream_callback: Optional[Callable] = None,
    ) -> ClaudeResponse:
        """Execute command with SDK->subprocess fallback on JSON decode errors."""
        # Try SDK first if configured
        if self.config.use_sdk and self.sdk_manager:
            try:
                logger.debug("Attempting Claude SDK execution")
                response = await self.sdk_manager.execute_command(
                    prompt=prompt,
                    working_directory=working_directory,
                    session_id=session_id,
                    continue_session=continue_session,
                    stream_callback=stream_callback,
                )
                # Reset failure count on success
                self._sdk_failed_count = 0
                return response

            except Exception as e:
                error_str = str(e)
                # Check if this is a JSON decode error that indicates SDK issues
                if (
                    "Failed to decode JSON" in error_str
                    or "JSON decode error" in error_str
                    or "TaskGroup" in error_str
                    or "ExceptionGroup" in error_str
                ):
                    self._sdk_failed_count += 1
                    logger.warning(
                        "Claude SDK failed with JSON/TaskGroup error, falling back to subprocess",
                        error=error_str,
                        failure_count=self._sdk_failed_count,
                        error_type=type(e).__name__,
                    )

                    # Use subprocess fallback
                    try:
                        logger.info("Executing with subprocess fallback")
                        response = await self.process_manager.execute_command(
                            prompt=prompt,
                            working_directory=working_directory,
                            session_id=session_id,
                            continue_session=continue_session,
                            stream_callback=stream_callback,
                        )
                        logger.info("Subprocess fallback succeeded")
                        return response

                    except Exception as fallback_error:
                        logger.error(
                            "Both SDK and subprocess failed",
                            sdk_error=error_str,
                            subprocess_error=str(fallback_error),
                        )
                        # Re-raise the original SDK error since it was the primary method
                        raise e
                else:
                    # For non-JSON errors, re-raise immediately
                    logger.error(
                        "Claude SDK failed with non-JSON error", error=error_str
                    )
                    raise
        else:
            # Use subprocess directly if SDK not configured
            logger.debug("Using subprocess execution (SDK disabled)")
            return await self.process_manager.execute_command(
                prompt=prompt,
                working_directory=working_directory,
                session_id=session_id,
                continue_session=continue_session,
                stream_callback=stream_callback,
            )

    async def continue_session(
        self,
        user_id: int,
        working_directory: Path,
        prompt: Optional[str] = None,
        on_stream: Optional[Callable[[StreamUpdate], None]] = None,
    ) -> Optional[ClaudeResponse]:
        """Continue the most recent session."""
        logger.info(
            "Continuing session",
            user_id=user_id,
            working_directory=str(working_directory),
            has_prompt=bool(prompt),
        )

        # Get user's sessions
        sessions = await self.session_manager._get_user_sessions(user_id)

        # Find most recent session in this directory (exclude temporary sessions)
        matching_sessions = [
            s
            for s in sessions
            if s.project_path == working_directory
            and not s.session_id.startswith("temp_")
        ]

        if not matching_sessions:
            logger.info("No matching sessions found", user_id=user_id)
            return None

        # Get most recent
        latest_session = max(matching_sessions, key=lambda s: s.last_used)

        # Continue session
        return await self.run_command(
            prompt=prompt or "",
            working_directory=working_directory,
            user_id=user_id,
            session_id=latest_session.session_id,
            on_stream=on_stream,
        )

    async def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:
        """Get session information."""
        return await self.session_manager.get_session_info(session_id)

    async def get_user_sessions(self, user_id: int) -> List[Dict[str, Any]]:
        """Get all sessions for a user."""
        sessions = await self.session_manager._get_user_sessions(user_id)
        return [
            {
                "session_id": s.session_id,
                "project_path": str(s.project_path),
                "created_at": s.created_at.isoformat(),
                "last_used": s.last_used.isoformat(),
                "total_cost": s.total_cost,
                "message_count": s.message_count,
                "tools_used": s.tools_used,
                "expired": s.is_expired(self.config.session_timeout_hours),
            }
            for s in sessions
        ]

    async def cleanup_expired_sessions(self) -> int:
        """Clean up expired sessions."""
        return await self.session_manager.cleanup_expired_sessions()

    async def get_tool_stats(self) -> Dict[str, Any]:
        """Get tool usage statistics."""
        return self.tool_monitor.get_tool_stats()

    async def get_user_summary(self, user_id: int) -> Dict[str, Any]:
        """Get comprehensive user summary."""
        session_summary = await self.session_manager.get_user_session_summary(user_id)
        tool_usage = self.tool_monitor.get_user_tool_usage(user_id)

        return {
            "user_id": user_id,
            **session_summary,
            **tool_usage,
        }

    async def shutdown(self) -> None:
        """Shutdown integration and cleanup resources."""
        logger.info("Shutting down Claude integration")

        # Kill any active processes
        await self.manager.kill_all_processes()

        # Clean up expired sessions
        await self.cleanup_expired_sessions()

        logger.info("Claude integration shutdown complete")

    def _get_admin_instructions(self, blocked_tools: List[str]) -> str:
        """Generate admin instructions for enabling blocked tools."""
        instructions = []

        # Check if settings file exists
        settings_file = Path(".env")

        if blocked_tools:
            # Get current allowed tools and create merged list without duplicates
            current_tools = [
                "Read",
                "Write",
                "Edit",
                "Bash",
                "Glob",
                "Grep",
                "LS",
                "Task",
                "MultiEdit",
                "NotebookRead",
                "NotebookEdit",
                "WebFetch",
                "TodoRead",
                "TodoWrite",
                "WebSearch",
            ]
            merged_tools = list(
                dict.fromkeys(current_tools + blocked_tools)
            )  # Remove duplicates while preserving order
            merged_tools_str = ",".join(merged_tools)
            merged_tools_py = ", ".join(f'"{tool}"' for tool in merged_tools)

            instructions.append("**For Administrators:**")
            instructions.append("")

            if settings_file.exists():
                instructions.append(
                    "To enable these tools, add them to your `.env` file:"
                )
                instructions.append("```")
                instructions.append(f'CLAUDE_ALLOWED_TOOLS="{merged_tools_str}"')
                instructions.append("```")
            else:
                instructions.append("To enable these tools:")
                instructions.append("1. Create a `.env` file in your project root")
                instructions.append("2. Add the following line:")
                instructions.append("```")
                instructions.append(f'CLAUDE_ALLOWED_TOOLS="{merged_tools_str}"')
                instructions.append("```")

            instructions.append("")
            instructions.append("Or modify the default in `src/config/settings.py`:")
            instructions.append("```python")
            instructions.append("claude_allowed_tools: Optional[List[str]] = Field(")
            instructions.append(f"    default=[{merged_tools_py}],")
            instructions.append('    description="List of allowed Claude tools",')
            instructions.append(")")
            instructions.append("```")

        return "\n".join(instructions)

    def _create_tool_error_message(
        self,
        blocked_tools: List[str],
        allowed_tools: List[str],
        admin_instructions: str,
    ) -> str:
        """Create a comprehensive error message for tool validation failures."""
        tool_list = ", ".join(f"`{tool}`" for tool in blocked_tools)
        allowed_list = (
            ", ".join(f"`{tool}`" for tool in allowed_tools)
            if allowed_tools
            else "None"
        )

        message = [
            "ðŸš« **Tool Access Blocked**",
            "",
            f"Claude tried to use tools that are not currently allowed:",
            f"{tool_list}",
            "",
            "**Why this happened:**",
            "â€¢ Claude needs these tools to complete your request",
            "â€¢ These tools are not in the allowed tools list",
            "â€¢ This is a security feature to control what Claude can do",
            "",
            "**What you can do:**",
            "â€¢ Contact the administrator to request access to these tools",
            "â€¢ Try rephrasing your request to use different approaches",
            "â€¢ Use simpler requests that don't require these tools",
            "",
            "**Currently allowed tools:**",
            f"{allowed_list}",
            "",
            admin_instructions,
        ]

        return "\n".join(message)

```

### claude/parser.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 11,186 Ð±Ð°Ð¹Ñ‚

```python
"""Parse Claude Code output formats.

Features:
- JSON parsing
- Stream parsing
- Error detection
- Tool extraction
"""

import json
import re
from typing import Any, Dict, List

import structlog

from .exceptions import ClaudeParsingError

logger = structlog.get_logger()


class OutputParser:
    """Parse various Claude Code output formats."""

    @staticmethod
    def parse_json_output(output: str) -> Dict[str, Any]:
        """Parse single JSON output."""
        try:
            return json.loads(output)
        except json.JSONDecodeError as e:
            logger.error(
                "Failed to parse JSON output", output=output[:200], error=str(e)
            )
            raise ClaudeParsingError(f"Failed to parse JSON output: {e}")

    @staticmethod
    def parse_stream_json(lines: List[str]) -> List[Dict[str, Any]]:
        """Parse streaming JSON output."""
        messages = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            try:
                msg = json.loads(line)
                messages.append(msg)
            except json.JSONDecodeError:
                logger.warning("Skipping invalid JSON line", line=line)
                continue

        return messages

    @staticmethod
    def extract_code_blocks(content: str) -> List[Dict[str, str]]:
        """Extract code blocks from response."""
        code_blocks = []
        pattern = r"```(\w+)?\n(.*?)```"

        for match in re.finditer(pattern, content, re.DOTALL):
            language = match.group(1) or "text"
            code = match.group(2).strip()

            code_blocks.append({"language": language, "code": code})

        logger.debug("Extracted code blocks", count=len(code_blocks))
        return code_blocks

    @staticmethod
    def extract_file_operations(messages: List[Dict]) -> List[Dict[str, Any]]:
        """Extract file operations from tool calls."""
        file_ops = []

        for msg in messages:
            if msg.get("type") != "assistant":
                continue

            message = msg.get("message", {})
            for block in message.get("content", []):
                if block.get("type") != "tool_use":
                    continue

                tool_name = block.get("name", "")
                tool_input = block.get("input", {})

                # Check for file-related tools
                if tool_name in [
                    "create_file",
                    "edit_file",
                    "read_file",
                    "Write",
                    "Edit",
                    "Read",
                ]:
                    file_ops.append(
                        {
                            "operation": tool_name,
                            "path": tool_input.get("path")
                            or tool_input.get("file_path"),
                            "content": tool_input.get("content")
                            or tool_input.get("new_string"),
                            "old_content": tool_input.get("old_string"),
                            "timestamp": msg.get("timestamp"),
                        }
                    )

        logger.debug("Extracted file operations", count=len(file_ops))
        return file_ops

    @staticmethod
    def extract_shell_commands(messages: List[Dict]) -> List[Dict[str, Any]]:
        """Extract shell commands from tool calls."""
        shell_commands = []

        for msg in messages:
            if msg.get("type") != "assistant":
                continue

            message = msg.get("message", {})
            for block in message.get("content", []):
                if block.get("type") != "tool_use":
                    continue

                tool_name = block.get("name", "")
                tool_input = block.get("input", {})

                # Check for shell/bash tools
                if tool_name in ["bash", "shell", "Bash"]:
                    shell_commands.append(
                        {
                            "operation": tool_name,
                            "command": tool_input.get("command"),
                            "description": tool_input.get("description"),
                            "timestamp": msg.get("timestamp"),
                        }
                    )

        logger.debug("Extracted shell commands", count=len(shell_commands))
        return shell_commands

    @staticmethod
    def extract_response_text(messages: List[Dict]) -> str:
        """Extract all text content from assistant messages."""
        text_parts = []

        for msg in messages:
            if msg.get("type") != "assistant":
                continue

            message = msg.get("message", {})
            for block in message.get("content", []):
                if block.get("type") == "text":
                    text_parts.append(block.get("text", ""))

        return "\n".join(text_parts)

    @staticmethod
    def extract_tool_results(messages: List[Dict]) -> List[Dict[str, Any]]:
        """Extract tool results from tool_result messages."""
        tool_results = []

        for msg in messages:
            if msg.get("type") == "tool_result":
                result = msg.get("result", {})
                tool_results.append(
                    {
                        "tool_use_id": msg.get("tool_use_id"),
                        "content": result.get("content"),
                        "is_error": result.get("is_error", False),
                        "timestamp": msg.get("timestamp"),
                    }
                )

        logger.debug("Extracted tool results", count=len(tool_results))
        return tool_results

    @staticmethod
    def detect_errors(messages: List[Dict]) -> List[Dict[str, Any]]:
        """Detect errors in message stream."""
        errors = []

        for msg in messages:
            # Check for error messages
            if msg.get("is_error") or msg.get("type") == "error":
                errors.append(
                    {
                        "type": msg.get("type", "unknown"),
                        "subtype": msg.get("subtype"),
                        "message": msg.get("message", str(msg)),
                        "timestamp": msg.get("timestamp"),
                    }
                )

            # Check for tool result errors
            if msg.get("type") == "tool_result":
                result = msg.get("result", {})
                if result.get("is_error"):
                    errors.append(
                        {
                            "type": "tool_error",
                            "tool_use_id": msg.get("tool_use_id"),
                            "message": result.get("content", "Tool execution failed"),
                            "timestamp": msg.get("timestamp"),
                        }
                    )

        logger.debug("Detected errors", count=len(errors))
        return errors

    @staticmethod
    def summarize_session(messages: List[Dict]) -> Dict[str, Any]:
        """Create a summary of the session."""
        summary = {
            "total_messages": len(messages),
            "assistant_messages": 0,
            "user_messages": 0,
            "tool_calls": 0,
            "tool_results": 0,
            "errors": 0,
            "code_blocks": 0,
            "file_operations": 0,
            "shell_commands": 0,
        }

        full_text = ""

        for msg in messages:
            msg_type = msg.get("type")

            if msg_type == "assistant":
                summary["assistant_messages"] += 1

                # Extract text for analysis
                message = msg.get("message", {})
                for block in message.get("content", []):
                    if block.get("type") == "text":
                        full_text += block.get("text", "") + "\n"
                    elif block.get("type") == "tool_use":
                        summary["tool_calls"] += 1

            elif msg_type == "user":
                summary["user_messages"] += 1

            elif msg_type == "tool_result":
                summary["tool_results"] += 1

            elif msg.get("is_error") or msg_type == "error":
                summary["errors"] += 1

        # Analyze extracted content
        summary["code_blocks"] = len(OutputParser.extract_code_blocks(full_text))
        summary["file_operations"] = len(OutputParser.extract_file_operations(messages))
        summary["shell_commands"] = len(OutputParser.extract_shell_commands(messages))

        return summary


class ResponseFormatter:
    """Format Claude responses for Telegram display."""

    def __init__(self, max_message_length: int = 4000):
        """Initialize formatter."""
        self.max_message_length = max_message_length

    def format_response(self, content: str, include_metadata: bool = True) -> List[str]:
        """Format response content into Telegram messages."""
        if not content.strip():
            return ["_(Empty response)_"]

        # Split by code blocks first to preserve them
        parts = self._split_preserving_code_blocks(content)

        messages = []
        for part in parts:
            if len(part) <= self.max_message_length:
                messages.append(part)
            else:
                # Split long parts
                messages.extend(self._split_long_text(part))

        # Ensure we have at least one message
        if not messages:
            messages = ["_(No content to display)_"]

        return messages

    def _split_preserving_code_blocks(self, text: str) -> List[str]:
        """Split text while preserving code blocks."""
        parts = []
        current_part = ""
        in_code_block = False

        lines = text.split("\n")

        for line in lines:
            # Check for code block markers
            if line.strip().startswith("```"):
                in_code_block = not in_code_block

            line_with_newline = line + "\n"

            # If adding this line would exceed limit and we're not in a code block
            if (
                len(current_part + line_with_newline) > self.max_message_length
                and not in_code_block
                and current_part.strip()
            ):
                parts.append(current_part.rstrip())
                current_part = line_with_newline
            else:
                current_part += line_with_newline

        if current_part.strip():
            parts.append(current_part.rstrip())

        return parts

    def _split_long_text(self, text: str) -> List[str]:
        """Split text that's too long for a single message."""
        parts = []
        current = ""

        for char in text:
            if len(current + char) > self.max_message_length:
                if current:
                    parts.append(current)
                    current = char
                else:
                    # Single character somehow exceeds limit
                    parts.append(char)
                    current = ""
            else:
                current += char

        if current:
            parts.append(current)

        return parts

```

### claude/session.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 12,680 Ð±Ð°Ð¹Ñ‚

```python
"""Claude Code session management.

Features:
- Session state tracking
- Multi-project support
- Session persistence
- Cleanup policies
"""

import uuid
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
from typing import TYPE_CHECKING, Dict, List, Optional, Union

import structlog

from ..config.settings import Settings

if TYPE_CHECKING:
    from .integration import ClaudeResponse as CLIClaudeResponse
    from .sdk_integration import ClaudeResponse as SDKClaudeResponse

# Union type for both CLI and SDK responses
ClaudeResponse = Union["CLIClaudeResponse", "SDKClaudeResponse"]

logger = structlog.get_logger()


@dataclass
class ClaudeSession:
    """Claude Code session state."""

    session_id: str
    user_id: int
    project_path: Path
    created_at: datetime
    last_used: datetime
    total_cost: float = 0.0
    total_turns: int = 0
    message_count: int = 0
    tools_used: List[str] = field(default_factory=list)
    is_new_session: bool = False  # True if session hasn't been sent to Claude Code yet

    def is_expired(self, timeout_hours: int) -> bool:
        """Check if session has expired."""
        age = datetime.utcnow() - self.last_used
        return age > timedelta(hours=timeout_hours)

    def update_usage(self, response: ClaudeResponse) -> None:
        """Update session with usage from response."""
        self.last_used = datetime.utcnow()
        self.total_cost += response.cost
        self.total_turns += response.num_turns
        self.message_count += 1

        # Track unique tools
        if response.tools_used:
            for tool in response.tools_used:
                tool_name = tool.get("name")
                if tool_name and tool_name not in self.tools_used:
                    self.tools_used.append(tool_name)

    def to_dict(self) -> Dict:
        """Convert session to dictionary for storage."""
        return {
            "session_id": self.session_id,
            "user_id": self.user_id,
            "project_path": str(self.project_path),
            "created_at": self.created_at.isoformat(),
            "last_used": self.last_used.isoformat(),
            "total_cost": self.total_cost,
            "total_turns": self.total_turns,
            "message_count": self.message_count,
            "tools_used": self.tools_used,
        }

    @classmethod
    def from_dict(cls, data: Dict) -> "ClaudeSession":
        """Create session from dictionary."""
        return cls(
            session_id=data["session_id"],
            user_id=data["user_id"],
            project_path=Path(data["project_path"]),
            created_at=datetime.fromisoformat(data["created_at"]),
            last_used=datetime.fromisoformat(data["last_used"]),
            total_cost=data.get("total_cost", 0.0),
            total_turns=data.get("total_turns", 0),
            message_count=data.get("message_count", 0),
            tools_used=data.get("tools_used", []),
        )


class SessionStorage:
    """Abstract base class for session storage."""

    async def save_session(self, session: ClaudeSession) -> None:
        """Save session to storage."""
        raise NotImplementedError

    async def load_session(self, session_id: str) -> Optional[ClaudeSession]:
        """Load session from storage."""
        raise NotImplementedError

    async def delete_session(self, session_id: str) -> None:
        """Delete session from storage."""
        raise NotImplementedError

    async def get_user_sessions(self, user_id: int) -> List[ClaudeSession]:
        """Get all sessions for a user."""
        raise NotImplementedError

    async def get_all_sessions(self) -> List[ClaudeSession]:
        """Get all sessions."""
        raise NotImplementedError


class InMemorySessionStorage(SessionStorage):
    """In-memory session storage for development/testing."""

    def __init__(self):
        """Initialize in-memory storage."""
        self.sessions: Dict[str, ClaudeSession] = {}

    async def save_session(self, session: ClaudeSession) -> None:
        """Save session to memory."""
        self.sessions[session.session_id] = session
        logger.debug("Session saved to memory", session_id=session.session_id)

    async def load_session(self, session_id: str) -> Optional[ClaudeSession]:
        """Load session from memory."""
        session = self.sessions.get(session_id)
        if session:
            logger.debug("Session loaded from memory", session_id=session_id)
        return session

    async def delete_session(self, session_id: str) -> None:
        """Delete session from memory."""
        if session_id in self.sessions:
            del self.sessions[session_id]
            logger.debug("Session deleted from memory", session_id=session_id)

    async def get_user_sessions(self, user_id: int) -> List[ClaudeSession]:
        """Get all sessions for a user."""
        return [
            session for session in self.sessions.values() if session.user_id == user_id
        ]

    async def get_all_sessions(self) -> List[ClaudeSession]:
        """Get all sessions."""
        return list(self.sessions.values())


class SessionManager:
    """Manage Claude Code sessions."""

    def __init__(self, config: Settings, storage: SessionStorage):
        """Initialize session manager."""
        self.config = config
        self.storage = storage
        self.active_sessions: Dict[str, ClaudeSession] = {}

    async def get_or_create_session(
        self,
        user_id: int,
        project_path: Path,
        session_id: Optional[str] = None,
    ) -> ClaudeSession:
        """Get existing session or create new one."""
        logger.info(
            "Getting or creating session",
            user_id=user_id,
            project_path=str(project_path),
            session_id=session_id,
        )

        # Check for existing session
        if session_id and session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            if not session.is_expired(self.config.session_timeout_hours):
                logger.debug("Using active session", session_id=session_id)
                return session

        # Try to load from storage
        if session_id:
            session = await self.storage.load_session(session_id)
            if session and not session.is_expired(self.config.session_timeout_hours):
                self.active_sessions[session_id] = session
                logger.info("Loaded session from storage", session_id=session_id)
                return session

        # Check user session limit
        user_sessions = await self._get_user_sessions(user_id)
        if len(user_sessions) >= self.config.max_sessions_per_user:
            # Remove oldest session
            oldest = min(user_sessions, key=lambda s: s.last_used)
            await self.remove_session(oldest.session_id)
            logger.info(
                "Removed oldest session due to limit",
                removed_session_id=oldest.session_id,
                user_id=user_id,
            )

        # Create new session with temporary ID until Claude Code provides real session_id
        temp_session_id = f"temp_{str(uuid.uuid4())}"
        new_session = ClaudeSession(
            session_id=temp_session_id,
            user_id=user_id,
            project_path=project_path,
            created_at=datetime.utcnow(),
            last_used=datetime.utcnow(),
        )

        # Mark as new session (not from Claude Code yet)
        new_session.is_new_session = True

        # Save to storage
        await self.storage.save_session(new_session)
        self.active_sessions[new_session.session_id] = new_session

        logger.info(
            "Created new session",
            session_id=new_session.session_id,
            user_id=user_id,
            project_path=str(project_path),
        )

        return new_session

    async def update_session(self, session_id: str, response: ClaudeResponse) -> None:
        """Update session with response data."""
        if session_id in self.active_sessions:
            session = self.active_sessions[session_id]
            old_session_id = session.session_id

            # For new sessions, update to Claude's actual session ID
            if (
                hasattr(session, "is_new_session")
                and session.is_new_session
                and response.session_id
            ):
                # Remove old temporary session from memory
                del self.active_sessions[old_session_id]
                
                # Update session ID in database instead of deleting
                if hasattr(self.storage, 'update_session_id'):
                    await self.storage.update_session_id(old_session_id, response.session_id)
                else:
                    # Fallback to delete for storage implementations that don't support update
                    await self.storage.delete_session(old_session_id)

                # Update session with Claude's session ID
                session.session_id = response.session_id
                session.is_new_session = False

                # Store with new session ID
                self.active_sessions[response.session_id] = session

                logger.info(
                    "Session ID updated from temporary to Claude session ID",
                    old_session_id=old_session_id,
                    new_session_id=response.session_id,
                )
            elif hasattr(session, "is_new_session") and session.is_new_session:
                # Mark as no longer new even if no session_id from Claude
                session.is_new_session = False

            session.update_usage(response)

            # Persist to storage
            await self.storage.save_session(session)

            logger.debug(
                "Session updated",
                session_id=session.session_id,
                total_cost=session.total_cost,
                message_count=session.message_count,
            )

    async def remove_session(self, session_id: str) -> None:
        """Remove session."""
        if session_id in self.active_sessions:
            del self.active_sessions[session_id]

        await self.storage.delete_session(session_id)
        logger.info("Session removed", session_id=session_id)

    async def cleanup_expired_sessions(self) -> int:
        """Remove expired sessions."""
        logger.info("Starting session cleanup")

        all_sessions = await self.storage.get_all_sessions()
        expired_count = 0

        for session in all_sessions:
            if session.is_expired(self.config.session_timeout_hours):
                await self.remove_session(session.session_id)
                expired_count += 1

        logger.info("Session cleanup completed", expired_sessions=expired_count)
        return expired_count

    async def _get_user_sessions(self, user_id: int) -> List[ClaudeSession]:
        """Get all sessions for a user."""
        return await self.storage.get_user_sessions(user_id)

    async def get_session_info(self, session_id: str) -> Optional[Dict]:
        """Get session information."""
        session = self.active_sessions.get(session_id)

        if not session:
            session = await self.storage.load_session(session_id)

        if session:
            return {
                "session_id": session.session_id,
                "project": str(session.project_path),
                "created": session.created_at.isoformat(),
                "last_used": session.last_used.isoformat(),
                "cost": session.total_cost,
                "turns": session.total_turns,
                "messages": session.message_count,
                "tools_used": session.tools_used,
                "expired": session.is_expired(self.config.session_timeout_hours),
            }

        return None

    async def get_user_session_summary(self, user_id: int) -> Dict:
        """Get summary of user's sessions."""
        sessions = await self._get_user_sessions(user_id)

        total_cost = sum(s.total_cost for s in sessions)
        total_messages = sum(s.message_count for s in sessions)
        active_sessions = [
            s for s in sessions if not s.is_expired(self.config.session_timeout_hours)
        ]

        return {
            "user_id": user_id,
            "total_sessions": len(sessions),
            "active_sessions": len(active_sessions),
            "total_cost": total_cost,
            "total_messages": total_messages,
            "projects": list(set(str(s.project_path) for s in sessions)),
        }

```

### claude/integration.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 21,962 Ð±Ð°Ð¹Ñ‚

```python
"""Claude Code subprocess management.

Features:
- Async subprocess execution
- Stream handling
- Timeout management
- Error recovery
"""

import asyncio
import json
import uuid
from asyncio.subprocess import Process
from collections import deque
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, AsyncIterator, Callable, Dict, List, Optional

import structlog

from ..config.settings import Settings
from .exceptions import (
    ClaudeParsingError,
    ClaudeProcessError,
    ClaudeTimeoutError,
)

logger = structlog.get_logger()


@dataclass
class ClaudeResponse:
    """Response from Claude Code."""

    content: str
    session_id: str
    cost: float
    duration_ms: int
    num_turns: int
    is_error: bool = False
    error_type: Optional[str] = None
    tools_used: List[Dict[str, Any]] = field(default_factory=list)


@dataclass
class StreamUpdate:
    """Enhanced streaming update from Claude with richer context."""

    type: str  # 'assistant', 'user', 'system', 'result', 'tool_result', 'error', 'progress'
    content: Optional[str] = None
    tool_calls: Optional[List[Dict]] = None
    metadata: Optional[Dict] = None

    # Enhanced fields for better tracking
    timestamp: Optional[str] = None
    session_context: Optional[Dict] = None
    progress: Optional[Dict] = None
    error_info: Optional[Dict] = None

    # Execution tracking
    execution_id: Optional[str] = None
    parent_message_id: Optional[str] = None

    def is_error(self) -> bool:
        """Check if this update represents an error."""
        return self.type == "error" or (
            self.metadata and self.metadata.get("is_error", False)
        )

    def get_tool_names(self) -> List[str]:
        """Extract tool names from tool calls."""
        if not self.tool_calls:
            return []
        return [call.get("name") for call in self.tool_calls if call.get("name")]

    def get_progress_percentage(self) -> Optional[int]:
        """Get progress percentage if available."""
        if self.progress:
            return self.progress.get("percentage")
        return None

    def get_error_message(self) -> Optional[str]:
        """Get error message if this is an error update."""
        if self.error_info:
            return self.error_info.get("message")
        elif self.is_error() and self.content:
            return self.content
        return None


class ClaudeProcessManager:
    """Manage Claude Code subprocess execution with memory optimization."""

    def __init__(self, config: Settings):
        """Initialize process manager with configuration."""
        self.config = config
        self.active_processes: Dict[str, Process] = {}

        # Memory optimization settings
        self.max_message_buffer = 1000  # Limit message history
        self.streaming_buffer_size = (
            65536  # 64KB streaming buffer for large JSON messages
        )

    async def execute_command(
        self,
        prompt: str,
        working_directory: Path,
        session_id: Optional[str] = None,
        continue_session: bool = False,
        stream_callback: Optional[Callable[[StreamUpdate], None]] = None,
    ) -> ClaudeResponse:
        """Execute Claude Code command."""
        # Build command
        cmd = self._build_command(prompt, session_id, continue_session)

        # Create process ID for tracking
        process_id = str(uuid.uuid4())

        logger.info(
            "Starting Claude Code process",
            process_id=process_id,
            working_directory=str(working_directory),
            session_id=session_id,
            continue_session=continue_session,
        )

        try:
            # Start process
            process = await self._start_process(cmd, working_directory)
            self.active_processes[process_id] = process

            # Handle output with timeout
            result = await asyncio.wait_for(
                self._handle_process_output(process, stream_callback),
                timeout=self.config.claude_timeout_seconds,
            )

            logger.info(
                "Claude Code process completed successfully",
                process_id=process_id,
                cost=result.cost,
                duration_ms=result.duration_ms,
            )

            return result

        except asyncio.TimeoutError:
            # Kill process on timeout
            if process_id in self.active_processes:
                self.active_processes[process_id].kill()
                await self.active_processes[process_id].wait()

            logger.error(
                "Claude Code process timed out",
                process_id=process_id,
                timeout_seconds=self.config.claude_timeout_seconds,
            )

            raise ClaudeTimeoutError(
                f"Claude Code timed out after {self.config.claude_timeout_seconds}s"
            )

        except Exception as e:
            logger.error(
                "Claude Code process failed",
                process_id=process_id,
                error=str(e),
            )
            raise

        finally:
            # Clean up
            if process_id in self.active_processes:
                del self.active_processes[process_id]

    def _build_command(
        self, prompt: str, session_id: Optional[str], continue_session: bool
    ) -> List[str]:
        """Build Claude Code command with arguments."""
        cmd = [self.config.claude_binary_path or "claude"]

        if continue_session and not prompt:
            # Continue existing session without new prompt
            cmd.extend(["--continue"])
            if session_id:
                cmd.extend(["--resume", session_id])
        elif session_id and prompt and continue_session:
            # Follow-up message in existing session - use resume with new prompt
            cmd.extend(["--resume", session_id, "-p", prompt])
        elif prompt:
            # New session with prompt (including new sessions with session_id)
            cmd.extend(["-p", prompt])
        else:
            # This shouldn't happen, but fallback to new session
            cmd.extend(["-p", ""])

        # Always use streaming JSON for real-time updates
        cmd.extend(["--output-format", "stream-json"])

        # stream-json requires --verbose when using --print mode
        cmd.extend(["--verbose"])

        # Add safety limits
        cmd.extend(["--max-turns", str(self.config.claude_max_turns)])

        # Add allowed tools if configured
        if (
            hasattr(self.config, "claude_allowed_tools")
            and self.config.claude_allowed_tools
        ):
            cmd.extend(["--allowedTools", ",".join(self.config.claude_allowed_tools)])

        logger.debug("Built Claude Code command", command=cmd)
        return cmd

    async def _start_process(self, cmd: List[str], cwd: Path) -> Process:
        """Start Claude Code subprocess."""
        return await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            cwd=str(cwd),
            # Limit memory usage
            limit=1024 * 1024 * 512,  # 512MB
        )

    async def _handle_process_output(
        self, process: Process, stream_callback: Optional[Callable]
    ) -> ClaudeResponse:
        """Memory-optimized output handling with bounded buffers."""
        message_buffer = deque(maxlen=self.max_message_buffer)
        result = None
        parsing_errors = []

        async for line in self._read_stream_bounded(process.stdout):
            try:
                msg = json.loads(line)

                # Enhanced validation
                if not self._validate_message_structure(msg):
                    parsing_errors.append(f"Invalid message structure: {line[:100]}")
                    continue

                message_buffer.append(msg)

                # Process immediately to avoid memory buildup
                update = self._parse_stream_message(msg)
                if update and stream_callback:
                    try:
                        await stream_callback(update)
                    except Exception as e:
                        logger.warning(
                            "Stream callback failed",
                            error=str(e),
                            update_type=update.type,
                        )

                # Check for final result
                if msg.get("type") == "result":
                    logger.debug("Found result message", message_keys=list(msg.keys()), message_sample=str(msg)[:500])
                    result = msg

            except json.JSONDecodeError as e:
                parsing_errors.append(f"JSON decode error: {e}")
                logger.warning(
                    "Failed to parse JSON line", line=line[:200], error=str(e)
                )
                continue

        # Enhanced error reporting
        if parsing_errors:
            logger.warning(
                "Parsing errors encountered",
                count=len(parsing_errors),
                errors=parsing_errors[:5],
            )

        # Wait for process to complete
        return_code = await process.wait()

        if return_code != 0:
            stderr = await process.stderr.read()
            error_msg = stderr.decode("utf-8", errors="replace")
            logger.error(
                "Claude Code process failed",
                return_code=return_code,
                stderr=error_msg,
            )

            # Check for specific error types
            if "usage limit reached" in error_msg.lower():
                # Extract reset time if available
                import re

                time_match = re.search(
                    r"reset at (\d+[apm]+)", error_msg, re.IGNORECASE
                )
                timezone_match = re.search(r"\(([^)]+)\)", error_msg)

                reset_time = time_match.group(1) if time_match else "later"
                timezone = timezone_match.group(1) if timezone_match else ""

                user_friendly_msg = (
                    f"â±ï¸ **Claude AI Usage Limit Reached**\n\n"
                    f"You've reached your Claude AI usage limit for this period.\n\n"
                    f"**When will it reset?**\n"
                    f"Your limit will reset at **{reset_time}**"
                    f"{f' ({timezone})' if timezone else ''}\n\n"
                    f"**What you can do:**\n"
                    f"â€¢ Wait for the limit to reset automatically\n"
                    f"â€¢ Try again after the reset time\n"
                    f"â€¢ Use simpler requests that require less processing\n"
                    f"â€¢ Contact support if you need a higher limit"
                )

                raise ClaudeProcessError(user_friendly_msg)

            # Generic error handling for other cases
            raise ClaudeProcessError(
                f"Claude Code exited with code {return_code}: {error_msg}"
            )

        if not result:
            logger.error("No result message received from Claude Code")
            raise ClaudeParsingError("No result message received from Claude Code")

        return self._parse_result(result, list(message_buffer))

    async def _read_stream(self, stream) -> AsyncIterator[str]:
        """Read lines from stream."""
        while True:
            line = await stream.readline()
            if not line:
                break
            yield line.decode("utf-8", errors="replace").strip()

    async def _read_stream_bounded(self, stream) -> AsyncIterator[str]:
        """Read stream with memory bounds to prevent excessive memory usage."""
        buffer = b""

        while True:
            chunk = await stream.read(self.streaming_buffer_size)
            if not chunk:
                break

            buffer += chunk

            # Process complete lines
            while b"\n" in buffer:
                line, buffer = buffer.split(b"\n", 1)
                yield line.decode("utf-8", errors="replace").strip()

        # Process remaining buffer
        if buffer:
            yield buffer.decode("utf-8", errors="replace").strip()

    def _parse_stream_message(self, msg: Dict) -> Optional[StreamUpdate]:
        """Enhanced parsing with comprehensive message type support."""
        msg_type = msg.get("type")

        # Add support for more message types
        if msg_type == "assistant":
            return self._parse_assistant_message(msg)
        elif msg_type == "tool_result":
            return self._parse_tool_result_message(msg)
        elif msg_type == "user":
            return self._parse_user_message(msg)
        elif msg_type == "system":
            return self._parse_system_message(msg)
        elif msg_type == "error":
            return self._parse_error_message(msg)
        elif msg_type == "progress":
            return self._parse_progress_message(msg)

        # Unknown message type - log and continue
        logger.debug("Unknown message type", msg_type=msg_type, msg=msg)
        return None

    def _parse_assistant_message(self, msg: Dict) -> StreamUpdate:
        """Parse assistant message with enhanced context."""
        message = msg.get("message", {})
        content_blocks = message.get("content", [])

        # Get text content
        text_content = []
        tool_calls = []

        for block in content_blocks:
            if block.get("type") == "text":
                text_content.append(block.get("text", ""))
            elif block.get("type") == "tool_use":
                tool_calls.append(
                    {
                        "name": block.get("name"),
                        "input": block.get("input", {}),
                        "id": block.get("id"),
                    }
                )

        return StreamUpdate(
            type="assistant",
            content="\n".join(text_content) if text_content else None,
            tool_calls=tool_calls if tool_calls else None,
            timestamp=msg.get("timestamp"),
            session_context={"session_id": msg.get("session_id")},
            execution_id=msg.get("id"),
        )

    def _parse_tool_result_message(self, msg: Dict) -> StreamUpdate:
        """Parse tool execution results."""
        result = msg.get("result", {})
        content = result.get("content") if isinstance(result, dict) else str(result)

        return StreamUpdate(
            type="tool_result",
            content=content,
            metadata={
                "tool_use_id": msg.get("tool_use_id"),
                "is_error": (
                    result.get("is_error", False) if isinstance(result, dict) else False
                ),
                "execution_time_ms": (
                    result.get("execution_time_ms")
                    if isinstance(result, dict)
                    else None
                ),
            },
            timestamp=msg.get("timestamp"),
            session_context={"session_id": msg.get("session_id")},
            error_info={"message": content} if result.get("is_error", False) else None,
        )

    def _parse_user_message(self, msg: Dict) -> StreamUpdate:
        """Parse user message."""
        message = msg.get("message", {})
        content = message.get("content", "")

        # Handle both string and block format content
        if isinstance(content, list):
            text_parts = []
            for block in content:
                if isinstance(block, dict) and block.get("type") == "text":
                    text_parts.append(block.get("text", ""))
                elif isinstance(block, str):
                    text_parts.append(block)
            content = "\n".join(text_parts)

        return StreamUpdate(
            type="user",
            content=content if content else None,
            timestamp=msg.get("timestamp"),
            session_context={"session_id": msg.get("session_id")},
        )

    def _parse_system_message(self, msg: Dict) -> StreamUpdate:
        """Parse system messages including init and other subtypes."""
        subtype = msg.get("subtype")

        if subtype == "init":
            # Initial system message with available tools
            return StreamUpdate(
                type="system",
                metadata={
                    "subtype": "init",
                    "tools": msg.get("tools", []),
                    "mcp_servers": msg.get("mcp_servers", []),
                    "model": msg.get("model"),
                    "cwd": msg.get("cwd"),
                    "permission_mode": msg.get("permissionMode"),
                },
                session_context={"session_id": msg.get("session_id")},
            )
        else:
            # Other system messages
            return StreamUpdate(
                type="system",
                content=msg.get("message", str(msg)),
                metadata={"subtype": subtype},
                timestamp=msg.get("timestamp"),
                session_context={"session_id": msg.get("session_id")},
            )

    def _parse_error_message(self, msg: Dict) -> StreamUpdate:
        """Parse error messages."""
        error_message = msg.get("message", msg.get("error", str(msg)))

        return StreamUpdate(
            type="error",
            content=error_message,
            error_info={
                "message": error_message,
                "code": msg.get("code"),
                "subtype": msg.get("subtype"),
            },
            timestamp=msg.get("timestamp"),
            session_context={"session_id": msg.get("session_id")},
        )

    def _parse_progress_message(self, msg: Dict) -> StreamUpdate:
        """Parse progress update messages."""
        return StreamUpdate(
            type="progress",
            content=msg.get("message", msg.get("status")),
            progress={
                "percentage": msg.get("percentage"),
                "step": msg.get("step"),
                "total_steps": msg.get("total_steps"),
                "operation": msg.get("operation"),
            },
            timestamp=msg.get("timestamp"),
            session_context={"session_id": msg.get("session_id")},
        )

    def _validate_message_structure(self, msg: Dict) -> bool:
        """Validate message has required structure."""
        required_fields = ["type"]
        return all(field in msg for field in required_fields)

    def _parse_result(self, result: Dict, messages: List[Dict]) -> ClaudeResponse:
        """Parse final result message."""
        # Debug: log the result structure
        logger.debug("Parsing Claude result", result_keys=list(result.keys()), result_content=result.get("result", "NO_RESULT"))

        # Extract actual content from messages if result field is empty
        content = result.get("result", "")
        if not content:
            # Look for assistant messages with actual content
            for msg in reversed(messages):  # Start from the last message
                if msg.get("type") == "assistant":
                    message = msg.get("message", {})
                    if isinstance(message.get("content"), list):
                        for block in message["content"]:
                            if block.get("type") == "text" and block.get("text"):
                                content = block["text"]
                                break
                    elif isinstance(message.get("content"), str):
                        content = message["content"]

                    if content:
                        break

        # Extract tools used from messages
        tools_used = []
        for msg in messages:
            if msg.get("type") == "assistant":
                message = msg.get("message", {})
                for block in message.get("content", []):
                    if block.get("type") == "tool_use":
                        tools_used.append(
                            {
                                "name": block.get("name"),
                                "timestamp": msg.get("timestamp"),
                            }
                        )

        # Check if this is an error due to max turns
        is_error = result.get("is_error", False)
        error_type = result.get("subtype") if is_error else None

        # Handle max_turns specially - it's not really an error, just a limit
        if result.get("subtype") == "error_max_turns":
            logger.info("Claude reached max turns limit", num_turns=result.get("num_turns", 0))
            if not content:
                content = "Claude Ð´Ð¾ÑÑÐ³ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ñ— ÐºÑ–Ð»ÑŒÐºÐ¾ÑÑ‚Ñ– Ñ…Ð¾Ð´Ñ–Ð², Ð°Ð»Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ð² Ð¾Ð±Ñ€Ð¾Ð±ÐºÑƒ."

        return ClaudeResponse(
            content=content,
            session_id=result.get("session_id", ""),
            cost=result.get("total_cost_usd", result.get("cost_usd", 0.0)),
            duration_ms=result.get("duration_ms", 0),
            num_turns=result.get("num_turns", 0),
            is_error=is_error,
            error_type=error_type,
            tools_used=tools_used,
        )

    async def kill_all_processes(self) -> None:
        """Kill all active processes."""
        logger.info(
            "Killing all active Claude processes", count=len(self.active_processes)
        )

        for process_id, process in self.active_processes.items():
            try:
                process.kill()
                await process.wait()
                logger.info("Killed Claude process", process_id=process_id)
            except Exception as e:
                logger.warning(
                    "Failed to kill process", process_id=process_id, error=str(e)
                )

        self.active_processes.clear()

    def get_active_process_count(self) -> int:
        """Get number of active processes."""
        return len(self.active_processes)

```

### localization/storage.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 3,623 Ð±Ð°Ð¹Ñ‚

```python
"""User language preference storage."""

import asyncio
from typing import Dict, Optional

import structlog

from ..storage.facade import Storage

logger = structlog.get_logger()


class UserLanguageStorage:
    """Manages user language preferences."""

    def __init__(self, storage: Storage):
        """Initialize with storage facade."""
        self.storage = storage
        self._cache: Dict[int, str] = {}

    async def get_user_language(self, user_id: int) -> Optional[str]:
        """Get user's preferred language.
        
        Args:
            user_id: Telegram user ID
            
        Returns:
            Language code or None if not set
        """
        # Check cache first
        if user_id in self._cache:
            return self._cache[user_id]

        # Try to get from database
        try:
            language = await self._get_from_database(user_id)
            if language:
                self._cache[user_id] = language
            return language
        except Exception as e:
            logger.error("Failed to get user language", user_id=user_id, error=str(e))
            return None

    async def set_user_language(self, user_id: int, language: str) -> bool:
        """Set user's preferred language.
        
        Args:
            user_id: Telegram user ID
            language: Language code to set
            
        Returns:
            True if successfully set
        """
        try:
            success = await self._set_in_database(user_id, language)
            if success:
                self._cache[user_id] = language
            return success
        except Exception as e:
            logger.error("Failed to set user language", user_id=user_id, language=language, error=str(e))
            return False

    async def _get_from_database(self, user_id: int) -> Optional[str]:
        """Get language from database."""
        # For now, use a simple approach with database queries
        # This can be expanded to use the existing storage system
        async with self.storage.db_manager.get_connection() as connection:
            try:
                cursor = await connection.execute(
                    "SELECT language FROM user_languages WHERE user_id = ?",
                    (user_id,)
                )
                row = await cursor.fetchone()
                return row[0] if row else None
            except Exception:
                # If table doesn't exist, create it
                await self._create_table_if_not_exists(connection)
                return None

    async def _set_in_database(self, user_id: int, language: str) -> bool:
        """Set language in database."""
        async with self.storage.db_manager.get_connection() as connection:
            try:
                await self._create_table_if_not_exists(connection)
                await connection.execute(
                    "INSERT OR REPLACE INTO user_languages (user_id, language) VALUES (?, ?)",
                    (user_id, language)
                )
                await connection.commit()
                return True
            except Exception as e:
                logger.error("Database error", error=str(e))
                return False

    async def _create_table_if_not_exists(self, connection) -> None:
        """Create user_languages table if it doesn't exist."""
        await connection.execute("""
            CREATE TABLE IF NOT EXISTS user_languages (
                user_id INTEGER PRIMARY KEY,
                language TEXT NOT NULL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)

```

### localization/__init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 194 Ð±Ð°Ð¹Ñ‚

```python
"""Localization module for multi-language support."""

from .manager import LocalizationManager
from .storage import UserLanguageStorage

__all__ = ["LocalizationManager", "UserLanguageStorage"]

```

### localization/manager.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 7,361 Ð±Ð°Ð¹Ñ‚

```python
"""Localization manager for handling translations."""

import json
import os
import threading
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional

import structlog

logger = structlog.get_logger()


class LocalizationManager:
    """Manages translations and localization."""

    def __init__(self, translations_dir: str = "translations"):
        """Initialize the localization manager.
        
        Args:
            translations_dir: Directory containing translation files
        """
        self.translations_dir = Path(__file__).parent / translations_dir
        self.translations: Dict[str, Dict[str, Any]] = {}
        self.default_language = "en"
        self.missing_keys: Dict[str, Dict[str, Any]] = {}
        self._lock = threading.Lock()
        self._load_translations()

    def _load_translations(self) -> None:
        """Load all translation files."""
        if not self.translations_dir.exists():
            logger.warning("Translations directory not found", dir=self.translations_dir)
            return

        for file_path in self.translations_dir.glob("*.json"):
            language_code = file_path.stem
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    self.translations[language_code] = json.load(f)
                logger.info("Loaded translations", language=language_code, file=str(file_path))
            except Exception as e:
                logger.error("Failed to load translation file", file=str(file_path), error=str(e))

    def get(self, key: str, language: str = None, **kwargs) -> str:
        """Get translated text for the given key.
        
        Args:
            key: Translation key (supports dot notation for nested keys)
            language: Language code (defaults to default_language)
            **kwargs: Variables to format into the translation
            
        Returns:
            Translated and formatted text
        """
        if language is None:
            language = self.default_language

        # Get the translation from the specified language or fallback to default
        translation_dict = self.translations.get(language, self.translations.get(self.default_language, {}))
        
        # Navigate nested keys using dot notation
        keys = key.split(".")
        value = translation_dict
        
        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                # If key not found, track it and return the key itself as fallback
                self._track_missing_key(key, language)
                logger.warning("Translation key not found", key=key, language=language)
                return key

        # Format the translation with provided variables
        if isinstance(value, str) and kwargs:
            try:
                return value.format(**kwargs)
            except KeyError as e:
                logger.error("Missing variable in translation", key=key, variable=str(e))
                return value
        
        return str(value)

    def get_available_languages(self) -> Dict[str, str]:
        """Get list of available languages.
        
        Returns:
            Dictionary mapping language codes to language names
        """
        languages = {}
        for lang_code in self.translations:
            lang_info = self.translations[lang_code].get("_meta", {})
            languages[lang_code] = lang_info.get("name", lang_code.upper())
        
        return languages

    def is_language_available(self, language: str) -> bool:
        """Check if a language is available.
        
        Args:
            language: Language code to check
            
        Returns:
            True if language is available
        """
        return language in self.translations

    def _track_missing_key(self, key: str, language: str) -> None:
        """Track missing translation keys with frequency and timestamp.
        
        Args:
            key: The missing translation key
            language: The language code that was requested
        """
        with self._lock:
            key_id = f"{key}:{language}"
            current_time = datetime.now().isoformat()
            
            if key_id in self.missing_keys:
                self.missing_keys[key_id]["frequency"] += 1
                self.missing_keys[key_id]["last_accessed"] = current_time
            else:
                self.missing_keys[key_id] = {
                    "key": key,
                    "language": language,
                    "frequency": 1,
                    "first_accessed": current_time,
                    "last_accessed": current_time
                }

    def dump_missing_translations(self, output_file: str = "missing_translations.json") -> None:
        """Export missing translation keys to a JSON file.
        
        Args:
            output_file: Path to the output JSON file
        """
        with self._lock:
            # Create output data structure
            output_data = {
                "generated_at": datetime.now().isoformat(),
                "total_missing_keys": len(self.missing_keys),
                "missing_keys": list(self.missing_keys.values()),
                "summary_by_language": {}
            }
            
            # Generate summary by language
            for key_data in self.missing_keys.values():
                lang = key_data["language"]
                if lang not in output_data["summary_by_language"]:
                    output_data["summary_by_language"][lang] = {
                        "count": 0,
                        "total_frequency": 0
                    }
                output_data["summary_by_language"][lang]["count"] += 1
                output_data["summary_by_language"][lang]["total_frequency"] += key_data["frequency"]
            
            # Write to file with thread-safe access
            try:
                output_path = Path(output_file)
                output_path.parent.mkdir(parents=True, exist_ok=True)
                
                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(output_data, f, indent=2, ensure_ascii=False)
                
                logger.info("Missing translations exported", 
                           file=str(output_path), 
                           total_keys=len(self.missing_keys))
                           
            except Exception as e:
                logger.error("Failed to export missing translations", 
                           file=output_file, 
                           error=str(e))
                raise

    def get_missing_keys_summary(self) -> Dict[str, Any]:
        """Get summary of missing translation keys.
        
        Returns:
            Dictionary with summary information about missing keys
        """
        with self._lock:
            return {
                "total_missing_keys": len(self.missing_keys),
                "languages_affected": list(set(data["language"] for data in self.missing_keys.values())),
                "most_frequent_keys": sorted(
                    self.missing_keys.values(),
                    key=lambda x: x["frequency"],
                    reverse=True
                )[:10]
            }

```

### localization/util.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 2,534 Ð±Ð°Ð¹Ñ‚

```python
"""Centralized localization utilities with proper error handling."""

from typing import Any, Dict, Optional
from telegram import Update
from telegram.ext import ContextTypes

from .helpers import get_user_text
from .manager import LocalizationManager
from .storage import UserLanguageStorage


async def t(context: ContextTypes.DEFAULT_TYPE, user_id: int, key: str, **kwargs) -> str:
    """Get localized text with proper error handling and fallbacks.
    
    Args:
        context: Bot context containing localization services
        user_id: Telegram user ID
        key: Translation key
        **kwargs: Variables to format into the translation
        
    Returns:
        Localized text or fallback key in brackets if translation fails
    """
    localization: Optional[LocalizationManager] = context.bot_data.get("localization")
    user_language_storage: Optional[UserLanguageStorage] = context.bot_data.get("user_language_storage")
    
    if not localization or not user_language_storage:
        return f"[{key}]"
    
    try:
        return await get_user_text(localization, user_language_storage, user_id, key, **kwargs)
    except Exception:
        return f"[{key}]"


def t_sync(context: ContextTypes.DEFAULT_TYPE, key: str, language: Optional[str] = None, **kwargs) -> str:
    """Get localized text synchronously for bot startup/static strings.
    
    Args:
        context: Bot context containing localization services
        key: Translation key
        language: Language code, falls back to default if None
        **kwargs: Variables to format into the translation
        
    Returns:
        Localized text or fallback key in brackets if translation fails
    """
    localization: Optional[LocalizationManager] = context.bot_data.get("localization")
    
    if not localization:
        return f"[{key}]"
    
    try:
        return localization.get(key, language=language, **kwargs)
    except Exception:
        return f"[{key}]"


def get_user_id(update: Update) -> Optional[int]:
    """Safely get user ID from update.
    
    Args:
        update: Telegram update object
        
    Returns:
        User ID or None if not available
    """
    if update.effective_user:
        return update.effective_user.id
    return None


def get_effective_message(update: Update):
    """Safely get effective message from update.
    
    Args:
        update: Telegram update object
        
    Returns:
        Message object or None if not available
    """
    return update.effective_message

```

### localization/helpers.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 933 Ð±Ð°Ð¹Ñ‚

```python
"""Helper functions for localization."""

from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from .manager import LocalizationManager
    from .storage import UserLanguageStorage


async def get_user_text(
    localization: "LocalizationManager",
    user_lang_storage: "UserLanguageStorage", 
    user_id: int,
    key: str,
    **kwargs
) -> str:
    """Get localized text for a specific user.
    
    Args:
        localization: Localization manager instance
        user_lang_storage: User language storage instance
        user_id: Telegram user ID
        key: Translation key
        **kwargs: Variables to format into the translation
        
    Returns:
        Localized text
    """
    # Get user's preferred language
    user_language = await user_lang_storage.get_user_language(user_id)
    
    # Use the user's language or fall back to default
    return localization.get(key, language=user_language, **kwargs)

```

### localization/translations/uk.json

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 63,776 Ð±Ð°Ð¹Ñ‚

```json
{
  "_meta": {
    "name": "Ð£ÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ°",
    "code": "uk"
  },
  "mcp": {
    "errors": {
      "system_not_available": "ðŸ”§ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° MCP Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ.",
      "add_failed": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð´Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ ÑÐµÑ€Ð²ÐµÑ€Ð°: {error}",
      "list_failed": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð½Ñ ÑÐ¿Ð¸ÑÐºÑƒ ÑÐµÑ€Ð²ÐµÑ€Ñ–Ð²: {error}",
      "select_failed": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð¸Ð±Ð¾Ñ€Ñƒ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ: {error}",
      "ask_failed": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ: {error}",
      "remove_failed": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð¸Ð´Ð°Ð»ÐµÐ½Ð½Ñ ÑÐµÑ€Ð²ÐµÑ€Ð°: {error}",
      "status_failed": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð½Ñ ÑÑ‚Ð°Ñ‚ÑƒÑÑƒ: {error}",
      "callback_failed": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸ MCP. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·."
    },
    "list": {
      "title": "ðŸ“‹ MCP Ð¡ÐµÑ€Ð²ÐµÑ€Ð¸:",
      "no_servers": "ðŸ”§ Ð£ Ð²Ð°Ñ Ñ‰Ðµ Ð½ÐµÐ¼Ð°Ñ” Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð¸Ñ… MCP ÑÐµÑ€Ð²ÐµÑ€Ñ–Ð².\n\nMCP (Model Context Protocol) Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” Claude Ð¿Ñ€Ð°Ñ†ÑŽÐ²Ð°Ñ‚Ð¸ Ð· Ð·Ð¾Ð²Ð½Ñ–ÑˆÐ½Ñ–Ð¼Ð¸ Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸ Ñ‚Ð° Ð´Ð¶ÐµÑ€ÐµÐ»Ð°Ð¼Ð¸ Ð´Ð°Ð½Ð¸Ñ….\n\n**ÐŸÐ¾Ð¿ÑƒÐ»ÑÑ€Ð½Ñ– ÑÐµÑ€Ð²ÐµÑ€Ð¸:**\nâ€¢ GitHub - Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ð´Ð¾ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ñ—Ð²\nâ€¢ File System - Ñ€Ð¾Ð±Ð¾Ñ‚Ð° Ð· Ñ„Ð°Ð¹Ð»Ð°Ð¼Ð¸\nâ€¢ PostgreSQL - Ð·Ð°Ð¿Ð¸Ñ‚Ð¸ Ð´Ð¾ Ð‘Ð”\nâ€¢ Git - ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–ÑÐ¼Ð¸",
      "status_active": "Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¾",
      "status_error": "Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° - {error}",
      "status_disabled": "Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾",
      "status_inactive": "Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: Ð½Ðµ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹",
      "last_used": "ÐžÑÑ‚Ð°Ð½Ð½Ñ” Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ: {time}"
    },
    "add": {
      "select_type": "ðŸ”§ **Ð”Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ MCP ÑÐµÑ€Ð²ÐµÑ€Ð°**\n\nÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ Ñ‚Ð¸Ð¿ ÑÐµÑ€Ð²ÐµÑ€Ð°, ÑÐºÐ¸Ð¹ Ñ…Ð¾Ñ‡ÐµÑ‚Ðµ Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚Ð¸:",
      "invalid_type": "âŒ ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¸Ð¹ Ñ‚Ð¸Ð¿ ÑÐµÑ€Ð²ÐµÑ€Ð°: {server_type}",
      "quick_not_supported": "âš ï¸ Ð¨Ð²Ð¸Ð´ÐºÐµ Ð´Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ Ð´Ð»Ñ {server_type} Ð½Ðµ Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÑ”Ñ‚ÑŒÑÑ.\n\nÐ’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ Ñ–Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹ Ð¼Ð°Ð¹ÑÑ‚ÐµÑ€:",
      "wizard": {
        "title": "ðŸ”§ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ {server_type}",
        "step": "ÐšÑ€Ð¾Ðº {current} Ð· {total}",
        "enter_value": "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ {field_name}:",
        "invalid_input": "âŒ ÐÐµÐ²Ñ–Ñ€Ð½Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ. {error}",
        "success": "âœ… Ð¡ÐµÑ€Ð²ÐµÑ€ '{server_name}' ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾ Ð´Ð¾Ð´Ð°Ð½Ð¾!\n\nÐ’Ð¸ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ /mcpselect Ð´Ð»Ñ Ð°ÐºÑ‚Ð¸Ð²Ð°Ñ†Ñ–Ñ— Ñ‚Ð° /mcpask Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð².",
        "failed": "âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð´Ð¾Ð´Ð°Ñ‚Ð¸ ÑÐµÑ€Ð²ÐµÑ€: {error}"
      }
    },
    "select": {
      "success": "âœ… ÐÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð²ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾: **{server_name}**\n\nÐ¢ÐµÐ¿ÐµÑ€ Ð²Ð¸ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ /mcpask Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð² Ð· Ñ†Ð¸Ð¼ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼.",
      "failed": "âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð²ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: {error}",
      "no_enabled_servers": "âŒ Ð£ Ð²Ð°Ñ Ð½ÐµÐ¼Ð°Ñ” Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¸Ñ… MCP ÑÐµÑ€Ð²ÐµÑ€Ñ–Ð².\n\nÐ’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /mcpadd Ð´Ð»Ñ Ð´Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ ÑÐµÑ€Ð²ÐµÑ€Ñ–Ð².",
      "choose_context": "ðŸŽ¯ **Ð’Ð¸Ð±Ñ–Ñ€ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ**\n\nÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ MCP ÑÐµÑ€Ð²ÐµÑ€ Ð´Ð»Ñ Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¸Ñ… Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð²:",
      "context_cleared": "âœ… ÐÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð¾."
    },
    "ask": {
      "no_query": "â“ Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð·Ð°Ð¿Ð¸Ñ‚ Ð¿Ñ–ÑÐ»Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸.\n\nÐŸÑ€Ð¸ÐºÐ»Ð°Ð´: `/mcpask ÐŸÐ¾ÐºÐ°Ð¶Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ git Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–ÑŽ`",
      "processing": "ðŸ¤– ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ Ð· MCP ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼...\n\n**Ð—Ð°Ð¿Ð¸Ñ‚:** {query}",
      "context_error": "ðŸŽ¯ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ: {error}\n\nÐ’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /mcpselect Ð´Ð»Ñ Ð²Ð¸Ð±Ð¾Ñ€Ñƒ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ ÑÐµÑ€Ð²ÐµÑ€Ð°.",
      "execution_error": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ: {error}",
      "no_context": "ðŸŽ¯ **ÐÐµÐ¼Ð°Ñ” Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ**\n\nÐ’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /mcpselect Ð´Ð»Ñ Ð²Ð¸Ð±Ð¾Ñ€Ñƒ MCP ÑÐµÑ€Ð²ÐµÑ€Ð°, Ð°Ð±Ð¾ Ð¾Ð±ÐµÑ€Ñ–Ñ‚ÑŒ Ð¾Ð´Ð¸Ð½ Ð· Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ñ…:"
    },
    "remove": {
      "confirm": "âš ï¸ **ÐŸÑ–Ð´Ñ‚Ð²ÐµÑ€Ð´Ð¶ÐµÐ½Ð½Ñ Ð²Ð¸Ð´Ð°Ð»ÐµÐ½Ð½Ñ**\n\nÐ’Ð¸ ÑÐ¿Ñ€Ð°Ð²Ð´Ñ– Ñ…Ð¾Ñ‡ÐµÑ‚Ðµ Ð²Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸ ÑÐµÑ€Ð²ÐµÑ€ **{server_name}**?\n\nÐ¦ÑŽ Ð´Ñ–ÑŽ Ð½ÐµÐ¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ ÑÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸.",
      "success": "âœ… Ð¡ÐµÑ€Ð²ÐµÑ€ '{server_name}' ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾ Ð²Ð¸Ð´Ð°Ð»ÐµÐ½Ð¾.",
      "failed": "âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð²Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸ ÑÐµÑ€Ð²ÐµÑ€: {error}",
      "no_servers": "âŒ Ð£ Ð²Ð°Ñ Ð½ÐµÐ¼Ð°Ñ” ÑÐµÑ€Ð²ÐµÑ€Ñ–Ð² Ð´Ð»Ñ Ð²Ð¸Ð´Ð°Ð»ÐµÐ½Ð½Ñ.",
      "select_server": "ðŸ—‘ï¸ **Ð’Ð¸Ð´Ð°Ð»ÐµÐ½Ð½Ñ MCP ÑÐµÑ€Ð²ÐµÑ€Ð°**\n\nÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ ÑÐµÑ€Ð²ÐµÑ€ Ð´Ð»Ñ Ð²Ð¸Ð´Ð°Ð»ÐµÐ½Ð½Ñ:"
    },
    "status": {
      "title": "ðŸ“Š MCP Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð°:",
      "checking": "ðŸ” ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° ÑÑ‚Ð°Ñ‚ÑƒÑÑƒ MCP ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸...",
      "connected": "Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¾",
      "active_context": "ÐÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: {context}",
      "no_context": "ÐÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: Ð½ÐµÐ¼Ð°Ñ”",
      "servers_summary": "ÐŸÑ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ… ÑÐµÑ€Ð²ÐµÑ€Ñ–Ð²: {active}/{enabled} Ð· {total}",
      "usage_stats": "Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ (7 Ð´Ð½Ñ–Ð²):",
      "queries_count": "Ð—Ð°Ð¿Ð¸Ñ‚Ñ–Ð² Ð· ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼: {count}",
      "success_rate": "Ð£ÑÐ¿Ñ–ÑˆÐ½Ð¸Ñ… Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð²: {rate}%",
      "avg_response": "Ð¡ÐµÑ€ÐµÐ´Ð½Ñ–Ð¹ Ñ‡Ð°Ñ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ–: {time}Ñ",
      "total_cost": "Ð—Ð°Ð³Ð°Ð»ÑŒÐ½Ð° Ð²Ð°Ñ€Ñ‚Ñ–ÑÑ‚ÑŒ: ${cost}"
    },
    "buttons": {
      "add_first_server": "âž• Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð¿ÐµÑ€ÑˆÐ¸Ð¹ ÑÐµÑ€Ð²ÐµÑ€",
      "add_server": "âž• Ð”Ð¾Ð´Ð°Ñ‚Ð¸ ÑÐµÑ€Ð²ÐµÑ€",
      "refresh_status": "ðŸ”„ ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ",
      "system_status": "ðŸ“Š Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸",
      "list_servers": "ðŸ“‹ Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑÐµÑ€Ð²ÐµÑ€Ñ–Ð²",
      "select_context": "ðŸŽ¯ Ð’Ð¸Ð±Ñ€Ð°Ñ‚Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚",
      "clear_context": "ðŸ”„ ÐžÑ‡Ð¸ÑÑ‚Ð¸Ñ‚Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚",
      "confirm_remove": "âœ… Ð¢Ð°Ðº, Ð²Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸",
      "cancel": "âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸",
      "enable_server": "âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÑƒÑ‚Ð¸",
      "disable_server": "â¸ï¸ Ð’Ð¸Ð¼ÐºÐ½ÑƒÑ‚Ð¸",
      "remove_server": "ðŸ—‘ï¸ Ð’Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸",
      "test_connection": "ðŸ” Ð¢ÐµÑÑ‚ Ð·'Ñ”Ð´Ð½Ð°Ð½Ð½Ñ"
    },
    "manage": {
      "title": "âš™ï¸ Ð£Ð¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð¼: **{server_name}**",
      "server_info": "**Ð¢Ð¸Ð¿:** {server_type}\n**Ð¡Ñ‚Ð°Ñ‚ÑƒÑ:** {status}\n**Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾:** {enabled}",
      "last_check": "ÐžÑÑ‚Ð°Ð½Ð½Ñ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ°: {time}",
      "error_details": "Ð”ÐµÑ‚Ð°Ð»Ñ– Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ¸: {error}",
      "enable_success": "âœ… Ð¡ÐµÑ€Ð²ÐµÑ€ '{server_name}' ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾.",
      "disable_success": "â¸ï¸ Ð¡ÐµÑ€Ð²ÐµÑ€ '{server_name}' Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾.",
      "test_success": "âœ… Ð—'Ñ”Ð´Ð½Ð°Ð½Ð½Ñ Ð· ÑÐµÑ€Ð²ÐµÑ€Ð¾Ð¼ '{server_name}' ÑƒÑÐ¿Ñ–ÑˆÐ½Ðµ.",
      "test_failed": "âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚Ð¸ÑÑ Ð´Ð¾ ÑÐµÑ€Ð²ÐµÑ€Ð°: {error}"
    },
    "setup": {
      "github": {
        "token_prompt": "ðŸ”‘ **GitHub Personal Access Token**\n\nÐ’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð²Ð°Ñˆ GitHub Ñ‚Ð¾ÐºÐµÐ½ Ð´Ð»Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ñƒ Ð´Ð¾ API:\n\n_(Ð¢Ð¾ÐºÐµÐ½ Ð·Ð±ÐµÑ€Ñ–Ð³Ð°Ñ”Ñ‚ÑŒÑÑ Ð±ÐµÐ·Ð¿ÐµÑ‡Ð½Ð¾ Ñ‚Ð° Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ñ‚ÑŒÑÑ Ñ‚Ñ–Ð»ÑŒÐºÐ¸ Ð´Ð»Ñ MCP)_",
        "token_help": "**Ð¯Ðº Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ñ‚Ð¾ÐºÐµÐ½:**\n1. ÐŸÐµÑ€ÐµÐ¹Ð´Ñ–Ñ‚ÑŒ Ð´Ð¾ github.com/settings/tokens\n2. Generate new token (classic)\n3. Ð’Ð¸Ð±ÐµÑ€Ñ–Ñ‚ÑŒ scopes: repo, read:user\n4. Ð¡ÐºÐ¾Ð¿Ñ–ÑŽÐ¹Ñ‚Ðµ Ñ‚Ð¾ÐºÐµÐ½",
        "name_prompt": "ðŸ“ **ÐÐ°Ð·Ð²Ð° ÑÐµÑ€Ð²ÐµÑ€Ð°**\n\nÐ’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ð´Ð»Ñ GitHub ÑÐµÑ€Ð²ÐµÑ€Ð°:\n\n_(Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ñ‚ÑŒÑÑ Ð´Ð»Ñ Ñ–Ð´ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ—)_"
      },
      "filesystem": {
        "path_prompt": "ðŸ“ **Ð”Ð¾Ð·Ð²Ð¾Ð»ÐµÐ½Ð° Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ**\n\nÐ’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ð½Ð¸Ð¹ ÑˆÐ»ÑÑ… Ð´Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—, Ð´Ð¾ ÑÐºÐ¾Ñ— Claude Ð¼Ð°Ñ‚Ð¸Ð¼Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿:\n\n_(ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´: /home/user/projects)_",
        "path_help": "**Ð’Ð°Ð¶Ð»Ð¸Ð²Ð¾:**\nâ€¢ Ð’ÐºÐ°Ð¶Ñ–Ñ‚ÑŒ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð¸Ð¹ ÑˆÐ»ÑÑ…\nâ€¢ ÐŸÐµÑ€ÐµÐºÐ¾Ð½Ð°Ð¹Ñ‚ÐµÑÑ, Ñ‰Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ Ñ–ÑÐ½ÑƒÑ”\nâ€¢ Claude Ð¼Ð°Ñ‚Ð¸Ð¼Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ñ‚Ñ–Ð»ÑŒÐºÐ¸ Ð´Ð¾ Ñ†Ñ–Ñ”Ñ— Ð¿Ð°Ð¿ÐºÐ¸",
        "name_prompt": "ðŸ“ **ÐÐ°Ð·Ð²Ð° ÑÐµÑ€Ð²ÐµÑ€Ð°**\n\nÐ’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ð´Ð»Ñ Filesystem ÑÐµÑ€Ð²ÐµÑ€Ð°:"
      },
      "postgres": {
        "connection_prompt": "ðŸ˜ **PostgreSQL Connection**\n\nÐ’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ñ€ÑÐ´Ð¾Ðº Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ Ð´Ð¾ Ð±Ð°Ð·Ð¸ Ð´Ð°Ð½Ð¸Ñ…:\n\n_(Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚: postgresql://user:pass@host:port/db)_",
        "connection_help": "**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸:**\nâ€¢ postgresql://user:pass@localhost:5432/mydb\nâ€¢ postgresql://user:pass@server.com:5432/prod\n\n**ÐŸÐµÑ€ÐµÐºÐ¾Ð½Ð°Ð¹Ñ‚ÐµÑÑ, Ñ‰Ð¾ Ð‘Ð” Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°**",
        "name_prompt": "ðŸ“ **ÐÐ°Ð·Ð²Ð° ÑÐµÑ€Ð²ÐµÑ€Ð°**\n\nÐ’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ð´Ð»Ñ PostgreSQL ÑÐµÑ€Ð²ÐµÑ€Ð°:"
      },
      "validation": {
        "required": "Ð¦Ðµ Ð¿Ð¾Ð»Ðµ Ñ” Ð¾Ð±Ð¾Ð²'ÑÐ·ÐºÐ¾Ð²Ð¸Ð¼",
        "invalid_token": "ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ GitHub Ñ‚Ð¾ÐºÐµÐ½Ñƒ",
        "invalid_path": "ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ ÑˆÐ»ÑÑ… Ð´Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—",
        "invalid_connection": "ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ connection string"
      }
    }
  },
  "commands": {
    "claude": {
      "title": "ðŸ” **ÐÐ²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ Claude CLI**",
      "step1": "1ï¸âƒ£ Ð’Ñ–Ð´ÐºÑ€Ð¸Ð¹Ñ‚Ðµ Ñ†Ðµ Ð¿Ð¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ Ð² Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ñ–:",
      "step2": "2ï¸âƒ£ ÐÐ²Ñ‚Ð¾Ñ€Ð¸Ð·ÑƒÐ¹Ñ‚ÐµÑÑŒ Ñ‡ÐµÑ€ÐµÐ· Ð²Ð°Ñˆ Ð°ÐºÐ°ÑƒÐ½Ñ‚ Anthropic",
      "step3": "3ï¸âƒ£ Ð¡ÐºÐ¾Ð¿Ñ–ÑŽÐ¹Ñ‚Ðµ ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð· Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð°",
      "step4": "4ï¸âƒ£ ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ ÐºÐ¾Ð´ Ð² Ñ†ÐµÐ¹ Ñ‡Ð°Ñ‚",
      "waiting": "â³ ÐžÑ‡Ñ–ÐºÑƒÑŽ Ð½Ð° ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—...",
      "timeout": "â° **Ð§Ð°Ñ Ð¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð½Ñ ÐºÐ¾Ð´Ñƒ Ð²Ð¸Ñ‡ÐµÑ€Ð¿Ð°Ð½Ð¾**\n\nÐ‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð¿Ð¾Ñ‡Ð½Ñ–Ñ‚ÑŒ Ð¿Ñ€Ð¾Ñ†ÐµÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð·Ð°Ð½Ð¾Ð²Ð¾ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾ÑŽ `/claude`",
      "success": "âœ… **ÐÐ²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ Claude CLI ÑƒÑÐ¿Ñ–ÑˆÐ½Ð°!**\n\nClaude Ñ‚ÐµÐ¿ÐµÑ€ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ– Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð´Ð¾ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸.",
      "error_generic": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Claude CLI**",
      "error_invalid_code": "âŒ **ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—**\n\nÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ ÐºÐ¾Ð´ Ñ– ÑÐ¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ð°Ð±Ð¾ Ð¿Ð¾Ñ‡Ð½Ñ–Ñ‚ÑŒ Ð¿Ñ€Ð¾Ñ†ÐµÑ Ð·Ð°Ð½Ð¾Ð²Ð¾ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾ÑŽ `/claude`",
      "error_process": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð¿ÑƒÑÐºÑƒ Ð¿Ñ€Ð¾Ñ†ÐµÑÑƒ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—**\n\nÐ¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ð°Ð±Ð¾ Ð·Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°.",
      "error_rate_limit": "â±ï¸ **Ð”Ð¾ÑÑÐ³Ð½ÑƒÑ‚Ð¾ Ð»Ñ–Ð¼Ñ–Ñ‚ ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ– Claude API**\n\nðŸ“… Ð¡ÐµÑ€Ð²Ñ–Ñ Ñ‚Ð¸Ð¼Ñ‡Ð°ÑÐ¾Ð²Ð¾ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹\nâ° ÐÐ°ÑÑ‚ÑƒÐ¿Ð½Ð° ÑÐ¿Ñ€Ð¾Ð±Ð° Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð°: {reset_time}\nðŸ”„ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ Ð°Ð±Ð¾ Ð·Ð°Ñ‡ÐµÐºÐ°Ð¹Ñ‚Ðµ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾Ð³Ð¾ Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ",
      "error_quota": "ðŸ“Š **Ð”Ð¾ÑÑÐ³Ð½ÑƒÑ‚Ð¾ Ð´ÐµÐ½Ð½Ð¸Ð¹ Ð»Ñ–Ð¼Ñ–Ñ‚ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ**\n\nâ° Ð¡ÐµÑ€Ð²Ñ–Ñ Ð±ÑƒÐ´Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹ Ð·Ð°Ð²Ñ‚Ñ€Ð°\nðŸ“ˆ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾ÑŽ `/status`",
      "error_network": "ðŸŒ **ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð· Ð¼ÐµÑ€ÐµÐ¶ÐµÐ²Ð¸Ð¼ Ð·'Ñ”Ð´Ð½Ð°Ð½Ð½ÑÐ¼**\n\nÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ð·'Ñ”Ð´Ð½Ð°Ð½Ð½Ñ Ð· Ñ–Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ð¾Ð¼ Ñ– ÑÐ¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·.",
      "error_server": "ðŸ”§ **Ð¢Ð¸Ð¼Ñ‡Ð°ÑÐ¾Ð²Ñ– Ñ‚ÐµÑ…Ð½Ñ–Ñ‡Ð½Ñ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ ÑÐµÑ€Ð²ÐµÑ€Ñƒ Anthropic**\n\nâ³ Ð—Ð°Ñ‡ÐµÐºÐ°Ð¹Ñ‚Ðµ ÐºÑ–Ð»ÑŒÐºÐ° Ñ…Ð²Ð¸Ð»Ð¸Ð½ Ñ– ÑÐ¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·",
      "cancelled": "âŒ ÐÐ²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–ÑŽ ÑÐºÐ°ÑÐ¾Ð²Ð°Ð½Ð¾",
      "already_waiting": "â³ **ÐŸÑ€Ð¾Ñ†ÐµÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð²Ð¶Ðµ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð¾**\n\nÐžÑ‡Ñ–ÐºÑƒÑŽ Ð½Ð° ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—. ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ ÐºÐ¾Ð´ Ð°Ð±Ð¾ ÑÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚ÐµÑÑŒ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾ÑŽ `/cancel` Ð´Ð»Ñ ÑÐºÐ°ÑÑƒÐ²Ð°Ð½Ð½Ñ.",
      "starting": "ðŸš€ **Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ Ð¿Ñ€Ð¾Ñ†ÐµÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Claude CLI...**",
      "processing": "âš™ï¸ **ÐžÐ±Ñ€Ð¾Ð±Ð»ÑÑŽ ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—...**",
      "session_expired": "â° **Ð¡ÐµÑÑ–Ñ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð·Ð°ÐºÑ–Ð½Ñ‡Ð¸Ð»Ð°ÑÑ**\n\nÐŸÐ¾Ñ‡Ð½Ñ–Ñ‚ÑŒ Ð¿Ñ€Ð¾Ñ†ÐµÑ Ð·Ð°Ð½Ð¾Ð²Ð¾ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾ÑŽ `/claude`",
      "verified": "âœ… **ÐÐ²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–ÑŽ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐµÐ½Ð¾!** Claude CLI Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð´Ð¾ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸.",
      "connectivity_issue": "ðŸŒ **ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð· Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½ÑÐ¼ Ð´Ð¾ Claude API**\n\nâš ï¸ Ð¢Ð¾ÐºÐµÐ½ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð´Ñ–Ð¹ÑÐ½Ð¸Ð¹ Ñ‰Ðµ {hours} Ð³Ð¾Ð´Ð¸Ð½, Ð°Ð»Ðµ Claude CLI Ð½Ðµ Ð¼Ð¾Ð¶Ðµ Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚Ð¸ÑÑ Ð´Ð¾ ÑÐµÑ€Ð²ÐµÑ€Ñ–Ð² Anthropic.\n\nðŸ”„ Ð¦Ðµ Ð¼Ð¾Ð¶Ðµ Ð±ÑƒÑ‚Ð¸:\nâ€¢ Ð¢Ð¸Ð¼Ñ‡Ð°ÑÐ¾Ð²Ð° Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð¼ÐµÑ€ÐµÐ¶Ñ–\nâ€¢ Ð¢ÐµÑ…Ð½Ñ–Ñ‡Ð½Ñ– Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸ Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ð°Ñ… Anthropic\nâ€¢ Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ– Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð½Ñ Ð±Ñ€Ð°Ð½Ð´Ð¼Ð°ÑƒÐµÑ€Ð°\n\nðŸ’¡ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ Ð°Ð±Ð¾ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ Ð´Ð¾ Ñ–Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ñƒ.",
      "token_expired": "â° **Ð¢Ð¾ÐºÐµÐ½ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Claude CLI Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð¾Ñ‡ÐµÐ½Ð¸Ð¹**\n\nÐŸÐ¾Ñ‡Ð½Ñ–Ñ‚ÑŒ Ð½Ð¾Ð²Ð¸Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—."
    },
    "restart": {
      "title": "ðŸ”„ **ÐŸÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐº Ð±Ð¾Ñ‚Ð°**",
      "description": "ÐŸÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ð±Ð¾Ñ‚Ð° Ð· Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð½ÑÐ¼ Ð¿Ð°Ð¼'ÑÑ‚Ñ– Ñ‚Ð° Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð½ÑÐ¼ ÐºÐ¾Ð´Ñƒ",
      "restarting": "ðŸ”„ **ÐŸÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐºÐ°ÑŽ Ð±Ð¾Ñ‚Ð°...**\n\nÐ—ÑƒÐ¿Ð¸Ð½ÑÑŽ Ð²ÑÑ– Ð¿Ñ€Ð¾Ñ†ÐµÑÐ¸ Ñ‚Ð° Ð·Ð°Ð¿ÑƒÑÐºÐ°ÑŽ Ð·Ð°Ð½Ð¾Ð²Ð¾...",
      "initiated": "âœ… **ÐŸÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐº Ñ–Ð½Ñ–Ñ†Ñ–Ð¹Ð¾Ð²Ð°Ð½Ð¾**\n\nÐŸÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐºÐ°ÑŽÑÑ Ð·Ð°Ñ€Ð°Ð·...",
      "access_denied": "ðŸš« Ð£ Ð²Ð°Ñ Ð½ÐµÐ¼Ð°Ñ” Ð¿Ñ€Ð°Ð² Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐºÑƒ Ð±Ð¾Ñ‚Ð°.",
      "script_not_found": "âŒ **Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐºÑƒ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\nÐŸÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÑ‚Ñ–Ñ‚ÑŒ Ð²Ñ€ÑƒÑ‡Ð½Ñƒ.",
      "failed": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐºÑƒ**"
    },
    "status": {
      "title": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ ÑÐµÑÑ–Ñ—",
      "active": "Ð¡ÐµÑÑ–Ñ Claude Ð°ÐºÑ‚Ð¸Ð²Ð½Ð°",
      "inactive": "Ð¡ÐµÑÑ–Ñ Claude Ð½ÐµÐ°ÐºÑ‚Ð¸Ð²Ð½Ð°"
    },
    "ls": {
      "title": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸ Ð² Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—"
    },
    "pwd": {
      "title": "ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð° Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ"
    },
    "cd": {
      "usage": "Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ",
      "success": "ðŸ“‚ Ð—Ð¼Ñ–Ð½ÐµÐ½Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ Ð½Ð°: `{directory}`",
      "failed": "âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð·Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ Ð½Ð°: `{directory}`"
    },
    "projects": {
      "title": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸",
      "list": "Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð²Ð°ÑˆÐ¸Ñ… Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ–Ð² Ð±ÑƒÐ´Ðµ Ñ‚ÑƒÑ‚ Ð²Ñ–Ð´Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹"
    },
    "export": {
      "title": "Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ ÑÐµÑÑ–Ñ—",
      "processing": "Ð“Ð¾Ñ‚ÑƒÑŽ ÐµÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð´Ð°Ð½Ð¸Ñ… ÑÐµÑÑ–Ñ—..."
    },
    "audit": {
      "title": "ðŸ” Ð†Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð°ÑƒÐ´Ð¸Ñ‚",
      "description": "ÐÐ½Ð°Ð»Ñ–Ð· ÐºÐ¾Ð´Ñƒ Ð±Ð¾Ñ‚Ð° Ð· Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ Claude",
      "starting": "Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð°ÑƒÐ´Ð¸Ñ‚...",
      "analyzing": "ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ ÐºÐ¾Ð´ Ñ‚Ð° Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ...",
      "completed": "ÐÑƒÐ´Ð¸Ñ‚ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾",
      "no_issues": "ðŸŽ‰ ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾!",
      "critical_warning": "ðŸš¨ Ð£Ð’ÐÐ“Ð! Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ñ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸"
    },
    "dracon": {
      "title": "ðŸ”§ DRACON-YAML ÐœÐ¾Ð´ÐµÐ»ÑŽÐ²Ð°Ð½Ð½Ñ Ð›Ð¾Ð³Ñ–ÐºÐ¸ Ð‘Ð¾Ñ‚Ð°",
      "description": "ÐœÐ¾Ð´ÐµÐ»ÑŽÐ¹Ñ‚Ðµ Ð»Ð¾Ð³Ñ–ÐºÑƒ Ð±Ð¾Ñ‚Ð° Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ YAML-ÑÑ…ÐµÐ¼ Ð· Ð°Ð½Ð°Ð»Ñ–Ð·Ð¾Ð¼ Ð³Ñ€Ð°Ñ„Ñ–Ð²",
      "help": "Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° DRACON (Ð”Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ðµ Ð ÑƒÑÑÐºÐ¸Ðµ ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹, ÐšÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÐžÐ±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÑŽÑ‚ ÐÐ°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚ÑŒ) Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŽÐ²Ð°Ð½Ð½Ñ Ð»Ð¾Ð³Ñ–ÐºÐ¸ Ð±Ð¾Ñ‚Ð°",
      "analyzing": "ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ DRACON ÑÑ…ÐµÐ¼Ñƒ...",
      "generating": "Ð“ÐµÐ½ÐµÑ€ÑƒÑŽ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¸...",
      "validating": "Ð’Ð°Ð»Ñ–Ð´ÑƒÑŽ ÑÑ…ÐµÐ¼Ñƒ...",
      "completed": "ÐÐ½Ð°Ð»Ñ–Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾",
      "invalid_schema": "âŒ ÐÐµÐ¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð° DRACON ÑÑ…ÐµÐ¼Ð°",
      "no_components": "âŒ ÐÐµÐ¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ Ð·Ð³ÐµÐ½ÐµÑ€ÑƒÐ²Ð°Ñ‚Ð¸ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¸"
    },
    "refactor": {
      "title": "ðŸ”„ DRACON Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³Ñƒ",
      "description": "Ð—Ð²Ð¾Ñ€Ð¾Ñ‚Ð½Ð¸Ð¹ Ñ–Ð½Ð¶Ð¸Ð½Ñ–Ñ€Ð¸Ð½Ð³ Ñ–ÑÐ½ÑƒÑŽÑ‡Ð¾Ð³Ð¾ ÐºÐ¾Ð´Ñƒ Ð±Ð¾Ñ‚Ð° Ð² DRACON ÑÑ…ÐµÐ¼Ð¸",
      "analyzing": "ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ð±Ð¾Ñ‚Ð°...",
      "generating": "Ð“ÐµÐ½ÐµÑ€ÑƒÑŽ DRACON ÑÑ…ÐµÐ¼Ñƒ Ð· ÐºÐ¾Ð´Ñƒ...",
      "suggesting": "Ð“ÐµÐ½ÐµÑ€ÑƒÑŽ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ— Ð· Ñ€ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³Ñƒ...",
      "completed": "ÐÐ½Ð°Ð»Ñ–Ð· Ñ€ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³Ñƒ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾",
      "access_denied": "âŒ Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ð·Ð°Ð±Ð¾Ñ€Ð¾Ð½ÐµÐ½Ð¾. Ð ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹ Ñ‚Ñ–Ð»ÑŒÐºÐ¸ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°Ð¼"
    },
    "img": {
      "title": "ðŸ“¸ ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° Ð—Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ",
      "description": "ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ Claude AI",
      "instructions": "ðŸ“¸ **Ð ÐµÐ¶Ð¸Ð¼ ÐžÐ±Ñ€Ð¾Ð±ÐºÐ¸ Ð—Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ**\n\nÐ‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð½Ð°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð²Ð°ÑˆÑ– Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ (Ð´Ð¾ {max_images} Ñ„Ð°Ð¹Ð»Ñ–Ð²). Ð’Ð¸ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð½Ð°Ð´ÑÐ¸Ð»Ð°Ñ‚Ð¸ Ñ—Ñ… Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¼Ñƒ Ð°Ð±Ð¾ Ð²ÑÑ– Ð²Ñ–Ð´Ñ€Ð°Ð·Ñƒ.\n\n**ÐŸÑ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÐ²Ð°Ð½Ñ– Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸:** PNG, JPG, JPEG, GIF, WebP\n**ÐœÐ°ÐºÑ. Ñ€Ð¾Ð·Ð¼Ñ–Ñ€ Ñ„Ð°Ð¹Ð»Ñƒ:** {max_size}ÐœÐ‘ Ð½Ð° Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ\n\nÐŸÑ–ÑÐ»Ñ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð²Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ñ–Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ñ–Ñ— Ð°Ð±Ð¾ 'Ð³Ð¾Ñ‚Ð¾Ð²Ð¾' Ð´Ð»Ñ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸.\n\nÐÐ°Ð´Ñ€ÑƒÐºÑƒÐ¹Ñ‚Ðµ 'ÑÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸' Ð´Ð»Ñ Ð·ÑƒÐ¿Ð¸Ð½ÐºÐ¸.",
      "session_expired": "âŒ Ð¡ÐµÑÑ–Ñ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ Ð·Ð°ÐºÑ–Ð½Ñ‡Ð¸Ð»Ð°ÑÑ. Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /img Ð´Ð»Ñ Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ð½Ð¾Ð²Ð¾Ñ— ÑÐµÑÑ–Ñ—.",
      "image_received": "âœ… Ð—Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ {current}/{max} Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð¾. ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð±Ñ–Ð»ÑŒÑˆÐµ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ Ð°Ð±Ð¾ Ð½Ð°Ð±ÐµÑ€Ñ–Ñ‚ÑŒ 'Ð³Ð¾Ñ‚Ð¾Ð²Ð¾' Ð´Ð»Ñ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸.",
      "no_images": "âŒ Ð—Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ Ñ‰Ðµ Ð½Ðµ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ñ–. Ð¡Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ð½Ð°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ.",
      "cancelled": "ðŸš« Ð¡ÐµÑÑ–Ñ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ ÑÐºÐ°ÑÐ¾Ð²Ð°Ð½Ð°.",
      "instruction_updated": "ðŸ“ Ð†Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ñ–Ñ Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð°. ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð° ÐºÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ: {count}. ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ 'Ð³Ð¾Ñ‚Ð¾Ð²Ð¾' Ð´Ð»Ñ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð°Ð±Ð¾ Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶ÑƒÐ¹Ñ‚Ðµ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ.",
      "processing": "ðŸ”„ ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° {count} Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ(ÐµÐ½ÑŒ) Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ Claude...",
      "error": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ: {error}",
      "fix_mode_activated": "ðŸ”§ **Ð ÐµÐ¶Ð¸Ð¼ Ð’Ð¸Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ñ ÐšÐ¾Ð´Ñƒ ÐÐºÑ‚Ð¸Ð²Ð¾Ð²Ð°Ð½Ð¾**\n\nÐ‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð¾Ð¿Ð¸ÑˆÑ–Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ, ÑÐºÑƒ Ð²Ð¸ Ð±Ð°Ñ‡Ð¸Ñ‚Ðµ Ð½Ð° ÑÐºÑ€Ñ–Ð½ÑˆÐ¾Ñ‚Ñ–:\nâ€¢ Ð©Ð¾ Ð½Ðµ Ñ‚Ð°Ðº Ð· Ñ–Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ¾Ð¼/ÐºÐ¾Ð´Ð¾Ð¼?\nâ€¢ Ð©Ð¾ Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ð¾ Ð·Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸/Ð²Ð¸Ð¿Ñ€Ð°Ð²Ð¸Ñ‚Ð¸?\nâ€¢ Ð§Ð¸ Ñ” ÑÐºÑ–ÑÑŒ Ð¾ÑÐ¾Ð±Ð»Ð¸Ð²Ñ– Ð²Ð¸Ð¼Ð¾Ð³Ð¸ Ð°Ð±Ð¾ Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð½Ñ?\nâ€¢ Ð¯ÐºÐ° Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ñ–Ñ/Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ñ‚ÑŒÑÑ?\n\nÐ¯ Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÑŽ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ Ñ‚Ð° Ð´Ð¾ÑÐ»Ñ–Ð´ÑŽ Ð²Ð°ÑˆÑƒ ÐºÐ¾Ð´Ð¾Ð²Ñƒ Ð±Ð°Ð·Ñƒ, Ñ‰Ð¾Ð± Ñ€ÐµÐ°Ð»Ñ–Ð·ÑƒÐ²Ð°Ñ‚Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ñ–Ð´Ð½Ñ– Ð²Ð¸Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ñ.",
      "image_processing_disabled": "âŒ ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð° Ð² Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½ÑÑ…."
    },
    "actions": {
      "title": "Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ—",
      "description": "Ð’Ð¸Ð±ÐµÑ€Ñ–Ñ‚ÑŒ Ð´Ñ–ÑŽ Ð·Ñ– ÑÐ¿Ð¸ÑÐºÑƒ Ð½Ð¸Ð¶Ñ‡Ðµ:"
    },
    "settings": {
      "title": "ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ",
      "description": "Ð¢ÑƒÑ‚ Ð¼Ð¾Ð¶Ð½Ð° Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸ Ð±Ð¾Ñ‚Ð°."
    },
    "main_menu": {
      "title": "Ð“Ð¾Ð»Ð¾Ð²Ð½Ðµ Ð¼ÐµÐ½ÑŽ",
      "description": "ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ñ„ÑƒÐ½ÐºÑ†Ñ–Ñ— Ð±Ð¾Ñ‚Ð° Ð´Ð»Ñ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸ Ð· Claude Code."
    },
    "start": {
      "welcome": "ðŸ‘‹ Ð’Ñ–Ñ‚Ð°ÑŽ Ñƒ Claude Code Telegram Ð±Ð¾Ñ‚Ñ–, {name}!",
      "description": "ðŸ¤– Ð¯ Ð´Ð¾Ð¿Ð¾Ð¼Ð°Ð³Ð°ÑŽ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ð²Ñ–Ð´Ð´Ð°Ð»ÐµÐ½Ð¸Ð¹ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ð´Ð¾ Claude Code Ñ‡ÐµÑ€ÐµÐ· Telegram.",
      "available_commands": "**Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸:**",
      "help_cmd": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñƒ Ð´Ð¾Ð²Ñ–Ð´ÐºÑƒ",
      "new_cmd": "ÐŸÐ¾Ñ‡Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ ÑÐµÑÑ–ÑŽ Ð· Claude",
      "ls_cmd": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸ Ð² Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—",
      "cd_cmd": "Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ",
      "projects_cmd": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸",
      "status_cmd": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ ÑÐµÑÑ–Ñ—",
      "actions_cmd": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ ÑˆÐ²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ—",
      "git_cmd": "ÐšÐ¾Ð¼Ð°Ð½Ð´Ð¸ Git Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–ÑŽ",
      "quick_start": "**Ð¨Ð²Ð¸Ð´ÐºÐ¸Ð¹ ÑÑ‚Ð°Ñ€Ñ‚:**",
      "quick_start_1": "Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ `/projects` Ñ‰Ð¾Ð± Ð¿Ð¾Ð±Ð°Ñ‡Ð¸Ñ‚Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸",
      "quick_start_2": "Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ `/cd <Ð¿Ñ€Ð¾ÐµÐºÑ‚>` Ñ‰Ð¾Ð± Ð¿ÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ð´Ð¾ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ",
      "quick_start_3": "ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð±ÑƒÐ´ÑŒ-ÑÐºÐµ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ñ‰Ð¾Ð± Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¸ ÐºÐ¾Ð´Ð¸Ñ‚Ð¸ Ð· Claude!",
      "security_note": "ðŸ”’ Ð’Ð°Ñˆ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ð·Ð°Ñ…Ð¸Ñ‰ÐµÐ½Ð¸Ð¹ Ñ– Ð²ÑÑ– Ð´Ñ–Ñ— Ð»Ð¾Ð³ÑƒÑŽÑ‚ÑŒÑÑ.",
      "usage_note": "ðŸ“Š Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ `/status` Ñ‰Ð¾Ð± Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð»Ñ–Ð¼Ñ–Ñ‚Ð¸ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ."
    },
    "help": {
      "title": "ðŸ¤– **Ð”Ð¾Ð²Ñ–Ð´ÐºÐ° Claude Code Telegram Bot**",
      "navigation_title": "**ÐšÐ¾Ð¼Ð°Ð½Ð´Ð¸ Ð½Ð°Ð²Ñ–Ð³Ð°Ñ†Ñ–Ñ—:**",
      "ls_desc": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸ Ñ– Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—",
      "cd_desc": "Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ",
      "pwd_desc": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñƒ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ",
      "projects_desc": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸",
      "session_title": "**ÐšÐ¾Ð¼Ð°Ð½Ð´Ð¸ ÑÐµÑÑ–Ñ—:**",
      "new_desc": "ÐŸÐ¾Ñ‡Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ ÑÐµÑÑ–ÑŽ Claude",
      "continue_desc": "ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð½ÑŽ ÑÐµÑÑ–ÑŽ (Ð· Ð¾Ð¿Ñ†Ñ–Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¸Ð¼ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½ÑÐ¼)",
      "end_desc": "Ð—Ð°Ð²ÐµÑ€ÑˆÐ¸Ñ‚Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñƒ ÑÐµÑÑ–ÑŽ",
      "status_desc": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ ÑÐµÑÑ–Ñ— Ñ‚Ð° Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ",
      "export_desc": "Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ñ–ÑÑ‚Ð¾Ñ€Ñ–ÑŽ ÑÐµÑÑ–Ñ—",
      "actions_desc": "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð½Ñ– ÑˆÐ²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ—",
      "git_desc": "Ð†Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ Ð¿Ñ€Ð¾ Git Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ð¹",
      "usage_title": "**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ:**",
      "usage_cd": "Ð£Ð²Ñ–Ð¹Ñ‚Ð¸ Ð² Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ",
      "usage_ls": "ÐŸÐ¾Ð´Ð¸Ð²Ð¸Ñ‚Ð¸ÑÑ Ñ‰Ð¾ Ñ” Ð² Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—",
      "usage_code": "ÐŸÐ¾Ð¿Ñ€Ð¾ÑÐ¸Ñ‚Ð¸ Claude Ð½Ð°Ð¿Ð¸ÑÐ°Ñ‚Ð¸ ÐºÐ¾Ð´",
      "usage_file": "ÐÐ°Ð´Ñ–ÑÐ»Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð» Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ´Ñƒ Claude",
      "file_ops_title": "**ÐžÐ¿ÐµÑ€Ð°Ñ†Ñ–Ñ— Ð· Ñ„Ð°Ð¹Ð»Ð°Ð¼Ð¸:**",
      "file_ops_send": "ÐÐ°Ð´ÑÐ¸Ð»Ð°Ð¹Ñ‚Ðµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ– Ñ„Ð°Ð¹Ð»Ð¸ (.py, .js, .md, Ñ‚Ð¾Ñ‰Ð¾) Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ´Ñƒ",
      "file_ops_modify": "Claude Ð¼Ð¾Ð¶Ðµ Ñ‡Ð¸Ñ‚Ð°Ñ‚Ð¸, Ð·Ð¼Ñ–Ð½ÑŽÐ²Ð°Ñ‚Ð¸ Ñ‚Ð° ÑÑ‚Ð²Ð¾Ñ€ÑŽÐ²Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸",
      "file_ops_security": "Ð’ÑÑ– Ð¾Ð¿ÐµÑ€Ð°Ñ†Ñ–Ñ— Ð· Ñ„Ð°Ð¹Ð»Ð°Ð¼Ð¸ Ð² Ð¼ÐµÐ¶Ð°Ñ… Ð´Ð¾Ð·Ð²Ð¾Ð»ÐµÐ½Ð¾Ñ— Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—",
      "security_title": "**Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ— Ð±ÐµÐ·Ð¿ÐµÐºÐ¸:**",
      "security_path": "ðŸ”’ Ð—Ð°Ñ…Ð¸ÑÑ‚ Ð²Ñ–Ð´ Ð¾Ð±Ñ…Ð¾Ð´Ñƒ ÑˆÐ»ÑÑ…Ñ–Ð²",
      "security_rate": "â±ï¸ ÐžÐ±Ð¼ÐµÐ¶ÐµÐ½Ð½Ñ ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ– Ð´Ð»Ñ Ð·Ð°Ð¿Ð¾Ð±Ñ–Ð³Ð°Ð½Ð½Ñ Ð·Ð»Ð¾Ð²Ð¶Ð¸Ð²Ð°Ð½Ð½ÑÐ¼",
      "security_usage": "ðŸ“Š Ð’Ñ–Ð´ÑÑ‚ÐµÐ¶ÐµÐ½Ð½Ñ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ñ‚Ð° Ð»Ñ–Ð¼Ñ–Ñ‚Ð¸",
      "security_validation": "ðŸ›¡ï¸ Ð’Ð°Ð»Ñ–Ð´Ð°Ñ†Ñ–Ñ Ñ‚Ð° ÑÐ°Ð½Ñ–Ñ‚Ð°Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ Ð²Ð²Ð¾Ð´Ñƒ",
      "tips_title": "**ÐŸÐ¾Ñ€Ð°Ð´Ð¸:**",
      "tips_specific": "Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ–, Ð·Ñ€Ð¾Ð·ÑƒÐ¼Ñ–Ð»Ñ– Ð·Ð°Ð¿Ð¸Ñ‚Ð¸ Ð´Ð»Ñ ÐºÑ€Ð°Ñ‰Ð¸Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ–Ð²",
      "tips_status": "ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÐ¹Ñ‚Ðµ `/status` Ñ‰Ð¾Ð± Ð²Ñ–Ð´ÑÑ‚ÐµÐ¶ÑƒÐ²Ð°Ñ‚Ð¸ Ð²Ð°ÑˆÐµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ",
      "tips_buttons": "Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ ÐºÐ½Ð¾Ð¿ÐºÐ¸ ÑˆÐ²Ð¸Ð´ÐºÐ¸Ñ… Ð´Ñ–Ð¹ ÐºÐ¾Ð»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾"
    }
  },
  "help": {
    "title": "ðŸ¤– **Ð”Ð¾Ð²Ñ–Ð´ÐºÐ° Claude Code Telegram Bot**",
    "commands": "**ÐšÐ¾Ð¼Ð°Ð½Ð´Ð¸ Ð½Ð°Ð²Ñ–Ð³Ð°Ñ†Ñ–Ñ—:**\nâ€¢ `/ls` - ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸ Ñ– Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—\nâ€¢ `/cd <Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ>` - Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ\nâ€¢ `/pwd` - ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñƒ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ\nâ€¢ `/projects` - ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸\n\n**ÐšÐ¾Ð¼Ð°Ð½Ð´Ð¸ ÑÐµÑÑ–Ñ—:**\nâ€¢ `/new` - ÐŸÐ¾Ñ‡Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ ÑÐµÑÑ–ÑŽ Claude\nâ€¢ `/continue` - ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð½ÑŽ ÑÐµÑÑ–ÑŽ\nâ€¢ `/status` - ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ ÑÐµÑÑ–Ñ—\nâ€¢ `/export` - Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ñ–ÑÑ‚Ð¾Ñ€Ñ–Ñ— ÑÐµÑÑ–Ñ—\n\n**DRACON ÑÐ¸ÑÑ‚ÐµÐ¼Ð° (Ð’Ñ–Ð·ÑƒÐ°Ð»ÑŒÐ½Ðµ Ð¼Ð¾Ð´ÐµÐ»ÑŽÐ²Ð°Ð½Ð½Ñ):**\nâ€¢ `/dracon help` - Ð”Ð¾Ð²Ñ–Ð´ÐºÐ° Ð¿Ð¾ DRACON\nâ€¢ `/dracon diagram <ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ> <Ñ„Ð°Ð¹Ð»>` - ðŸŽ¨ Ð’Ñ–Ð·ÑƒÐ°Ð»ÑŒÐ½Ð° Ð´Ñ–Ð°Ð³Ñ€Ð°Ð¼Ð°\nâ€¢ `/dracon list [ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ]` - Ð¡Ð¿Ð¸ÑÐ¾Ðº ÑÑ…ÐµÐ¼\nâ€¢ `/dracon analyze <yaml>` - ÐÐ½Ð°Ð»Ñ–Ð· ÑÑ…ÐµÐ¼Ð¸\nâ€¢ `/refactor` - Ð ÐµÐ²ÐµÑ€Ñ-Ñ–Ð½Ð¶Ð¸Ð½Ñ–Ñ€Ð¸Ð½Ð³ ÐºÐ¾Ð´Ñƒ Ð² DRACON\n\n**Ð¡Ð¿ÐµÑ†Ñ–Ð°Ð»ÑŒÐ½Ñ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸:**\nâ€¢ `/actions` - ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ ÑˆÐ²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ—\nâ€¢ `/git` - ÐšÐ¾Ð¼Ð°Ð½Ð´Ð¸ Git Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–ÑŽ\nâ€¢ `/claude` - ÐÐ²Ñ‚Ð¾Ñ€Ð¸Ð·ÑƒÐ²Ð°Ñ‚Ð¸ Claude CLI\nâ€¢ `/img` - ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ Ð· Claude\n\n**MCP ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸:**\nâ€¢ `/mcpadd` - Ð”Ð¾Ð´Ð°Ñ‚Ð¸ MCP ÑÐµÑ€Ð²ÐµÑ€\nâ€¢ `/mcplist` - Ð¡Ð¿Ð¸ÑÐ¾Ðº MCP ÑÐµÑ€Ð²ÐµÑ€Ñ–Ð²\nâ€¢ `/mcpselect` - Ð’Ð¸Ð±Ñ€Ð°Ñ‚Ð¸ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚\nâ€¢ `/mcpask` - Ð—Ð°Ð¿Ð¸Ñ‚ Ð· MCP ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼\nâ€¢ `/mcpremove` - Ð’Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸ MCP ÑÐµÑ€Ð²ÐµÑ€\nâ€¢ `/mcpstatus` - Ð¡Ñ‚Ð°Ñ‚ÑƒÑ MCP ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸\n\n**ÐŸÐ»Ð°Ð½ÑƒÐ²Ð°Ð»ÑŒÐ½Ð¸Ðº:**\nâ€¢ `/schedules` - Ð£Ð¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°Ð¼Ð¸\nâ€¢ `/add_schedule` - Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ Ð·Ð°Ð´Ð°Ñ‡Ñƒ\n\n**Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ñ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸:**\nâ€¢ `/restart` - ÐŸÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ð±Ð¾Ñ‚Ð°\n\n**ÐŸÐ¾Ñ€Ð°Ð´Ð¸:**\nâ€¢ ÐÐ°Ð´ÑÐ¸Ð»Ð°Ð¹Ñ‚Ðµ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ– Ñ„Ð°Ð¹Ð»Ð¸ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ´Ñƒ\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ– Ð·Ð°Ð¿Ð¸Ñ‚Ð¸\nâ€¢ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÐ¹Ñ‚Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾ÑŽ `/status`",
    "navigation_section": "**ÐÐ°Ð²Ñ–Ð³Ð°Ñ†Ñ–Ñ:**",
    "sessions_section": "**Ð¡ÐµÑÑ–Ñ—:**",
    "tips_section": "**ÐŸÐ¾Ñ€Ð°Ð´Ð¸:**",
    "send_text_tip": "â€¢ ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð±ÑƒÐ´ÑŒ-ÑÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð²Ð·Ð°Ñ”Ð¼Ð¾Ð´Ñ–Ñ— Ð· Claude",
    "upload_files_tip": "â€¢ Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ñ‚Ðµ Ñ„Ð°Ð¹Ð»Ð¸ Ð´Ð»Ñ Ð¾Ð³Ð»ÑÐ´Ñƒ ÐºÐ¾Ð´Ñƒ",
    "use_buttons_tip": "â€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ ÐºÐ½Ð¾Ð¿ÐºÐ¸ Ð´Ð»Ñ ÑˆÐ²Ð¸Ð´ÐºÐ¸Ñ… Ð´Ñ–Ð¹",
    "detailed_help_note": "Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ `/help` Ð´Ð»Ñ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ñ— Ð´Ð¾Ð²Ñ–Ð´ÐºÐ¸.",
    "quick_help_title": "ðŸ¤– **Ð¨Ð²Ð¸Ð´ÐºÐ° Ð´Ð¾Ð²Ñ–Ð´ÐºÐ°**"
  },
  "buttons": {
    "new_session": "ðŸ†• ÐÐ¾Ð²Ð° ÑÐµÑÑ–Ñ",
    "continue_session": "ðŸ”„ ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸",
    "status": "ðŸ“Š Ð¡Ñ‚Ð°Ñ‚ÑƒÑ",
    "export": "ðŸ“¤ Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚",
    "help": "â“ Ð”Ð¾Ð²Ñ–Ð´ÐºÐ°",
    "full_help": "ðŸ“š ÐŸÐ¾Ð²Ð½Ð° Ð´Ð¾Ð²Ñ–Ð´ÐºÐ°",
    "settings": "âš™ï¸ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ",
    "main_menu": "ðŸ  Ð“Ð¾Ð»Ð¾Ð²Ð½Ðµ Ð¼ÐµÐ½ÑŽ",
    "confirmed": "âœ… ÐŸÑ–Ð´Ñ‚Ð²ÐµÑ€Ð´Ð¶ÐµÐ½Ð¾",
    "cancelled": "âŒ Ð¡ÐºÐ°ÑÐ¾Ð²Ð°Ð½Ð¾",
    "back": "ÐÐ°Ð·Ð°Ð´",
    "show_projects": "ðŸ“ ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸",
    "get_help": "â“ ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ñƒ",
    "check_status": "ðŸ“Š ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ",
    "language_settings": "ðŸŒ ÐœÐ¾Ð²Ð°",
    "root": "ðŸ  ÐšÐ¾Ñ€Ñ–Ð½ÑŒ",
    "refresh": "ðŸ”„ ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸",
    "list_files": "ðŸ“ Ð¤Ð°Ð¹Ð»Ð¸",
    "projects": "ðŸ“ ÐŸÑ€Ð¾ÐµÐºÑ‚Ð¸",
    "start_coding": "ðŸ“ ÐŸÐ¾Ñ‡Ð°Ñ‚Ð¸ ÐºÐ¾Ð´Ð¸Ñ‚Ð¸",
    "change_project": "ðŸ“ Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚",
    "quick_actions": "ðŸ“‹ Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ—",
    "continue": "ðŸ”„ ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸",
    "explain": "ðŸ’¡ ÐŸÐ¾ÑÑÐ½Ð¸Ñ‚Ð¸",
    "debug": "ðŸ”§ Ð’Ñ–Ð´Ð»Ð°Ð´Ð¸Ñ‚Ð¸",
    "continue_prompt": "âœ… **Ð“Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð´Ð¾ Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶ÐµÐ½Ð½Ñ!**\n\nÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð²Ð°ÑˆÐµ Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ Ð°Ð±Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚:\nâ€¢ Ð”Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ñ– ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð½Ñ Ñ‰Ð¾Ð´Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸\nâ€¢ Ð—Ð°Ð¿Ð¸Ñ‚ Ð½Ð° Ð²Ð¿Ñ€Ð¾Ð²Ð°Ð´Ð¶ÐµÐ½Ð½Ñ Ð·Ð¼Ñ–Ð½\nâ€¢ Ð†Ð½ÑˆÑ– Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ Ð¿Ð¾ ÐºÐ¾Ð´Ñƒ\n\nÐ‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð¾Ð¿Ð¸ÑˆÑ–Ñ‚ÑŒ Ñ‰Ð¾ ÑÐ°Ð¼Ðµ Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ð¾ Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸ Ð´Ð°Ð»Ñ–.",
    "continue_dialog": "ðŸ”„ ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸ Ð´Ñ–Ð°Ð»Ð¾Ð³",
    "go_up": "â¬†ï¸ Ð’Ð³Ð¾Ñ€Ñƒ",
    "git_status": "ðŸ“Š Git Ð¡Ñ‚Ð°Ñ‚ÑƒÑ",
    "lint_code": "ðŸ”§ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ ÐºÐ¾Ð´",
    "show_diff": "ðŸ“Š ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð·Ð¼Ñ–Ð½Ð¸",
    "create_task": "ðŸ“ Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ",
    "from_template": "ðŸ“‹ Ð—Ñ– ÑˆÐ°Ð±Ð»Ð¾Ð½Ñƒ",
    "add": "âž• Ð”Ð¾Ð´Ð°Ñ‚Ð¸",
    "edit": "ðŸ“ Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸",
    "update": "ðŸ”„ ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸",
    "add_task": "âž• Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ",
    "change_dnd": "ðŸŒ™ Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ DND",
    "advanced_settings": "âš¡ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ",
    "detailed_logs": "ðŸ“‹ Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ– Ð»Ð¾Ð³Ð¸",
    "statistics": "ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°",
    "create_prompt": "ðŸ“ Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚",
    "prompts_list": "ðŸ“‹ Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²",
    "prompt_templates": "ðŸ“‹ Ð¨Ð°Ð±Ð»Ð¾Ð½Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²",
    "back_to_menu": "â¬…ï¸ ÐÐ°Ð·Ð°Ð´ Ð´Ð¾ Ð¼ÐµÐ½ÑŽ",
    "create_new": "ðŸ“ Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð½Ð¾Ð²Ð¸Ð¹",
    "back_simple": "â¬…ï¸ ÐÐ°Ð·Ð°Ð´",
    "prompts_settings": "ðŸ”§ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ",
    "prompts_history": "ðŸ“Š Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ",
    "json_export": "ðŸ“‹ JSON",
    "markdown_export": "ðŸ“ Markdown"
  },
  "messages": {
    "language_select": "ðŸŒ **Ð’Ð¸Ð±Ñ–Ñ€ Ð¼Ð¾Ð²Ð¸**\n\nÐ‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð¾Ð±ÐµÑ€Ñ–Ñ‚ÑŒ Ð²Ð°ÑˆÑƒ Ð±Ð°Ð¶Ð°Ð½Ñƒ Ð¼Ð¾Ð²Ñƒ:",
    "language_changed": "âœ… ÐœÐ¾Ð²Ð° Ð·Ð¼Ñ–Ð½ÐµÐ½Ð° Ð½Ð° {language_name}",
    "language_not_available": "âŒ ÐœÐ¾Ð²Ð° Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°: {language}",
    "error_occurred": "âŒ Ð¡Ñ‚Ð°Ð»Ð°ÑÑ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°: {error}",
    "working": "ÐŸÑ€Ð°Ñ†ÑŽÑŽ...",
    "processing": "ðŸ”„ **{content}**",
    "claude_unavailable": "âŒ **Claude Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°**\n\nÐ†Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Claude Code Ð½Ðµ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð° Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾. Ð—Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°.",
    "executing_action": "ðŸš€ **Ð’Ð¸ÐºÐ¾Ð½ÑƒÑŽ {action}**\n\nÐ‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð·Ð°Ñ‡ÐµÐºÐ°Ð¹Ñ‚Ðµ...",
    "action_completed": "âœ… **{action} Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾**",
    "action_failed": "âŒ **Ð”Ñ–Ñ Ð½Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð°**\n\nÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð²Ð¸ÐºÐ¾Ð½Ð°Ñ‚Ð¸ {action}. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·.",
    "what_next": "ðŸ’¡ **Ð©Ð¾ Ð²Ð¸ Ð± Ñ…Ð¾Ñ‚Ñ–Ð»Ð¸ Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸ Ð´Ð°Ð»Ñ–?**"
  },
  "errors": {
    "service_unavailable": "âŒ Ð¡Ð»ÑƒÐ¶Ð±Ð° Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ.",
    "session_start_failed": "âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ ÑÐµÑÑ–ÑŽ",
    "command_failed": "âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð²Ð¸ÐºÐ¾Ð½Ð°Ñ‚Ð¸ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ",
    "unexpected_error": "âŒ Ð’Ð¸Ð½Ð¸ÐºÐ»Ð° Ð½ÐµÐ¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ.",
    "settings_not_available": "âŒ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–",
    "quick_actions_unavailable": "âŒ Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ— Ð·Ð°Ñ€Ð°Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ.",
    "image_processing_disabled": "âŒ ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ Ð²Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð°. Ð—Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð° Ð´Ð»Ñ ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð½Ñ."
  },
  "quick_actions": {
    "title": "ðŸ› ï¸ **Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ—**\n\nÐ’Ð¸Ð±ÐµÑ€Ñ–Ñ‚ÑŒ Ð·Ð°Ð³Ð°Ð»ÑŒÐ½Ñƒ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ñ€Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ¸:",
    "no_actions": "ÐÐµÐ¼Ð°Ñ” ÑˆÐ²Ð¸Ð´ÐºÐ¸Ñ… Ð´Ñ–Ð¹ Ð´Ð»Ñ Ñ†ÑŒÐ¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ.",
    "unavailable": "Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ— Ð½Ð°Ñ€Ð°Ð·Ñ– Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–.",
    "test": {
      "name": "ðŸ§ª Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ñ‚ÐµÑÑ‚Ð¸"
    },
    "install": {
      "name": "ðŸ“¦ Ð’ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ð¸ Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ÑÑ‚Ñ–"
    },
    "format": {
      "name": "ðŸŽ¨ Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ ÐºÐ¾Ð´"
    },
    "find_todos": {
      "name": "ðŸ” Ð—Ð½Ð°Ð¹Ñ‚Ð¸ TODO"
    },
    "build": {
      "name": "ðŸ”¨ Ð—Ð±Ñ–Ñ€ÐºÐ°"
    },
    "start": {
      "name": "ðŸš€ Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ ÑÐµÑ€Ð²ÐµÑ€"
    },
    "git_status": {
      "name": "ðŸ“Š Git ÑÑ‚Ð°Ñ‚ÑƒÑ"
    },
    "lint": {
      "name": "ðŸ”§ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ ÐºÐ¾Ð´"
    }
  },
  "status": {
    "title": "ðŸ“Š **Ð¡Ñ‚Ð°Ñ‚ÑƒÑ ÑÐµÑÑ–Ñ—**",
    "directory": "ðŸ“‚ Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ: `{directory}`",
    "claude_session_active": "ðŸ¤– Ð¡ÐµÑÑ–Ñ Claude: âœ… ÐÐºÑ‚Ð¸Ð²Ð½Ð°",
    "claude_session_inactive": "ðŸ¤– Ð¡ÐµÑÑ–Ñ Claude: âŒ ÐÐµÐ°ÐºÑ‚Ð¸Ð²Ð½Ð°",
    "usage": "ðŸ’° Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ: ${usage} / ${limit} ({percent}%)",
    "last_update": "ðŸ• ÐžÑÑ‚Ð°Ð½Ð½Ñ” Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ: {time} UTC",
    "session_id": "ðŸ†” ID ÑÐµÑÑ–Ñ—: `{session_id}...`",
    "usage_info": "ðŸ’° Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ: ${current_cost} / ${cost_limit} ({cost_percentage}%)",
    "usage_error": "ðŸ’° Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ: _ÐÐµ Ð²Ð´Ð°Ñ”Ñ‚ÑŒÑÑ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ð´Ð°Ð½Ñ–_"
  },
  "errors_extended": {
    "unknown_action": "âŒ **ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð° Ð´Ñ–Ñ**\n\n{message}",
    "error_processing": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð´Ñ–Ñ—**\n\n{error}",
    "access_denied": "âŒ **Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ð·Ð°Ð±Ð¾Ñ€Ð¾Ð½ÐµÐ½Ð¾**\n\n{error}",
    "directory_not_found": "âŒ **Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\nÐ”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ `{path}` Ð±Ñ–Ð»ÑŒÑˆÐµ Ð½Ðµ Ñ–ÑÐ½ÑƒÑ” Ð°Ð±Ð¾ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°.",
    "not_a_directory": "âŒ **ÐÐµ Ñ” Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ”ÑŽ**\n\n`{path}` Ð½Ðµ Ñ” Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ”ÑŽ.",
    "error_changing_directory": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð¼Ñ–Ð½Ð¸ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—**\n\n{error}",
    "unknown_action_type": "âŒ **ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¸Ð¹ Ñ‚Ð¸Ð¿ Ð´Ñ–Ñ—: {action_type}**\n\n{message}",
    "error_listing_directory": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ´Ñƒ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—: {error}",
    "error_loading_projects": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñ–Ð²: {error}",
    "claude_integration_not_available": "âŒ **Claude Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°**\n\nÐ†Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Claude Code Ð½Ðµ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð° Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾. Ð—Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°.",
    "no_session_found": "âŒ **Ð¡ÐµÑÑ–ÑŽ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\n{message}",
    "error_continuing_session": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶ÐµÐ½Ð½Ñ ÑÐµÑÑ–Ñ—**\n\n{message}",
    "git_integration_disabled": "âŒ **Git Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ð²Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð°**\n\n{message}",
    "git_integration_unavailable": "âŒ **Git Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°**\n\n{message}",
    "git_error": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Git**\n\n{error}",
    "export_unavailable": "âŒ **Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹**\n\nÐ¡ÐµÑ€Ð²Ñ–Ñ ÐµÐºÑÐ¿Ð¾Ñ€Ñ‚Ñƒ ÑÐµÑÑ–Ñ— Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹.",
    "no_active_session": "âŒ **ÐÐµÐ¼Ð°Ñ” Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ñ— ÑÐµÑÑ–Ñ—**\n\nÐÐµÐ¼Ð°Ñ” Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ñ— ÑÐµÑÑ–Ñ— Ð´Ð»Ñ ÐµÐºÑÐ¿Ð¾Ñ€Ñ‚Ñƒ.",
    "export_failed": "âŒ **Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð½Ðµ Ð²Ð´Ð°Ð²ÑÑ**\n\n{error}",
    "localization_not_available": "âŒ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð»Ð¾ÐºÐ°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ— Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°",
    "quick_actions_disabled": "âŒ **Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ— Ð²Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ñ–**\n\n{message}",
    "file_upload_rejected": "âŒ **Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñƒ Ð²Ñ–Ð´Ñ…Ð¸Ð»ÐµÐ½Ð¾**\n\n{error}",
    "file_too_large": "âŒ **Ð¤Ð°Ð¹Ð» Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹**\n\nÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€ Ñ„Ð°Ð¹Ð»Ñƒ: {max_size}ÐœÐ‘\nÐ’Ð°Ñˆ Ñ„Ð°Ð¹Ð»: {file_size}ÐœÐ‘",
    "error_processing_message": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ**\n\n{error}",
    "error_processing_file": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ñ„Ð°Ð¹Ð»Ñƒ**\n\n{error}",
    "error_processing_image": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ**\n\n{error}",
    "timeout_error": "â° **Ð¢Ð°Ð¹Ð¼-Ð°ÑƒÑ‚ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ**\n\nÐ’Ð°Ñˆ Ð·Ð°Ð¿Ð¸Ñ‚ Ð·Ð°Ð¹Ð½ÑÐ² Ð·Ð°Ð±Ð°Ð³Ð°Ñ‚Ð¾ Ñ‡Ð°ÑÑƒ Ñ– Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ð²ÑÑ Ñ‚Ð°Ð¹Ð¼-Ð°ÑƒÑ‚Ð¾Ð¼.\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ€Ð¾Ð·Ð±Ð¸Ñ‚Ð¸ Ð·Ð°Ð¿Ð¸Ñ‚ Ð½Ð° Ð¼ÐµÐ½ÑˆÑ– Ñ‡Ð°ÑÑ‚Ð¸Ð½Ð¸\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ–ÑˆÑ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸\nâ€¢ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ñ‡ÐµÑ€ÐµÐ· Ð¼Ð¸Ñ‚ÑŒ",
    "rate_limit_reached": "â±ï¸ **Ð”Ð¾ÑÑÐ³Ð½ÑƒÑ‚Ð¾ Ð»Ñ–Ð¼Ñ–Ñ‚ ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ–**\n\nÐ—Ð°Ð±Ð°Ð³Ð°Ñ‚Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð² Ð·Ð° ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ð¿ÐµÑ€Ñ–Ð¾Ð´ Ñ‡Ð°ÑÑƒ.\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð—Ð°Ñ‡ÐµÐºÐ°Ð¹Ñ‚Ðµ Ð¼Ð¸Ñ‚ÑŒ Ð¿ÐµÑ€ÐµÐ´ Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑŽ ÑÐ¿Ñ€Ð¾Ð±Ð¾ÑŽ\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ–ÑˆÑ– Ð·Ð°Ð¿Ð¸Ñ‚Ð¸\nâ€¢ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ð²Ð°ÑˆÐµ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾ÑŽ `/status`",
    "no_conversation_found": "ðŸ”„ **Ð¡ÐµÑÑ–ÑŽ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\nÐ¡ÐµÑÑ–ÑŽ Claude Ð½Ðµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð·Ð½Ð°Ð¹Ñ‚Ð¸ Ð°Ð±Ð¾ Ð²Ð¾Ð½Ð° Ð·Ð°ÐºÑ–Ð½Ñ‡Ð¸Ð»Ð°ÑÑ.\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ `/new` Ñ‰Ð¾Ð± Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ ÑÐµÑÑ–ÑŽ\nâ€¢ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ð¸Ñ‚ Ð·Ð½Ð¾Ð²Ñƒ\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ `/status` Ñ‰Ð¾Ð± Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñƒ ÑÐµÑÑ–ÑŽ",
    "claude_code_error": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Claude Code**\n\nÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¾Ð±Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ð¸Ñ‚: {error}\n\nÐ¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ð°Ð±Ð¾ Ð·Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°, ÑÐºÑ‰Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð½Ðµ Ð·Ð½Ð¸ÐºÐ½Ðµ.",
    "failed_to_send_response": "âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð½Ð°Ð´Ñ–ÑÐ»Ð°Ñ‚Ð¸ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·."
  },
  "auth": {
    "authentication_required": "ðŸ”’ ÐŸÐ¾Ñ‚Ñ€Ñ–Ð±Ð½Ð° Ð°Ð²Ñ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ.",
    "authentication_required_command": "ðŸ”’ Ð”Ð»Ñ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ñ†Ñ–Ñ”Ñ— ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸ Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ð° Ð°Ð²Ñ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ.",
    "session_unavailable": "ðŸ”’ Ð†Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ Ð¿Ñ€Ð¾ ÑÐµÑÑ–ÑŽ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°.",
    "admin_access_required": "ðŸ”’ **ÐŸÐ¾Ñ‚Ñ€Ñ–Ð±ÐµÐ½ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°**\n\nÐ¦Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð° Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÑ” Ð¿Ñ€Ð¸Ð²Ñ–Ð»ÐµÑ—Ð² Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°."
  },
  "system_errors": {
    "auth_required": "ðŸ”’ ÐŸÐ¾Ñ‚Ñ€Ñ–Ð±Ð½Ð° Ð°Ð²Ñ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ. Ð—Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°.",
    "security_violation": "ðŸ›¡ï¸ Ð’Ð¸ÑÐ²Ð»ÐµÐ½Ð¾ Ð¿Ð¾Ñ€ÑƒÑˆÐµÐ½Ð½Ñ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸. Ð¦ÑŽ Ð¿Ð¾Ð´Ñ–ÑŽ Ð·Ð°Ñ€ÐµÑ”ÑÑ‚Ñ€Ð¾Ð²Ð°Ð½Ð¾.",
    "rate_limit_exceeded": "â±ï¸ ÐŸÐµÑ€ÐµÐ²Ð¸Ñ‰ÐµÐ½Ð¾ Ð»Ñ–Ð¼Ñ–Ñ‚ ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ–. Ð—Ð°Ñ‡ÐµÐºÐ°Ð¹Ñ‚Ðµ Ð¿ÐµÑ€ÐµÐ´ Ð²Ñ–Ð´Ð¿Ñ€Ð°Ð²ÐºÐ¾ÑŽ Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¸Ñ… Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½ÑŒ.",
    "configuration_error": "âš™ï¸ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ—. Ð—Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°.",
    "operation_timeout": "â° ÐžÐ¿ÐµÑ€Ð°Ñ†Ñ–Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ð»Ð°ÑÑ Ñ‚Ð°Ð¹Ð¼-Ð°ÑƒÑ‚Ð¾Ð¼. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ð· Ð¿Ñ€Ð¾ÑÑ‚Ñ–ÑˆÐ¸Ð¼ Ð·Ð°Ð¿Ð¸Ñ‚Ð¾Ð¼.",
    "unexpected_error": "âŒ Ð’Ð¸Ð½Ð¸ÐºÐ»Ð° Ð½ÐµÐ¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·."
  },
  "session": {
    "new_started": "ðŸ†• ÐÐ¾Ð²Ñƒ ÑÐµÑÑ–ÑŽ Ñ€Ð¾Ð·Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¾",
    "continue_ready": "ðŸ”„ Ð“Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸ Ñ€Ð¾Ð±Ð¾Ñ‚Ñƒ! ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð¼ÐµÐ½Ñ– ÐºÐ¾Ð´ Ð°Ð±Ð¾ Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ.",
    "ended": "ðŸ Ð¡ÐµÑÑ–ÑŽ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾",
    "cleared": "ðŸ”„ Ð¡ÐµÑÑ–ÑŽ Claude Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð¾. ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ, Ñ‰Ð¾Ð± Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¸ ÐºÐ¾Ð´Ð¸Ñ‚Ð¸ Ð² Ñ†Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—.",
    "ready_to_code": "ðŸš€ **Ð“Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð´Ð¾ ÐºÐ¾Ð´ÑƒÐ²Ð°Ð½Ð½Ñ!**",
    "send_message_prompt": "ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð¼ÐµÐ½Ñ– Ð±ÑƒÐ´ÑŒ-ÑÐºÐµ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ, Ñ‰Ð¾Ð± Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¸ ÐºÐ¾Ð´ÑƒÐ²Ð°Ñ‚Ð¸ Ð· Claude:",
    "examples_title": "**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸:**",
    "example_create_script": "â€¢ _\"Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸ Python ÑÐºÑ€Ð¸Ð¿Ñ‚ ÑÐºÐ¸Ð¹...\"_",
    "example_debug_code": "â€¢ _\"Ð”Ð¾Ð¿Ð¾Ð¼Ð¾Ð¶Ð¸ Ð²Ñ–Ð´Ð»Ð°Ð´Ð¸Ñ‚Ð¸ Ñ†ÐµÐ¹ ÐºÐ¾Ð´...\"_",
    "example_explain_file": "â€¢ _\"ÐŸÐ¾ÑÑÐ½Ð¸ ÑÐº Ð¿Ñ€Ð°Ñ†ÑŽÑ” Ñ†ÐµÐ¹ Ñ„Ð°Ð¹Ð»...\"_",
    "example_upload_file": "â€¢ Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ñ‚Ðµ Ñ„Ð°Ð¹Ð» Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ´Ñƒ",
    "help_message": "Ð¯ Ñ‚ÑƒÑ‚, Ñ‰Ð¾Ð± Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ñ‚Ð¸ Ð· ÑƒÑÑ–Ð¼Ð° Ð²Ð°ÑˆÐ¸Ð¼Ð¸ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð°Ð¼Ð¸ Ð² ÐºÐ¾Ð´ÑƒÐ²Ð°Ð½Ð½Ñ–!"
  },
  "commands_extended": {
    "new_session": {
      "title": "ðŸ†• **ÐÐ¾Ð²Ð° ÑÐµÑÑ–Ñ Claude Code**",
      "working_directory": "ðŸ“‚ Ð Ð¾Ð±Ð¾Ñ‡Ð° Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ: `{relative_path}/`",
      "ready_message": "Ð“Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð´Ð¾Ð¿Ð¾Ð¼Ð°Ð³Ð°Ñ‚Ð¸ Ð· ÐºÐ¾Ð´ÑƒÐ²Ð°Ð½Ð½ÑÐ¼! ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð¼ÐµÐ½Ñ– Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ñ‰Ð¾Ð± Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¸, Ð°Ð±Ð¾ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ ÐºÐ½Ð¾Ð¿ÐºÐ¸ Ð½Ð¸Ð¶Ñ‡Ðµ:",
      "button_start_coding": "ðŸ“ ÐŸÐ¾Ñ‡Ð°Ñ‚Ð¸ ÐºÐ¾Ð´ÑƒÐ²Ð°Ñ‚Ð¸",
      "button_change_project": "ðŸ“ Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚",
      "button_quick_actions": "ðŸ“‹ Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ—",
      "button_help": "â“ Ð”Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð°"
    },
    "continue_session": {
      "continuing": "ðŸ”„ **ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶ÐµÐ½Ð½Ñ ÑÐµÑÑ–Ñ—**",
      "session_id": "ID ÑÐµÑÑ–Ñ—: `{session_id}...`",
      "directory": "Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ: `{relative_path}/`",
      "processing_message": "ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° Ð²Ð°ÑˆÐ¾Ð³Ð¾ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ...",
      "continuing_message": "ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶ÑƒÑ”Ð¼Ð¾ Ð· Ñ‚Ð¾Ð³Ð¾ Ð¼Ñ–ÑÑ†Ñ, Ð´Ðµ Ð·ÑƒÐ¿Ð¸Ð½Ð¸Ð»Ð¸ÑÑ...",
      "looking_for_session": "ðŸ” **ÐŸÐ¾ÑˆÑƒÐº Ð¾ÑÑ‚Ð°Ð½Ð½ÑŒÐ¾Ñ— ÑÐµÑÑ–Ñ—**",
      "searching_message": "Ð¨ÑƒÐºÐ°ÑŽ Ð²Ð°ÑˆÑƒ Ð¾ÑÑ‚Ð°Ð½Ð½ÑŽ ÑÐµÑÑ–ÑŽ Ð² Ñ†Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—..."
    },
    "cd": {
      "usage_title": "**Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ:** `/cd <Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ>`",
      "examples_title": "**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸:**",
      "example_subdirectory": "Ð£Ð²Ñ–Ð¹Ñ‚Ð¸ Ð² Ð¿Ñ–Ð´Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ",
      "example_up_level": "ÐŸÑ–Ð´Ð½ÑÑ‚Ð¸ÑÑ Ð½Ð° Ð¾Ð´Ð¸Ð½ Ñ€Ñ–Ð²ÐµÐ½ÑŒ Ð²Ð³Ð¾Ñ€Ñƒ",
      "example_root": "ÐŸÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ð´Ð¾ ÐºÐ¾Ñ€ÐµÐ½Ñ Ð´Ð¾Ð·Ð²Ð¾Ð»ÐµÐ½Ð¾Ñ— Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—",
      "tips_title": "**ÐŸÐ¾Ñ€Ð°Ð´Ð¸:**",
      "tip_ls": "Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ `/ls` Ñ‰Ð¾Ð± Ð¿Ð¾Ð±Ð°Ñ‡Ð¸Ñ‚Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—",
      "tip_projects": "Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ `/projects` Ñ‰Ð¾Ð± Ð¿Ð¾Ð±Ð°Ñ‡Ð¸Ñ‚Ð¸ Ð²ÑÑ– Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸",
      "access_denied": "âŒ **Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ð·Ð°Ð±Ð¾Ñ€Ð¾Ð½ÐµÐ½Ð¾**",
      "directory_not_found": "âŒ **Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\n`{path}` Ð½Ðµ Ñ–ÑÐ½ÑƒÑ”.",
      "not_a_directory": "âŒ **ÐÐµ Ñ” Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ”ÑŽ**\n\n`{path}` Ð½Ðµ Ñ” Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ”ÑŽ.",
      "directory_changed": "âœ… **Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ Ð·Ð¼Ñ–Ð½ÐµÐ½Ð¾**\n\nðŸ“‚ ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð° Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ: `{relative_path}/`\n\nðŸ”„ Ð¡ÐµÑÑ–ÑŽ Claude Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð¾. ÐœÐ¾Ð¶ÐµÑ‚Ðµ Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¸ ÐºÐ¾Ð´ÑƒÐ²Ð°Ñ‚Ð¸ Ð² Ñ†Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—!"
    },
    "pwd": {
      "title": "ðŸ“ **ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð° Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ**",
      "relative": "Ð’Ñ–Ð´Ð½Ð¾ÑÐ½Ð°: `{relative_path}/`",
      "absolute": "ÐÐ±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð°: `{absolute_path}`",
      "button_list_files": "ðŸ“ Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ„Ð°Ð¹Ð»Ñ–Ð²",
      "button_projects": "ðŸ“‹ ÐŸÑ€Ð¾ÐµÐºÑ‚Ð¸"
    },
    "ls": {
      "empty_directory": "_(Ð¿Ð¾Ñ€Ð¾Ð¶Ð½Ñ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ)_",
      "more_items": "_... Ñ‚Ð° Ñ‰Ðµ {count} ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ–Ð²_",
      "button_go_up": "â¬†ï¸ Ð’Ð³Ð¾Ñ€Ñƒ",
      "button_go_to_root": "ðŸ  Ð”Ð¾ ÐºÐ¾Ñ€ÐµÐ½Ñ",
      "button_refresh": "ðŸ”„ ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸",
      "button_projects": "ðŸ“ ÐŸÑ€Ð¾ÐµÐºÑ‚Ð¸"
    },
    "projects": {
      "no_projects_title": "ðŸ“ **ÐŸÑ€Ð¾ÐµÐºÑ‚Ð¸ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**",
      "no_projects_message": "Ð’ Ð´Ð¾Ð·Ð²Ð¾Ð»ÐµÐ½Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ— Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¿Ñ–Ð´Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ð¹.\nÐ¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ Ð´ÐµÑÐºÑ– Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ— Ñ‰Ð¾Ð± Ð¾Ñ€Ð³Ð°Ð½Ñ–Ð·ÑƒÐ²Ð°Ñ‚Ð¸ Ð²Ð°ÑˆÑ– Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸!",
      "available_projects_title": "ðŸ“ **Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸**",
      "click_to_navigate": "ÐÐ°Ñ‚Ð¸ÑÐ½Ñ–Ñ‚ÑŒ Ð½Ð° Ð¿Ñ€Ð¾ÐµÐºÑ‚ Ð½Ð¸Ð¶Ñ‡Ðµ Ñ‰Ð¾Ð± Ð¿ÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ð´Ð¾ Ð½ÑŒÐ¾Ð³Ð¾:",
      "button_go_to_root": "ðŸ  Ð”Ð¾ ÐºÐ¾Ñ€ÐµÐ½Ñ",
      "button_refresh": "ðŸ”„ ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸",
      "error_loading": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ–Ð²: {error}"
    },
    "status": {
      "session_active": "âœ… ÐÐºÑ‚Ð¸Ð²Ð½Ð°",
      "session_none": "âŒ ÐÐµÐ¼Ð°Ñ”",
      "usage_unable_retrieve": "ðŸ’° Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ: _ÐÐµ Ð²Ð´Ð°Ñ”Ñ‚ÑŒÑÑ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸_",
      "button_continue": "ðŸ”„ ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸",
      "button_new_session": "ðŸ†• ÐÐ¾Ð²Ð° ÑÐµÑÑ–Ñ",
      "button_start_session": "ðŸ†• ÐŸÐ¾Ñ‡Ð°Ñ‚Ð¸ ÑÐµÑÑ–ÑŽ",
      "button_export": "ðŸ“¤ Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚",
      "button_refresh": "ðŸ”„ ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸"
    },
    "export": {
      "not_available_title": "ðŸ“¤ **Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ ÑÐµÑÑ–Ñ—**",
      "not_available_message": "Ð¤ÑƒÐ½ÐºÑ†Ñ–Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ–ÑÑ‚ÑŒ ÐµÐºÑÐ¿Ð¾Ñ€Ñ‚Ñƒ ÑÐµÑÑ–Ñ— Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°.",
      "planned_features_title": "**Ð—Ð°Ð¿Ð»Ð°Ð½Ð¾Ð²Ð°Ð½Ñ– Ñ„ÑƒÐ½ÐºÑ†Ñ–Ñ—:**",
      "planned_export_history": "Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ñ–ÑÑ‚Ð¾Ñ€Ñ–Ñ— Ñ€Ð¾Ð·Ð¼Ð¾Ð²",
      "planned_save_state": "Ð—Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ ÑÑ‚Ð°Ð½Ñƒ ÑÐµÑÑ–Ñ—",
      "planned_share_conversations": "ÐŸÐ¾Ð´Ñ–Ð»Ð¸Ñ‚Ð¸ÑÑ Ñ€Ð¾Ð·Ð¼Ð¾Ð²Ð°Ð¼Ð¸",
      "planned_create_backups": "Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ð¸Ñ… ÐºÐ¾Ð¿Ñ–Ð¹ ÑÐµÑÑ–Ð¹",
      "no_active_session_title": "âŒ **ÐÐµÐ¼Ð°Ñ” Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ñ— ÑÐµÑÑ–Ñ—**",
      "no_active_session_message": "ÐÐµÐ¼Ð°Ñ” Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ñ— ÑÐµÑÑ–Ñ— Claude Ð´Ð»Ñ ÐµÐºÑÐ¿Ð¾Ñ€Ñ‚Ñƒ.",
      "what_you_can_do_title": "**Ð©Ð¾ Ð²Ð¸ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**",
      "start_new_session": "ÐŸÐ¾Ñ‡Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ ÑÐµÑÑ–ÑŽ Ð· `/new`",
      "continue_existing_session": "ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸ Ñ–ÑÐ½ÑƒÑŽÑ‡Ñƒ ÑÐµÑÑ–ÑŽ Ð· `/continue`",
      "check_status": "ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð²Ð°Ñˆ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð· `/status`",
      "export_title": "ðŸ“¤ **Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ ÑÐµÑÑ–Ñ—**",
      "ready_to_export": "Ð“Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð´Ð¾ ÐµÐºÑÐ¿Ð¾Ñ€Ñ‚Ñƒ ÑÐµÑÑ–Ñ—: `{session_id}...`",
      "choose_format": "**Ð’Ð¸Ð±ÐµÑ€Ñ–Ñ‚ÑŒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ ÐµÐºÑÐ¿Ð¾Ñ€Ñ‚Ñƒ:**",
      "button_markdown": "ðŸ“ Markdown",
      "button_html": "ðŸŒ HTML",
      "button_json": "ðŸ“‹ JSON",
      "button_cancel": "âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸"
    }
  },
  "messages_extended": {
    "failed_send_response": "âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð½Ð°Ð´Ñ–ÑÐ»Ð°Ñ‚Ð¸ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·.",
    "what_next": "ðŸ’¡ **Ð©Ð¾ Ð²Ð¸ Ð± Ñ…Ð¾Ñ‚Ñ–Ð»Ð¸ Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸ Ð´Ð°Ð»Ñ–?**"
  },
  "scheduled_prompts": {
    "error_loading_tasks": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ– ÑÐ¿Ð¸ÑÐºÑƒ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ",
    "error_system_toggle": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð¼Ñ–Ð½Ñ– ÑÑ‚Ð°Ð½Ñƒ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸",
    "history_empty": "ðŸ“Š **Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð¿Ð¾Ñ€Ð¾Ð¶Ð½Ñ**",
    "error_loading_history": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ– Ñ–ÑÑ‚Ð¾Ñ€Ñ–Ñ—"
  },
  "files": {
    "processing_file": "ðŸ“„ ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° Ñ„Ð°Ð¹Ð»Ñƒ: `{filename}`...",
    "processing_file_with_type": "ðŸ“„ ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° {type} Ñ„Ð°Ð¹Ð»Ñƒ: `{filename}`...",
    "available_projects": "ðŸ“ **Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ð¸**\n\n{message}\nÐÐ°Ñ‚Ð¸ÑÐ½Ñ–Ñ‚ÑŒ Ð½Ð° Ð¿Ñ€Ð¾Ñ”ÐºÑ‚ Ñ‰Ð¾Ð± Ð¿ÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ð´Ð¾ Ð½ÑŒÐ¾Ð³Ð¾:",
    "export_session": "ðŸ“¤ **Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ ÑÐµÑÑ–Ñ—**\n\nÐ“ÐµÐ½ÐµÑ€ÑƒÑ”Ñ‚ÑŒÑÑ {format} ÐµÐºÑÐ¿Ð¾Ñ€Ñ‚...",
    "export_complete_details": "ðŸ“¤ **Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ ÑÐµÑÑ–Ñ— Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾**\n\nÐ¤Ð¾Ñ€Ð¼Ð°Ñ‚: {format}\nÐ Ð¾Ð·Ð¼Ñ–Ñ€: {size} Ð±Ð°Ð¹Ñ‚\nÐ¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð¾: {created_at}"
  },
  "git": {
    "diff_title": "ðŸ“Š **Git Diff**\n\n```\n{diff}\n```",
    "unknown_git_action": "âŒ **ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð° Git Ð´Ñ–Ñ: {action}**\n\n{message}"
  },
  "processing": {
    "thinking": "ðŸ¤” ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° Ð²Ð°ÑˆÐ¾Ð³Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ...",
    "working_on_request": "ðŸ”„ ÐŸÑ€Ð°Ñ†ÑŽÑŽ Ð½Ð°Ð´ Ð²Ð°ÑˆÐ¸Ð¼ Ð·Ð°Ð¿Ð¸Ñ‚Ð¾Ð¼...",
    "generating_response": "âœ¨ Ð“ÐµÐ½ÐµÑ€ÑƒÑŽ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ..."
  },
  "availability": {
    "cli_available": "ðŸŸ¢ **Claude CLI Ð·Ð½Ð¾Ð²Ñƒ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹**\nðŸ“… `{timestamp}`\nðŸ–¥ï¸ `{platform}`\nâ±ï¸ {duration}",
    "cli_unavailable": "ðŸ”´ **Claude CLI Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹ (Ð»Ñ–Ð¼Ñ–Ñ‚ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ)**\nðŸ“… `{timestamp}`",
    "reset_time_expected": "\nâ³ ÐžÑ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð¸Ð¹ Ñ‡Ð°Ñ Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ: {time} (Ð·Ð° Ð´Ð°Ð½Ð¸Ð¼Ð¸ CLI)",
    "reset_time_actual": "\nðŸ“… Ð¤Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ð¸Ð¹ Ñ‡Ð°Ñ Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ: {actual_time}\nâ³ ÐžÑ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð¸Ð¹ Ð±ÑƒÐ²: {expected_time}",
    "downtime_duration": "(Ð¿ÐµÑ€ÐµÑ€Ð²Ð°: {hours}Ð³Ð¾Ð´ {minutes}Ñ…Ð²)"
  },
  "errors_command": {
    "error_continuing_session": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶ÐµÐ½Ð½Ñ ÑÐµÑÑ–Ñ—**\n\nÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ–Ð´ Ñ‡Ð°Ñ ÑÐ¿Ñ€Ð¾Ð±Ð¸ Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸ Ð²Ð°ÑˆÑƒ ÑÐµÑÑ–ÑŽ:\n\n`{error}`\n\n**ÐŸÑ€Ð¾Ð¿Ð¾Ð·Ð¸Ñ†Ñ–Ñ—:**\nâ€¢ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ ÑÐµÑÑ–ÑŽ Ð· `/new`\nâ€¢ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑ ÑÐµÑÑ–Ñ— Ð· `/status`\nâ€¢ Ð—Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ¸, ÑÐºÑ‰Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð·Ð°Ð»Ð¸ÑˆÐ°Ñ”Ñ‚ÑŒÑÑ",
    "claude_integration_unavailable": "âŒ **Ð†Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Claude Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°**\n\nÐ†Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Claude Code Ð½Ðµ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð° Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾.",
    "no_session_found": "âŒ **Ð¡ÐµÑÑ–ÑŽ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\nÐÐµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð½ÐµÐ´Ð°Ð²Ð½ÑŒÐ¾Ñ— ÑÐµÑÑ–Ñ— Claude Ð² Ñ†Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—.\nÐ”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ: `{path}/`\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð¡ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚ÐµÑÑŒ ÐºÐ½Ð¾Ð¿ÐºÐ¾ÑŽ Ð½Ð¸Ð¶Ñ‡Ðµ Ñ‰Ð¾Ð± Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ ÑÐµÑÑ–ÑŽ\nâ€¢ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑ ÑÐµÑÑ–Ñ—\nâ€¢ ÐŸÐµÑ€ÐµÐ¹Ð´Ñ–Ñ‚ÑŒ Ð´Ð¾ Ñ–Ð½ÑˆÐ¾Ñ— Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—",
    "access_denied": "âŒ **Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ð·Ð°Ð±Ð¾Ñ€Ð¾Ð½ÐµÐ½Ð¾**\n\n{error}",
    "directory_not_found": "âŒ **Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\n`{path}` Ð½Ðµ Ñ–ÑÐ½ÑƒÑ”.",
    "not_a_directory": "âŒ **ÐÐµ Ñ” Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ”ÑŽ**\n\n`{path}` Ð½Ðµ Ñ” Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ”ÑŽ.",
    "error_changing_directory": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð¼Ñ–Ð½Ð¸ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—**\n\n{error}",
    "error_listing_directory": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ñ‡Ð¸Ñ‚Ð°Ð½Ð½Ñ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—: {error}",
    "no_projects_found": "ðŸ“ **ÐŸÑ€Ð¾Ñ”ÐºÑ‚Ñ–Ð² Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\nÐ’ Ð·Ð°Ñ‚Ð²ÐµÑ€Ð´Ð¶ÐµÐ½Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ— Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¿Ñ–Ð´Ð¿Ð°Ð¿Ð¾Ðº.\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð½Ð¾Ð²Ð¸Ð¹ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚ Ð°Ð±Ð¾ Ð¿Ð°Ð¿ÐºÑƒ\nâ€¢ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ñ‚Ð²ÐµÑ€Ð´Ð¶ÐµÐ½Ð¾Ñ— Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñƒ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑŽ Ð´Ð»Ñ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸",
    "error_loading_projects": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñ–Ð²: {error}",
    "export_failed": "âŒ **Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð½Ðµ Ð²Ð´Ð°Ð²ÑÑ**\n\n{error}",
    "quick_actions_disabled": "âŒ **Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ— Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾**\n\nÐ¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ— Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾ Ð² Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½ÑÑ….\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð²Ð¸Ñ‡Ð°Ð¹Ð½Ñ– Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸\nâ€¢ Ð—Ð²ÐµÑ€Ð½ÑƒÑ‚Ð¸ÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð° Ð´Ð»Ñ ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð½Ñ",
    "quick_actions_unavailable": "âŒ **Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ— Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–**\n\nÐ¡ÐµÑ€Ð²Ñ–Ñ ÑˆÐ²Ð¸Ð´ÐºÐ¸Ñ… Ð´Ñ–Ð¹ Ð·Ð°Ñ€Ð°Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹.\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸",
    "no_actions_available": "ðŸ¤– **ÐÐµÐ¼Ð°Ñ” Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ñ… Ð´Ñ–Ð¹**\n\nÐÐ° Ð¶Ð°Ð»ÑŒ, Ð½ÐµÐ¼Ð°Ñ” ÑˆÐ²Ð¸Ð´ÐºÐ¸Ñ… Ð´Ñ–Ð¹ Ð´Ð»Ñ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ ÑÑ‚Ð°Ð½Ñƒ.\n\n**Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ:**\nâ€¢ ÐŸÐ¾Ñ‡Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ ÑÐµÑÑ–ÑŽ Ð· `/new`\nâ€¢ ÐŸÐµÑ€ÐµÐ³Ð»ÑÐ½ÑƒÑ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸ Ð· `/ls`\nâ€¢ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð· `/status`",
    "git_integration_disabled": "âŒ **Git Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð°**\n\nGit Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð° Ð² Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½ÑÑ….\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð²Ð¸Ñ‡Ð°Ð¹Ð½Ñ– git ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸ Ð² Claude\nâ€¢ Ð—Ð²ÐµÑ€Ð½ÑƒÑ‚Ð¸ÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð° Ð´Ð»Ñ ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð½Ñ",
    "git_integration_unavailable": "âŒ **Git Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°**\n\nÐ¡ÐµÑ€Ð²Ñ–Ñ Git Ð·Ð°Ñ€Ð°Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹.\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ git ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸ Ð² Claude",
    "not_git_repository": "ðŸ“‚ **ÐÐµ Ñ” Git Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ñ”Ð¼**\n\nÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð° Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ Ð½Ðµ Ñ” git Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ñ”Ð¼.\n\n**ÐžÐ¿Ñ†Ñ–Ñ—:**\nâ€¢ Ð†Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·ÑƒÐ²Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ð¸Ð¹ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ð¹\nâ€¢ ÐŸÐµÑ€ÐµÐ¹Ñ‚Ð¸ Ð´Ð¾ Ñ–ÑÐ½ÑƒÑŽÑ‡Ð¾Ð³Ð¾ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–ÑŽ\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð²Ð¸Ñ‡Ð°Ð¹Ð½Ñ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸"
  },
  "errors_message": {
    "session_not_found": "ðŸ”„ **Ð¡ÐµÑÑ–ÑŽ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\nÐ¡ÐµÑÑ–ÑŽ Claude Ð½Ðµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð·Ð½Ð°Ð¹Ñ‚Ð¸ Ð°Ð±Ð¾ Ð²Ð¾Ð½Ð° Ð·Ð°ÐºÑ–Ð½Ñ‡Ð¸Ð»Ð°ÑÑ.\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ `/new` Ñ‰Ð¾Ð± Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ ÑÐµÑÑ–ÑŽ\nâ€¢ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ð¸Ñ‚ Ð·Ð½Ð¾Ð²Ñƒ\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ `/status` Ñ‰Ð¾Ð± Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñƒ ÑÐµÑÑ–ÑŽ",
    "rate_limit_reached": "â±ï¸ **Ð›Ñ–Ð¼Ñ–Ñ‚ ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ– Ð´Ð¾ÑÑÐ³Ð½ÑƒÑ‚Ð¾**\n\nÐ—Ð°Ð±Ð°Ð³Ð°Ñ‚Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð² Ð·Ð° ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ñ‡Ð°Ñ.\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð—Ð°Ñ‡ÐµÐºÐ°Ð¹Ñ‚Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ Ð¿ÐµÑ€ÐµÐ´ Ð½Ð¾Ð²Ð¾ÑŽ ÑÐ¿Ñ€Ð¾Ð±Ð¾ÑŽ\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ–ÑˆÑ– Ð·Ð°Ð¿Ð¸Ñ‚Ð¸\nâ€¢ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ð· `/status`",
    "request_timeout": "â° **Ð¢Ð°Ð¹Ð¼Ð°ÑƒÑ‚ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ**\n\nÐ’Ð°Ñˆ Ð·Ð°Ð¿Ð¸Ñ‚ Ð·Ð°Ð¹Ð½ÑÐ² Ð·Ð°Ð±Ð°Ð³Ð°Ñ‚Ð¾ Ñ‡Ð°ÑÑƒ Ñ– Ð·Ð°ÐºÑ–Ð½Ñ‡Ð¸Ð²ÑÑ Ñ‚Ð°Ð¹Ð¼Ð°ÑƒÑ‚Ð¾Ð¼.\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ€Ð¾Ð·Ð±Ð¸Ñ‚Ð¸ Ð·Ð°Ð¿Ð¸Ñ‚ Ð½Ð° Ð¼ÐµÐ½ÑˆÑ– Ñ‡Ð°ÑÑ‚Ð¸Ð½Ð¸\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ–ÑˆÑ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸\nâ€¢ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð·Ð½Ð¾Ð²Ñƒ Ñ‡ÐµÑ€ÐµÐ· Ð¼Ð¾Ð¼ÐµÐ½Ñ‚",
    "claude_code_error": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Claude Code**\n\nÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¾Ð±Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ð¸Ñ‚: {error}\n\nÐ‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, ÑÐ¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð·Ð½Ð¾Ð²Ñƒ Ð°Ð±Ð¾ Ð·Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°, ÑÐºÑ‰Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð·Ð°Ð»Ð¸ÑˆÐ°Ñ”Ñ‚ÑŒÑÑ.",
    "file_format_not_supported": "âŒ **Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ„Ð°Ð¹Ð»Ñƒ Ð½Ðµ Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÑ”Ñ‚ÑŒÑÑ**\n\nÐ¤Ð°Ð¹Ð» Ð¼Ð°Ñ” Ð±ÑƒÑ‚Ð¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¸Ð¼ Ñ‚Ð° Ð·Ð°ÐºÐ¾Ð´Ð¾Ð²Ð°Ð½Ð¸Ð¼ Ð² UTF-8.\n\n**ÐŸÑ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÐ²Ð°Ð½Ñ– Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸:**\nâ€¢ Ð¤Ð°Ð¹Ð»Ð¸ ÐºÐ¾Ð´Ñƒ (.py, .js, .ts, Ñ‚Ð¾Ñ‰Ð¾)\nâ€¢ Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ñ– Ñ„Ð°Ð¹Ð»Ð¸ (.txt, .md)\nâ€¢ Ð¤Ð°Ð¹Ð»Ð¸ ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ— (.json, .yaml, .toml)\nâ€¢ Ð¤Ð°Ð¹Ð»Ð¸ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—",
    "claude_integration_not_available": "âŒ **Ð†Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Claude Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°**\n\nÐ†Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Claude Code Ð½Ðµ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð° Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾.",
    "processing_image": "ðŸ–¼ï¸ ÐžÐ±Ñ€Ð¾Ð±ÐºÐ° Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ...",
    "analyzing_image": "ðŸ¤– ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ Ð· Claude...",
    "file_truncated_notice": "\n... (Ñ„Ð°Ð¹Ð» Ð¾Ð±Ñ€Ñ–Ð·Ð°Ð½Ð¾ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸)",
    "review_file_default": "Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ½ÑŒÑ‚Ðµ Ñ†ÐµÐ¹ Ñ„Ð°Ð¹Ð»:"
  },
  "export": {
    "session_export_complete": "ðŸ“¤ **Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ ÑÐµÑÑ–Ñ— Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾**\n\nÐ¤Ð¾Ñ€Ð¼Ð°Ñ‚: {format}\nÐ Ð¾Ð·Ð¼Ñ–Ñ€: {size} Ð±Ð°Ð¹Ñ‚\nÐ¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð¾: {created_at}",
    "export_complete": "âœ… **Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾**\n\nÐ’Ð°ÑˆÐ° ÑÐµÑÑ–Ñ Ð±ÑƒÐ»Ð° ÐµÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¾Ð²Ð°Ð½Ð° ÑÐº {filename}.\nÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ñ„Ð°Ð¹Ð» Ð²Ð¸Ñ‰Ðµ Ð´Ð»Ñ Ð¿Ð¾Ð²Ð½Ð¾Ñ— Ñ–ÑÑ‚Ð¾Ñ€Ñ–Ñ— Ñ€Ð¾Ð·Ð¼Ð¾Ð².",
    "export_session_progress": "ðŸ“¤ **Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ ÑÐµÑÑ–Ñ—**\n\nÐ“ÐµÐ½ÐµÑ€ÑƒÑ”Ñ‚ÑŒÑÑ {format} ÐµÐºÑÐ¿Ð¾Ñ€Ñ‚..."
  },
  "progress": {
    "tool_failed": "âŒ **{tool_name} Ð½Ðµ Ð²Ð´Ð°Ð²ÑÑ**\n\n_{error_message}_",
    "tool_completed": "âœ… **{tool_name} Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾**{execution_time}",
    "working_default": "ðŸ”„ **ÐŸÑ€Ð°Ñ†ÑŽÑŽ...**",
    "working_with_content": "ðŸ”„ **{content}**",
    "error_generic": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°**\n\n_{error_message}_",
    "using_tools": "ðŸ”§ **Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑŽ Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸:** {tools_text}",
    "claude_working": "ðŸ¤– **Claude Ð¿Ñ€Ð°Ñ†ÑŽÑ”...**\n\n_{content_preview}_",
    "starting_model": "ðŸš€ **Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ {model}** Ð· {tools_count} Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¼Ð¸ Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸",
    "processing_request": "ðŸ¤” ÐžÐ±Ñ€Ð¾Ð±Ð»ÑÑŽ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ð¸Ñ‚...",
    "processing_file_claude": "ðŸ¤– ÐžÐ±Ñ€Ð¾Ð±Ð»ÑÑŽ Ñ„Ð°Ð¹Ð» Ð· Claude...",
    "processing_file_basic": "ðŸ“„ ÐžÐ±Ñ€Ð¾Ð±Ð»ÑÑŽ Ñ„Ð°Ð¹Ð»: `{filename}`...",
    "processing_file_with_type": "ðŸ“„ ÐžÐ±Ñ€Ð¾Ð±Ð»ÑÑŽ {type} Ñ„Ð°Ð¹Ð»: `{filename}`...",
    "step_progress": "ÐšÑ€Ð¾Ðº {step} Ð· {total_steps}",
    "unknown_tool": "ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¸Ð¹",
    "tool_fallback": "Ð†Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚"
  },
  "error_messages": {
    "session_not_found": "ðŸ”„ **Ð¡ÐµÑÑ–ÑŽ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\nÐ¡ÐµÑÑ–ÑŽ Claude Ð½Ðµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð·Ð½Ð°Ð¹Ñ‚Ð¸ Ð°Ð±Ð¾ Ð²Ð¾Ð½Ð° Ð·Ð°ÐºÑ–Ð½Ñ‡Ð¸Ð»Ð°ÑÑ.\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ `/new` Ñ‰Ð¾Ð± Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ ÑÐµÑÑ–ÑŽ\nâ€¢ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ð¸Ñ‚ Ð·Ð½Ð¾Ð²Ñƒ\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ `/status` Ñ‰Ð¾Ð± Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñƒ ÑÐµÑÑ–ÑŽ",
    "rate_limit_reached": "â±ï¸ **Ð”Ð¾ÑÑÐ³Ð½ÑƒÑ‚Ð¾ Ð»Ñ–Ð¼Ñ–Ñ‚ ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ–**\n\nÐ—Ð°Ð±Ð°Ð³Ð°Ñ‚Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð² Ð·Ð° ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹ Ð¿ÐµÑ€Ñ–Ð¾Ð´ Ñ‡Ð°ÑÑƒ.\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð—Ð°Ñ‡ÐµÐºÐ°Ð¹Ñ‚Ðµ Ð¼Ð¸Ñ‚ÑŒ Ð¿ÐµÑ€ÐµÐ´ Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑŽ ÑÐ¿Ñ€Ð¾Ð±Ð¾ÑŽ\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ–ÑˆÑ– Ð·Ð°Ð¿Ð¸Ñ‚Ð¸\nâ€¢ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾ÑŽ `/status`",
    "request_timeout": "â° **Ð¢Ð°Ð¹Ð¼-Ð°ÑƒÑ‚ Ð·Ð°Ð¿Ð¸Ñ‚Ñƒ**\n\nÐ’Ð°Ñˆ Ð·Ð°Ð¿Ð¸Ñ‚ Ð·Ð°Ð¹Ð½ÑÐ² Ð·Ð°Ð±Ð°Ð³Ð°Ñ‚Ð¾ Ñ‡Ð°ÑÑƒ Ñ– Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ð²ÑÑ Ñ‚Ð°Ð¹Ð¼-Ð°ÑƒÑ‚Ð¾Ð¼.\n\n**Ð©Ð¾ Ð¼Ð¾Ð¶Ð½Ð° Ð·Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸:**\nâ€¢ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ€Ð¾Ð·Ð±Ð¸Ñ‚Ð¸ Ð·Ð°Ð¿Ð¸Ñ‚ Ð½Ð° Ð¼ÐµÐ½ÑˆÑ– Ñ‡Ð°ÑÑ‚Ð¸Ð½Ð¸\nâ€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ–ÑˆÑ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸\nâ€¢ Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ñ‡ÐµÑ€ÐµÐ· Ð¼Ð¸Ñ‚ÑŒ",
    "claude_code_error": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Claude Code**\n\nÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¾Ð±Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸ Ð²Ð°Ñˆ Ð·Ð°Ð¿Ð¸Ñ‚: {error}\n\nÐ¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ð°Ð±Ð¾ Ð·Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°, ÑÐºÑ‰Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð½Ðµ Ð·Ð½Ð¸ÐºÐ½Ðµ.",
    "claude_integration_not_available": "âŒ **Claude Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°**\n\nÐ†Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ Claude Code Ð½Ðµ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð° Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾. Ð—Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°.",
    "file_upload_rejected": "âŒ **Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñƒ Ð²Ñ–Ð´Ñ…Ð¸Ð»ÐµÐ½Ð¾**\n\n{error}",
    "file_too_large": "âŒ **Ð¤Ð°Ð¹Ð» Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹**\n\nÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€ Ñ„Ð°Ð¹Ð»Ñƒ: {max_size}ÐœÐ‘\nÐ’Ð°Ñˆ Ñ„Ð°Ð¹Ð»: {file_size}ÐœÐ‘",
    "file_format_not_supported": "âŒ **Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ„Ð°Ð¹Ð»Ñƒ Ð½Ðµ Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÑ”Ñ‚ÑŒÑÑ**\n\nÐ¤Ð°Ð¹Ð» Ð¼Ð°Ñ” Ð±ÑƒÑ‚Ð¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¸Ð¼ Ñ‚Ð° Ð·Ð°ÐºÐ¾Ð´Ð¾Ð²Ð°Ð½Ð¸Ð¼ Ð² UTF-8.\n\n**ÐŸÑ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÐ²Ð°Ð½Ñ– Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸:**\nâ€¢ Ð¤Ð°Ð¹Ð»Ð¸ ÐºÐ¾Ð´Ñƒ (.py, .js, .ts, Ñ‚Ð¾Ñ‰Ð¾)\nâ€¢ Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ñ– Ñ„Ð°Ð¹Ð»Ð¸ (.txt, .md)\nâ€¢ Ð¤Ð°Ð¹Ð»Ð¸ ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ— (.json, .yaml, .toml)\nâ€¢ Ð¤Ð°Ð¹Ð»Ð¸ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—",
    "processing_message_error": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ**\n\n{error}",
    "processing_file_error": "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ñ„Ð°Ð¹Ð»Ñƒ**\n\n{error}",
    "send_response_failed": "âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð½Ð°Ð´Ñ–ÑÐ»Ð°Ñ‚Ð¸ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·."
  },
  "callback_errors": {
    "unknown_action": "âŒ ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð° Ð´Ñ–Ñ",
    "action_not_implemented": "âŒ Ð”Ñ–Ñ Ð½Ðµ Ñ€ÐµÐ°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ð°"
  },
  "security": {
    "auth_required": "ðŸ”’ ÐŸÐ¾Ñ‚Ñ€Ñ–Ð±Ð½Ð° Ð°Ð²Ñ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ. Ð—Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°.",
    "security_violation": "ðŸ›¡ï¸ Ð’Ð¸ÑÐ²Ð»ÐµÐ½Ð¾ Ð¿Ð¾Ñ€ÑƒÑˆÐµÐ½Ð½Ñ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸. Ð¦ÑŽ Ð¿Ð¾Ð´Ñ–ÑŽ Ð·Ð°Ñ€ÐµÑ”ÑÑ‚Ñ€Ð¾Ð²Ð°Ð½Ð¾.",
    "rate_limit_exceeded": "â±ï¸ ÐŸÐµÑ€ÐµÐ²Ð¸Ñ‰ÐµÐ½Ð¾ Ð»Ñ–Ð¼Ñ–Ñ‚ ÑˆÐ²Ð¸Ð´ÐºÐ¾ÑÑ‚Ñ–. Ð—Ð°Ñ‡ÐµÐºÐ°Ð¹Ñ‚Ðµ Ð¿ÐµÑ€ÐµÐ´ Ð²Ñ–Ð´Ð¿Ñ€Ð°Ð²ÐºÐ¾ÑŽ Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¸Ñ… Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½ÑŒ.",
    "configuration_error": "âš™ï¸ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ—. Ð—Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°.",
    "operation_timeout": "â° ÐžÐ¿ÐµÑ€Ð°Ñ†Ñ–Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐ¸Ð»Ð°ÑÑ Ñ‚Ð°Ð¹Ð¼-Ð°ÑƒÑ‚Ð¾Ð¼. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ð· Ð¿Ñ€Ð¾ÑÑ‚Ñ–ÑˆÐ¸Ð¼ Ð·Ð°Ð¿Ð¸Ñ‚Ð¾Ð¼.",
    "unauthorized_access": "ðŸ” Ð¡Ð¿Ñ€Ð¾Ð±Ð° Ð½ÐµÐ°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð¾Ð²Ð°Ð½Ð¾Ð³Ð¾ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ñƒ Ð·Ð°Ð±Ð»Ð¾ÐºÐ¾Ð²Ð°Ð½Ð°."
  },
  "schedule": {
    "create_new": "Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð½Ð¾Ð²Ðµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ",
    "advanced": "Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ñ– Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ",
    "change_dnd": "Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ DND Ð¿ÐµÑ€Ñ–Ð¾Ð´",
    "add_task": "Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ",
    "edit_task": "Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ",
    "update_list": "ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº",
    "back_to_list": "ÐÐ°Ð·Ð°Ð´ Ð´Ð¾ ÑÐ¿Ð¸ÑÐºÑƒ",
    "back_to_settings": "ÐÐ°Ð·Ð°Ð´ Ð´Ð¾ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½ÑŒ"
  },
  "notifications": {
    "availability_issue": "âš ï¸ Ð’Ð¸ÑÐ²Ð»ÐµÐ½Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ Ð· Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–ÑÑ‚ÑŽ Claude API.",
    "update_available": "ðŸ†• Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð° Ð½Ð¾Ð²Ð° Ð²ÐµÑ€ÑÑ–Ñ Ð±Ð¾Ñ‚Ð°.",
    "daily_reset": "ðŸ” Ð©Ð¾Ð´ÐµÐ½Ð½Ð¸Ð¹ Ð»Ñ–Ð¼Ñ–Ñ‚ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ ÑÐºÐ¸Ð½ÑƒÑ‚Ð¾.",
    "quota_warning": "âš ï¸ Ð’Ð¸ Ð½Ð°Ð±Ð»Ð¸Ð¶Ð°Ñ”Ñ‚ÐµÑÑŒ Ð´Ð¾ Ñ‰Ð¾Ð´ÐµÐ½Ð½Ð¾Ð³Ð¾ Ð»Ñ–Ð¼Ñ–Ñ‚Ñƒ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ."
  },
  "explain": {
    "processing": "ðŸ¤– ÐžÑ‚Ñ€Ð¸Ð¼ÑƒÑŽ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ðµ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð½Ñ...",
    "no_response": "âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð½Ñ",
    "failed": "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð½Ñ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð½Ñ"
  },
  "claude_status": {
    "unavailable": "ðŸ”´ Claude Ð·Ð°Ñ€Ð°Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹",
    "checking": "ðŸŸ¡ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑŽ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–ÑÑ‚ÑŒ Claude...",
    "available": "ðŸŸ¢ Claude Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹",
    "rate_limited": "â³ Claude Ñ‚Ð¸Ð¼Ñ‡Ð°ÑÐ¾Ð²Ð¾ Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð¸Ð¹ (rate limit)",
    "auth_expired": "ðŸ”‘ ÐŸÐ¾Ñ‚Ñ€Ñ–Ð±Ð½Ð° Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð° Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ Claude",
    "network_error": "ðŸŒ ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ Ð· Ð¼ÐµÑ€ÐµÐ¶ÐµÑŽ",
    "unknown_error": "â“ ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° Claude",

    "estimated_recovery": "ÐžÑ‡Ñ–ÐºÑƒÑ”Ñ‚ÑŒÑÑ Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ñ‡ÐµÑ€ÐµÐ·: {time}",
    "check_again": "ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ ÑÑ‚Ð°Ñ‚ÑƒÑ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾ÑŽ /claude_status",
    "notification_enabled": "âœ… Ð¡Ð¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾ ÑÑ‚Ð°Ñ‚ÑƒÑ ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾",
    "notification_disabled": "âŒ Ð¡Ð¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾",

    "title": "ðŸ“Š Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Claude CLI",
    "current_status": "ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ:",
    "last_check": "ÐžÑÑ‚Ð°Ð½Ð½Ñ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ°:",
    "uptime": "Ð§Ð°Ñ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸:",
    "downtime": "Ð§Ð°Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ–:",
    "recovery_prediction": "ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð· Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ:",
    "history_24h": "Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ Ð·Ð° 24 Ð³Ð¾Ð´Ð¸Ð½Ð¸:",
    "notifications_settings": "ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ ÑÐ¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½ÑŒ"
  }
}

```

### localization/translations/en.json

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 11,307 Ð±Ð°Ð¹Ñ‚

```json
{
  "_meta": {
    "name": "English",
    "code": "en"
  },
  "commands": {
    "start": {
      "welcome": "ðŸ‘‹ Welcome to Claude Code Telegram Bot, {name}!",
      "description": "ðŸ¤– I help you access Claude Code remotely through Telegram.",
      "available_commands": "**Available Commands:**",
      "help_cmd": "Show detailed help",
      "new_cmd": "Start a new Claude session",
      "ls_cmd": "List files in current directory",
      "cd_cmd": "Change directory",
      "projects_cmd": "Show available projects",
      "status_cmd": "Show session status",
      "actions_cmd": "Show quick actions",
      "git_cmd": "Git repository commands",
      "quick_start": "**Quick Start:**",
      "quick_start_1": "Use `/projects` to see available projects",
      "quick_start_2": "Use `/cd <project>` to navigate to a project",
      "quick_start_3": "Send any message to start coding with Claude!",
      "security_note": "ðŸ”’ Your access is secured and all actions are logged.",
      "usage_note": "ðŸ“Š Use `/status` to check your usage limits."
    },
    "help": {
      "title": "ðŸ¤– **Claude Code Telegram Bot Help**",
      "commands": "Available commands:\n/status - Status\n/new - New session\n/actions - Actions\n/restart - Restart bot"
    },
    "restart": {
      "title": "ðŸ”„ **Bot Restart**",
      "description": "Restart the bot with memory cleanup and code updates",
      "restarting": "ðŸ”„ **Restarting bot...**\n\nStopping all processes and starting fresh...",
      "initiated": "âœ… **Restart initiated**\n\nRestarting now...",
      "access_denied": "ðŸš« You don't have permission to restart the bot.",
      "script_not_found": "âŒ **Restart script not found**\n\nPlease restart manually.",
      "failed": "âŒ **Restart failed**"
    },
    "status": {
      "title": "ðŸ“Š Bot Status",
      "active": "Claude session is active",
      "inactive": "Claude session is inactive"
    },
    "ls": {
      "title": "ðŸ“ File List"
    },
    "cd": {
      "usage": "Usage: /cd <directory>",
      "success": "ðŸ“‚ Changed directory to: `{directory}`",
      "failed": "âŒ Failed to change directory to: `{directory}`"
    },
    "pwd": {
      "title": "ðŸ“‚ Current Directory"
    },
    "projects": {
      "title": "ðŸ“ Available Projects",
      "list": "ðŸ“‚ Browse folders using /ls command"
    },
    "actions": {
      "title": "âš¡ Quick Actions",
      "description": "Choose an action to perform:"
    },
    "export": {
      "title": "ðŸ’¾ Export Session",
      "processing": "Processing session data..."
    },
    "main_menu": {
      "title": "Main Menu",
      "description": "Main bot functions for working with Claude Code."
    },
    "audit": {
      "title": "ðŸ” Intelligent Audit",
      "description": "Bot code analysis with Claude",
      "starting": "Starting intelligent audit...",
      "analyzing": "Analyzing code and architecture...",
      "completed": "Audit completed",
      "no_issues": "ðŸŽ‰ No issues found!",
      "critical_warning": "ðŸš¨ WARNING! Critical issues found"
    },
    "dracon": {
      "title": "ðŸ”§ DRACON-YAML Bot Logic Modeling",
      "description": "Model bot logic using YAML schemas with graph analysis",
      "help": "DRACON (Ð”Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ðµ Ð ÑƒÑÑÐºÐ¸Ðµ ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹, ÐšÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÐžÐ±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÑŽÑ‚ ÐÐ°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚ÑŒ) system for bot logic modeling",
      "analyzing": "Analyzing DRACON schema...",
      "generating": "Generating components...",
      "validating": "Validating schema...",
      "completed": "Analysis completed",
      "invalid_schema": "âŒ Invalid DRACON schema",
      "no_components": "âŒ No components could be generated"
    },
    "refactor": {
      "title": "ðŸ”„ DRACON Refactoring System",
      "description": "Reverse engineer existing bot code into DRACON schemas",
      "analyzing": "Analyzing bot architecture...",
      "generating": "Generating DRACON schema from code...",
      "suggesting": "Generating refactoring suggestions...",
      "completed": "Refactoring analysis completed",
      "access_denied": "âŒ Access denied. Refactoring available only to administrators"
    },
    "img": {
      "title": "ðŸ“¸ Image Processing",
      "description": "Process images with Claude AI",
      "instructions": "ðŸ“¸ **Image Processing Mode**\n\nPlease send your images (up to {max_images} files). You can send them one by one or all at once.\n\n**Supported formats:** PNG, JPG, JPEG, GIF, WebP\n**Max file size:** {max_size}MB per image\n\nAfter uploading, type your instructions or 'done' to process.\n\nType 'cancel' to stop.",
      "session_expired": "âŒ Image session has expired. Use /img to start a new session.",
      "image_received": "âœ… Image {current}/{max} received. Send more images or type 'done' to process.",
      "no_images": "âŒ No images uploaded yet. Please send images first.",
      "cancelled": "ðŸš« Image session cancelled.",
      "instruction_updated": "ðŸ“ Instruction updated. Current images: {count}. Send 'done' to process or continue uploading images.",
      "processing": "ðŸ”„ Processing {count} image(s) with Claude...",
      "error": "âŒ Error processing images: {error}"
    }
  },
  "buttons": {
    "show_projects": "ðŸ“ Show Projects",
    "get_help": "â“ Get Help",
    "new_session": "ðŸ†• New Session",
    "check_status": "ðŸ“Š Check Status",
    "language_settings": "ðŸŒ Language",
    "back": "â¬…ï¸ Back",
    "select_language": "Select Language",
    "list_files": "ðŸ“ List Files",
    "full_help": "ðŸ“– Full Help",
    "main_menu": "ðŸ  Main Menu",
    "root": "ðŸ  Root",
    "help": "â“ Help",
    "continue": "ðŸ”„ Continue",
    "refresh": "ðŸ”„ Refresh",
    "projects": "ðŸ“ Projects",
    "continue_session": "ðŸ”„ Continue Session",
    "export_session": "ðŸ’¾ Export Session",
    "export": "ðŸ’¾ Export",
    "settings": "âš™ï¸ Settings",
    "status": "ðŸ“Š Status",
    "git_info": "ðŸ“Š Git Info",
    "save_code": "ðŸ’¾ Save Code",
    "explain": "â“ Explain",
    "debug": "ðŸ”§ Debug",
    "go_up": "â¬†ï¸ Go Up",
    "git_status": "ðŸ“Š Git Status",
    "lint_code": "ðŸ”§ Lint Code",
    "show_diff": "ðŸ“Š Show Diff",
    "create_task": "ðŸ“ Create Task",
    "from_template": "ðŸ“‹ From Template",
    "add": "âž• Add",
    "edit": "ðŸ“ Edit",
    "update": "ðŸ”„ Update",
    "add_task": "âž• Add Task",
    "change_dnd": "ðŸŒ™ Change DND",
    "advanced_settings": "âš¡ Settings",
    "detailed_logs": "ðŸ“‹ Detailed Logs",
    "statistics": "ðŸ“Š Statistics",
    "create_prompt": "ðŸ“ Create Prompt",
    "prompts_list": "ðŸ“‹ Prompts List",
    "prompt_templates": "ðŸ“‹ Prompt Templates",
    "back_to_menu": "â¬…ï¸ Back to Menu",
    "create_new": "ðŸ“ Create New",
    "back_simple": "â¬…ï¸ Back",
    "prompts_settings": "ðŸ”§ Settings",
    "prompts_history": "ðŸ“Š History",
    "json_export": "ðŸ“‹ JSON",
    "markdown_export": "ðŸ“ Markdown"
  },
  "status": {
    "title": "ðŸ“Š Bot Status",
    "directory": "ðŸ“‚ Current Directory: {directory}",
    "claude_session_active": "ðŸ¤– Claude Session: âœ… Active",
    "claude_session_inactive": "ðŸ¤– Claude Session: âŒ Inactive",
    "usage": "ðŸ“Š Usage Statistics",
    "session_id": "ðŸ†” Session ID: {session_id}",
    "usage_info": "You have used {used}/{limit} credits this session",
    "usage_error": "âŒ Failed to retrieve usage data",
    "last_update": "ðŸ• Last update: {time} UTC"
  },
  "help": {
    "title": "â“ Help",
    "commands": "**Navigation Commands:**\nâ€¢ `/ls` - List files and directories\nâ€¢ `/cd <directory>` - Change to directory\nâ€¢ `/pwd` - Show current directory\nâ€¢ `/projects` - Show available projects\n\n**Session Commands:**\nâ€¢ `/new` - Start new Claude session\nâ€¢ `/continue` - Continue last session\nâ€¢ `/status` - Show session status\nâ€¢ `/export` - Export session history\n\n**DRACON System (Visual Modeling):**\nâ€¢ `/dracon help` - DRACON help\nâ€¢ `/dracon diagram <category> <file>` - ðŸŽ¨ Visual diagram\nâ€¢ `/dracon list [category]` - List schemas\nâ€¢ `/dracon analyze <yaml>` - Analyze schema\nâ€¢ `/refactor` - Reverse engineer code to DRACON\n\n**Special Commands:**\nâ€¢ `/actions` - Show quick actions\nâ€¢ `/git` - Git repository commands\nâ€¢ `/claude` - Authorize Claude CLI\nâ€¢ `/img` - Image processing with Claude\n\n**MCP Commands:**\nâ€¢ `/mcpadd` - Add MCP server\nâ€¢ `/mcplist` - List MCP servers\nâ€¢ `/mcpselect` - Select active context\nâ€¢ `/mcpask` - Query with MCP context\nâ€¢ `/mcpremove` - Remove MCP server\nâ€¢ `/mcpstatus` - MCP system status\n\n**Scheduler:**\nâ€¢ `/schedules` - Task management\nâ€¢ `/add_schedule` - Add new task\n\n**System Commands:**\nâ€¢ `/restart` - Restart bot\n\n**Tips:**\nâ€¢ Send text files for viewing\nâ€¢ Use specific queries\nâ€¢ Check status with `/status`"
  },
  "session": {
    "new_started": "ðŸ†• New session started",
    "cleared": "ðŸ”„ Session cleared",
    "save_complete": "ðŸ’¾ Code saved",
    "continued": "ðŸ”„ Session continued",
    "no_active_session": "âŒ No active session"
  },
  "actions": {
    "title": "âš¡ Quick Actions"
  },
  "pwd": {
    "title": "ðŸ“‚ Directory: {directory}"
  },
  "projects": {
    "title": "ðŸ“ Projects ({count})"
  },
  "settings": {
    "title": "âš™ï¸ Settings"
  },
  "explain": {
    "processing": "ðŸ¤” Analyzing code..."
  },
  "messages": {
    "welcome": "ðŸ‘‹ Welcome to Claude Code Bot!",
    "welcome_back": "ðŸ‘‹ Welcome back!",
    "session_started": "ðŸš€ Session started",
    "session_ended": "ðŸ Session ended",
    "authentication_success": "âœ… Authentication successful",
    "file_processed": "ðŸ“„ File processed",
    "command_executed": "âš¡ Command executed",
    "maintenance_mode": "ðŸ”§ Maintenance mode",
    "server_overloaded": "âš ï¸ Server overloaded"
  },
  "errors": {
    "settings_not_available": "âŒ Settings not available",
    "task_loading_failed": "âŒ Failed to load task list",
    "system_state_change_failed": "âŒ Failed to change system state",
    "git_operation_failed": "âŒ **Git Error**\n\n{error}",
    "claude_code_error": "âŒ **Claude Code Error**",
    "unexpected_error": "âŒ An unexpected error occurred. Try again later.",
    "status_failed": "âŒ Failed to get status",
    "help_failed": "âŒ Failed to load help",
    "session_new_failed": "âŒ Failed to start new session",
    "actions_failed": "âŒ Failed to load actions",
    "pwd_failed": "âŒ Failed to get directory",
    "projects_failed": "âŒ Failed to load projects",
    "save_failed": "âŒ Failed to save code: {error}",
    "continue_failed": "âŒ Failed to continue session",
    "explain_failed": "âŒ Failed to explain code",
    "refresh_failed": "âŒ Failed to refresh",
    "settings_failed": "âŒ Failed to open settings",
    "service_unavailable": "âŒ Service unavailable",
    "command_failed": "âŒ Command failed",
    "image_processing_disabled": "âŒ Image processing is disabled. Contact administrator to enable."
  },
  "schedule": {
    "create_new": "Create New Task",
    "advanced": "Advanced Settings",
    "change_dnd": "Change DND Period",
    "add_task": "Add Task",
    "edit_task": "Edit Task",
    "update_list": "Update List",
    "back_to_list": "Back to List",
    "back_to_settings": "Back to Settings"
  }
}

```

### utils/constants.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 1,760 Ð±Ð°Ð¹Ñ‚

```python
"""Application-wide constants."""

# Version info
APP_NAME = "Claude Code Telegram Bot"
APP_DESCRIPTION = "Telegram bot for remote Claude Code access"

# Default limits
DEFAULT_CLAUDE_TIMEOUT_SECONDS = 300
DEFAULT_CLAUDE_MAX_TURNS = 20
DEFAULT_CLAUDE_MAX_COST_PER_USER = 10.0

DEFAULT_RATE_LIMIT_REQUESTS = 10
DEFAULT_RATE_LIMIT_WINDOW = 60
DEFAULT_RATE_LIMIT_BURST = 20

DEFAULT_SESSION_TIMEOUT_HOURS = 24
DEFAULT_MAX_SESSIONS_PER_USER = 5

# Message limits
TELEGRAM_MAX_MESSAGE_LENGTH = 4096
SAFE_MESSAGE_LENGTH = 4000  # Leave room for formatting

# Session limits
MAX_SESSION_LENGTH = 1000  # Maximum messages per session

# File limits
MAX_FILE_SIZE_MB = 10
MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_MB * 1024 * 1024

# Allowed file extensions
ALLOWED_FILE_EXTENSIONS = {
    ".py",
    ".js",
    ".ts",
    ".jsx",
    ".tsx",
    ".java",
    ".cpp",
    ".c",
    ".h",
    ".hpp",
    ".cs",
    ".go",
    ".rs",
    ".rb",
    ".php",
    ".swift",
    ".kt",
    ".md",
    ".txt",
    ".json",
    ".yml",
    ".yaml",
    ".toml",
    ".xml",
    ".html",
    ".css",
    ".scss",
    ".sql",
    ".sh",
    ".bash",
}

# Security patterns to block
DANGEROUS_PATTERNS = [
    r"\.\.",  # Parent directory
    r"~",  # Home directory
    r"\$",  # Variable expansion
    r"`",  # Command substitution
    r";",  # Command chaining
    r"&&",  # Command chaining
    r"\|\|",  # Command chaining
    r">",  # Redirection
    r"<",  # Redirection
    r"\|",  # Piping
]

# Database defaults
DEFAULT_DATABASE_URL = "sqlite:///data/bot.db"
DEFAULT_BACKUP_RETENTION_DAYS = 30

# Claude Code defaults
DEFAULT_CLAUDE_BINARY = "claude"
DEFAULT_CLAUDE_OUTPUT_FORMAT = "stream-json"

# Logging
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

```

### utils/__init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 0 Ð±Ð°Ð¹Ñ‚

```python


```

### bot/__init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 55 Ð±Ð°Ð¹Ñ‚

```python
"""Telegram bot module for Claude Code integration."""

```

### bot/core.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 19,180 Ð±Ð°Ð¹Ñ‚

```python
"""Main Telegram bot class.

Features:
- Command registration
- Handler management
- Context injection
- Graceful shutdown
"""

import asyncio
from typing import Any, Callable, Dict, Optional

import structlog
from telegram import BotCommand, Update
from telegram.ext import (
    Application,
    CallbackQueryHandler,
    CommandHandler,
    ContextTypes,
    MessageHandler,
    filters,
)

from ..config.features import FeatureFlags
from ..config.settings import Settings
from ..exceptions import ClaudeCodeTelegramError
from .features.registry import FeatureRegistry

logger = structlog.get_logger()


class ClaudeCodeBot:
    """Main bot orchestrator."""

    def __init__(self, settings: Settings, dependencies: Dict[str, Any]):
        """Initialize bot with settings and dependencies."""
        self.settings = settings
        self.deps = dependencies
        self.app: Optional[Application] = None
        self.is_running = False
        self.feature_registry: Optional[FeatureRegistry] = None

    async def initialize(self) -> None:
        """Initialize bot application."""
        logger.info("Initializing Telegram bot")

        # Create application with persistence
        from telegram.ext import PicklePersistence
        import os

        # Set up persistence for user_data and context
        persistence_file = os.path.join(os.getcwd(), "data", "telegram_persistence.pickle")
        os.makedirs(os.path.dirname(persistence_file), exist_ok=True)
        persistence = PicklePersistence(filepath=persistence_file)

        builder = Application.builder()
        builder.token(self.settings.telegram_token_str)
        builder.persistence(persistence)

        # Configure connection settings
        builder.connect_timeout(30)
        builder.read_timeout(30)
        builder.write_timeout(30)
        builder.pool_timeout(30)

        self.app = builder.build()

        # Initialize feature registry
        self.feature_registry = FeatureRegistry(
            config=self.settings,
            storage=self.deps.get("storage"),
            security=self.deps.get("security"),
        )

        # Add feature registry to dependencies
        self.deps["features"] = self.feature_registry

        # Set bot commands for menu
        await self._set_bot_commands()

        # Register handlers
        self._register_handlers()

        # Add middleware
        self._add_middleware()

        # Add Claude availability middleware
        from .middleware.claude_availability import claude_availability_middleware
        self.app.add_handler(
            MessageHandler(
                filters.ALL, self._create_middleware_handler(claude_availability_middleware)
            ),
            group=-4,
        )

        # Set error handler
        self.app.add_error_handler(self._error_handler)

        # Set up Claude availability monitoring if enabled
        features = FeatureFlags(self.settings)
        if features.claude_availability_monitor:
            from .features.availability_monitor import setup_availability_monitor
            await setup_availability_monitor(self.app, self.settings)

        # TODO: Fix TaskScheduler import issues
        # Initialize task scheduler for automated task execution
        # await self._setup_task_scheduler()

        logger.info("Bot initialization complete")

    async def _set_bot_commands(self) -> None:
        """Set bot command menu."""
        commands = [
            BotCommand("start", "Start bot and show help"),
            BotCommand("help", "Show available commands"),
            BotCommand("new", "Start new Claude session"),
            BotCommand("continue", "Continue last session"),
            BotCommand("ls", "List files in current directory"),
            BotCommand("cd", "Change directory"),
            BotCommand("pwd", "Show current directory"),
            BotCommand("projects", "Show all projects"),
            BotCommand("status", "Show session status"),
            BotCommand("export", "Export current session"),
            BotCommand("actions", "Show quick actions"),
            BotCommand("git", "Git repository commands"),
            BotCommand("login", "Authenticate Claude CLI"),
            BotCommand("cancel", "Cancel authentication process"),
            BotCommand("schedules", "Manage scheduled tasks"),
            BotCommand("add_schedule", "Add new scheduled task"),
            BotCommand("tasks", "Manage automated task queue"),
            BotCommand("auto", "Toggle automation mode"),
            BotCommand("schedule", "Schedule tasks for automation"),
            BotCommand("restart", "Restart the bot"),
            BotCommand("audit", "Intelligent bot code audit"),
            BotCommand("dracon", "DRACON-YAML bot logic modeling"),
            BotCommand("refactor", "Reverse engineer bot to DRACON schemas"),
            BotCommand("claude_status", "Show Claude CLI availability status"),
            BotCommand("claude_notifications", "Manage Claude availability notifications"),
            BotCommand("claude_history", "Show Claude availability history"),
        ]

        # Add image processing command if enabled
        if self.settings.enable_image_processing:
            commands.append(BotCommand("img", "Process images with Claude"))

        # Add MCP commands
        commands.extend([
            BotCommand("mcpadd", "Add MCP server"),
            BotCommand("mcplist", "List MCP servers"),
            BotCommand("mcpselect", "Select active MCP context"),
            BotCommand("mcpask", "Ask with MCP context"),
            BotCommand("mcpremove", "Remove MCP server"),
            BotCommand("mcpstatus", "Show MCP system status"),
        ])

        await self.app.bot.set_my_commands(commands)
        logger.info("Bot commands set", commands=[cmd.command for cmd in commands])

    def _register_handlers(self) -> None:
        """Register all command and message handlers."""
        from .handlers import callback, command, message, mcp_commands

        # Command handlers
        handlers = [
            ("start", command.start_command),
            ("help", command.help_handler),
            ("new", command.new_handler),
            ("continue", command.continue_session),
            ("end", command.end_session),
            ("ls", command.list_files),
            ("cd", command.change_directory),
            ("pwd", command.pwd_handler),
            ("projects", command.projects_handler),
            ("status", command.status_handler),
            ("export", command.export_session),
            ("actions", command.actions_handler),
            ("git", command.git_handler),
            ("login", command.login_command),
            ("cancel", command.cancel_auth_command),
            ("schedules", command.schedules_command),
            ("add_schedule", command.add_schedule_command),
            ("restart", command.restart_command),
            ("audit", command.audit_command),
            ("dracon", command.dracon_command),
            ("refactor", command.refactor_command),
            ("claude_status", command.claude_status_command),
            ("claude_notifications", command.claude_notifications_command),
            ("claude_history", command.claude_history_command),
        ]

        # Add image processing command if enabled
        if self.settings.enable_image_processing:
            handlers.append(("img", command.img_command))

        # Add task scheduler commands
        from .handlers import task_commands
        handlers.extend([
            ("tasks", task_commands.task_queue_command),
            ("auto", task_commands.auto_mode_command),
            ("schedule", task_commands.schedule_command),
        ])

        # Add MCP command handlers
        handlers.extend([
            ("mcpadd", mcp_commands.mcpadd_command),
            ("mcplist", mcp_commands.mcplist_command),
            ("mcpselect", mcp_commands.mcpselect_command),
            ("mcpask", mcp_commands.mcpask_command),
            ("mcpremove", mcp_commands.mcpremove_command),
            ("mcpstatus", mcp_commands.mcpstatus_command),
        ])

        for cmd, handler in handlers:
            self.app.add_handler(CommandHandler(cmd, self._inject_deps(handler)))

        # Message handlers with priority groups
        self.app.add_handler(
            MessageHandler(
                filters.TEXT & ~filters.COMMAND,
                self._inject_deps(message.handle_text_message),
            ),
            group=10,
        )

        self.app.add_handler(
            MessageHandler(
                filters.Document.ALL, self._inject_deps(message.handle_document)
            ),
            group=10,
        )

        self.app.add_handler(
            MessageHandler(filters.PHOTO, self._inject_deps(message.handle_photo)),
            group=10,
        )

        # Callback query handler
        self.app.add_handler(
            CallbackQueryHandler(self._inject_deps(callback.handle_callback_query))
        )

        logger.info("Bot handlers registered")

    def _inject_deps(self, handler: Callable) -> Callable:
        """Inject dependencies into handlers."""

        async def wrapped(update: Update, context: ContextTypes.DEFAULT_TYPE):
            # Add dependencies to context
            for key, value in self.deps.items():
                context.bot_data[key] = value

            # Add settings
            context.bot_data["settings"] = self.settings

            return await handler(update, context)

        return wrapped

    def _add_middleware(self) -> None:
        """Add middleware to application."""
        from .middleware.auth import auth_middleware
        from .middleware.rate_limit import rate_limit_middleware
        from .middleware.security import security_middleware

        # Middleware runs in order of group numbers (lower = earlier)
        # Security middleware first (validate inputs)
        self.app.add_handler(
            MessageHandler(
                filters.ALL, self._create_middleware_handler(security_middleware)
            ),
            group=-3,
        )

        # Authentication second
        self.app.add_handler(
            MessageHandler(
                filters.ALL, self._create_middleware_handler(auth_middleware)
            ),
            group=-2,
        )

        # Rate limiting third
        self.app.add_handler(
            MessageHandler(
                filters.ALL, self._create_middleware_handler(rate_limit_middleware)
            ),
            group=-1,
        )

        logger.info("Middleware added to bot")

    def _create_middleware_handler(self, middleware_func: Callable) -> Callable:
        """Create middleware handler that injects dependencies."""

        async def middleware_wrapper(
            update: Update, context: ContextTypes.DEFAULT_TYPE
        ):
            # Inject dependencies into context
            for key, value in self.deps.items():
                context.bot_data[key] = value
            context.bot_data["settings"] = self.settings

            # Create a dummy handler that continues processing
            async def continue_handler(event, data):
                # This allows the message to continue to the actual handlers
                return None

            # Call middleware with Telegram-style parameters
            result = await middleware_func(continue_handler, update, context.bot_data)
            
            # If middleware returns None, it blocked the request
            # If it returns result of handler, continue processing
            return result

        return middleware_wrapper

    async def start(self) -> None:
        """Start the bot."""
        if self.is_running:
            logger.warning("Bot is already running")
            return

        await self.initialize()

        logger.info(
            "Starting bot", mode="webhook" if self.settings.webhook_url else "polling"
        )

        try:
            self.is_running = True

            if self.settings.webhook_url:
                # Webhook mode
                await self.app.run_webhook(
                    listen="0.0.0.0",
                    port=self.settings.webhook_port,
                    url_path=self.settings.webhook_path,
                    webhook_url=self.settings.webhook_url,
                    drop_pending_updates=True,
                    allowed_updates=Update.ALL_TYPES,
                )
            else:
                # Polling mode - initialize and start polling manually
                await self.app.initialize()
                await self.app.start()
                await self.app.updater.start_polling(
                    allowed_updates=Update.ALL_TYPES,
                    drop_pending_updates=True,
                )

                # Keep running until manually stopped
                while self.is_running:
                    await asyncio.sleep(1)
        except Exception as e:
            logger.error("Error running bot", error=str(e))
            raise ClaudeCodeTelegramError(f"Failed to start bot: {str(e)}") from e
        finally:
            self.is_running = False

    async def stop(self) -> None:
        """Gracefully stop the bot."""
        if not self.is_running:
            logger.warning("Bot is not running")
            return

        logger.info("Stopping bot")

        try:
            self.is_running = False  # Stop the main loop first

            # Shutdown feature registry
            if self.feature_registry:
                self.feature_registry.shutdown()

            if self.app:
                # Stop the updater if it's running
                if self.app.updater.running:
                    await self.app.updater.stop()

                # Stop the application
                await self.app.stop()
                await self.app.shutdown()

            logger.info("Bot stopped successfully")
        except Exception as e:
            logger.error("Error stopping bot", error=str(e))
            raise ClaudeCodeTelegramError(f"Failed to stop bot: {str(e)}") from e

    async def _error_handler(
        self, update: Update, context: ContextTypes.DEFAULT_TYPE
    ) -> None:
        """Handle errors globally."""
        import traceback
        error = context.error
        logger.error(
            "Global error handler triggered",
            error=str(error),
            error_type=type(error).__name__ if error else None,
            traceback=traceback.format_exc(),
            update_type=type(update).__name__ if update else None,
            user_id=(
                update.effective_user.id if update and update.effective_user else None
            ),
        )

        # Determine error message for user
        from ..exceptions import (
            AuthenticationError,
            ConfigurationError,
            RateLimitExceeded,
            SecurityError,
        )

        error_messages = {
            AuthenticationError: "ðŸ”’ Authentication required. Please contact the administrator.",
            SecurityError: "ðŸ›¡ï¸ Security violation detected. This incident has been logged.",
            RateLimitExceeded: "â±ï¸ Rate limit exceeded. Please wait before sending more messages.",
            ConfigurationError: "âš™ï¸ Configuration error. Please contact the administrator.",
            asyncio.TimeoutError: "â° Operation timed out. Please try again with a simpler request.",
        }

        error_type = type(error)
        user_message = error_messages.get(
            error_type, "âŒ An unexpected error occurred. Please try again."
        )

        # Try to notify user
        if update and update.effective_message:
            try:
                await update.effective_message.reply_text(user_message)
            except Exception:
                logger.exception("Failed to send error message to user")

        # Log to audit system if available
        from ..security.audit import AuditLogger

        audit_logger: Optional[AuditLogger] = context.bot_data.get("audit_logger")
        if audit_logger and update and update.effective_user:
            try:
                await audit_logger.log_security_violation(
                    user_id=update.effective_user.id,
                    violation_type="system_error",
                    details=f"Error type: {error_type.__name__}, Message: {str(error)}",
                    severity="medium",
                )
            except Exception:
                logger.exception("Failed to log error to audit system")

    async def _setup_task_scheduler(self) -> None:
        """Initialize task scheduler for automated execution."""
        try:
            logger.info("Setting up task scheduler")

            # Initialize scheduled task repository
            from ..storage.repositories.scheduled_task_repository import ScheduledTaskRepository
            task_repository = ScheduledTaskRepository(self.deps["database"].db_path)
            await task_repository.create_table()

            # Initialize task scheduler
            from .features.task_scheduler import TaskScheduler
            task_scheduler = TaskScheduler(
                repository=task_repository,
                claude_integration=self.deps["claude_integration"],
                settings=self.settings
            )

            # Store in bot context for access by handlers
            self.app.bot_data["task_scheduler"] = task_scheduler
            self.app.bot_data["task_repository"] = task_repository

            logger.info("Task scheduler initialized successfully")

        except Exception as e:
            logger.error("Failed to setup task scheduler", error=str(e), exc_info=True)
            # Don't raise - this is not critical for basic bot operation

    async def get_bot_info(self) -> Dict[str, Any]:
        """Get bot information."""
        if not self.app:
            return {"status": "not_initialized"}

        try:
            me = await self.app.bot.get_me()
            return {
                "status": "running" if self.is_running else "initialized",
                "username": me.username,
                "first_name": me.first_name,
                "id": me.id,
                "can_join_groups": me.can_join_groups,
                "can_read_all_group_messages": me.can_read_all_group_messages,
                "supports_inline_queries": me.supports_inline_queries,
                "webhook_url": self.settings.webhook_url,
                "webhook_port": (
                    self.settings.webhook_port if self.settings.webhook_url else None
                ),
            }
        except Exception as e:
            logger.error("Failed to get bot info", error=str(e))
            return {"status": "error", "error": str(e)}

    async def health_check(self) -> bool:
        """Perform health check."""
        try:
            if not self.app:
                return False

            # Try to get bot info
            await self.app.bot.get_me()
            return True
        except Exception as e:
            logger.error("Health check failed", error=str(e))
            return False

```

### bot/handlers/message.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 63,064 Ð±Ð°Ð¹Ñ‚

```python
"""Message handlers for non-command inputs."""

import asyncio
from typing import Optional

import structlog
from telegram import Update
from telegram.ext import ContextTypes

from ...claude.exceptions import ClaudeToolValidationError
from ...config.settings import Settings
from ...security.audit import AuditLogger
from ...security.rate_limiter import RateLimiter
from ...security.validators import SecurityValidator
from .command import handle_claude_auth_code

logger = structlog.get_logger()


async def _format_progress_update(update_obj) -> Optional[str]:
    """Format progress updates with enhanced context and visual indicators."""
    if update_obj.type == "tool_result":
        # Show tool completion status
        tool_name = "Unknown"
        if update_obj.metadata and update_obj.metadata.get("tool_use_id"):
            # Try to extract tool name from context if available
            tool_name = update_obj.metadata.get("tool_name", "Tool")

        if update_obj.is_error():
            return f"âŒ **{tool_name} failed**\n\n_{update_obj.get_error_message()}_"
        else:
            execution_time = ""
            if update_obj.metadata and update_obj.metadata.get("execution_time_ms"):
                time_ms = update_obj.metadata["execution_time_ms"]
                execution_time = f" ({time_ms}ms)"
            return f"âœ… **{tool_name} completed**{execution_time}"

    elif update_obj.type == "progress":
        # Handle progress updates
        progress_text = f"ðŸ”„ **{update_obj.content or 'Working...'}**"

        percentage = update_obj.get_progress_percentage()
        if percentage is not None:
            # Create a simple progress bar
            filled = int(percentage / 10)  # 0-10 scale
            bar = "â–ˆ" * filled + "â–‘" * (10 - filled)
            progress_text += f"\n\n`{bar}` {percentage}%"

        if update_obj.progress:
            step = update_obj.progress.get("step")
            total_steps = update_obj.progress.get("total_steps")
            if step and total_steps:
                progress_text += f"\n\nStep {step} of {total_steps}"

        return progress_text

    elif update_obj.type == "error":
        # Handle error messages
        return f"âŒ **Error**\n\n_{update_obj.get_error_message()}_"

    elif update_obj.type == "assistant" and update_obj.tool_calls:
        # Show when tools are being called
        tool_names = update_obj.get_tool_names()
        if tool_names:
            tools_text = ", ".join(tool_names)
            return f"ðŸ”§ **Using tools:** {tools_text}"

    elif update_obj.type == "assistant" and update_obj.content:
        # Regular content updates with preview
        content_preview = (
            update_obj.content[:150] + "..."
            if len(update_obj.content) > 150
            else update_obj.content
        )
        return f"ðŸ¤– **Claude is working...**\n\n_{content_preview}_"

    elif update_obj.type == "system":
        # System initialization or other system messages
        if update_obj.metadata and update_obj.metadata.get("subtype") == "init":
            tools = update_obj.metadata.get("tools", [])
            tools_count = len(tools) if tools is not None else 0
            model = update_obj.metadata.get("model", "Claude")
            return f"ðŸš€ **Starting {model}** with {tools_count} tools available"

    return None


def _format_error_message(error_str: str) -> str:
    """Format error messages for user-friendly display."""
    if "usage limit reached" in error_str.lower():
        # Usage limit error - already user-friendly from integration.py
        return error_str
    elif "tool not allowed" in error_str.lower():
        # Tool validation error - already handled in facade.py
        return error_str
    elif "no conversation found" in error_str.lower():
        return (
            f"ðŸ”„ **Session Not Found**\n\n"
            f"The Claude session could not be found or has expired.\n\n"
            f"**What you can do:**\n"
            f"â€¢ Use `/new` to start a fresh session\n"
            f"â€¢ Try your request again\n"
            f"â€¢ Use `/status` to check your current session"
        )
    elif "rate limit" in error_str.lower():
        return (
            f"â±ï¸ **Rate Limit Reached**\n\n"
            f"Too many requests in a short time period.\n\n"
            f"**What you can do:**\n"
            f"â€¢ Wait a moment before trying again\n"
            f"â€¢ Use simpler requests\n"
            f"â€¢ Check your current usage with `/status`"
        )
    elif "timeout" in error_str.lower():
        return (
            f"â° **Request Timeout**\n\n"
            f"Your request took too long to process and timed out.\n\n"
            f"**What you can do:**\n"
            f"â€¢ Try breaking down your request into smaller parts\n"
            f"â€¢ Use simpler commands\n"
            f"â€¢ Try again in a moment"
        )
    else:
        # Generic error handling
        return (
            f"âŒ **Claude Code Error**\n\n"
            f"Failed to process your request: {error_str}\n\n"
            f"Please try again or contact the administrator if the problem persists."
        )


async def handle_text_message(
    update: Update, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle regular text messages as Claude prompts."""
    user_id = update.effective_user.id
    message_text = update.message.text

    logger.debug("handle_text_message called", user_id=user_id,
                message_text=(message_text[:50] + "...") if message_text and len(message_text) > 50 else message_text)
    settings: Settings = context.bot_data["settings"]

    # Get services
    rate_limiter: Optional[RateLimiter] = context.bot_data.get("rate_limiter")
    audit_logger: Optional[AuditLogger] = context.bot_data.get("audit_logger")

    logger.info(
        "Processing text message", user_id=user_id, message_length=len(message_text)
    )

    # First check if this is a Claude authentication code
    if await handle_claude_auth_code(update, context):
        return

    # Check if user is creating a scheduled task
    if context.user_data and context.user_data.get('creating_task'):
        await handle_task_creation_dialogue(update, context)
        return

    # Check if user is in file editing workflow
    if context.user_data and context.user_data.get('file_action'):
        await handle_file_action_message(update, context)
        return

    # Check if user has active image session and handle it
    if context.user_data and context.user_data.get('awaiting_images'):
        logger.info("Text message for user with active image session", user_id=user_id, message_text=message_text)
        image_command_handler = context.bot_data.get('image_command_handler')
        if image_command_handler:
            logger.info("Routing text message to image_command_handler", user_id=user_id)
            await image_command_handler.handle_text_message(update, context)
            return
        else:
            logger.error("Image command handler not found for text message", user_id=user_id)

    try:
        # Check rate limit with estimated cost for text processing
        estimated_cost = _estimate_text_processing_cost(message_text)

        if rate_limiter:
            allowed, limit_message = await rate_limiter.check_rate_limit(
                user_id, estimated_cost
            )
            if not allowed:
                await update.message.reply_text(f"â±ï¸ {limit_message}")
                return

        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ– Claude (Ð·Ð³Ñ–Ð´Ð½Ð¾ Ð· Ð¿Ð»Ð°Ð½Ð¾Ð¼)
        availability_monitor = context.bot_data.get("claude_availability_monitor")
        if availability_monitor:
            is_available, status_details = await availability_monitor.check_availability_with_details()
            if not is_available:
                await send_unavailable_message(update, status_details)
                return

        # Send typing indicator
        await update.message.chat.send_action("typing")

        # Create progress message
        progress_msg = await update.message.reply_text(
            "ðŸ¤” Processing your request...",
            reply_to_message_id=update.message.message_id,
        )

        # Get Claude integration and storage from context
        claude_integration = context.bot_data.get("claude_integration")
        storage = context.bot_data.get("storage")

        if not claude_integration:
            await update.message.reply_text(
                "âŒ **Claude integration not available**\n\n"
                "The Claude Code integration is not properly configured. "
                "Please contact the administrator.",
                parse_mode=None,
            )
            return

        # Get current directory
        current_dir = context.user_data.get(
            "current_directory", settings.approved_directory
        )

        # Get existing session ID
        session_id = context.user_data.get("claude_session_id")

        # Enhanced stream updates handler with progress tracking
        async def stream_handler(update_obj):
            try:
                progress_text = await _format_progress_update(update_obj)
                if progress_text:
                    await progress_msg.edit_text(progress_text, parse_mode="Markdown")
            except Exception as e:
                logger.warning("Failed to update progress message", error=str(e))

        # Run Claude command
        claude_response = None
        try:
            claude_response = await claude_integration.run_command(
                prompt=message_text,
                working_directory=current_dir,
                user_id=user_id,
                session_id=session_id,
                on_stream=stream_handler,
            )

            # Update session ID
            context.user_data["claude_session_id"] = claude_response.session_id

            # Check if Claude changed the working directory and update our tracking
            _update_working_directory_from_claude_response(
                claude_response, context, settings, user_id
            )

            # Log interaction to storage
            if storage:
                try:
                    await storage.save_claude_interaction(
                        user_id=user_id,
                        session_id=claude_response.session_id,
                        prompt=message_text,
                        response=claude_response,
                        ip_address=None,  # Telegram doesn't provide IP
                    )
                except Exception as e:
                    logger.warning("Failed to log interaction to storage", error=str(e))

            # Format response
            from ..utils.formatting import ResponseFormatter

            formatter = ResponseFormatter(settings)
            formatted_messages = formatter.format_claude_response(
                claude_response.content
            )

        except ClaudeToolValidationError as e:
            # Tool validation error with detailed instructions
            logger.error(
                "Tool validation error",
                error=str(e),
                user_id=user_id,
                blocked_tools=e.blocked_tools,
            )
            # Error message already formatted, create FormattedMessage
            from ..utils.formatting import FormattedMessage

            formatted_messages = [FormattedMessage(str(e), parse_mode=None)]
        except Exception as e:
            logger.error("Claude integration failed", error=str(e), user_id=user_id)
            # Format error and create FormattedMessage
            from ..utils.formatting import FormattedMessage

            formatted_messages = [
                FormattedMessage(_format_error_message(str(e)), parse_mode=None)
            ]

        # Delete progress message
        await progress_msg.delete()

        # Send formatted responses (may be multiple messages)
        for i, message in enumerate(formatted_messages):
            try:
                await update.message.reply_text(
                    message.text,
                    parse_mode=message.parse_mode,
                    reply_markup=message.reply_markup,
                    reply_to_message_id=update.message.message_id if i == 0 else None,
                )

                # Small delay between messages to avoid rate limits
                if i < len(formatted_messages) - 1:
                    await asyncio.sleep(0.5)

            except Exception as e:
                logger.error(
                    "Failed to send response message", 
                    error=str(e), 
                    message_index=i,
                    message_text=message.text[:200],
                    parse_mode=message.parse_mode
                )
                # Try to send error message
                await update.message.reply_text(
                    "âŒ Failed to send response. Please try again.",
                    reply_to_message_id=update.message.message_id if i == 0 else None,
                )

        # Update session info
        context.user_data["last_message"] = update.message.text

        # Add conversation enhancements if available
        features = context.bot_data.get("features")
        conversation_enhancer = (
            features.get_conversation_enhancer() if features else None
        )

        if conversation_enhancer and claude_response:
            try:
                # Update conversation context
                conversation_enhancer.update_context(user_id, claude_response)

                # Check if we should show follow-up suggestions
                if conversation_enhancer.should_show_suggestions(claude_response):
                    # Get conversation context
                    conversation_context = conversation_enhancer.get_context(user_id)

                    # Generate follow-up suggestions
                    suggestions = conversation_enhancer.generate_follow_up_suggestions(
                        claude_response.content,
                        claude_response.tools_used or [],
                        conversation_context,
                    )

                    if suggestions:
                        # Create keyboard with suggestions
                        suggestion_keyboard = (
                            conversation_enhancer.create_follow_up_keyboard(suggestions)
                        )

                        # Send follow-up suggestions
                        await update.message.reply_text(
                            "ðŸ’¡ **What would you like to do next?**",
                            parse_mode=None,
                            reply_markup=suggestion_keyboard,
                        )

            except Exception as e:
                logger.warning(
                    "Conversation enhancement failed", error=str(e), user_id=user_id
                )

        # Log successful message processing
        if audit_logger:
            await audit_logger.log_command(
                user_id=user_id,
                command="text_message",
                args=[update.message.text[:100]],  # First 100 chars
                success=True,
            )

        logger.info("Text message processed successfully", user_id=user_id)

    except Exception as e:
        # Clean up progress message if it exists
        try:
            await progress_msg.delete()
        except:
            pass

        error_msg = f"âŒ **Error processing message**\n\n{str(e)}"
        await update.message.reply_text(error_msg, parse_mode=None)

        # Log failed processing
        if audit_logger:
            await audit_logger.log_command(
                user_id=user_id,
                command="text_message",
                args=[update.message.text[:100]],
                success=False,
            )

        logger.error("Error processing text message", error=str(e), user_id=user_id)


async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle file uploads."""
    user_id = update.effective_user.id
    document = update.message.document
    settings: Settings = context.bot_data["settings"]

    # First check if user is in file editing workflow
    if context.user_data and context.user_data.get('file_action'):
        await handle_document_message(update, context)
        return

    # Get services
    security_validator: Optional[SecurityValidator] = context.bot_data.get(
        "security_validator"
    )
    audit_logger: Optional[AuditLogger] = context.bot_data.get("audit_logger")
    rate_limiter: Optional[RateLimiter] = context.bot_data.get("rate_limiter")

    logger.info(
        "Processing document upload",
        user_id=user_id,
        filename=document.file_name,
        file_size=document.file_size,
    )

    try:
        # Validate filename using security validator
        if security_validator:
            valid, error = security_validator.validate_filename(document.file_name)
            if not valid:
                await update.message.reply_text(
                    f"âŒ **File Upload Rejected**\n\n{error}"
                )

                # Log security violation
                if audit_logger:
                    await audit_logger.log_security_violation(
                        user_id=user_id,
                        violation_type="invalid_file_upload",
                        details=f"Filename: {document.file_name}, Error: {error}",
                        severity="medium",
                    )
                return

        # Check file size limits
        max_size = 10 * 1024 * 1024  # 10MB
        if document.file_size > max_size:
            await update.message.reply_text(
                f"âŒ **File Too Large**\n\n"
                f"Maximum file size: {max_size // 1024 // 1024}MB\n"
                f"Your file: {document.file_size / 1024 / 1024:.1f}MB"
            )
            return

        # Check rate limit for file processing
        file_cost = _estimate_file_processing_cost(document.file_size)
        if rate_limiter:
            allowed, limit_message = await rate_limiter.check_rate_limit(
                user_id, file_cost
            )
            if not allowed:
                await update.message.reply_text(f"â±ï¸ {limit_message}")
                return

        # Send processing indicator
        await update.message.chat.send_action("upload_document")

        progress_msg = await update.message.reply_text(
            f"ðŸ“„ Processing file: `{document.file_name}`...", parse_mode=None
        )

        # Check if enhanced file handler is available
        features = context.bot_data.get("features")
        file_handler = features.get_file_handler() if features else None

        if file_handler:
            # Use enhanced file handler
            try:
                processed_file = await file_handler.handle_document_upload(
                    document,
                    user_id,
                    update.message.caption or "Please review this file:",
                )
                prompt = processed_file.prompt

                # Update progress message with file type info
                await progress_msg.edit_text(
                    f"ðŸ“„ Processing {processed_file.type} file: `{document.file_name}`...",
                    parse_mode=None,
                )

            except Exception as e:
                logger.warning(
                    "Enhanced file handler failed, falling back to basic handler",
                    error=str(e),
                )
                file_handler = None  # Fall back to basic handling

        if not file_handler:
            # Fall back to basic file handling
            file = await document.get_file()
            file_bytes = await file.download_as_bytearray()

            # Try to decode as text
            try:
                content = file_bytes.decode("utf-8")

                # Check content length
                max_content_length = 50000  # 50KB of text
                if len(content) > max_content_length:
                    content = (
                        content[:max_content_length]
                        + "\n... (file truncated for processing)"
                    )

                # Create prompt with file content
                caption = update.message.caption or "Please review this file:"
                prompt = f"{caption}\n\n**File:** `{document.file_name}`\n\n```\n{content}\n```"

            except UnicodeDecodeError:
                await progress_msg.edit_text(
                    "âŒ **File Format Not Supported**\n\n"
                    "File must be text-based and UTF-8 encoded.\n\n"
                    "**Supported formats:**\n"
                    "â€¢ Source code files (.py, .js, .ts, etc.)\n"
                    "â€¢ Text files (.txt, .md)\n"
                    "â€¢ Configuration files (.json, .yaml, .toml)\n"
                    "â€¢ Documentation files"
                )
                return

        # Delete progress message
        await progress_msg.delete()

        # Create a new progress message for Claude processing
        claude_progress_msg = await update.message.reply_text(
            "ðŸ¤– Processing file with Claude...", parse_mode=None
        )

        # Get Claude integration from context
        claude_integration = context.bot_data.get("claude_integration")

        if not claude_integration:
            await claude_progress_msg.edit_text(
                "âŒ **Claude integration not available**\n\n"
                "The Claude Code integration is not properly configured.",
                parse_mode=None,
            )
            return

        # Get current directory and session
        current_dir = context.user_data.get(
            "current_directory", settings.approved_directory
        )
        session_id = context.user_data.get("claude_session_id")

        # Process with Claude
        try:
            claude_response = await claude_integration.run_command(
                prompt=prompt,
                working_directory=current_dir,
                user_id=user_id,
                session_id=session_id,
            )

            # Update session ID
            context.user_data["claude_session_id"] = claude_response.session_id

            # Check if Claude changed the working directory and update our tracking
            _update_working_directory_from_claude_response(
                claude_response, context, settings, user_id
            )

            # Format and send response
            from ..utils.formatting import ResponseFormatter

            formatter = ResponseFormatter(settings)
            formatted_messages = formatter.format_claude_response(
                claude_response.content
            )

            # Delete progress message
            await claude_progress_msg.delete()

            # Send responses
            for i, message in enumerate(formatted_messages):
                await update.message.reply_text(
                    message.text,
                    parse_mode=message.parse_mode,
                    reply_markup=message.reply_markup,
                    reply_to_message_id=(update.message.message_id if i == 0 else None),
                )

                if i < len(formatted_messages) - 1:
                    await asyncio.sleep(0.5)

        except Exception as e:
            await claude_progress_msg.edit_text(
                _format_error_message(str(e)), parse_mode=None
            )
            logger.error("Claude file processing failed", error=str(e), user_id=user_id)

        # Log successful file processing
        if audit_logger:
            await audit_logger.log_file_access(
                user_id=user_id,
                file_path=document.file_name,
                action="upload_processed",
                success=True,
                file_size=document.file_size,
            )

    except Exception as e:
        try:
            await progress_msg.delete()
        except:
            pass

        error_msg = f"âŒ **Error processing file**\n\n{str(e)}"
        await update.message.reply_text(error_msg, parse_mode=None)

        # Log failed file processing
        if audit_logger:
            await audit_logger.log_file_access(
                user_id=user_id,
                file_path=document.file_name,
                action="upload_failed",
                success=False,
                file_size=document.file_size,
            )

        logger.error("Error processing document", error=str(e), user_id=user_id)


async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle photo uploads."""
    user_id = update.effective_user.id
    settings: Settings = context.bot_data["settings"]

    logger.debug("handle_photo called", user_id=user_id,
                has_photo=update.message.photo is not None if update.message else False,
                has_text=update.message.text is not None if update.message else False,
                message_text=update.message.text if update.message and update.message.text else None,
                message_type=type(update.message).__name__ if update.message else None)

    # Check if user has active image session
    logger.debug("Checking image session",
                 user_id=user_id,
                 has_user_data=context.user_data is not None,
                 user_data_keys=list(context.user_data.keys()) if context.user_data else [],
                 awaiting_images=context.user_data.get('awaiting_images', False) if context.user_data else False,
                 has_image_command_handler='image_command_handler' in context.bot_data)

    if context.user_data and context.user_data.get('awaiting_images'):
        logger.info("User has active image session - routing to image_command_handler", user_id=user_id)
        image_command_handler = context.bot_data.get('image_command_handler')
        if image_command_handler:
            logger.info("Calling image_command_handler.handle_image_upload", user_id=user_id)
            await image_command_handler.handle_image_upload(update, context)
            return
        else:
            logger.error("Image command handler not found in bot_data", user_id=user_id)
    else:
        logger.debug("No active image session for user", user_id=user_id,
                    has_user_data=context.user_data is not None,
                    awaiting_images=context.user_data.get('awaiting_images', False) if context.user_data else False)

    # Check if enhanced image handler is available
    features = context.bot_data.get("features")
    image_handler = features.get_image_handler() if features else None

    if image_handler:
        try:
            # Send processing indicator
            progress_msg = await update.message.reply_text(
                "ðŸ“¸ Processing image...", parse_mode=None
            )

            # Get the largest photo size
            if not update.message.photo:
                await progress_msg.edit_text("âŒ No photo found in message.")
                return
            photo = update.message.photo[-1]

            # Process image with enhanced handler
            processed_image = await image_handler.process_image(
                photo, update.message.caption
            )

            # Delete progress message
            await progress_msg.delete()

            # Create Claude progress message
            claude_progress_msg = await update.message.reply_text(
                "ðŸ¤– Analyzing image with Claude...", parse_mode=None
            )

            # Get Claude integration
            claude_integration = context.bot_data.get("claude_integration")

            if not claude_integration:
                await claude_progress_msg.edit_text(
                    "âŒ **Claude integration not available**\n\n"
                    "The Claude Code integration is not properly configured.",
                    parse_mode=None,
                )
                return

            # Get current directory and session
            current_dir = context.user_data.get(
                "current_directory", settings.approved_directory
            )
            session_id = context.user_data.get("claude_session_id")

            # Process with Claude
            try:
                claude_response = await claude_integration.run_command(
                    prompt=processed_image.prompt,
                    working_directory=current_dir,
                    user_id=user_id,
                    session_id=session_id,
                )

                # Update session ID
                context.user_data["claude_session_id"] = claude_response.session_id

                # Format and send response
                from ..utils.formatting import ResponseFormatter

                formatter = ResponseFormatter(settings)
                formatted_messages = formatter.format_claude_response(
                    claude_response.content
                )

                # Delete progress message
                await claude_progress_msg.delete()

                # Send responses
                for i, message in enumerate(formatted_messages):
                    await update.message.reply_text(
                        message.text,
                        parse_mode=message.parse_mode,
                        reply_markup=message.reply_markup,
                        reply_to_message_id=(
                            update.message.message_id if i == 0 else None
                        ),
                    )

                    if i < len(formatted_messages) - 1:
                        await asyncio.sleep(0.5)

            except Exception as e:
                await claude_progress_msg.edit_text(
                    _format_error_message(str(e)), parse_mode=None
                )
                logger.error(
                    "Claude image processing failed", error=str(e), user_id=user_id
                )

        except Exception as e:
            logger.error("Image processing failed", error=str(e), user_id=user_id)
            await update.message.reply_text(
                f"âŒ **Error processing image**\n\n{str(e)}", parse_mode=None
            )
    else:
        # Fall back to unsupported message
        await update.message.reply_text(
            "ðŸ“¸ **Photo Upload**\n\n"
            "Photo processing is not yet supported.\n\n"
            "**Currently supported:**\n"
            "â€¢ Text files (.py, .js, .md, etc.)\n"
            "â€¢ Configuration files\n"
            "â€¢ Documentation files\n\n"
            "**Coming soon:**\n"
            "â€¢ Image analysis\n"
            "â€¢ Screenshot processing\n"
            "â€¢ Diagram interpretation"
        )


def _estimate_text_processing_cost(text: str) -> float:
    """Estimate cost for processing text message."""
    # Base cost
    base_cost = 0.001

    # Additional cost based on length
    length_cost = len(text) * 0.00001

    # Additional cost for complex requests
    complex_keywords = [
        "analyze",
        "generate",
        "create",
        "build",
        "implement",
        "refactor",
        "optimize",
        "debug",
        "explain",
        "document",
    ]

    text_lower = text.lower()
    complexity_multiplier = 1.0

    for keyword in complex_keywords:
        if keyword in text_lower:
            complexity_multiplier += 0.5

    return (base_cost + length_cost) * min(complexity_multiplier, 3.0)


def _estimate_file_processing_cost(file_size: int) -> float:
    """Estimate cost for processing uploaded file."""
    # Base cost for file handling
    base_cost = 0.005

    # Additional cost based on file size (per KB)
    size_cost = (file_size / 1024) * 0.0001

    return base_cost + size_cost


async def _generate_placeholder_response(
    message_text: str, context: ContextTypes.DEFAULT_TYPE
) -> dict:
    """Generate placeholder response until Claude integration is implemented."""
    settings: Settings = context.bot_data["settings"]
    current_dir = getattr(
        context.user_data, "current_directory", settings.approved_directory
    )
    relative_path = current_dir.relative_to(settings.approved_directory)

    # Analyze the message for intent
    message_lower = message_text.lower()

    if any(
        word in message_lower for word in ["list", "show", "see", "directory", "files"]
    ):
        response_text = (
            f"ðŸ¤– **Claude Code Response** _(Placeholder)_\n\n"
            f"I understand you want to see files. Try using the `/ls` command to list files "
            f"in your current directory (`{relative_path}/`).\n\n"
            f"**Available commands:**\n"
            f"â€¢ `/ls` - List files\n"
            f"â€¢ `/cd <dir>` - Change directory\n"
            f"â€¢ `/projects` - Show projects\n\n"
            f"_Note: Full Claude Code integration will be available in the next phase._"
        )

    elif any(word in message_lower for word in ["create", "generate", "make", "build"]):
        response_text = (
            f"ðŸ¤– **Claude Code Response** _(Placeholder)_\n\n"
            f"I understand you want to create something! Once the Claude Code integration "
            f"is complete, I'll be able to:\n\n"
            f"â€¢ Generate code files\n"
            f"â€¢ Create project structures\n"
            f"â€¢ Write documentation\n"
            f"â€¢ Build complete applications\n\n"
            f"**Current directory:** `{relative_path}/`\n\n"
            f"_Full functionality coming soon!_"
        )

    elif any(word in message_lower for word in ["help", "how", "what", "explain"]):
        response_text = (
            f"ðŸ¤– **Claude Code Response** _(Placeholder)_\n\n"
            f"I'm here to help! Try using `/help` for available commands.\n\n"
            f"**What I can do now:**\n"
            f"â€¢ Navigate directories (`/cd`, `/ls`, `/pwd`)\n"
            f"â€¢ Show projects (`/projects`)\n"
            f"â€¢ Manage sessions (`/new`, `/status`)\n\n"
            f"**Coming soon:**\n"
            f"â€¢ Full Claude Code integration\n"
            f"â€¢ Code generation and editing\n"
            f"â€¢ File operations\n"
            f"â€¢ Advanced programming assistance"
        )

    else:
        response_text = (
            f"ðŸ¤– **Claude Code Response** _(Placeholder)_\n\n"
            f"I received your message: \"{message_text[:100]}{'...' if len(message_text) > 100 else ''}\"\n\n"
            f"**Current Status:**\n"
            f"â€¢ Directory: `{relative_path}/`\n"
            f"â€¢ Bot core: âœ… Active\n"
            f"â€¢ Claude integration: ðŸ”„ Coming soon\n\n"
            f"Once Claude Code integration is complete, I'll be able to process your "
            f"requests fully and help with coding tasks!\n\n"
            f"For now, try the available commands like `/ls`, `/cd`, and `/help`."
        )

    return {"text": response_text, "parse_mode": "Markdown"}


def _update_working_directory_from_claude_response(
    claude_response, context, settings, user_id
):
    """Update the working directory based on Claude's response content."""
    import re
    from pathlib import Path

    # Look for directory changes in Claude's response
    # This searches for common patterns that indicate directory changes
    patterns = [
        r"(?:^|\n).*?cd\s+([^\s\n]+)",  # cd command
        r"(?:^|\n).*?Changed directory to:?\s*([^\s\n]+)",  # explicit directory change
        r"(?:^|\n).*?Current directory:?\s*([^\s\n]+)",  # current directory indication
        r"(?:^|\n).*?Working directory:?\s*([^\s\n]+)",  # working directory indication
    ]

    content = claude_response.content.lower()
    current_dir = context.user_data.get(
        "current_directory", settings.approved_directory
    )

    for pattern in patterns:
        matches = re.findall(pattern, content, re.MULTILINE | re.IGNORECASE)
        for match in matches:
            try:
                # Clean up the path
                new_path = match.strip().strip("\"'`")

                # Handle relative paths
                if new_path.startswith("./") or new_path.startswith("../"):
                    new_path = (current_dir / new_path).resolve()
                elif not new_path.startswith("/"):
                    # Relative path without ./
                    new_path = (current_dir / new_path).resolve()
                else:
                    # Absolute path
                    new_path = Path(new_path).resolve()

                # Validate that the new path is within the approved directory
                if (
                    new_path.is_relative_to(settings.approved_directory)
                    and new_path.exists()
                ):
                    context.user_data["current_directory"] = new_path
                    logger.info(
                        "Updated working directory from Claude response",
                        old_dir=str(current_dir),
                        new_dir=str(new_path),
                        user_id=user_id,
                    )
                    return  # Take the first valid match

            except (ValueError, OSError) as e:
                # Invalid path, skip this match
                logger.debug(
                    "Invalid path in Claude response", path=match, error=str(e)
                )
                continue


async def handle_task_creation_dialogue(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle task creation multi-step dialogue."""
    from telegram import InlineKeyboardButton, InlineKeyboardMarkup
    from datetime import datetime, timedelta
    import uuid

    user_id = update.effective_user.id
    message_text = update.message.text
    task_data = context.user_data.get('creating_task', {})
    step = task_data.get('step', 'prompt')

    if step == 'prompt':
        # Step 1: User sent prompt text
        task_data['prompt'] = message_text
        task_data['step'] = 'schedule'
        context.user_data['creating_task'] = task_data

        keyboard = [
            [
                InlineKeyboardButton("â° Ð—Ð°Ñ€Ð°Ð· (Ð¿Ñ–Ð´ Ñ‡Ð°Ñ DND)", callback_data="schedule:time:dnd"),
                InlineKeyboardButton("ðŸŒ… Ð—Ð°Ð²Ñ‚Ñ€Ð° Ð²Ñ€Ð°Ð½Ñ†Ñ–", callback_data="schedule:time:morning")
            ],
            [
                InlineKeyboardButton("ðŸ•˜ Ð—Ð°Ð²Ñ‚Ñ€Ð° Ð²Ð²ÐµÑ‡ÐµÑ€Ñ–", callback_data="schedule:time:evening"),
                InlineKeyboardButton("ðŸ“… Ð©Ð¾Ð´ÐµÐ½Ð½Ð¾", callback_data="schedule:time:daily")
            ],
            [
                InlineKeyboardButton("ðŸ”„ Ð©Ð¾Ñ‚Ð¸Ð¶Ð½Ñ", callback_data="schedule:time:weekly"),
                InlineKeyboardButton("âš™ï¸ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ñ‡Ð°Ñ", callback_data="schedule:time:custom")
            ],
            [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="schedule:cancel_create")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        await update.message.reply_text(
            f"âœ… **ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¾:**\n`{message_text[:100]}{'...' if len(message_text) > 100 else ''}`\n\n"
            f"**ÐšÑ€Ð¾Ðº 2 Ð· 3: ÐšÐ¾Ð»Ð¸ Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸?**\n\n"
            f"ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ Ñ‡Ð°Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ:",
            reply_markup=reply_markup
        )

    elif step == 'custom_time':
        # Step 2b: User sent custom time
        try:
            # Parse time like "14:30", "9:00", "23:00"
            import re
            time_match = re.match(r'^(\d{1,2}):(\d{2})$', message_text.strip())
            if not time_match:
                await update.message.reply_text(
                    "âŒ **ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ‡Ð°ÑÑƒ**\n\n"
                    "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ñ‡Ð°Ñ Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ– Ð“Ð“:Ð¥Ð¥ (Ð½Ð°Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´, 14:30, 09:00, 23:15)\n\n"
                    "ÐÐ±Ð¾ ÑÐºÐ°ÑÑƒÐ¹Ñ‚Ðµ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ:",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="schedule:cancel_create")]
                    ])
                )
                return

            hour, minute = int(time_match.group(1)), int(time_match.group(2))
            if hour > 23 or minute > 59:
                await update.message.reply_text(
                    "âŒ **ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ Ñ‡Ð°Ñ**\n\n"
                    "Ð“Ð¾Ð´Ð¸Ð½Ð° Ð¿Ð¾Ð²Ð¸Ð½Ð½Ð° Ð±ÑƒÑ‚Ð¸ Ð²Ñ–Ð´ 00 Ð´Ð¾ 23, Ñ…Ð²Ð¸Ð»Ð¸Ð½Ð¸ Ð²Ñ–Ð´ 00 Ð´Ð¾ 59\n\n"
                    "Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ð°Ð±Ð¾ ÑÐºÐ°ÑÑƒÐ¹Ñ‚Ðµ:",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="schedule:cancel_create")]
                    ])
                )
                return

            task_data['custom_time'] = f"{hour:02d}:{minute:02d}"
            task_data['step'] = 'confirm'
            context.user_data['creating_task'] = task_data

            await _show_task_confirmation(update, task_data)

        except Exception as e:
            logger.error("Error parsing custom time", error=str(e))
            await update.message.reply_text(
                "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ñ‡Ð°ÑÑƒ**\n\n"
                "Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ð°Ð±Ð¾ ÑÐºÐ°ÑÑƒÐ¹Ñ‚Ðµ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ:",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="schedule:cancel_create")]
                ])
            )


async def _show_task_confirmation(update, task_data):
    """Show task confirmation with all details."""
    from telegram import InlineKeyboardButton, InlineKeyboardMarkup

    prompt = task_data.get('prompt', '')
    schedule_type = task_data.get('schedule_type', 'dnd')
    custom_time = task_data.get('custom_time', '')

    # Format schedule description
    schedule_desc = {
        'dnd': 'ÐŸÑ–Ð´ Ñ‡Ð°Ñ DND Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ (23:00-08:00)',
        'morning': 'Ð—Ð°Ð²Ñ‚Ñ€Ð° Ð¾ 08:00',
        'evening': 'Ð—Ð°Ð²Ñ‚Ñ€Ð° Ð¾ 20:00',
        'daily': 'Ð©Ð¾Ð´ÐµÐ½Ð½Ð¾ Ð¾ 08:00',
        'weekly': 'Ð©Ð¾Ñ‚Ð¸Ð¶Ð½Ñ (Ð¿Ð¾Ð½ÐµÐ´Ñ–Ð»Ð¾Ðº Ð¾ 09:00)',
        'custom': f'Ð©Ð¾Ð´ÐµÐ½Ð½Ð¾ Ð¾ {custom_time}' if custom_time else 'ÐÐ°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ‡Ð°Ñ'
    }

    message = (
        f"ðŸ“ **ÐŸÑ–Ð´Ñ‚Ð²ÐµÑ€Ð´Ð¶ÐµÐ½Ð½Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ**\n\n"
        f"**Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ:**\n`{prompt[:200]}{'...' if len(prompt) > 200 else ''}`\n\n"
        f"**Ð Ð¾Ð·ÐºÐ»Ð°Ð´:** {schedule_desc.get(schedule_type, 'ÐÐµ Ð²ÐºÐ°Ð·Ð°Ð½Ð¾')}\n\n"
        f"**ÐšÑ€Ð¾Ðº 3 Ð· 3:** ÐŸÑ–Ð´Ñ‚Ð²ÐµÑ€Ð´Ñ–Ñ‚ÑŒ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ"
    )

    keyboard = [
        [
            InlineKeyboardButton("âœ… Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:confirm_task"),
            InlineKeyboardButton("âœï¸ Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸", callback_data="schedule:edit_task")
        ],
        [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="schedule:cancel_create")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    if hasattr(update, 'message') and update.message:
        await update.message.reply_text(message, reply_markup=reply_markup)
    else:
        # Called from callback, need to edit message
        await update.edit_message_text(message, reply_markup=reply_markup)


async def handle_file_action_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle text messages during file editing workflow."""
    from telegram import InlineKeyboardButton, InlineKeyboardMarkup
    from pathlib import Path

    user_id = update.effective_user.id
    message_text = update.message.text
    file_action = context.user_data.get('file_action', {})
    action_type = file_action.get('type')
    step = file_action.get('step')

    settings: Settings = context.bot_data["settings"]
    current_dir = context.user_data.get("current_directory", settings.approved_directory)

    logger.info("Handling file action message", user_id=user_id, action_type=action_type, step=step, filename=message_text)

    if step == "waiting_filename":
        # User sent filename for reading or editing
        filename = message_text.strip()

        # Basic filename validation
        if not filename:
            await update.message.reply_text(
                "âŒ **ÐŸÐ¾Ñ€Ð¾Ð¶Ð½Ñ Ð½Ð°Ð·Ð²Ð° Ñ„Ð°Ð¹Ð»Ñƒ**\n\n"
                "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ:",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="action:quick_actions")]
                ])
            )
            return

        # Security check - prevent path traversal
        if ".." in filename or filename.startswith("/"):
            await update.message.reply_text(
                "âŒ **ÐÐµÐ´Ð¾Ð·Ð²Ð¾Ð»ÐµÐ½Ð° Ð½Ð°Ð·Ð²Ð° Ñ„Ð°Ð¹Ð»Ñƒ**\n\n"
                "ÐÐ°Ð·Ð²Ð° Ñ„Ð°Ð¹Ð»Ñƒ Ð½Ðµ Ð¼Ð¾Ð¶Ðµ Ð¼Ñ–ÑÑ‚Ð¸Ñ‚Ð¸ '..' Ð°Ð±Ð¾ Ð¿Ð¾Ñ‡Ð¸Ð½Ð°Ñ‚Ð¸ÑÑ Ð· '/'.\n"
                "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð²Ñ–Ð´Ð½Ð¾ÑÐ½Ñƒ Ð½Ð°Ð·Ð²Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ Ð² Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—:",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="action:quick_actions")]
                ])
            )
            return

        file_path = current_dir / filename

        if action_type == "read":
            # Handle file reading
            try:
                if not file_path.exists():
                    await update.message.reply_text(
                        f"âŒ **Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\n"
                        f"Ð¤Ð°Ð¹Ð» `{filename}` Ð½Ðµ Ñ–ÑÐ½ÑƒÑ” Ð² Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—.\n"
                        f"ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ð½Ð°Ð·Ð²Ñƒ Ñ‚Ð° ÑÐ¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·:",
                        reply_markup=InlineKeyboardMarkup([
                            [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_read")]
                        ])
                    )
                    return

                if not file_path.is_file():
                    await update.message.reply_text(
                        f"âŒ **Ð¦Ðµ Ð½Ðµ Ñ„Ð°Ð¹Ð»**\n\n"
                        f"`{filename}` Ñ” Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ”ÑŽ, Ð° Ð½Ðµ Ñ„Ð°Ð¹Ð»Ð¾Ð¼.\n"
                        f"Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ:",
                        reply_markup=InlineKeyboardMarkup([
                            [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_read")]
                        ])
                    )
                    return

                # Check file size
                file_size = file_path.stat().st_size
                if file_size > 1024 * 1024:  # 1MB limit for reading
                    await update.message.reply_text(
                        f"âŒ **Ð¤Ð°Ð¹Ð» Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹**\n\n"
                        f"Ð¤Ð°Ð¹Ð» `{filename}` Ð¼Ð°Ñ” Ñ€Ð¾Ð·Ð¼Ñ–Ñ€ {file_size:,} Ð±Ð°Ð¹Ñ‚.\n"
                        f"ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€ Ð´Ð»Ñ Ñ‡Ð¸Ñ‚Ð°Ð½Ð½Ñ: 1MB.\n\n"
                        f"Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸ Claude Ð´Ð»Ñ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸ Ð· Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¼Ð¸ Ñ„Ð°Ð¹Ð»Ð°Ð¼Ð¸.",
                        reply_markup=InlineKeyboardMarkup([
                            [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_read")]
                        ])
                    )
                    return

                # Read file content
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                except UnicodeDecodeError:
                    # Try with different encoding
                    with open(file_path, 'r', encoding='latin-1') as f:
                        content = f.read()

                # Truncate content if too long for Telegram message
                max_length = 3500  # Leave room for formatting
                if len(content) > max_length:
                    content = content[:max_length] + "\n\n... (Ñ„Ð°Ð¹Ð» Ð¾Ð±Ñ€Ñ–Ð·Ð°Ð½Ð¾)"

                response_text = (
                    f"ðŸ“– **Ð’Ð¼Ñ–ÑÑ‚ Ñ„Ð°Ð¹Ð»Ñƒ:** `{filename}`\n\n"
                    f"```\n{content}\n```\n\n"
                    f"ðŸ“ **Ð Ð¾Ð·Ð¼Ñ–Ñ€:** {file_size:,} Ð±Ð°Ð¹Ñ‚"
                )

                await update.message.reply_text(
                    response_text,
                    reply_markup=InlineKeyboardMarkup([
                        [
                            InlineKeyboardButton("âœï¸ Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»", callback_data="file_edit:select_edit"),
                            InlineKeyboardButton("ðŸ“‹ ÐœÐµÐ½ÑŽ", callback_data="action:quick_actions")
                        ]
                    ])
                )

                # Clear file action state
                context.user_data.pop("file_action", None)

            except Exception as e:
                logger.error("Error reading file", error=str(e), filename=filename)
                await update.message.reply_text(
                    f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ñ‡Ð¸Ñ‚Ð°Ð½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñƒ**\n\n"
                    f"ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð» `{filename}`:\n"
                    f"```\n{str(e)}\n```",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_read")]
                    ])
                )

        elif action_type == "edit":
            # Handle file editing - download file for user
            try:
                if not file_path.exists():
                    await update.message.reply_text(
                        f"âŒ **Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\n"
                        f"Ð¤Ð°Ð¹Ð» `{filename}` Ð½Ðµ Ñ–ÑÐ½ÑƒÑ” Ð² Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—.\n"
                        f"ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ð½Ð°Ð·Ð²Ñƒ Ñ‚Ð° ÑÐ¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·:",
                        reply_markup=InlineKeyboardMarkup([
                            [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_edit")]
                        ])
                    )
                    return

                if not file_path.is_file():
                    await update.message.reply_text(
                        f"âŒ **Ð¦Ðµ Ð½Ðµ Ñ„Ð°Ð¹Ð»**\n\n"
                        f"`{filename}` Ñ” Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ”ÑŽ, Ð° Ð½Ðµ Ñ„Ð°Ð¹Ð»Ð¾Ð¼.\n"
                        f"Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ:",
                        reply_markup=InlineKeyboardMarkup([
                            [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_edit")]
                        ])
                    )
                    return

                # Check file size
                file_size = file_path.stat().st_size
                if file_size > 20 * 1024 * 1024:  # 20MB limit for editing
                    await update.message.reply_text(
                        f"âŒ **Ð¤Ð°Ð¹Ð» Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹**\n\n"
                        f"Ð¤Ð°Ð¹Ð» `{filename}` Ð¼Ð°Ñ” Ñ€Ð¾Ð·Ð¼Ñ–Ñ€ {file_size:,} Ð±Ð°Ð¹Ñ‚.\n"
                        f"ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€ Ð´Ð»Ñ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ: 20MB.",
                        reply_markup=InlineKeyboardMarkup([
                            [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_edit")]
                        ])
                    )
                    return

                # Send file for editing
                progress_msg = await update.message.reply_text(
                    f"ðŸ“¤ **ÐÐ°Ð´ÑÐ¸Ð»Ð°ÑŽ Ñ„Ð°Ð¹Ð» Ð´Ð»Ñ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ...**\n\n"
                    f"ðŸ“ Ð¤Ð°Ð¹Ð»: `{filename}`\n"
                    f"ðŸ“ Ð Ð¾Ð·Ð¼Ñ–Ñ€: {file_size:,} Ð±Ð°Ð¹Ñ‚"
                )

                def _format_file_size(size: int) -> str:
                    """Format file size in human-readable format."""
                    for unit in ["B", "KB", "MB", "GB"]:
                        if size < 1024:
                            return f"{size:.1f}{unit}" if unit != "B" else f"{size}B"
                        size /= 1024
                    return f"{size:.1f}TB"

                # Send the file
                with open(file_path, 'rb') as file:
                    await update.message.reply_document(
                        document=file,
                        filename=filename,
                        caption=(
                            f"âœï¸ **Ð¤Ð°Ð¹Ð» Ð´Ð»Ñ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ**\n\n"
                            f"ðŸ“ ÐÐ°Ð·Ð²Ð°: `{filename}`\n"
                            f"ðŸ“ Ð Ð¾Ð·Ð¼Ñ–Ñ€: {_format_file_size(file_size)}\n\n"
                            f"ðŸ”„ **Ð¯Ðº Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸:**\n"
                            f"1. Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ñ‚Ðµ Ñ†ÐµÐ¹ Ñ„Ð°Ð¹Ð»\n"
                            f"2. Ð’Ñ–Ð´Ñ€ÐµÐ´Ð°Ð³ÑƒÐ¹Ñ‚Ðµ Ñƒ Ð²Ð°ÑˆÐ¾Ð¼Ñƒ Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¾Ñ€Ñ–\n"
                            f"3. ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð²Ñ–Ð´Ñ€ÐµÐ´Ð°Ð³Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ„Ð°Ð¹Ð» Ð½Ð°Ð·Ð°Ð´ ÑÐº Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚\n"
                            f"4. Ð¯ Ð·Ð±ÐµÑ€ÐµÐ¶Ñƒ Ð·Ð¼Ñ–Ð½Ð¸\n\n"
                            f"ðŸ’¾ ÐžÑ‡Ñ–ÐºÑƒÑŽ Ð²Ñ–Ð´Ñ€ÐµÐ´Ð°Ð³Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ„Ð°Ð¹Ð»..."
                        )
                    )

                # Update state to wait for edited file
                context.user_data["file_action"] = {
                    "type": "edit",
                    "step": "waiting_edited_file",
                    "filename": filename,
                    "original_path": str(file_path)
                }

                # Update progress message
                await progress_msg.edit_text(
                    f"âœ… **Ð¤Ð°Ð¹Ð» Ð½Ð°Ð´Ñ–ÑÐ»Ð°Ð½Ð¾**\n\n"
                    f"ðŸ“ Ð¤Ð°Ð¹Ð» `{filename}` Ð½Ð°Ð´Ñ–ÑÐ»Ð°Ð½Ð¾ Ð²Ð¸Ñ‰Ðµ.\n\n"
                    f"ðŸ“ Ð’Ñ–Ð´Ñ€ÐµÐ´Ð°Ð³ÑƒÐ¹Ñ‚Ðµ Ñ„Ð°Ð¹Ð» Ñ‚Ð° Ð½Ð°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð¹Ð¾Ð³Ð¾ Ð½Ð°Ð·Ð°Ð´ ÑÐº Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚.\n\n"
                    f"ðŸ’¡ **ÐŸÑ–Ð´ÐºÐ°Ð·ÐºÐ°:** ÐŸÐµÑ€ÐµÐºÐ¾Ð½Ð°Ð¹Ñ‚ÐµÑÑ Ñ‰Ð¾ Ð·Ð±ÐµÑ€ÐµÐ³Ð»Ð¸ Ñ„Ð°Ð¹Ð» Ð· Ñ‚Ñ–Ñ”ÑŽ Ð¶ Ð½Ð°Ð·Ð²Ð¾ÑŽ!",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ", callback_data="file_edit:cancel")]
                    ])
                )

            except Exception as e:
                logger.error("Error preparing file for editing", error=str(e), filename=filename)
                await update.message.reply_text(
                    f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ñ„Ð°Ð¹Ð»Ñƒ**\n\n"
                    f"ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¿Ñ–Ð´Ð³Ð¾Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð» `{filename}` Ð´Ð»Ñ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ:\n"
                    f"```\n{str(e)}\n```",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_edit")]
                    ])
                )

    else:
        # Unknown step or state
        logger.warning("Unknown file action step", user_id=user_id, step=step, action_type=action_type)
        context.user_data.pop("file_action", None)
        await update.message.reply_text(
            "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÑÑ‚Ð°Ð½Ñƒ**\n\n"
            "Ð¡Ñ‚Ð°Ð½ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñƒ Ð¿Ð¾Ñ€ÑƒÑˆÐµÐ½Ð¾. ÐŸÐ¾Ñ‡Ð½Ñ–Ñ‚ÑŒ ÑÐ¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ.",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("ðŸ“‹ Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ—", callback_data="action:quick_actions")]
            ])
        )


async def handle_document_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle document uploads for file editing workflow."""
    from telegram import InlineKeyboardButton, InlineKeyboardMarkup
    from pathlib import Path
    import shutil

    user_id = update.effective_user.id
    file_action = context.user_data.get('file_action', {})

    # Check if user is in file editing workflow
    if not file_action or file_action.get('step') != 'waiting_edited_file':
        # User sent document but not in editing workflow - ignore or provide guidance
        await update.message.reply_text(
            "ðŸ“„ **Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð¾**\n\n"
            "Ð©Ð¾Ð± Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð», Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ ÑˆÐ²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ—:\n"
            "1. ÐÐ°Ñ‚Ð¸ÑÐ½Ñ–Ñ‚ÑŒ ðŸ“‹ Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ—\n"
            "2. ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ âœï¸ Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»\n"
            "3. Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ\n\n"
            "Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ Ð½Ðµ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¾.",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("ðŸ“‹ Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ—", callback_data="action:quick_actions")]
            ])
        )
        return

    settings: Settings = context.bot_data["settings"]
    current_dir = context.user_data.get("current_directory", settings.approved_directory)
    expected_filename = file_action.get('filename')
    original_path = Path(file_action.get('original_path', ''))

    document = update.message.document
    uploaded_filename = document.file_name

    logger.info("Processing uploaded document", user_id=user_id,
                uploaded_filename=uploaded_filename, expected_filename=expected_filename)

    try:
        # Validate filename matches expected
        if uploaded_filename != expected_filename:
            await update.message.reply_text(
                f"âš ï¸ **ÐÐµÐ²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ñ–ÑÑ‚ÑŒ Ð½Ð°Ð·Ð²Ð¸ Ñ„Ð°Ð¹Ð»Ñƒ**\n\n"
                f"ÐžÑ‡Ñ–ÐºÑƒÐ²Ð°Ð²: `{expected_filename}`\n"
                f"ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ð²: `{uploaded_filename}`\n\n"
                f"Ð¤Ð°Ð¹Ð» Ð±ÑƒÐ´Ðµ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¾ Ð· Ð¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð¾ÑŽ Ð½Ð°Ð·Ð²Ð¾ÑŽ.",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("âœ… ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸", callback_data="file_edit:confirm_save")],
                    [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="file_edit:cancel")]
                ])
            )

        # Check file size (Telegram limit)
        if document.file_size > 20 * 1024 * 1024:  # 20MB
            await update.message.reply_text(
                f"âŒ **Ð¤Ð°Ð¹Ð» Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹**\n\n"
                f"Ð Ð¾Ð·Ð¼Ñ–Ñ€ Ñ„Ð°Ð¹Ð»Ñƒ: {document.file_size:,} Ð±Ð°Ð¹Ñ‚\n"
                f"ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€: 20MB\n\n"
                f"Ð—Ð¼ÐµÐ½ÑˆÑ–Ñ‚ÑŒ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€ Ñ„Ð°Ð¹Ð»Ñƒ Ñ‚Ð° ÑÐ¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·.",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_edit")]
                ])
            )
            return

        # Show processing message
        progress_msg = await update.message.reply_text(
            f"ðŸ’¾ **Ð—Ð±ÐµÑ€Ñ–Ð³Ð°ÑŽ Ð²Ñ–Ð´Ñ€ÐµÐ´Ð°Ð³Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ„Ð°Ð¹Ð»...**\n\n"
            f"ðŸ“ Ð¤Ð°Ð¹Ð»: `{expected_filename}`\n"
            f"ðŸ“ Ð Ð¾Ð·Ð¼Ñ–Ñ€: {document.file_size:,} Ð±Ð°Ð¹Ñ‚\n\n"
            f"â³ Ð—Ð°Ñ‡ÐµÐºÐ°Ð¹Ñ‚Ðµ..."
        )

        # Download and save file
        file_obj = await context.bot.get_file(document.file_id)

        # Create backup of original file
        backup_path = original_path.with_suffix(original_path.suffix + '.backup')
        if original_path.exists():
            shutil.copy2(original_path, backup_path)

        # Save new file content
        await file_obj.download_to_drive(original_path)

        # Clear file action state
        context.user_data.pop("file_action", None)

        # Show success message
        await progress_msg.edit_text(
            f"âœ… **Ð¤Ð°Ð¹Ð» ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¾!**\n\n"
            f"ðŸ“ Ð¤Ð°Ð¹Ð»: `{expected_filename}`\n"
            f"ðŸ“ ÐÐ¾Ð²Ð¸Ð¹ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€: {document.file_size:,} Ð±Ð°Ð¹Ñ‚\n"
            f"ðŸ’¾ Ð ÐµÐ·ÐµÑ€Ð²Ð½Ð° ÐºÐ¾Ð¿Ñ–Ñ: `{backup_path.name}`\n\n"
            f"ðŸŽ‰ Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾!",
            reply_markup=InlineKeyboardMarkup([
                [
                    InlineKeyboardButton("ðŸ“– ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð·Ð¼Ñ–Ð½Ð¸", callback_data="file_edit:select_read"),
                    InlineKeyboardButton("ðŸ“‹ ÐœÐµÐ½ÑŽ", callback_data="action:quick_actions")
                ]
            ])
        )

        logger.info("File editing completed successfully", user_id=user_id, filename=expected_filename,
                   original_size=original_path.stat().st_size if original_path.exists() else 0,
                   new_size=document.file_size)

    except Exception as e:
        logger.error("Error saving edited file", error=str(e), user_id=user_id, filename=expected_filename)

        # Clear state on error
        context.user_data.pop("file_action", None)

        await update.message.reply_text(
            f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñƒ**\n\n"
            f"ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð·Ð±ÐµÑ€ÐµÐ³Ñ‚Ð¸ Ñ„Ð°Ð¹Ð» `{expected_filename}`:\n"
            f"```\n{str(e)}\n```\n\n"
            f"Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð·Ð¼Ñ–Ð½ÐµÐ½Ð¾.",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("ðŸ”™ ÐŸÐ¾Ð²ÐµÑ€Ð½ÑƒÑ‚Ð¸ÑÑ", callback_data="action:quick_actions")]
            ])
        )


async def send_unavailable_message(update: Update, status_details: dict) -> None:
    """ÐÐ°Ð´Ñ–ÑÐ»Ð°Ñ‚Ð¸ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–ÑÑ‚ÑŒ Claude Ð·Ð³Ñ–Ð´Ð½Ð¾ Ð· Ð¿Ð»Ð°Ð½Ð¾Ð¼."""
    try:
        # ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑÐ½Ðµ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ
        status_message = status_details.get("status_message", "ðŸ”´ Claude Ð·Ð°Ñ€Ð°Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹")

        # ÐŸÐ¾Ð±ÑƒÐ´ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ð¾Ð²Ð½Ðµ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ
        message_parts = [status_message]

        if "estimated_recovery" in status_details:
            message_parts.append(f"\nâ³ {status_details['estimated_recovery']}")

        message_parts.append("\n\nðŸ’¡ Ð¯ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÑŽ Ð² Ð³Ñ€ÑƒÐ¿Ñƒ, ÐºÐ¾Ð»Ð¸ Claude ÑÑ‚Ð°Ð½Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹")
        message_parts.append("\nðŸ“‹ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /claude_status Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸")

        full_message = "".join(message_parts)

        # ÐÐ°Ð´Ñ–ÑÐ»Ð°Ñ‚Ð¸ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ
        await update.message.reply_text(full_message, parse_mode=None)

        logger.info("Claude unavailable message sent",
                   user_id=update.effective_user.id,
                   reason=status_details.get("reason"))

    except Exception as e:
        logger.error(f"Error sending unavailable message: {e}")
        # Fallback Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ
        await update.message.reply_text(
            "ðŸ”´ Claude Ð·Ð°Ñ€Ð°Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹\n\n"
            "Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ Ð°Ð±Ð¾ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /claude_status Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸.",
            parse_mode=None
        )

```

### bot/handlers/image_command.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 23,536 Ð±Ð°Ð¹Ñ‚

```python
"""Main /img command handler for image processing.

Features:
- Multi-image upload support  
- Batch processing with Claude CLI
- Session management for image contexts
- Progress indicators and error handling
"""

import asyncio
import uuid
from pathlib import Path
from typing import Dict, List, Optional, cast
import structlog
from telegram import Update
from telegram.ext import ContextTypes

from ...claude.facade import ClaudeIntegration
from ...claude.exceptions import ClaudeError, ClaudeTimeoutError, ClaudeProcessError
from ...config.settings import Settings
from ...exceptions import SecurityError
from ...localization.util import t, get_user_id, get_effective_message
from ..features.image_processor import ImageProcessor, ProcessedImage
from ..utils.error_handler import safe_user_error

logger = structlog.get_logger(__name__)

class ImageCommandHandler:
    """Handler for /img command and image processing workflow."""

    def __init__(self, settings: Settings, image_processor: ImageProcessor):
        """Initialize image command handler."""
        self.settings = settings
        self.image_processor = image_processor
        self.active_sessions: Dict[int, 'ImageSession'] = {}
        self.max_images_per_batch = settings.image_max_batch_size
        self.session_timeout = settings.image_session_timeout_minutes * 60

    async def handle_img_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Handle /img command to start image processing session."""
        logger.debug("handle_img_command called", update_type=type(update).__name__)

        user_id = get_user_id(update)
        message = get_effective_message(update)

        logger.debug("handle_img_command data", user_id=user_id, has_message=message is not None)

        if not user_id or not message:
            logger.warning("handle_img_command: missing user_id or message")
            return

        # Check if image processing is enabled
        if not self.settings.enable_image_processing:
            logger.warning("Image processing disabled in settings")
            error_text = await t(context, user_id, "errors.image_processing_disabled")
            await message.reply_text(error_text)
            return

        logger.info("Starting image command session", user_id=user_id)

        # Extract initial instruction from command
        message_text = message.text or ""
        parts = message_text.split(maxsplit=1) if message_text else []
        initial_instruction = parts[1] if len(parts) > 1 else None

        # Create new image session
        session = ImageSession(
            user_id=user_id,
            initial_instruction=initial_instruction,
            timeout=self.session_timeout
        )
        self.active_sessions[user_id] = session

        # Send instruction message
        instruction_text = await self._get_instruction_message(context, user_id)
        await message.reply_text(
            instruction_text,
            parse_mode=None
        )

        # Set user state for image collection
        if context.user_data is not None:
            context.user_data['awaiting_images'] = True
            context.user_data['image_session_id'] = session.session_id
        else:
            context.user_data = {
                'awaiting_images': True,
                'image_session_id': session.session_id
            }

        # Schedule session cleanup
        asyncio.create_task(self._cleanup_session_after_timeout(user_id, session.session_id))

    async def handle_image_upload(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Handle image uploads during an active session."""
        logger.debug("handle_image_upload called", update_type=type(update).__name__)

        user_id = get_user_id(update)
        message = get_effective_message(update)

        logger.debug("handle_image_upload data", user_id=user_id, has_message=message is not None,
                     user_in_sessions=user_id in self.active_sessions if user_id else False)

        if not user_id or not message or user_id not in self.active_sessions:
            logger.warning("handle_image_upload: missing user_id/message or no active session")
            return

        session = self.active_sessions[user_id]

        if not session.is_active():
            logger.warning("Session expired for user", user_id=user_id)
            await self._cleanup_session(user_id, context)
            error_text = await t(context, user_id, "commands.img.session_expired")
            await message.reply_text(error_text)
            return

        try:
            # Process the uploaded image
            logger.debug("Processing image upload", has_photo=hasattr(message, 'photo') and message.photo is not None,
                        photo_type=type(message.photo).__name__ if hasattr(message, 'photo') and message.photo else None)

            photo = None
            logger.debug("Photo check details",
                        has_photo=bool(message.photo),
                        photo_type=type(message.photo).__name__ if message.photo else None,
                        photo_length=len(message.photo) if message.photo else 0,
                        is_list=isinstance(message.photo, list) if message.photo else False,
                        is_tuple=isinstance(message.photo, tuple) if message.photo else False)

            if message.photo and (isinstance(message.photo, (list, tuple))) and len(message.photo) > 0:
                photo = message.photo[-1]
                logger.debug("Selected photo", photo_id=photo.file_id if photo else None)

            if photo:
                processed_image = await self.image_processor.process_telegram_photo(
                    photo, 
                    message.caption,
                    user_id
                )
                session.add_image(processed_image)

                # Send confirmation
                confirmation_text = await t(
                    context, user_id, "commands.img.image_received",
                    current=len(session.images),
                    max=self.max_images_per_batch
                )
                await message.reply_text(confirmation_text)

                # Check if batch is full
                if len(session.images) >= self.max_images_per_batch:
                    await self._process_session_images(update, context, session)

        except SecurityError as e:
            logger.warning("Security error processing image", error=str(e), user_id=user_id)
            await message.reply_text(f"âŒ Security error: {str(e)}")
        except Exception as e:
            logger.error("Error processing image upload", error=str(e), user_id=user_id)
            await safe_user_error(message, f"Error processing image: {str(e)}")

    async def handle_text_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        """Handle text messages during image session."""
        user_id = get_user_id(update)
        message = get_effective_message(update)
        
        if not user_id or not message or user_id not in self.active_sessions:
            return

        session = self.active_sessions[user_id]
        message_text = (message.text or "").strip().lower()

        if message_text in ['done', 'Ð³Ð¾Ñ‚Ð¾Ð²Ð¾', 'Ð¿Ñ€Ð¾Ñ†ÐµÑ', 'process']:
            logger.info("User requested processing", user_id=user_id, images_count=len(session.images))
            if session.images:
                await self._process_session_images(update, context, session)
            else:
                logger.info("No images in session for processing", user_id=user_id)
                no_images_text = await t(context, user_id, "commands.img.no_images")
                await message.reply_text(no_images_text)
        elif message_text in ['cancel', 'ÑÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸', 'Ð²Ñ–Ð´Ð¼Ñ–Ð½Ð°']:
            await self._cleanup_session(user_id, context)
            cancelled_text = await t(context, user_id, "commands.img.cancelled")
            await message.reply_text(cancelled_text)
        elif message_text in ['Ð·Ð°Ð¿Ð¸Ñ‚', 'query', 'fix', 'Ñ„Ñ–ÐºÑ']:
            # Set special mode for UI/code improvement requests
            session.set_ui_fix_mode(True)
            session.set_instruction(message.text)
            fix_mode_text = await t(context, user_id, "commands.img.fix_mode_activated")
            await message.reply_text(fix_mode_text)
        else:
            # Update session instruction
            session.set_instruction(message.text)
            updated_text = await t(
                context, user_id, "commands.img.instruction_updated",
                count=len(session.images)
            )
            await message.reply_text(updated_text)

    async def _process_session_images(
        self, 
        update: Update, 
        context: ContextTypes.DEFAULT_TYPE, 
        session: 'ImageSession'
    ) -> None:
        """Process all images in session with Claude CLI."""
        user_id = get_user_id(update)
        message = get_effective_message(update)
        
        if not user_id or not message or not session.images:
            error_text = await t(context, user_id, "commands.img.no_images")
            await message.reply_text(error_text)
            return

        processing_text = await t(
            context, user_id, "commands.img.processing",
            count=len(session.images)
        )
        progress_msg = await message.reply_text(processing_text)

        try:
            # Get Claude integration
            claude_integration = context.bot_data.get('claude_integration')
            if not claude_integration:
                await progress_msg.edit_text("âŒ Claude integration not available.")
                return

            # Build prompt with image references
            prompt = self._build_claude_prompt(session)

            # Get current working directory
            settings = context.bot_data.get("settings")
            if not settings:
                current_dir = Path.cwd()
            else:
                settings_typed = cast(Settings, settings)
                current_dir = context.user_data.get(
                    'current_directory', 
                    settings_typed.approved_directory
                ) if context.user_data else settings_typed.approved_directory

            # Process with Claude
            claude_integration_typed = cast(ClaudeIntegration, claude_integration)
            claude_response = await claude_integration_typed.run_command_with_images(
                prompt=prompt,
                images=session.images,
                working_directory=current_dir,
                user_id=user_id,
                session_id=context.user_data.get('claude_session_id') if context.user_data else None
            )

            # Update session ID
            if context.user_data:
                context.user_data['claude_session_id'] = claude_response.session_id

            # Check if response is empty
            if not claude_response.content or not claude_response.content.strip():
                logger.warning("Empty response from Claude", user_id=user_id)
                error_text = await t(context, user_id, "commands.img.error", error="Claude Ð½Ðµ Ð¿Ð¾Ð²ÐµÑ€Ð½ÑƒÐ² Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ")
                await self._safe_edit_or_send_error(progress_msg, message, error_text)
                return

            # Format and send response
            from ..utils.formatting import ResponseFormatter
            formatter = ResponseFormatter(self.settings)
            formatted_messages = formatter.format_claude_response(claude_response.content)

            # Check if formatted messages are empty
            if not formatted_messages or all(not msg.text.strip() for msg in formatted_messages):
                logger.warning("Empty formatted messages", user_id=user_id)
                error_text = await t(context, user_id, "commands.img.error", error="Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð½Ðµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð²Ñ–Ð´Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸")
                await self._safe_edit_or_send_error(progress_msg, message, error_text)
                return

            # Delete progress message safely
            try:
                await progress_msg.delete()
            except Exception as e:
                logger.warning("Could not delete progress message", error=str(e))

            # Send responses
            for i, response_msg in enumerate(formatted_messages):
                try:
                    await message.reply_text(
                        response_msg.text,
                        parse_mode=response_msg.parse_mode,
                        reply_markup=response_msg.reply_markup,
                        reply_to_message_id=message.message_id if i == 0 else None
                    )
                except Exception as e:
                    logger.error("Failed to send response message", error=str(e), message_index=i)
                    # Try to send a fallback message
                    try:
                        await message.reply_text(f"Ð§Ð°ÑÑ‚Ð¸Ð½Ð° Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– #{i+1}: {response_msg.text[:1000]}")
                    except:
                        pass

                if i < len(formatted_messages) - 1:
                    await asyncio.sleep(0.5)

        except ClaudeTimeoutError as e:
            logger.error("Claude timeout processing images", error=str(e))
            error_text = await t(context, user_id, "commands.img.error", error="Timeout - ÑÐ¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ")
            await self._safe_edit_or_send_error(progress_msg, message, error_text)
        except ClaudeProcessError as e:
            logger.error("Claude process error processing images", error=str(e))
            error_text = await t(context, user_id, "commands.img.error", error="Claude CLI Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹")
            await self._safe_edit_or_send_error(progress_msg, message, error_text)
        except ClaudeError as e:
            logger.error("Claude error processing images", error=str(e))
            error_text = await t(context, user_id, "commands.img.error", error=str(e))
            await self._safe_edit_or_send_error(progress_msg, message, error_text)
        except Exception as e:
            logger.error("Unexpected error processing images with Claude", error=str(e))
            error_text = await t(context, user_id, "commands.img.error", error="ÐÐµÐ¿ÐµÑ€ÐµÐ´Ð±Ð°Ñ‡ÐµÐ½Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°")
            await self._safe_edit_or_send_error(progress_msg, message, error_text)

        finally:
            # Clean up session
            await self._cleanup_session(session.user_id, context)

    def _build_claude_prompt(self, session: 'ImageSession') -> str:
        """Build Claude prompt with image context."""
        base_instruction = session.instruction or "Please analyze these images and provide insights."

        image_info = []
        for i, img in enumerate(session.images, 1):
            info = f"Image {i}: {img.filename}"
            if img.caption:
                info += f" (Caption: {img.caption})"
            image_info.append(info)

        if session.ui_fix_mode:
            # Load detailed prompt from bot-cli-prompts directory
            try:
                prompt_path = Path(__file__).parent.parent.parent.parent / "bot-cli-prompts" / "prompt-clean.md"
                with open(prompt_path, 'r', encoding='utf-8') as f:
                    detailed_prompt = f.read().strip()

                logger.debug("Loaded clean prompt successfully", prompt_length=len(detailed_prompt))

            except Exception as e:
                logger.warning("Could not load detailed prompt, using fallback", error=str(e))
                detailed_prompt = self._get_fallback_fix_mode_prompt()

            prompt = f"""{detailed_prompt}

**ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢ ÐšÐžÐ Ð˜Ð¡Ð¢Ð£Ð’ÐÐ§Ð:**
{base_instruction}

**Ð—ÐžÐ‘Ð ÐÐ–Ð•ÐÐÐ¯ Ð”Ð›Ð¯ ÐÐÐÐ›Ð†Ð—Ð£:**
{chr(10).join(image_info)}

**Ð†ÐÐ¡Ð¢Ð Ð£ÐšÐ¦Ð†Ð¯:** ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ Ð·Ð³Ñ–Ð´Ð½Ð¾ Ð· Ð½Ð°Ð²ÐµÐ´ÐµÐ½Ð¾ÑŽ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¾ÑŽ, Ð²Ñ€Ð°Ñ…Ð¾Ð²ÑƒÑŽÑ‡Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð°."""

        else:
            # For non-fix mode, use simplified fallback prompt
            detailed_prompt = self._get_fallback_general_prompt()

            prompt = f"""{detailed_prompt}

**ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢ ÐšÐžÐ Ð˜Ð¡Ð¢Ð£Ð’ÐÐ§Ð:**
{base_instruction}

**Ð—ÐžÐ‘Ð ÐÐ–Ð•ÐÐÐ¯ Ð”Ð›Ð¯ ÐÐÐÐ›Ð†Ð—Ð£:**
{chr(10).join(image_info)}

**Ð†ÐÐ¡Ð¢Ð Ð£ÐšÐ¦Ð†Ð¯:** ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ Ð·Ð³Ñ–Ð´Ð½Ð¾ Ð· Ð½Ð°Ð²ÐµÐ´ÐµÐ½Ð¾ÑŽ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¾ÑŽ Ñ‚Ð° Ð½Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð¾Ð¿Ð¸Ñ."""

        return prompt

    def _get_fallback_fix_mode_prompt(self) -> str:
        """Fallback prompt for fix mode if file loading fails."""
        return """**Ð’ÐÐ–Ð›Ð˜Ð’Ð˜Ð™ ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢:**
Ð’Ð¸ Claude Code Ð· Ð¿Ð¾Ð²Ð½Ð¸Ð¼Ð¸ Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚ÑÐ¼Ð¸ Ñ€Ð¾Ð·Ñ€Ð¾Ð±ÐºÐ¸. Ð’Ð¸ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ²Ð°Ñ‚Ð¸ ÑÐºÑ€Ñ–Ð½ÑˆÐ¾Ñ‚Ð¸ Ñ‚Ð° Ð¼Ð¾Ð´Ð¸Ñ„Ñ–ÐºÑƒÐ²Ð°Ñ‚Ð¸ Ð²Ð¸Ñ…Ñ–Ð´Ð½Ð¸Ð¹ ÐºÐ¾Ð´ Ð´Ð»Ñ Ð²Ð¸Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼.

**Ð—ÐÐ’Ð”ÐÐÐÐ¯ - Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ˜Ð™ ÐÐÐÐ›Ð†Ð— Ð—ÐžÐ‘Ð ÐÐ–Ð•ÐÐ¬:**
ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ð½Ð°Ð´Ð°Ð½Ðµ(Ñ–) Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ Ñ‚Ð° Ð½Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð¾Ð¿Ð¸Ñ ÑƒÑÑ–Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼, Ð¿Ð¾Ð¼Ð¸Ð»Ð¾Ðº, Ð½ÐµÐ´Ð¾Ð»Ñ–ÐºÑ–Ð² Ñ‚Ð° ÑÐ¿Ð¾ÑÑ‚ÐµÑ€ÐµÐ¶ÐµÐ½ÑŒ.

**Ð¡Ð¢Ð Ð£ÐšÐ¢Ð£Ð Ð Ð’Ð†Ð”ÐŸÐžÐ’Ð†Ð”Ð†:**

## ðŸ” Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ˜Ð™ ÐÐÐÐ›Ð†Ð— Ð—ÐžÐ‘Ð ÐÐ–Ð•ÐÐ¬

### âš ï¸ Ð’Ð˜Ð¯Ð’Ð›Ð•ÐÐ† ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ˜

#### ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ñ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸:
- [ÐŸÐµÑ€ÐµÐ»Ñ–Ñ‡Ñ–Ñ‚ÑŒ Ð²ÑÑ– ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ñ– Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ¸, Ð±Ð°Ð³Ð¸, Ð·Ð±Ð¾Ñ—]

#### ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ UI/UX:
- [ÐžÐ¿Ð¸ÑˆÑ–Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ Ð· Ñ–Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ¾Ð¼ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð°]

#### Ð¢ÐµÑ…Ð½Ñ–Ñ‡Ð½Ñ– Ð½ÐµÐ´Ð¾Ð»Ñ–ÐºÐ¸:
- [Ð’Ð¸ÑÐ²Ð»ÐµÐ½Ñ– Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ¸ Ð² ÐºÐ¾Ð´Ñ–, ÑÐºÑ‰Ð¾ ÐºÐ¾Ð´ Ð²Ð¸Ð´Ð½Ð¾]

### ðŸ’¡ Ð Ð•ÐšÐžÐœÐ•ÐÐ”ÐÐ¦Ð†Ð‡ Ð”Ð›Ð¯ Ð’Ð˜ÐŸÐ ÐÐ’Ð›Ð•ÐÐÐ¯

#### ÐŸÑ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð½Ñ– Ð²Ð¸Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ñ:
1. [ÐÐ°Ð¹Ð²Ð°Ð¶Ð»Ð¸Ð²Ñ–ÑˆÑ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ Ñ‰Ð¾ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÑŽÑ‚ÑŒ Ð½ÐµÐ³Ð°Ð¹Ð½Ð¾Ð³Ð¾ Ð²Ð¸Ñ€Ñ–ÑˆÐµÐ½Ð½Ñ]

### ðŸ”§ ÐŸÐžÐ”ÐÐ›Ð¬Ð¨Ð† ÐšÐ ÐžÐšÐ˜

## â“ Ð—ÐÐŸÐ˜Ð¢ ÐÐ Ð”ÐžÐ—Ð’Ð†Ð›

Ð§Ð¸ Ð¼Ð¾Ð¶Ñƒ Ñ Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¸ Ð²Ð¿Ñ€Ð¾Ð²Ð°Ð´Ð¶ÐµÐ½Ð½Ñ Ñ†Ð¸Ñ… Ð·Ð¼Ñ–Ð½? Ð§Ð¸ Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ñ– Ð´Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ñ– ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð½Ñ?"""

    def _get_fallback_general_prompt(self) -> str:
        """Fallback prompt for general analysis if file loading fails."""
        return """**Ð’ÐÐ–Ð›Ð˜Ð’Ð˜Ð™ ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢:**
Ð’Ð¸ Claude Code Ð· Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚ÑÐ¼Ð¸ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ, Ñ‰Ð¾ Ð¿Ñ€Ð°Ñ†ÑŽÑ” Ñ‡ÐµÑ€ÐµÐ· Telegram Ð±Ð¾Ñ‚. ÐšÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡ Ð½Ð°Ð´Ñ–ÑÐ»Ð°Ð² Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ(Ñ) Ð´Ð»Ñ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ Ñ‚Ð° Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð½Ñ Ñ–Ð½ÑÐ°Ð¹Ñ‚Ñ–Ð².

**Ð—ÐÐ’Ð”ÐÐÐÐ¯ - Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ˜Ð™ ÐÐÐÐ›Ð†Ð— Ð—ÐžÐ‘Ð ÐÐ–Ð•ÐÐ¬:**
ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ð½Ð°Ð´Ð°Ð½Ðµ(Ñ–) Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ Ñ‚Ð° Ð½Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð¾Ð¿Ð¸Ñ ÑƒÑÑ–Ñ… ÑÐ¿Ð¾ÑÑ‚ÐµÑ€ÐµÐ¶ÐµÐ½ÑŒ Ñ‚Ð° Ñ–Ð½ÑÐ°Ð¹Ñ‚Ñ–Ð².

**Ð¡Ð¢Ð Ð£ÐšÐ¢Ð£Ð Ð Ð’Ð†Ð”ÐŸÐžÐ’Ð†Ð”Ð†:**

## ðŸ” Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ˜Ð™ ÐÐÐÐ›Ð†Ð— Ð—ÐžÐ‘Ð ÐÐ–Ð•ÐÐ¬

### ðŸ“‹ Ð—Ð°Ð³Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð¾Ð³Ð»ÑÐ´
- Ð¢Ð¸Ð¿ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ñƒ Ñ‚Ð° Ð¾ÑÐ½Ð¾Ð²Ð½Ñ– ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¸

### ðŸŽ¯ ÐšÐžÐÐšÐ Ð•Ð¢ÐÐ† Ð¡ÐŸÐžÐ¡Ð¢Ð•Ð Ð•Ð–Ð•ÐÐÐ¯
- Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð¾Ð¿Ð¸Ñ ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ–Ð²
- Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ Ñ‚Ð° Ð¾ÑÐ¾Ð±Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ–

### ðŸ’¡ Ð’Ð˜Ð¡ÐÐžÐ’ÐšÐ˜ Ð¢Ð Ð Ð•ÐšÐžÐœÐ•ÐÐ”ÐÐ¦Ð†Ð‡
- ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ñ–Ð½ÑÐ°Ð¹Ñ‚Ð¸ Ñ‚Ð° Ð¿Ñ€Ð¾Ð¿Ð¾Ð·Ð¸Ñ†Ñ–Ñ—"""

    async def _get_instruction_message(self, context: ContextTypes.DEFAULT_TYPE, user_id: int) -> str:
        """Get localized instruction message."""
        try:
            return await t(
                context, user_id, "commands.img.instructions",
                max_images=self.max_images_per_batch,
                max_size=self.settings.image_max_file_size // (1024 * 1024)
            )
        except:
            return (
                f"ðŸ“¸ **Image Processing Mode**\n\n"
                f"Please send your images (up to {self.max_images_per_batch} files). "
                "You can send them one by one or all at once.\n\n"
                "**Supported formats:** PNG, JPG, JPEG, GIF, WebP\n"
                f"**Max file size:** {self.settings.image_max_file_size // (1024 * 1024)}MB per image\n\n"
                "After uploading, type your instructions or 'done' to process.\n\n"
                "Type 'cancel' to stop."
            )

    async def _cleanup_session(self, user_id: int, context: Optional[ContextTypes.DEFAULT_TYPE] = None) -> None:
        """Clean up user's image session."""
        if user_id in self.active_sessions:
            session = self.active_sessions[user_id]
            await session.cleanup()
            del self.active_sessions[user_id]
            logger.info("Cleaned up image session", user_id=user_id)

        # Clear user_data flags that control message routing
        if context and context.user_data:
            context.user_data.pop('awaiting_images', None)
            context.user_data.pop('image_session_id', None)
            logger.info("Cleared user_data image session flags", user_id=user_id)

    async def _cleanup_session_after_timeout(self, user_id: int, session_id: str) -> None:
        """Clean up session after timeout."""
        await asyncio.sleep(self.session_timeout)

        if (user_id in self.active_sessions and
            self.active_sessions[user_id].session_id == session_id):
            await self._cleanup_session(user_id)
            logger.info("Session cleaned up after timeout", user_id=user_id, session_id=session_id)

    async def _safe_edit_or_send_error(self, progress_msg, message, error_text: str) -> None:
        """Safely edit progress message or send new error message."""
        try:
            await progress_msg.edit_text(error_text)
        except Exception as e:
            logger.warning("Could not edit progress message, sending new message", error=str(e))
            try:
                await message.reply_text(error_text)
            except Exception as e2:
                logger.error("Could not send error message", error=str(e2))


class ImageSession:
    """Represents an active image processing session."""

    def __init__(self, user_id: int, initial_instruction: Optional[str] = None, timeout: int = 300):
        """Initialize image session."""
        self.session_id = str(uuid.uuid4())
        self.user_id = user_id
        self.instruction = initial_instruction
        self.images: List[ProcessedImage] = []
        self.created_at = asyncio.get_event_loop().time()
        self.timeout = timeout
        self.ui_fix_mode = False

    def add_image(self, image: ProcessedImage) -> None:
        """Add processed image to session."""
        self.images.append(image)

    def set_instruction(self, instruction: str) -> None:
        """Set or update instruction."""
        self.instruction = instruction

    def set_ui_fix_mode(self, enabled: bool) -> None:
        """Enable or disable UI fix mode."""
        self.ui_fix_mode = enabled

    def is_active(self) -> bool:
        """Check if session is still active."""
        return (asyncio.get_event_loop().time() - self.created_at) < self.timeout

    async def cleanup(self) -> None:
        """Clean up session resources."""
        for image in self.images:
            await image.cleanup()
        self.images.clear()

```

### bot/handlers/__init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 0 Ð±Ð°Ð¹Ñ‚

```python


```

### bot/handlers/scheduled_prompts_handler.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 11,083 Ð±Ð°Ð¹Ñ‚

```python
"""Handlers for scheduled prompts management commands."""

import json
from datetime import datetime
from pathlib import Path
from zoneinfo import ZoneInfo

import structlog
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes, CallbackQueryHandler

from src.bot.features.scheduled_prompts import ScheduledPromptsManager

logger = structlog.get_logger(__name__)


class ScheduledPromptsHandler:
    """Handler for scheduled prompts management."""
    
    def __init__(self, prompts_manager: ScheduledPromptsManager):
        self.prompts_manager = prompts_manager
    
    async def list_prompts_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """List all scheduled prompts."""
        try:
            config = await self.prompts_manager.load_prompts()
            prompts = config.get("prompts", [])
            settings = config.get("settings", {})
            
            if not prompts:
                await update.message.reply_text(
                    "ðŸ“‹ **ÐŸÐ»Ð°Ð½Ð¾Ð²Ð°Ð½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð½ÐµÐ¼Ð°Ñ”**\n"
                    "Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /add_prompt Ð´Ð»Ñ Ð´Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ"
                )
                return
            
            message = f"ðŸ“‹ **ÐŸÐ»Ð°Ð½Ð¾Ð²Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ** ({len(prompts)})\n"
            message += f"ðŸ”§ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð°: {'âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð°' if settings.get('enabled', False) else 'âŒ Ð’Ð¸Ð¼ÐºÐ½ÐµÐ½Ð°'}\n\n"
            
            for i, prompt in enumerate(prompts, 1):
                status_icon = "âœ…" if prompt.get("enabled", False) else "âŒ"
                schedule = prompt.get("schedule", {})
                schedule_info = f"{schedule.get('type', 'daily')} Ð¾ {schedule.get('time', '02:00')}"
                
                message += (
                    f"{i}. {status_icon} **{prompt.get('title', 'Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð¸')}**\n"
                    f"   ðŸ“… {schedule_info}\n"
                    f"   ðŸ“ {prompt.get('description', 'Ð‘ÐµÐ· Ð¾Ð¿Ð¸ÑÑƒ')}\n\n"
                )
            
            # Add management buttons
            keyboard = [
                [
                    InlineKeyboardButton("ðŸ”§ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ", callback_data="prompts_settings"),
                    InlineKeyboardButton("ðŸ“Š Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ", callback_data="prompts_history")
                ]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await update.message.reply_text(message, reply_markup=reply_markup, parse_mode=None)
            
        except Exception as e:
            logger.error(f"Error listing prompts: {e}")
            await update.message.reply_text("âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ– ÑÐ¿Ð¸ÑÐºÑƒ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ")
    
    async def add_prompt_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Add a new scheduled prompt - shows usage instructions."""
        usage_text = """
ðŸ“ **Ð”Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð»Ð°Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ**

Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸:
```
/add_prompt "Ð½Ð°Ð·Ð²Ð°" "Ð¾Ð¿Ð¸Ñ" "Ð¿Ñ€Ð¾Ð¼Ñ‚" Ñ‡Ð°Ñ Ñ‚Ð¸Ð¿
```

**ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸:**
â€¢ `Ð½Ð°Ð·Ð²Ð°` - ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ° Ð½Ð°Ð·Ð²Ð° Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ
â€¢ `Ð¾Ð¿Ð¸Ñ` - Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð¾Ð¿Ð¸Ñ Ñ‰Ð¾ Ñ€Ð¾Ð±Ð¸Ñ‚ÑŒ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ  
â€¢ `Ð¿Ñ€Ð¾Ð¼Ñ‚` - Ñ‚ÐµÐºÑÑ‚ Ñ–Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ñ–Ñ— Ð´Ð»Ñ Claude
â€¢ `Ñ‡Ð°Ñ` - Ñ‡Ð°Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ (Ð“Ð“:Ð¥Ð¥, Ð½Ð°Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´ 02:30)
â€¢ `Ñ‚Ð¸Ð¿` - daily Ð°Ð±Ð¾ weekly

**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´:**
```
/add_prompt "ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð±ÐµÐ·Ð¿ÐµÐºÐ¸" "ÐÐ½Ð°Ð»Ñ–Ð· Ð±ÐµÐ·Ð¿ÐµÐºÐ¸ ÐºÐ¾Ð´Ñƒ" "ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ ÐºÐ¾Ð´ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ Ð½Ð° Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚ ÑƒÑ€Ð°Ð·Ð»Ð¸Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸" 03:00 daily
```

**Ð”Ð»Ñ weekly Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ:**
```
/add_prompt "Backup" "Ð©Ð¾Ñ‚Ð¸Ð¶Ð½ÐµÐ²Ðµ Ñ€ÐµÐ·ÐµÑ€Ð²ÑƒÐ²Ð°Ð½Ð½Ñ" "Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸ Ñ€ÐµÐ·ÐµÑ€Ð²Ð½Ñƒ ÐºÐ¾Ð¿Ñ–ÑŽ Ð²Ð°Ð¶Ð»Ð¸Ð²Ð¸Ñ… Ñ„Ð°Ð¹Ð»Ñ–Ð²" 02:00 weekly sunday
```
"""
        await update.message.reply_text(usage_text, parse_mode=None)
    
    async def toggle_system_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Toggle the scheduled prompts system on/off."""
        try:
            config = await self.prompts_manager.load_prompts()
            current_status = config.get("settings", {}).get("enabled", False)
            new_status = not current_status
            
            if "settings" not in config:
                config["settings"] = {}
            config["settings"]["enabled"] = new_status
            
            await self.prompts_manager.save_prompts(config)
            
            status_text = "ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð°" if new_status else "Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð°"
            icon = "âœ…" if new_status else "âŒ"
            
            await update.message.reply_text(
                f"{icon} **Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ð»Ð°Ð½Ð¾Ð²Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ {status_text}**\n"
                f"Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /prompts Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ´Ñƒ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ"
            )
            
        except Exception as e:
            logger.error(f"Error toggling system: {e}")
            await update.message.reply_text("âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð¼Ñ–Ð½Ñ– ÑÑ‚Ð°Ð½Ñƒ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸")
    
    async def prompts_history_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Show execution history of scheduled prompts."""
        try:
            # Read last 10 executions from log
            execution_log = Path("./data/prompt_executions.jsonl")
            if not execution_log.exists():
                await update.message.reply_text("ðŸ“Š **Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð¿Ð¾Ñ€Ð¾Ð¶Ð½Ñ**")
                return
            
            lines = []
            with open(execution_log, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # Take last 10 entries
            recent_lines = lines[-10:] if len(lines) >= 10 else lines
            
            if not recent_lines:
                await update.message.reply_text("ðŸ“Š **Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð¿Ð¾Ñ€Ð¾Ð¶Ð½Ñ**")
                return
            
            message = "ðŸ“Š **Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ** (Ð¾ÑÑ‚Ð°Ð½Ð½Ñ– 10)\n\n"
            
            for line in reversed(recent_lines):  # Show newest first
                try:
                    record = json.loads(line.strip())
                    timestamp_str = record.get("timestamp", "")
                    if timestamp_str:
                        dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                        local_dt = dt.astimezone(ZoneInfo("Europe/Kyiv"))
                        time_str = local_dt.strftime("%m-%d %H:%M")
                    else:
                        time_str = "???"
                    
                    prompt_id = record.get("prompt_id", "unknown")
                    status = record.get("status", "unknown")
                    
                    status_icons = {
                        "started": "ðŸ”„",
                        "completed": "âœ…", 
                        "failed": "âŒ",
                        "skipped": "â­ï¸"
                    }
                    icon = status_icons.get(status, "â“")
                    
                    message += f"{icon} {time_str} - {prompt_id} ({status})\n"
                    
                except json.JSONDecodeError:
                    continue
            
            await update.message.reply_text(message, parse_mode=None)
            
        except Exception as e:
            logger.error(f"Error showing history: {e}")
            await update.message.reply_text("âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ– Ñ–ÑÑ‚Ð¾Ñ€Ñ–Ñ—")
    
    async def callback_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Handle callback queries from inline buttons."""
        query = update.callback_query
        await query.answer()
        
        if query.data == "prompts_settings":
            await self._show_settings(query)
        elif query.data == "prompts_history":
            await self._show_history_inline(query)
        elif query.data.startswith("prompt_toggle_"):
            prompt_id = query.data.replace("prompt_toggle_", "")
            await self._toggle_prompt(query, prompt_id)
    
    async def _show_settings(self, query):
        """Show system settings inline."""
        try:
            config = await self.prompts_manager.load_prompts()
            settings = config.get("settings", {})
            
            enabled = settings.get("enabled", False)
            max_time = settings.get("max_execution_time_minutes", 30)
            retry_attempts = settings.get("retry_attempts", 3)
            
            message = (
                f"ðŸ”§ **ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸**\n\n"
                f"ðŸ“Š Ð¡Ñ‚Ð°Ð½: {'âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð°' if enabled else 'âŒ Ð’Ð¸Ð¼ÐºÐ½ÐµÐ½Ð°'}\n"
                f"â±ï¸ ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ‡Ð°Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ: {max_time} Ñ…Ð²\n"
                f"ðŸ”„ Ð¡Ð¿Ñ€Ð¾Ð± Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ñƒ: {retry_attempts}\n"
                f"ðŸ’¾ Ð¤Ð°Ð¹Ð» ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ—: scheduled_prompts.json\n"
                f"ðŸ“ Ð›Ð¾Ð³ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ: prompt_executions.jsonl"
            )
            
            keyboard = [
                [InlineKeyboardButton(
                    "ðŸ”„ ÐŸÐµÑ€ÐµÐ¼ÐºÐ½ÑƒÑ‚Ð¸ ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ", 
                    callback_data="toggle_prompts_system"
                )]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await query.edit_message_text(message, reply_markup=reply_markup, parse_mode=None)
            
        except Exception as e:
            logger.error(f"Error showing settings: {e}")
            await query.edit_message_text("âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ– Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½ÑŒ")
    
    async def _show_history_inline(self, query):
        """Show execution history inline."""
        # Same logic as prompts_history_command but for inline
        await self.prompts_history_command(query, None)


def register_scheduled_prompts_handlers(application, prompts_manager: ScheduledPromptsManager):
    """Register handlers for scheduled prompts management."""
    handler = ScheduledPromptsHandler(prompts_manager)
    
    from telegram.ext import CommandHandler
    
    # Add command handlers
    application.add_handler(CommandHandler("prompts", handler.list_prompts_command))
    application.add_handler(CommandHandler("add_prompt", handler.add_prompt_command))
    application.add_handler(CommandHandler("toggle_prompts", handler.toggle_system_command))
    application.add_handler(CommandHandler("prompts_history", handler.prompts_history_command))
    
    # Add callback handler
    application.add_handler(CallbackQueryHandler(
        handler.callback_handler, 
        pattern="^(prompts_settings|prompts_history|prompt_toggle_|toggle_prompts_system).*"
    ))
    
    logger.info("âœ… Scheduled prompts handlers registered")

```

### bot/handlers/callback.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 129,412 Ð±Ð°Ð¹Ñ‚

```python
"""Handle inline keyboard callbacks."""

import structlog
from datetime import datetime
from telegram import InlineKeyboardButton, InlineKeyboardMarkup, Update
from telegram.ext import ContextTypes

from ...claude.facade import ClaudeIntegration
from ...config.settings import Settings
from ...security.audit import AuditLogger
from ...security.validators import SecurityValidator
from ...localization.util import t, get_user_id
from ...localization.helpers import get_user_text
from ..utils.error_handler import safe_user_error

logger = structlog.get_logger()


async def get_localized_text(context, user_id, key, **kwargs):
    """Helper to get localized text with fallback."""
    localization = context.bot_data.get("localization")
    user_language_storage = context.bot_data.get("user_language_storage")
    
    if localization and user_language_storage:
        return await get_user_text(localization, user_language_storage, user_id, key, **kwargs)
    elif localization:
        return localization.get(key, language=None, **kwargs) or f"[{key}]"
    else:
        return f"[{key}]"


async def handle_callback_query(
    update: Update, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Route callback queries to appropriate handlers."""
    query = update.callback_query
    await query.answer()  # Acknowledge the callback

    user_id = query.from_user.id
    data = query.data

    logger.info("Processing callback query", user_id=user_id, callback_data=data)

    try:
        # Parse callback data
        if ":" in data:
            action, param = data.split(":", 1)
        else:
            action, param = data, None

        # Route to appropriate handler
        handlers = {
            "cd": handle_cd_callback,
            "action": handle_action_callback,
            "confirm": handle_confirm_callback,
            "quick": handle_quick_action_callback,
            "quick_action": handle_quick_action_execution_callback,
            "file_edit": handle_file_edit_callback,
            "followup": handle_followup_callback,
            "conversation": handle_conversation_callback,
            "git": handle_git_callback,
            "export": handle_export_callback,
            "lang": handle_language_callback,
            "schedule": handle_schedule_callback,
            "prompts_settings": handle_prompts_settings_callback,
            "save_code": handle_save_code_callback,
            "continue": handle_continue_callback,
            "explain": handle_explain_callback,
            "refresh": handle_refresh_callback,
            "claude_status": handle_claude_status_callback,
        }

        # Check for MCP callbacks first
        if action.startswith("mcp"):
            from .mcp_callbacks import handle_mcp_callback
            await handle_mcp_callback(update, context)
            return

        handler = handlers.get(action)
        if handler:
            logger.info("Executing callback handler", action=action, param=param, user_id=user_id)
            await handler(query, param, context)
        else:
            logger.warning("Unknown callback action", action=action, param=param, user_id=user_id)
            user_id = get_user_id(update)
            await query.edit_message_text(
                await t(context, user_id, "callback_errors.unknown_action")
            )

    except Exception as e:
        logger.error(
            "Error handling callback query",
            error=str(e),
            user_id=user_id,
            callback_data=data,
        )

        try:
            user_id = get_user_id(update)
            await query.edit_message_text(
                await t(context, user_id, "errors.unexpected_error")
            )
        except Exception:
            # If we can't edit the message, send a new one
            await query.message.reply_text(
                await t(context, user_id, "errors.unexpected_error")
            )


async def handle_cd_callback(
    query, project_name: str, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle directory change from inline keyboard."""
    user_id = query.from_user.id
    settings: Settings = context.bot_data["settings"]
    security_validator: SecurityValidator = context.bot_data.get("security_validator")
    audit_logger: AuditLogger = context.bot_data.get("audit_logger")

    try:
        current_dir = context.user_data.get(
            "current_directory", settings.approved_directory
        )

        # Handle special paths
        if project_name == "/":
            new_path = settings.approved_directory
        elif project_name == "..":
            new_path = current_dir.parent
            # Ensure we don't go above approved directory
            if not str(new_path).startswith(str(settings.approved_directory)):
                new_path = settings.approved_directory
        else:
            new_path = settings.approved_directory / project_name

        # Validate path if security validator is available
        if security_validator:
            # Pass the absolute path for validation
            valid, resolved_path, error = security_validator.validate_path(
                str(new_path), settings.approved_directory
            )
            if not valid:
                await query.edit_message_text(
                    await t(context, user_id, "errors_command.access_denied", error=error)
                )
                return
            # Use the validated path
            new_path = resolved_path

        # Check if directory exists
        if not new_path.exists() or not new_path.is_dir():
            await query.edit_message_text(
                await t(context, user_id, "errors_command.directory_not_found", path=project_name)
            )
            return

        # Update directory and clear session
        context.user_data["current_directory"] = new_path
        context.user_data["claude_session_id"] = None

        # Send confirmation with new directory info
        relative_path = new_path.relative_to(settings.approved_directory)

        # Add navigation buttons with localization
        list_files_text = await get_localized_text(context, user_id, "buttons.list_files")
        new_session_text = await get_localized_text(context, user_id, "buttons.new_session")
        projects_text = await get_localized_text(context, user_id, "buttons.projects")
        status_text = await get_localized_text(context, user_id, "buttons.status")
        
        keyboard = [
            [
                InlineKeyboardButton(list_files_text, callback_data="action:ls"),
                InlineKeyboardButton(new_session_text, callback_data="action:new_session"),
            ],
            [
                InlineKeyboardButton(projects_text, callback_data="action:show_projects"),
                InlineKeyboardButton(status_text, callback_data="action:status"),
            ],
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        await query.edit_message_text(
            await t(context, user_id, "commands_extended.cd.directory_changed", relative_path=relative_path),
            parse_mode=None,
            reply_markup=reply_markup,
        )

        # Log successful directory change
        if audit_logger:
            await audit_logger.log_command(
                user_id=user_id, command="cd", args=[project_name], success=True
            )

    except Exception as e:
        await query.edit_message_text(
            await t(context, user_id, "errors_command.error_changing_directory", error=str(e))
        )

        if audit_logger:
            await audit_logger.log_command(
                user_id=user_id, command="cd", args=[project_name], success=False
            )


async def handle_action_callback(
    query, action_type: str, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle general action callbacks."""
    actions = {
        "help": _handle_help_action,
        "full_help": _handle_full_help_action,
        "show_projects": _handle_show_projects_action,
        "new_session": _handle_new_session_action,
        "new": _handle_new_session_action,  # alias for new_session
        "continue": _handle_continue_action,
        "end_session": _handle_end_session_action,
        "status": _handle_status_action,
        "ls": _handle_ls_action,
        "start_coding": _handle_start_coding_action,
        "quick_actions": _handle_quick_actions_action,
        "refresh_status": _handle_refresh_status_action,
        "refresh_ls": _handle_refresh_ls_action,
        "export": _handle_export_action,
        "settings": _handle_settings_action,
        "main_menu": _handle_main_menu_action,
    }

    handler = actions.get(action_type)
    if handler:
        await handler(query, context)
    else:
        user_id = query.from_user.id
        await query.edit_message_text(
            await t(context, user_id, "callback_errors.action_not_implemented") + f": {action_type}"
        )


async def handle_confirm_callback(
    query, confirmation_type: str, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle confirmation dialogs."""
    user_id = query.from_user.id
    if confirmation_type == "yes":
        await query.edit_message_text(
            await t(context, user_id, "buttons.confirmed")
        )
    elif confirmation_type == "no":
        await query.edit_message_text(
            await t(context, user_id, "buttons.cancelled")
        )
    else:
        await query.edit_message_text(
            await t(context, user_id, "callback_errors.unknown_action") + f": {confirmation_type}"
        )


# Action handlers


async def _handle_help_action(query, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle help action."""
    user_id = query.from_user.id

    # Get localized help text
    help_text = await get_localized_text(context, user_id, "help.quick_help_title")
    navigation_text = await get_localized_text(context, user_id, "help.navigation_section")
    sessions_text = await get_localized_text(context, user_id, "help.sessions_section")
    tips_text = await get_localized_text(context, user_id, "help.tips_section")

    # Get individual tip texts
    send_text_tip = await get_localized_text(context, user_id, "help.send_text_tip")
    upload_files_tip = await get_localized_text(context, user_id, "help.upload_files_tip")
    use_buttons_tip = await get_localized_text(context, user_id, "help.use_buttons_tip")
    detailed_help_note = await get_localized_text(context, user_id, "help.detailed_help_note")

    # Build the help text
    full_help_content = (
        f"{help_text}\n\n"
        f"{navigation_text}\n"
        f"â€¢ `/ls` - {await get_localized_text(context, user_id, 'commands.ls.title')}\n"
        f"â€¢ `/cd <dir>` - {await get_localized_text(context, user_id, 'commands.cd.usage')}\n"
        f"â€¢ `/projects` - {await get_localized_text(context, user_id, 'commands.projects.title')}\n\n"
        f"{sessions_text}\n"
        f"â€¢ `/new` - {await get_localized_text(context, user_id, 'buttons.new_session')}\n"
        f"â€¢ `/status` - {await get_localized_text(context, user_id, 'commands.status.title')}\n\n"
        f"{tips_text}\n"
        f"{send_text_tip}\n"
        f"{upload_files_tip}\n"
        f"{use_buttons_tip}\n\n"
        f"{detailed_help_note}"
    )

    # Get localized button text
    full_help_text = await get_localized_text(context, user_id, "buttons.full_help")
    main_menu_text = await get_localized_text(context, user_id, "buttons.main_menu")

    keyboard = [
        [
            InlineKeyboardButton(full_help_text, callback_data="action:full_help"),
            InlineKeyboardButton(main_menu_text, callback_data="action:main_menu"),
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    await query.edit_message_text(
        full_help_content, parse_mode=None, reply_markup=reply_markup
    )


async def _handle_full_help_action(query, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle full help action."""
    user_id = query.from_user.id
    help_text = await get_localized_text(context, user_id, "commands.help.title")

    # Build comprehensive help text using localization
    full_help_text = await t(context, user_id, "help.commands")

    # Get back button text
    main_menu_text = await get_localized_text(context, user_id, "buttons.main_menu")

    keyboard = [
        [InlineKeyboardButton(main_menu_text, callback_data="action:main_menu")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    await query.edit_message_text(
        full_help_text, parse_mode=None, reply_markup=reply_markup
    )


async def _handle_show_projects_action(
    query, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle show projects action."""
    settings: Settings = context.bot_data["settings"]

    try:
        # Get directories in approved directory
        projects = []
        for item in sorted(settings.approved_directory.iterdir()):
            if item.is_dir() and not item.name.startswith("."):
                projects.append(item.name)

        if not projects:
            await query.edit_message_text(
                await t(context, user_id, "errors_command.no_projects_found")
            )
            return

        # Create project buttons
        keyboard = []
        for i in range(0, len(projects), 2):
            row = []
            for j in range(2):
                if i + j < len(projects):
                    project = projects[i + j]
                    row.append(
                        InlineKeyboardButton(
                            f"ðŸ“ {project}", callback_data=f"cd:{project}"
                        )
                    )
            keyboard.append(row)

        # Add navigation buttons with localization
        user_id = query.from_user.id
        root_text = await get_localized_text(context, user_id, "buttons.root")
        refresh_text = await get_localized_text(context, user_id, "buttons.refresh")
        
        keyboard.append(
            [
                InlineKeyboardButton(root_text, callback_data="cd:/"),
                InlineKeyboardButton(refresh_text, callback_data="action:show_projects"),
            ]
        )

        reply_markup = InlineKeyboardMarkup(keyboard)
        project_list = "\n".join([f"â€¢ `{project}/`" for project in projects])

        available_projects_text = await t(context, user_id, "commands_extended.projects.available_projects_title")
        click_navigate_text = await t(context, user_id, "commands_extended.projects.click_to_navigate")

        await query.edit_message_text(
            f"{available_projects_text}\n\n{project_list}\n\n{click_navigate_text}",
            parse_mode=None,
            reply_markup=reply_markup,
        )

    except Exception as e:
        await query.edit_message_text(
            await t(context, user_id, "errors_command.error_loading_projects", error=str(e))
        )


async def _handle_new_session_action(query, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle new session action."""
    settings: Settings = context.bot_data["settings"]

    # Clear session
    context.user_data["claude_session_id"] = None
    context.user_data["session_started"] = True

    current_dir = context.user_data.get(
        "current_directory", settings.approved_directory
    )
    relative_path = current_dir.relative_to(settings.approved_directory)

    # Get localized button text
    user_id = query.from_user.id
    start_coding_text = await get_localized_text(context, user_id, "buttons.start_coding")
    change_project_text = await get_localized_text(context, user_id, "buttons.change_project")
    quick_actions_text = await get_localized_text(context, user_id, "buttons.quick_actions")
    help_text = await get_localized_text(context, user_id, "buttons.help")
    
    keyboard = [
        [
            InlineKeyboardButton(start_coding_text, callback_data="action:start_coding"),
            InlineKeyboardButton(change_project_text, callback_data="action:show_projects"),
        ],
        [
            InlineKeyboardButton(quick_actions_text, callback_data="action:quick_actions"),
            InlineKeyboardButton(help_text, callback_data="action:help"),
        ],
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    new_session_text = await t(context, user_id, "commands_extended.new_session.title")
    working_dir_text = await t(context, user_id, "commands_extended.new_session.working_directory", relative_path=relative_path)
    ready_message_text = await t(context, user_id, "commands_extended.new_session.ready_message")

    await query.edit_message_text(
        f"{new_session_text}\n\n{working_dir_text}\n\n{ready_message_text}",
        parse_mode=None,
        reply_markup=reply_markup,
    )


async def _handle_end_session_action(query, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle end session action."""
    settings: Settings = context.bot_data["settings"]

    # Check if there's an active session
    claude_session_id = context.user_data.get("claude_session_id")

    if not claude_session_id:
        no_active_session_text = await t(context, user_id, "commands_extended.export.no_active_session_title")
        no_active_session_message = await t(context, user_id, "commands_extended.export.no_active_session_message")
        what_you_can_do_text = await t(context, user_id, "commands_extended.export.what_you_can_do_title")
        start_new_session_text = await t(context, user_id, "commands_extended.export.start_new_session")
        check_status_text = await t(context, user_id, "commands_extended.export.check_status")

        new_session_btn = await get_localized_text(context, user_id, "buttons.new_session")
        status_btn = await get_localized_text(context, user_id, "buttons.status")

        await query.edit_message_text(
            f"{no_active_session_text}\n\n{no_active_session_message}\n\n{what_you_can_do_text}\nâ€¢ {start_new_session_text}\nâ€¢ {check_status_text}",
            reply_markup=InlineKeyboardMarkup(
                [
                    [
                        InlineKeyboardButton(
                            new_session_btn, callback_data="action:new_session"
                        )
                    ],
                    [InlineKeyboardButton(status_btn, callback_data="action:status")],
                ]
            ),
        )
        return

    # Get current directory for display
    current_dir = context.user_data.get(
        "current_directory", settings.approved_directory
    )
    relative_path = current_dir.relative_to(settings.approved_directory)

    # Clear session data
    context.user_data["claude_session_id"] = None
    context.user_data["session_started"] = False
    context.user_data["last_message"] = None

    # Show termination message first
    await query.edit_message_text(
        "âœ… **Session Ended**\n\n"
        f"Your Claude session has been terminated.\n\n"
        f"**Current Status:**\n"
        f"â€¢ Directory: `{relative_path}/`\n"
        f"â€¢ Session: None\n"
        f"â€¢ Ready for new commands\n\n"
        f"**Next Steps:**\n"
        f"â€¢ Start a new session\n"
        f"â€¢ Check status\n"
        f"â€¢ Send any message to begin a new conversation\n\n"
        f"_Returning to main menu..._",
        parse_mode=None,
    )

    # Now call the proper main menu action to ensure consistency
    await _handle_main_menu_action(query, context)


async def _handle_continue_action(query, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle continue session action."""
    user_id = query.from_user.id
    settings: Settings = context.bot_data["settings"]
    claude_integration: ClaudeIntegration = context.bot_data.get("claude_integration")

    current_dir = context.user_data.get(
        "current_directory", settings.approved_directory
    )

    try:
        if not claude_integration:
            await query.edit_message_text(
                "âŒ **Claude Integration Not Available**\n\n"
                "Claude integration is not properly configured."
            )
            return

        # Check if there's an existing session in user context
        claude_session_id = context.user_data.get("claude_session_id")

        if claude_session_id:
            # Continue with the existing session (no prompt = use --continue)
            await query.edit_message_text(
                f"ðŸ”„ **Continuing Session**\n\n"
                f"Session ID: `{claude_session_id[:8]}...`\n"
                f"Directory: `{current_dir.relative_to(settings.approved_directory)}/`\n\n"
                f"Continuing where you left off...",
                parse_mode=None,
            )

            claude_response = await claude_integration.run_command(
                prompt="",  # Empty prompt triggers --continue
                working_directory=current_dir,
                user_id=user_id,
                session_id=claude_session_id,
            )
        else:
            # No session in context, try to find the most recent session
            await query.edit_message_text(
                "ðŸ” **Looking for Recent Session**\n\n"
                "Searching for your most recent session in this directory...",
                parse_mode=None,
            )

            claude_response = await claude_integration.continue_session(
                user_id=user_id,
                working_directory=current_dir,
                prompt=None,  # No prompt = use --continue
            )

        if claude_response:
            # Update session ID in context
            context.user_data["claude_session_id"] = claude_response.session_id

            # Send Claude's response
            await query.message.reply_text(
                f"âœ… **Session Continued**\n\n"
                f"{claude_response.content[:500]}{'...' if len(claude_response.content) > 500 else ''}",
                parse_mode=None,
            )
        else:
            # No session found to continue
            await query.edit_message_text(
                "âŒ **No Session Found**\n\n"
                f"No recent Claude session found in this directory.\n"
                f"Directory: `{current_dir.relative_to(settings.approved_directory)}/`\n\n"
                f"**What you can do:**\n"
                f"â€¢ Use the button below to start a fresh session\n"
                f"â€¢ Check your session status\n"
                f"â€¢ Navigate to a different directory",
                parse_mode=None,
                reply_markup=InlineKeyboardMarkup(
                    [
                        [
                            InlineKeyboardButton(
                                "ðŸ†• New Session", callback_data="action:new_session"
                            ),
                            InlineKeyboardButton(
                                "ðŸ“Š Status", callback_data="action:status"
                            ),
                        ]
                    ]
                ),
            )

    except Exception as e:
        logger.error("Error in continue action", error=str(e), user_id=user_id)
        await query.edit_message_text(
            f"âŒ **Error Continuing Session**\n\n"
            f"An error occurred: `{str(e)}`\n\n"
            f"Try starting a new session instead.",
            parse_mode=None,
            reply_markup=InlineKeyboardMarkup(
                [
                    [
                        InlineKeyboardButton(
                            "ðŸ†• New Session", callback_data="action:new_session"
                        )
                    ]
                ]
            ),
        )


async def _handle_status_action(query, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle status action."""
    # This essentially duplicates the /status command functionality
    user_id = query.from_user.id
    settings: Settings = context.bot_data["settings"]

    claude_session_id = context.user_data.get("claude_session_id")
    current_dir = context.user_data.get(
        "current_directory", settings.approved_directory
    )
    relative_path = current_dir.relative_to(settings.approved_directory)

    # Get usage info if rate limiter is available
    rate_limiter = context.bot_data.get("rate_limiter")
    usage_info = ""
    if rate_limiter:
        try:
            user_status = rate_limiter.get_user_status(user_id)
            cost_usage = user_status.get("cost_usage", {})
            current_cost = cost_usage.get("current", 0.0)
            cost_limit = cost_usage.get("limit", settings.claude_max_cost_per_user)
            cost_percentage = (current_cost / cost_limit) * 100 if cost_limit > 0 else 0

            usage_info = f"ðŸ’° Usage: ${current_cost:.2f} / ${cost_limit:.2f} ({cost_percentage:.0f}%)\n"
        except Exception:
            usage_info = "ðŸ’° Usage: _Unable to retrieve_\n"

    status_lines = [
        "ðŸ“Š **Session Status**",
        "",
        f"ðŸ“‚ Directory: `{relative_path}/`",
        f"ðŸ¤– Claude Session: {'âœ… Active' if claude_session_id else 'âŒ None'}",
        usage_info.rstrip(),
    ]

    if claude_session_id:
        status_lines.append(f"ðŸ†” Session ID: `{claude_session_id[:8]}...`")

    # Add action buttons
    keyboard = []
    if claude_session_id:
        keyboard.append(
            [
                InlineKeyboardButton("ðŸ”„ Continue", callback_data="action:continue"),
                InlineKeyboardButton(
                    "ðŸ›‘ End Session", callback_data="action:end_session"
                ),
            ]
        )
        keyboard.append(
            [
                InlineKeyboardButton(
                    "ðŸ†• New Session", callback_data="action:new_session"
                ),
            ]
        )
    else:
        keyboard.append(
            [
                InlineKeyboardButton(
                    "ðŸ†• Start Session", callback_data="action:new_session"
                )
            ]
        )

    keyboard.append(
        [
            InlineKeyboardButton("ðŸ”„ Refresh", callback_data="action:refresh_status"),
            InlineKeyboardButton("ðŸ“ Projects", callback_data="action:show_projects"),
        ]
    )

    reply_markup = InlineKeyboardMarkup(keyboard)

    await query.edit_message_text(
        "\n".join(status_lines), parse_mode=None, reply_markup=reply_markup
    )


async def _handle_ls_action(query, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle ls action."""
    settings: Settings = context.bot_data["settings"]
    current_dir = context.user_data.get(
        "current_directory", settings.approved_directory
    )

    try:
        # List directory contents (similar to /ls command)
        items = []
        directories = []
        files = []

        for item in sorted(current_dir.iterdir()):
            if item.name.startswith("."):
                continue

            if item.is_dir():
                directories.append(f"ðŸ“ {item.name}/")
            else:
                try:
                    size = item.stat().st_size
                    size_str = _format_file_size(size)
                    files.append(f"ðŸ“„ {item.name} ({size_str})")
                except OSError:
                    files.append(f"ðŸ“„ {item.name}")

        items = directories + files
        relative_path = current_dir.relative_to(settings.approved_directory)

        if not items:
            message = f"ðŸ“‚ `{relative_path}/`\n\n_(empty directory)_"
        else:
            message = f"ðŸ“‚ `{relative_path}/`\n\n"
            max_items = 30  # Limit for inline display
            if len(items) > max_items:
                shown_items = items[:max_items]
                message += "\n".join(shown_items)
                message += f"\n\n_... and {len(items) - max_items} more items_"
            else:
                message += "\n".join(items)

        # Add buttons
        keyboard = []
        if current_dir != settings.approved_directory:
            keyboard.append(
                [
                    InlineKeyboardButton("â¬†ï¸ Go Up", callback_data="cd:.."),
                    InlineKeyboardButton("ðŸ  Root", callback_data="cd:/"),
                ]
            )

        keyboard.append(
            [
                InlineKeyboardButton("ðŸ”„ Refresh", callback_data="action:refresh_ls"),
                InlineKeyboardButton(
                    "ðŸ“‹ Projects", callback_data="action:show_projects"
                ),
            ]
        )

        reply_markup = InlineKeyboardMarkup(keyboard)

        await query.edit_message_text(
            message, parse_mode=None, reply_markup=reply_markup
        )

    except Exception as e:
        await query.edit_message_text(f"âŒ Error listing directory: {str(e)}")


async def _handle_start_coding_action(
    query, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle start coding action."""
    user_id = query.from_user.id
    
    # Get localized text
    ready_to_code = await get_localized_text(context, user_id, "session.ready_to_code")
    send_message_prompt = await get_localized_text(context, user_id, "session.send_message_prompt")
    examples_title = await get_localized_text(context, user_id, "session.examples_title")
    example_create_script = await get_localized_text(context, user_id, "session.example_create_script")
    example_debug_code = await get_localized_text(context, user_id, "session.example_debug_code")
    example_explain_file = await get_localized_text(context, user_id, "session.example_explain_file")
    example_upload_file = await get_localized_text(context, user_id, "session.example_upload_file")
    help_message = await get_localized_text(context, user_id, "session.help_message")
    
    message_text = (
        f"{ready_to_code}\n\n"
        f"{send_message_prompt}\n\n"
        f"{examples_title}\n"
        f"{example_create_script}\n"
        f"{example_debug_code}\n"
        f"{example_explain_file}\n"
        f"{example_upload_file}\n\n"
        f"{help_message}"
    )
    
    await query.edit_message_text(message_text)


async def _handle_quick_actions_action(
    query, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle quick actions menu."""
    user_id = query.from_user.id

    # NEW FUNCTIONAL BUTTONS - using quick_action callback for actual execution
    keyboard = [
        [
            InlineKeyboardButton("ðŸ“‹ ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸", callback_data="quick_action:ls"),
            InlineKeyboardButton("ðŸ  Ð”Ðµ Ñ?", callback_data="quick_action:pwd"),
        ],
        [
            InlineKeyboardButton("ðŸ’¾ Git Status", callback_data="quick_action:git_status"),
            InlineKeyboardButton("ðŸ” ÐŸÐ¾ÑˆÑƒÐº TODO", callback_data="quick_action:grep"),
        ],
        [
            InlineKeyboardButton("ðŸ“– Ð§Ð¸Ñ‚Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»", callback_data="file_edit:select_read"),
            InlineKeyboardButton("âœï¸ Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»", callback_data="file_edit:select_edit"),
        ],
        [
            InlineKeyboardButton("ðŸ” Ð—Ð½Ð°Ð¹Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸", callback_data="quick_action:find_files"),
            InlineKeyboardButton("ðŸ§ª Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ñ‚ÐµÑÑ‚Ð¸", callback_data="quick:test"),
        ],
        [InlineKeyboardButton("â¬…ï¸ " + await get_localized_text(context, user_id, "buttons.back"), callback_data="action:new_session")],
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    quick_actions_text = await get_localized_text(context, user_id, "quick_actions.title")

    await query.edit_message_text(
        quick_actions_text,
        parse_mode=None,
        reply_markup=reply_markup,
    )


async def _handle_refresh_status_action(
    query, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle refresh status action."""
    await _handle_status_action(query, context)


async def _handle_refresh_ls_action(query, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle refresh ls action."""
    await _handle_ls_action(query, context)


async def _handle_export_action(query, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle export action."""
    await query.edit_message_text(
        "ðŸ“¤ **Export Session**\n\n"
        "Session export functionality will be available once the storage layer is implemented.\n\n"
        "**Planned features:**\n"
        "â€¢ Export conversation history\n"
        "â€¢ Save session state\n"
        "â€¢ Share conversations\n"
        "â€¢ Create session backups\n\n"
        "_Coming in the next development phase!_"
    )


async def handle_quick_action_callback(
    query, action_id: str, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle quick action callbacks with localization."""
    user_id = query.from_user.id

    # Get localization components
    localization = context.bot_data.get("localization")
    user_language_storage = context.bot_data.get("user_language_storage")
    
    # Get quick actions manager from bot data if available
    quick_actions = context.bot_data.get("quick_actions")

    if not quick_actions:
        error_text = await get_localized_text(context, user_id, "errors.quick_actions_unavailable")
        await query.edit_message_text(error_text, parse_mode=None)
        return

    # Get Claude integration
    claude_integration: ClaudeIntegration = context.bot_data.get("claude_integration")
    if not claude_integration:
        error_text = await get_localized_text(context, user_id, "errors.claude_not_available")
        await query.edit_message_text(error_text, parse_mode=None)
        return

    settings: Settings = context.bot_data["settings"]
    current_dir = context.user_data.get(
        "current_directory", settings.approved_directory
    )

    try:
        # Get the action from the manager
        action = quick_actions.actions.get(action_id)
        if not action:
            error_text = await get_localized_text(context, user_id, "errors.action_not_found", action=action_id)
            await query.edit_message_text(error_text, parse_mode=None)
            return
            
        # Get localized action name
        if localization and user_language_storage:
            user_lang = await user_language_storage.get_user_language(user_id)
            action_display_name = localization.get(f"quick_actions.{action.id}.name", language=user_lang) or f"{action.icon} {action.name}"
        else:
            action_display_name = f"{action.icon} {action.name}"

        # Check if action is properly implemented
        if not action.command and not getattr(action, "prompt", None):
            error_text = await get_localized_text(context, user_id, "errors.action_not_implemented", action=action_display_name)
            await query.edit_message_text(error_text, parse_mode=None)
            return

        # Show execution message
        executing_text = await get_localized_text(context, user_id, "messages.executing_action", action=action_display_name)
        await query.edit_message_text(executing_text, parse_mode=None)

        # Run the action through Claude
        prompt = getattr(action, "prompt", None) or action.command
        claude_response = await claude_integration.run_command(
            prompt=prompt, working_directory=current_dir, user_id=user_id
        )

        if claude_response:
            # Show completion message and format response
            completed_text = await get_localized_text(context, user_id, "messages.action_completed", action=action_display_name)
            response_text = claude_response.content
            if len(response_text) > 4000:
                response_text = response_text[:4000] + "...\n\n_(Response truncated)_"

            await query.message.reply_text(
                f"{completed_text}\n\n{response_text}",
                parse_mode=None,
            )
        else:
            failed_text = await get_localized_text(context, user_id, "messages.action_failed", action=action_display_name)
            await query.edit_message_text(failed_text, parse_mode=None)

    except Exception as e:
        logger.error("Quick action execution failed", error=str(e), user_id=user_id)
        error_text = await get_localized_text(context, user_id, "errors.action_error", action=action_id, error=str(e))
        await query.edit_message_text(error_text, parse_mode=None)


async def handle_followup_callback(
    query, suggestion_hash: str, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle follow-up suggestion callbacks."""
    user_id = query.from_user.id

    # Get conversation enhancer from bot data if available
    conversation_enhancer = context.bot_data.get("conversation_enhancer")

    if not conversation_enhancer:
        await query.edit_message_text(
            "âŒ **Follow-up Not Available**\n\n"
            "Conversation enhancement features are not available."
        )
        return

    try:
        # Get stored suggestions (this would need to be implemented in the enhancer)
        # For now, we'll provide a generic response
        await query.edit_message_text(
            "ðŸ’¡ **Follow-up Suggestion Selected**\n\n"
            "This follow-up suggestion will be implemented once the conversation "
            "enhancement system is fully integrated with the message handler.\n\n"
            "**Current Status:**\n"
            "â€¢ Suggestion received âœ…\n"
            "â€¢ Integration pending ðŸ”„\n\n"
            "_You can continue the conversation by sending a new message._"
        )

        logger.info(
            "Follow-up suggestion selected",
            user_id=user_id,
            suggestion_hash=suggestion_hash,
        )

    except Exception as e:
        logger.error(
            "Error handling follow-up callback",
            error=str(e),
            user_id=user_id,
            suggestion_hash=suggestion_hash,
        )

        await query.edit_message_text(
            "âŒ **Error Processing Follow-up**\n\n"
            "An error occurred while processing your follow-up suggestion."
        )


async def handle_conversation_callback(
    query, action_type: str, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle conversation control callbacks."""
    user_id = query.from_user.id
    settings: Settings = context.bot_data["settings"]

    if action_type == "continue":
        # Remove suggestion buttons and show continue message
        await query.edit_message_text(
            "âœ… **Continuing Conversation**\n\n"
            "Send me your next message to continue coding!\n\n"
            "I'm ready to help with:\n"
            "â€¢ Code review and debugging\n"
            "â€¢ Feature implementation\n"
            "â€¢ Architecture decisions\n"
            "â€¢ Testing and optimization\n"
            "â€¢ Documentation\n\n"
            "_Just type your request or upload files._"
        )

    elif action_type == "end":
        # End the current session
        conversation_enhancer = context.bot_data.get("conversation_enhancer")
        if conversation_enhancer:
            conversation_enhancer.clear_context(user_id)

        # Clear session data
        context.user_data["claude_session_id"] = None
        context.user_data["session_started"] = False

        current_dir = context.user_data.get(
            "current_directory", settings.approved_directory
        )
        relative_path = current_dir.relative_to(settings.approved_directory)

        # Show termination message first
        await query.edit_message_text(
            "âœ… **Conversation Ended**\n\n"
            f"Your Claude session has been terminated.\n\n"
            f"**Current Status:**\n"
            f"â€¢ Directory: `{relative_path}/`\n"
            f"â€¢ Session: None\n"
            f"â€¢ Ready for new commands\n\n"
            f"**Next Steps:**\n"
            f"â€¢ Start a new session\n"
            f"â€¢ Check status\n"
            f"â€¢ Send any message to begin a new conversation\n\n"
            f"_Returning to main menu..._",
            parse_mode=None,
        )

        # Now call the proper main menu action to ensure consistency
        await _handle_main_menu_action(query, context)

        logger.info("Conversation ended via callback", user_id=user_id)

    else:
        user_id = query.from_user.id
        await query.edit_message_text(
            await t(context, user_id, "callback_errors.unknown_action") + f": {action_type}"
        )


async def handle_git_callback(
    query, git_action: str, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle git-related callbacks."""
    user_id = query.from_user.id
    settings: Settings = context.bot_data["settings"]
    features = context.bot_data.get("features")

    if not features or not features.is_enabled("git"):
        await query.edit_message_text(
            "âŒ **Git Integration Disabled**\n\n"
            "Git integration feature is not enabled."
        )
        return

    current_dir = context.user_data.get(
        "current_directory", settings.approved_directory
    )

    try:
        git_integration = features.get_git_integration()
        if not git_integration:
            await query.edit_message_text(
                "âŒ **Git Integration Unavailable**\n\n"
                "Git integration service is not available."
            )
            return

        if git_action == "status":
            # Refresh git status
            git_status = await git_integration.get_status(current_dir)
            status_message = git_integration.format_status(git_status)

            keyboard = [
                [
                    InlineKeyboardButton("ðŸ“Š Show Diff", callback_data="git:diff"),
                    InlineKeyboardButton("ðŸ“œ Show Log", callback_data="git:log"),
                ],
                [
                    InlineKeyboardButton("ðŸ”„ Refresh", callback_data="git:status"),
                    InlineKeyboardButton("ðŸ“ Files", callback_data="action:ls"),
                ],
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)

            await query.edit_message_text(
                status_message, parse_mode=None, reply_markup=reply_markup
            )

        elif git_action == "diff":
            # Show git diff
            diff_output = await git_integration.get_diff(current_dir)

            if not diff_output.strip():
                diff_message = "ðŸ“Š **Git Diff**\n\n_No changes to show._"
            else:
                # Clean up diff output for Telegram
                # Remove emoji symbols that interfere with markdown parsing
                clean_diff = diff_output.replace("âž•", "+").replace("âž–", "-").replace("ðŸ“", "@")
                
                # Limit diff output
                max_length = 2000
                if len(clean_diff) > max_length:
                    clean_diff = (
                        clean_diff[:max_length] + "\n\n_... output truncated ..._"
                    )

                diff_message = f"ðŸ“Š **Git Diff**\n\n```\n{clean_diff}\n```"

            keyboard = [
                [
                    InlineKeyboardButton("ðŸ“œ Show Log", callback_data="git:log"),
                    InlineKeyboardButton("ðŸ“Š Status", callback_data="git:status"),
                ]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)

            await query.edit_message_text(
                diff_message, parse_mode=None, reply_markup=reply_markup
            )

        elif git_action == "log":
            # Show git log
            commits = await git_integration.get_file_history(current_dir, ".")

            if not commits:
                log_message = "ðŸ“œ **Git Log**\n\n_No commits found._"
            else:
                log_message = "ðŸ“œ **Git Log**\n\n"
                for commit in commits[:10]:  # Show last 10 commits
                    short_hash = commit.hash[:7]
                    short_message = commit.message[:60]
                    if len(commit.message) > 60:
                        short_message += "..."
                    log_message += f"â€¢ `{short_hash}` {short_message}\n"

            keyboard = [
                [
                    InlineKeyboardButton("ðŸ“Š Show Diff", callback_data="git:diff"),
                    InlineKeyboardButton("ðŸ“Š Status", callback_data="git:status"),
                ]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)

            await query.edit_message_text(
                log_message, parse_mode=None, reply_markup=reply_markup
            )

        else:
            user_id = query.from_user.id
            await query.edit_message_text(
                await t(context, user_id, "callback_errors.unknown_action") + f": {git_action}"
            )

    except Exception as e:
        logger.error(
            "Error in git callback",
            error=str(e),
            git_action=git_action,
            user_id=user_id,
        )
        await query.edit_message_text(f"âŒ **Git Error**\n\n{str(e)}")


async def handle_export_callback(
    query, export_format: str, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle export format selection callbacks."""
    user_id = query.from_user.id
    features = context.bot_data.get("features")

    if export_format == "cancel":
        await query.edit_message_text(
            await t(context, user_id, "buttons.cancelled")
        )
        return

    session_exporter = features.get_session_export() if features else None
    if not session_exporter:
        await query.edit_message_text(
            "âŒ **Export Unavailable**\n\n" "Session export service is not available."
        )
        return

    # Get current session
    claude_session_id = context.user_data.get("claude_session_id")
    if not claude_session_id:
        await query.edit_message_text(
            "âŒ **No Active Session**\n\n" "There's no active session to export."
        )
        return

    try:
        # Show processing message
        await query.edit_message_text(
            f"ðŸ“¤ **Exporting Session**\n\n"
            f"Generating {export_format.upper()} export...",
            parse_mode=None,
        )

        # Export session
        exported_session = await session_exporter.export_session(
            claude_session_id, export_format
        )

        # Send the exported file
        from io import BytesIO

        file_bytes = BytesIO(exported_session.content.encode("utf-8"))
        file_bytes.name = exported_session.filename

        await query.message.reply_document(
            document=file_bytes,
            filename=exported_session.filename,
            caption=(
                f"ðŸ“¤ **Session Export Complete**\n\n"
                f"Format: {exported_session.format.upper()}\n"
                f"Size: {exported_session.size_bytes:,} bytes\n"
                f"Created: {exported_session.created_at.strftime('%Y-%m-%d %H:%M:%S')}"
            ),
            parse_mode=None,
        )

        # Update the original message
        await query.edit_message_text(
            f"âœ… **Export Complete**\n\n"
            f"Your session has been exported as {exported_session.filename}.\n"
            f"Check the file above for your complete conversation history.",
            parse_mode=None,
        )

    except Exception as e:
        logger.error(
            "Export failed", error=str(e), user_id=user_id, format=export_format
        )
        await query.edit_message_text(f"âŒ **Export Failed**\n\n{str(e)}")


async def handle_language_callback(query, param: str, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle language selection callbacks."""
    user_id = query.from_user.id
    localization = context.bot_data.get("localization")
    user_language_storage = context.bot_data.get("user_language_storage")
    
    if not localization or not user_language_storage:
        await query.edit_message_text("âŒ Localization system not available")
        return
    
    if param == "select":
        # Show language selection menu
        available_languages = localization.get_available_languages()
        
        keyboard = []
        row = []
        for lang_code, lang_name in available_languages.items():
            flag = "ðŸ‡ºðŸ‡¦" if lang_code == "uk" else "ðŸ‡ºðŸ‡¸"
            row.append(InlineKeyboardButton(f"{flag} {lang_name}", callback_data=f"lang:set:{lang_code}"))
            
            # Create rows of 2 buttons each
            if len(row) == 2:
                keyboard.append(row)
                row = []
        
        # Add remaining button if any
        if row:
            keyboard.append(row)
            
        # Add back button
        back_text = await get_user_text(localization, user_language_storage, user_id, "buttons.back")
        keyboard.append([InlineKeyboardButton(back_text, callback_data="action:help")])
        
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        # Get localized text
        select_message = await get_user_text(localization, user_language_storage, user_id, "messages.language_select")
        
        await query.edit_message_text(select_message, reply_markup=reply_markup)
        
    elif param.startswith("set:"):
        # Set user language
        new_language = param.split(":", 1)[1]
        
        if localization.is_language_available(new_language):
            success = await user_language_storage.set_user_language(user_id, new_language)
            
            if success:
                # Get language name for confirmation
                lang_name = localization.get_available_languages().get(new_language, new_language.upper())
                
                # Get confirmation message in NEW language
                confirmation_text = localization.get("messages.language_changed", language=new_language).format(language_name=lang_name)
                
                # Show language changed message with back button
                back_text = localization.get("buttons.back", language=new_language)
                keyboard = [[InlineKeyboardButton(back_text, callback_data="action:help")]]
                reply_markup = InlineKeyboardMarkup(keyboard)
                
                await query.edit_message_text(confirmation_text, reply_markup=reply_markup)
                
                logger.info("User language changed", user_id=user_id, new_language=new_language)
            else:
                error_text = await get_user_text(localization, user_language_storage, user_id, "messages.error_occurred", error="Failed to save language preference")
                await query.edit_message_text(error_text)
        else:
            error_text = await get_user_text(localization, user_language_storage, user_id, "messages.language_not_available", language=new_language)
            await query.edit_message_text(error_text)


async def handle_schedule_callback(query, param: str, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle scheduled prompts callbacks."""
    try:
        from ..features.scheduled_prompts import ScheduledPromptsManager
        
        user_id = query.from_user.id
        application = context.application
        settings = context.bot_data.get("settings")
        
        if not application or not settings:
            await query.edit_message_text("âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ñƒ Ð´Ð¾ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸")
            return
            
        prompts_manager = ScheduledPromptsManager(application, settings)
        
        if param == "add":
            # Show add schedule menu
            keyboard = [
                [InlineKeyboardButton("ðŸ“ Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:create_new")],
                [InlineKeyboardButton("ðŸ“‹ Ð—Ñ– ÑˆÐ°Ð±Ð»Ð¾Ð½Ñƒ", callback_data="schedule:from_template")],
                [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:list")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            message = (
                "âž• **Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð¿Ð»Ð°Ð½Ð¾Ð²Ðµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ**\n\n"
                "ÐŸÐ»Ð°Ð½Ð¾Ð²Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð²Ð¸ÐºÐ¾Ð½ÑƒÑŽÑ‚ÑŒÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾\n"
                "Ð¿Ñ–Ð´ Ñ‡Ð°Ñ DND Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ (23:00-08:00).\n\n"
                "ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ ÑÐ¿Ð¾ÑÑ–Ð± ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ:"
            )
            await query.edit_message_text(message, reply_markup=reply_markup)
            
        elif param == "list":
            # Show schedules list
            config = await prompts_manager.load_prompts()
            prompts = config.get("prompts", [])
            system_settings = config.get("settings", {})
            
            if not prompts:
                keyboard = [[
                    InlineKeyboardButton("âž• Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:add"),
                    InlineKeyboardButton("âš™ï¸ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ", callback_data="schedule:settings")
                ]]
                reply_markup = InlineKeyboardMarkup(keyboard)
                
                await query.edit_message_text(
                    "ðŸ“‹ **ÐŸÐ»Ð°Ð½Ð¾Ð²Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð½ÐµÐ¼Ð°Ñ”**\n\n"
                    "ðŸ”§ Ð”Ð¾Ð´Ð°Ð¹Ñ‚Ðµ Ð¿ÐµÑ€ÑˆÐµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð´Ð»Ñ Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸",
                    reply_markup=reply_markup
                )
                return
            
            enabled_count = sum(1 for p in prompts if p.get("enabled", False))
            system_status = "âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð°" if system_settings.get("enabled", False) else "âŒ Ð’Ð¸Ð¼ÐºÐ½ÐµÐ½Ð°"
            
            message = (
                f"ðŸ“‹ **ÐŸÐ»Ð°Ð½Ð¾Ð²Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ** ({len(prompts)})\n"
                f"ðŸ”§ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð°: {system_status} | ÐÐºÑ‚Ð¸Ð²Ð½Ð¸Ñ…: {enabled_count}\n\n"
            )
            
            for i, prompt in enumerate(prompts[:5], 1):  # Show first 5
                status_icon = "âœ…" if prompt.get("enabled", False) else "âŒ"
                schedule = prompt.get("schedule", {})
                schedule_info = f"{schedule.get('type', 'daily')} Ð¾ {schedule.get('time', '02:00')}"
                
                message += (
                    f"{i}. {status_icon} **{prompt.get('title', 'Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð¸')}**\n"
                    f"   ðŸ“… {schedule_info}\n\n"
                )
            
            if len(prompts) > 5:
                message += f"... Ñ‚Ð° Ñ‰Ðµ {len(prompts) - 5} Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ\n\n"
                
            keyboard = [
                [
                    InlineKeyboardButton("âž• Ð”Ð¾Ð´Ð°Ñ‚Ð¸", callback_data="schedule:add"),
                    InlineKeyboardButton("ðŸ“ Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸", callback_data="schedule:edit")
                ],
                [
                    InlineKeyboardButton("âš™ï¸ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ", callback_data="schedule:settings"),
                    InlineKeyboardButton("ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°", callback_data="schedule:stats")
                ],
                [
                    InlineKeyboardButton("ðŸ”„ ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸", callback_data="schedule:refresh"),
                    InlineKeyboardButton("â–¶ï¸ Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ð²ÑÑ–", callback_data="schedule:run_all")
                ]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(message, reply_markup=reply_markup)
            
        elif param == "settings":
            # Show system settings
            config = await prompts_manager.load_prompts()
            system_settings = config.get("settings", {})
            
            enabled = system_settings.get("enabled", False)
            dnd_start = system_settings.get("dnd_start", "23:00")
            dnd_end = system_settings.get("dnd_end", "08:00")
            max_concurrent = system_settings.get("max_concurrent_tasks", 1)
            
            message = (
                "âš™ï¸ **ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸**\n\n"
                f"ðŸ”§ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð°: {'âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð°' if enabled else 'âŒ Ð’Ð¸Ð¼ÐºÐ½ÐµÐ½Ð°'}\n"
                f"ðŸŒ™ DND Ð¿ÐµÑ€Ñ–Ð¾Ð´: {dnd_start} - {dnd_end}\n"
                f"âš¡ ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ: {max_concurrent}\n\n"
                "**Do Not Disturb (DND) Ð¿ÐµÑ€Ñ–Ð¾Ð´** - Ñ†Ðµ Ñ‡Ð°Ñ ÐºÐ¾Ð»Ð¸\n"
                "ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ñ– Ð½Ðµ Ð¿Ñ€Ð°Ñ†ÑŽÑŽÑ‚ÑŒ Ñ– ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¼Ð¾Ð¶Ðµ\n"
                "Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ð»Ð°Ð½Ð¾Ð²Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ."
            )
            
            keyboard = [
                [InlineKeyboardButton(
                    "âŒ Ð’Ð¸Ð¼ÐºÐ½ÑƒÑ‚Ð¸" if enabled else "âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÑƒÑ‚Ð¸",
                    callback_data=f"schedule:toggle_system"
                )],
                [
                    InlineKeyboardButton("ðŸŒ™ Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ DND", callback_data="schedule:change_dnd"),
                    InlineKeyboardButton("âš¡ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ", callback_data="schedule:advanced")
                ],
                [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:list")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(message, reply_markup=reply_markup)

        elif param == "edit":
            # Show list of tasks for editing
            config = await prompts_manager.load_prompts()
            prompts = config.get("prompts", [])

            if not prompts:
                await query.edit_message_text(
                    "ðŸ“ **ÐÐµÐ¼Ð°Ñ” Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð´Ð»Ñ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ**\n\n"
                    "Ð¡Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ð´Ð¾Ð´Ð°Ð¹Ñ‚Ðµ Ð¿Ð»Ð°Ð½Ð¾Ð²Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ.",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("âž• Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:add")],
                        [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:list")]
                    ])
                )
                return

            message = "ðŸ“ **Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ**\n\nÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð´Ð»Ñ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ:\n\n"
            keyboard = []

            for i, prompt in enumerate(prompts[:10]):  # Show first 10
                status_icon = "âœ…" if prompt.get("enabled", False) else "âŒ"
                title = prompt.get("title", f"Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ {i+1}")
                keyboard.append([
                    InlineKeyboardButton(
                        f"{status_icon} {title[:30]}{'...' if len(title) > 30 else ''}",
                        callback_data=f"schedule:edit_task:{i}"
                    )
                ])

            keyboard.append([InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:list")])
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(message, reply_markup=reply_markup)

        elif param.startswith("edit_task:"):
            # Edit specific task
            task_index = int(param.split(":", 1)[1])
            config = await prompts_manager.load_prompts()
            prompts = config.get("prompts", [])

            if task_index >= len(prompts):
                await query.edit_message_text(
                    "âŒ **Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\nÐ—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð· Ñ‚Ð°ÐºÐ¸Ð¼ Ð½Ð¾Ð¼ÐµÑ€Ð¾Ð¼ Ð½Ðµ Ñ–ÑÐ½ÑƒÑ”.",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:edit")]
                    ])
                )
                return

            task = prompts[task_index]
            schedule = task.get("schedule", {})

            message = (
                f"âœï¸ **Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ**\n\n"
                f"ðŸ“ **ÐÐ°Ð·Ð²Ð°:** {task.get('title', 'Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð¸')}\n"
                f"ðŸ“‹ **ÐžÐ¿Ð¸Ñ:** {task.get('description', 'Ð‘ÐµÐ· Ð¾Ð¿Ð¸ÑÑƒ')}\n"
                f"â° **Ð Ð¾Ð·ÐºÐ»Ð°Ð´:** {schedule.get('type', 'daily')} Ð¾ {schedule.get('time', '02:00')}\n"
                f"ðŸ”§ **Ð¡Ñ‚Ð°Ñ‚ÑƒÑ:** {'âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾' if task.get('enabled', False) else 'âŒ Ð’Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾'}\n\n"
                f"**ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚:**\n`{task.get('prompt', 'ÐÐµÐ¼Ð°Ñ” Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ')[:200]}{'...' if len(task.get('prompt', '')) > 200 else ''}`"
            )

            keyboard = [
                [
                    InlineKeyboardButton(
                        "âŒ Ð’Ð¸Ð¼ÐºÐ½ÑƒÑ‚Ð¸" if task.get("enabled", False) else "âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÑƒÑ‚Ð¸",
                        callback_data=f"schedule:toggle_task:{task_index}"
                    ),
                    InlineKeyboardButton("ðŸ—‘ï¸ Ð’Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸", callback_data=f"schedule:delete_task:{task_index}")
                ],
                [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:edit")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(message, reply_markup=reply_markup)

        elif param.startswith("toggle_task:"):
            # Toggle task enabled/disabled
            task_index = int(param.split(":", 1)[1])
            config = await prompts_manager.load_prompts()
            prompts = config.get("prompts", [])

            if task_index < len(prompts):
                prompts[task_index]["enabled"] = not prompts[task_index].get("enabled", False)
                await prompts_manager.save_prompts(config)

                status = "ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾" if prompts[task_index]["enabled"] else "Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾"
                await query.edit_message_text(
                    f"âœ… **Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ {status}**\n\n"
                    f"Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ '{prompts[task_index].get('title', 'Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð¸')}' Ð±ÑƒÐ»Ð¾ {status}.",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´ Ð´Ð¾ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ", callback_data=f"schedule:edit_task:{task_index}")]
                    ])
                )
            else:
                await query.edit_message_text("âŒ Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾")

        elif param.startswith("delete_task:"):
            # Delete task with confirmation
            task_index = int(param.split(":", 1)[1])
            config = await prompts_manager.load_prompts()
            prompts = config.get("prompts", [])

            if task_index < len(prompts):
                task_title = prompts[task_index].get('title', 'Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð¸')
                message = (
                    f"ðŸ—‘ï¸ **Ð’Ð¸Ð´Ð°Ð»ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ**\n\n"
                    f"Ð’Ð¸ Ð²Ð¿ÐµÐ²Ð½ÐµÐ½Ñ–, Ñ‰Ð¾ Ñ…Ð¾Ñ‡ÐµÑ‚Ðµ Ð²Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ:\n"
                    f"**'{task_title}'**?\n\n"
                    f"âš ï¸ Ð¦Ñ Ð´Ñ–Ñ Ð½ÐµÐ·Ð²Ð¾Ñ€Ð¾Ñ‚Ð½Ð°!"
                )

                keyboard = [
                    [
                        InlineKeyboardButton("âœ… Ð¢Ð°Ðº, Ð²Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸", callback_data=f"schedule:confirm_delete:{task_index}"),
                        InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data=f"schedule:edit_task:{task_index}")
                    ]
                ]
                reply_markup = InlineKeyboardMarkup(keyboard)
                await query.edit_message_text(message, reply_markup=reply_markup)
            else:
                await query.edit_message_text("âŒ Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾")

        elif param.startswith("confirm_delete:"):
            # Confirm task deletion
            task_index = int(param.split(":", 1)[1])
            config = await prompts_manager.load_prompts()
            prompts = config.get("prompts", [])

            if task_index < len(prompts):
                task_title = prompts[task_index].get('title', 'Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð¸')
                del prompts[task_index]
                await prompts_manager.save_prompts(config)

                await query.edit_message_text(
                    f"âœ… **Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð²Ð¸Ð´Ð°Ð»ÐµÐ½Ð¾**\n\n"
                    f"Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ '{task_title}' Ð±ÑƒÐ»Ð¾ ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾ Ð²Ð¸Ð´Ð°Ð»ÐµÐ½Ð¾.",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ“‹ ÐÐ°Ð·Ð°Ð´ Ð´Ð¾ ÑÐ¿Ð¸ÑÐºÑƒ", callback_data="schedule:list")]
                    ])
                )
            else:
                await query.edit_message_text("âŒ Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾")

        elif param == "stats":
            # Show execution statistics
            stats = await prompts_manager.get_execution_stats()
            
            message = (
                "ðŸ“Š **Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ**\n\n"
                f"ðŸ“ˆ Ð’ÑÑŒÐ¾Ð³Ð¾ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½ÑŒ: {stats.get('total_executions', 0)}\n"
                f"âœ… Ð£ÑÐ¿Ñ–ÑˆÐ½Ð¸Ñ…: {stats.get('successful', 0)}\n"
                f"âŒ ÐŸÐ¾Ð¼Ð¸Ð»Ð¾Ðº: {stats.get('failed', 0)}\n"
                f"â±ï¸ Ð¡ÐµÑ€ÐµÐ´Ð½Ñ–Ð¹ Ñ‡Ð°Ñ: {stats.get('avg_duration', 0):.1f}Ñ\n"
                f"ðŸ•’ ÐžÑÑ‚Ð°Ð½Ð½Ñ” Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ: {stats.get('last_execution', 'ÐÐµÐ¼Ð°Ñ”')}\n\n"
                f"ðŸ”„ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ñ€Ð°Ñ†ÑŽÑ”: {'âœ… Ð¢Ð°Ðº' if stats.get('system_active', False) else 'âŒ ÐÑ–'}"
            )
            
            keyboard = [
                [InlineKeyboardButton("ðŸ“‹ Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ– Ð»Ð¾Ð³Ð¸", callback_data="schedule:logs")],
                [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:list")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(message, reply_markup=reply_markup)
            
        elif param == "create_new":
            # Handle create new scheduled prompt
            # Store state for task creation dialogue
            user_id = query.from_user.id
            context.user_data["creating_task"] = {"step": "prompt", "user_id": user_id}

            await query.edit_message_text(
                "ðŸ“ **Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð½Ð¾Ð²Ðµ Ð¿Ð»Ð°Ð½Ð¾Ð²Ðµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ**\n\n"
                "**ÐšÑ€Ð¾Ðº 1 Ð· 3: Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚**\n\n"
                "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ, ÑÐºÐµ Ð±ÑƒÐ´Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð¾ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾:\n\n"
                "**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸:**\n"
                "â€¢ `ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ð¾ÑÑ‚Ð°Ð½Ð½Ñ– Ð·Ð¼Ñ–Ð½Ð¸ Ð² Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ–`\n"
                "â€¢ `Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸ Ñ‰Ð¾Ð´ÐµÐ½Ð½Ð¸Ð¹ Ð·Ð²Ñ–Ñ‚ Ð¿Ñ€Ð¾ ÐºÐ¾Ð´`\n"
                "â€¢ `ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ Ð±ÐµÐ·Ð¿ÐµÐºÑƒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ`\n"
                "â€¢ `ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·ÑƒÐ¹ ÐºÐ¾Ð´ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–`\n\n"
                "ðŸ’¬ ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð· Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ.",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="schedule:cancel_create")]
                ])
            )

        elif param == "from_template":
            # Handle create from template
            keyboard = [
                [
                    InlineKeyboardButton("ðŸ” ÐÐ½Ð°Ð»Ñ–Ð· ÐºÐ¾Ð´Ñƒ", callback_data="schedule:template:code_analysis"),
                    InlineKeyboardButton("ðŸ“Š Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ Ð·Ð²Ñ–Ñ‚Ñ–Ð²", callback_data="schedule:template:report_generation")
                ],
                [
                    InlineKeyboardButton("âš’ï¸ Ð ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³", callback_data="schedule:template:refactoring"),
                    InlineKeyboardButton("ðŸ“ Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ", callback_data="schedule:template:documentation")
                ],
                [
                    InlineKeyboardButton("ðŸ”’ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð±ÐµÐ·Ð¿ÐµÐºÐ¸", callback_data="schedule:template:security_audit"),
                    InlineKeyboardButton("ðŸ§ª Ð¢ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ", callback_data="schedule:template:testing")
                ],
                [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:add")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)

            message = (
                "ðŸ“‹ **ÐžÐ±Ñ€Ð°Ñ‚Ð¸ ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ**\n\n"
                "Ð’Ð¸Ð±ÐµÑ€Ñ–Ñ‚ÑŒ Ñ‚Ð¸Ð¿ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð·Ñ– ÑÐ¿Ð¸ÑÐºÑƒ Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ñ… ÑˆÐ°Ð±Ð»Ð¾Ð½Ñ–Ð²:\n\n"
                "ðŸ” **ÐÐ½Ð°Ð»Ñ–Ð· ÐºÐ¾Ð´Ñƒ** - Ð¿Ð¾Ð²Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ Ñ‚Ð° Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸\n"
                "ðŸ“Š **Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ Ð·Ð²Ñ–Ñ‚Ñ–Ð²** - ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð²Ñ–Ñ‚Ñ–Ð² Ñ‚Ð° ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸\n"
                "âš’ï¸ **Ð ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³** - Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ Ñ‚Ð° Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ ÐºÐ¾Ð´Ñƒ\n"
                "ðŸ“ **Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ** - ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ñ‚Ð° Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—\n"
                "ðŸ”’ **ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð±ÐµÐ·Ð¿ÐµÐºÐ¸** - Ð°Ð½Ð°Ð»Ñ–Ð· ÑƒÑ€Ð°Ð·Ð»Ð¸Ð²Ð¾ÑÑ‚ÐµÐ¹\n"
                "ðŸ§ª **Ð¢ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ** - Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ Ñ‚Ð° Ð·Ð°Ð¿ÑƒÑÐº Ñ‚ÐµÑÑ‚Ñ–Ð²\n\n"
                "_ÐÐ°Ñ‚Ð¸ÑÐ½Ñ–Ñ‚ÑŒ Ð½Ð° ÑˆÐ°Ð±Ð»Ð¾Ð½ Ð´Ð»Ñ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ_"
            )

            await query.edit_message_text(message, reply_markup=reply_markup)

        elif param.startswith("template:"):
            # Handle specific template selection
            template_type = param.split(":", 1)[1]
            await _handle_template_selection(query, template_type, context)
            
        elif param == "advanced":
            # Handle advanced settings  
            config = await prompts_manager.load_prompts()
            system_settings = config.get("settings", {})
            
            message = (
                "âš™ï¸ **Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ñ– Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ**\n\n"
                f"ðŸ”§ ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ: {system_settings.get('max_concurrent_tasks', 1)}\n"
                f"â° Ð¢Ð°Ð¹Ð¼-Ð°ÑƒÑ‚ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ: {system_settings.get('task_timeout', 300)}Ñ\n"
                f"ðŸ”„ Ð†Ð½Ñ‚ÐµÑ€Ð²Ð°Ð» Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸: {system_settings.get('check_interval', 60)}Ñ\n"
                f"ðŸ“ Ð›Ð¾Ð³ÑƒÐ²Ð°Ð½Ð½Ñ: {'âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾' if system_settings.get('logging_enabled', True) else 'âŒ Ð’Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾'}\n\n"
                "**ÐžÐ¿Ð¸Ñ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½ÑŒ:**\n"
                "â€¢ ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ - ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ÑÑŒ Ð¾Ð´Ð½Ð¾Ñ‡Ð°ÑÐ½Ð¾\n"
                "â€¢ Ð¢Ð°Ð¹Ð¼-Ð°ÑƒÑ‚ - Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ‡Ð°Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ\n"
                "â€¢ Ð†Ð½Ñ‚ÐµÑ€Ð²Ð°Ð» Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸ - ÑÐº Ñ‡Ð°ÑÑ‚Ð¾ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ” Ð½Ð¾Ð²Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ"
            )

            keyboard = [
                [
                    InlineKeyboardButton("ðŸ”§ Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ", callback_data="schedule:change_max_tasks"),
                    InlineKeyboardButton("â° Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ñ‚Ð°Ð¹Ð¼-Ð°ÑƒÑ‚", callback_data="schedule:change_timeout")
                ],
                [
                    InlineKeyboardButton("ðŸ”„ Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ñ–Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»", callback_data="schedule:change_interval"),
                    InlineKeyboardButton("ðŸ“ ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð¸Ñ‚Ð¸ Ð»Ð¾Ð³ÑƒÐ²Ð°Ð½Ð½Ñ", callback_data="schedule:toggle_logging")
                ],
                [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:settings")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(message, reply_markup=reply_markup)
            
        elif param == "change_dnd":
            # Handle change DND settings
            config = await prompts_manager.load_prompts()
            system_settings = config.get("settings", {})
            
            dnd_start = system_settings.get("dnd_start", "23:00")
            dnd_end = system_settings.get("dnd_end", "08:00")
            
            message = (
                "ðŸŒ™ **ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ DND Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ**\n\n"
                f"ðŸ“… ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ñ– Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ:\n"
                f"â€¢ ÐŸÐ¾Ñ‡Ð°Ñ‚Ð¾Ðº: {dnd_start}\n"
                f"â€¢ ÐšÑ–Ð½ÐµÑ†ÑŒ: {dnd_end}\n\n"
                "**Do Not Disturb (DND)** - Ñ†Ðµ Ð¿ÐµÑ€Ñ–Ð¾Ð´ Ñ‡Ð°ÑÑƒ,\n"
                "ÐºÐ¾Ð»Ð¸ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ñ– Ð·Ð°Ð·Ð²Ð¸Ñ‡Ð°Ð¹ Ð½Ðµ Ð¿Ñ€Ð°Ñ†ÑŽÑŽÑ‚ÑŒ\n"
                "Ñ– ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¼Ð¾Ð¶Ðµ Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ð»Ð°Ð½Ð¾Ð²Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ\n"
                "Ð±ÐµÐ· Ð¿ÐµÑ€ÐµÑˆÐºÐ¾Ð´.\n\n"
                "Ð—Ð¼Ñ–Ð½Ð° DND Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ Ð±ÑƒÐ´Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°\n"
                "Ð² Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¸Ñ… Ð²ÐµÑ€ÑÑ–ÑÑ… ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸."
            )
            
            keyboard = [
                [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:settings")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(message, reply_markup=reply_markup)

        elif param == "cancel_create":
            # Cancel task creation and clear state
            context.user_data.pop("creating_task", None)

            await query.edit_message_text(
                "âŒ **Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ ÑÐºÐ°ÑÐ¾Ð²Ð°Ð½Ð¾**\n\n"
                "ÐŸÐ¾Ð²ÐµÑ€Ñ‚Ð°Ñ”Ð¼Ð¾ÑÑŒ Ð´Ð¾ Ð³Ð¾Ð»Ð¾Ð²Ð½Ð¾Ð³Ð¾ Ð¼ÐµÐ½ÑŽ Ð¿Ð»Ð°Ð½Ð¾Ð²Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ.",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("ðŸ“‹ ÐÐ°Ð·Ð°Ð´ Ð´Ð¾ ÑÐ¿Ð¸ÑÐºÑƒ", callback_data="schedule:list")]
                ])
            )

        elif param == "change_max_tasks":
            # Handle changing max concurrent tasks
            config = await prompts_manager.load_prompts()
            system_settings = config.get("settings", {})
            current_max = system_settings.get("max_concurrent_tasks", 1)

            message = (
                "ðŸ”§ **Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ**\n\n"
                f"ðŸ“Š ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ: {current_max}\n\n"
                "ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ Ð½Ð¾Ð²Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ñ— ÐºÑ–Ð»ÑŒÐºÐ¾ÑÑ‚Ñ– Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ,\n"
                "ÑÐºÑ– Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ÑÑŒ Ð¾Ð´Ð½Ð¾Ñ‡Ð°ÑÐ½Ð¾:\n\n"
                "â€¢ **1** - Ð¿Ð¾ÑÐ»Ñ–Ð´Ð¾Ð²Ð½Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ (Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð¾Ð²Ð°Ð½Ð¾)\n"
                "â€¢ **2-3** - Ð¿Ð°Ñ€Ð°Ð»ÐµÐ»ÑŒÐ½Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ (Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÑ” Ð±Ñ–Ð»ÑŒÑˆÐµ Ñ€ÐµÑÑƒÑ€ÑÑ–Ð²)\n"
                "â€¢ **4+** - Ð²Ð¸ÑÐ¾ÐºÐµ Ð½Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ (Ð½Ðµ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð¾Ð²Ð°Ð½Ð¾)"
            )

            keyboard = [
                [
                    InlineKeyboardButton("1ï¸âƒ£ ÐžÐ´Ð½Ðµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:set_max:1"),
                    InlineKeyboardButton("2ï¸âƒ£ Ð”Ð²Ð° Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:set_max:2")
                ],
                [
                    InlineKeyboardButton("3ï¸âƒ£ Ð¢Ñ€Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:set_max:3"),
                    InlineKeyboardButton("4ï¸âƒ£ Ð§Ð¾Ñ‚Ð¸Ñ€Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:set_max:4")
                ],
                [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:advanced")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(message, reply_markup=reply_markup)

        elif param.startswith("set_max:"):
            # Handle setting max concurrent tasks
            new_max = int(param.split(":", 1)[1])
            config = await prompts_manager.load_prompts()

            if "settings" not in config:
                config["settings"] = {}
            config["settings"]["max_concurrent_tasks"] = new_max

            await prompts_manager.save_prompts(config)

            await query.edit_message_text(
                f"âœ… **ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾**\n\n"
                f"ðŸ”§ ÐœÐ°ÐºÑÐ¸Ð¼ÑƒÐ¼ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð²ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾: **{new_max}**\n\n"
                f"{'ðŸ“‹ Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸Ð¼ÑƒÑ‚ÑŒÑÑ Ð¿Ð¾ÑÐ»Ñ–Ð´Ð¾Ð²Ð½Ð¾' if new_max == 1 else f'âš¡ Ð”Ð¾ {new_max} Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ÑÑŒ Ð¿Ð°Ñ€Ð°Ð»ÐµÐ»ÑŒÐ½Ð¾'}\n\n"
                "ÐÐ¾Ð²Ñ– Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð±ÑƒÐ´ÑƒÑ‚ÑŒ Ð·Ð°ÑÑ‚Ð¾ÑÐ¾Ð²Ð°Ð½Ñ– Ð´Ð»Ñ Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ.",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("âš™ï¸ ÐÐ°Ð·Ð°Ð´ Ð´Ð¾ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½ÑŒ", callback_data="schedule:advanced")]
                ])
            )

        elif param == "change_timeout":
            # Handle changing task timeout
            config = await prompts_manager.load_prompts()
            system_settings = config.get("settings", {})
            current_timeout = system_settings.get("task_timeout", 300)

            message = (
                "â° **Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ñ‚Ð°Ð¹Ð¼-Ð°ÑƒÑ‚ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ**\n\n"
                f"ðŸ“Š ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ: {current_timeout} ÑÐµÐºÑƒÐ½Ð´\n\n"
                "ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ Ð½Ð¾Ð²Ð¸Ð¹ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ‡Ð°Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ:"
            )

            keyboard = [
                [
                    InlineKeyboardButton("ðŸ•‘ 2 Ñ…Ð² (120Ñ)", callback_data="schedule:set_timeout:120"),
                    InlineKeyboardButton("ðŸ•• 5 Ñ…Ð² (300Ñ)", callback_data="schedule:set_timeout:300")
                ],
                [
                    InlineKeyboardButton("ðŸ•™ 10 Ñ…Ð² (600Ñ)", callback_data="schedule:set_timeout:600"),
                    InlineKeyboardButton("ðŸ• 15 Ñ…Ð² (900Ñ)", callback_data="schedule:set_timeout:900")
                ],
                [
                    InlineKeyboardButton("ðŸ•• 30 Ñ…Ð² (1800Ñ)", callback_data="schedule:set_timeout:1800"),
                    InlineKeyboardButton("ðŸ• 60 Ñ…Ð² (3600Ñ)", callback_data="schedule:set_timeout:3600")
                ],
                [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:advanced")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(message, reply_markup=reply_markup)

        elif param.startswith("set_timeout:"):
            # Handle setting task timeout
            new_timeout = int(param.split(":", 1)[1])
            config = await prompts_manager.load_prompts()

            if "settings" not in config:
                config["settings"] = {}
            config["settings"]["task_timeout"] = new_timeout

            await prompts_manager.save_prompts(config)

            minutes = new_timeout // 60
            await query.edit_message_text(
                f"âœ… **ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾**\n\n"
                f"â° Ð¢Ð°Ð¹Ð¼-Ð°ÑƒÑ‚ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð²ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾: **{new_timeout}Ñ ({minutes} Ñ…Ð²)**\n\n"
                "Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ, ÑÐºÑ– Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸Ð¼ÑƒÑ‚ÑŒÑÑ Ð´Ð¾Ð²ÑˆÐµ Ð·Ð° Ñ†ÐµÐ¹ Ñ‡Ð°Ñ,\n"
                "Ð±ÑƒÐ´ÑƒÑ‚ÑŒ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ ÑÐºÐ°ÑÐ¾Ð²Ð°Ð½Ñ–.",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("âš™ï¸ ÐÐ°Ð·Ð°Ð´ Ð´Ð¾ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½ÑŒ", callback_data="schedule:advanced")]
                ])
            )

        elif param == "change_interval":
            # Handle changing check interval
            config = await prompts_manager.load_prompts()
            system_settings = config.get("settings", {})
            current_interval = system_settings.get("check_interval", 60)

            message = (
                "ðŸ”„ **Ð—Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸ Ñ–Ð½Ñ‚ÐµÑ€Ð²Ð°Ð» Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸**\n\n"
                f"ðŸ“Š ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ: {current_interval} ÑÐµÐºÑƒÐ½Ð´\n\n"
                "ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ ÑÐº Ñ‡Ð°ÑÑ‚Ð¾ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ‚Ð¸Ð¼Ðµ Ð½Ð¾Ð²Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð´Ð»Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ:"
            )

            keyboard = [
                [
                    InlineKeyboardButton("âš¡ 30Ñ", callback_data="schedule:set_interval:30"),
                    InlineKeyboardButton("ðŸ• 1Ñ…Ð² (60Ñ)", callback_data="schedule:set_interval:60")
                ],
                [
                    InlineKeyboardButton("ðŸ•• 2Ñ…Ð² (120Ñ)", callback_data="schedule:set_interval:120"),
                    InlineKeyboardButton("ðŸ•™ 5Ñ…Ð² (300Ñ)", callback_data="schedule:set_interval:300")
                ],
                [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:advanced")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(message, reply_markup=reply_markup)

        elif param.startswith("set_interval:"):
            # Handle setting check interval
            new_interval = int(param.split(":", 1)[1])
            config = await prompts_manager.load_prompts()

            if "settings" not in config:
                config["settings"] = {}
            config["settings"]["check_interval"] = new_interval

            await prompts_manager.save_prompts(config)

            minutes = new_interval // 60 if new_interval >= 60 else 0
            seconds = new_interval % 60
            time_str = f"{minutes}Ñ…Ð² {seconds}Ñ" if minutes > 0 else f"{seconds}Ñ"

            await query.edit_message_text(
                f"âœ… **ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾**\n\n"
                f"ðŸ”„ Ð†Ð½Ñ‚ÐµÑ€Ð²Ð°Ð» Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸ Ð²ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾: **{time_str}**\n\n"
                "Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ‚Ð¸Ð¼Ðµ Ð½Ð¾Ð²Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð· Ñ†Ð¸Ð¼ Ñ–Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ð¾Ð¼.",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("âš™ï¸ ÐÐ°Ð·Ð°Ð´ Ð´Ð¾ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½ÑŒ", callback_data="schedule:advanced")]
                ])
            )

        elif param == "toggle_logging":
            # Handle toggling logging
            config = await prompts_manager.load_prompts()
            system_settings = config.get("settings", {})
            current_logging = system_settings.get("logging_enabled", True)
            new_logging = not current_logging

            if "settings" not in config:
                config["settings"] = {}
            config["settings"]["logging_enabled"] = new_logging

            await prompts_manager.save_prompts(config)

            status = "ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾" if new_logging else "Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾"
            icon = "âœ…" if new_logging else "âŒ"

            await query.edit_message_text(
                f"âœ… **ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾**\n\n"
                f"ðŸ“ Ð›Ð¾Ð³ÑƒÐ²Ð°Ð½Ð½Ñ {icon} **{status}**\n\n"
                f"{'Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ– Ð»Ð¾Ð³Ð¸ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð·Ð°Ð¿Ð¸ÑÑƒÐ²Ð°Ñ‚Ð¸Ð¼ÑƒÑ‚ÑŒÑÑ Ð² ÑÐ¸ÑÑ‚ÐµÐ¼Ñƒ.' if new_logging else 'Ð›Ð¾Ð³ÑƒÐ²Ð°Ð½Ð½Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾ Ð´Ð»Ñ ÐµÐºÐ¾Ð½Ð¾Ð¼Ñ–Ñ— Ñ€ÐµÑÑƒÑ€ÑÑ–Ð².'}",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("âš™ï¸ ÐÐ°Ð·Ð°Ð´ Ð´Ð¾ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½ÑŒ", callback_data="schedule:advanced")]
                ])
            )

        elif param == "refresh":
            # Handle refresh tasks list
            # Simply redirect to list to reload data
            await handle_schedule_callback(query, context, "list")
            return

        elif param == "run_all":
            # Handle running all enabled tasks immediately
            config = await prompts_manager.load_prompts()
            prompts = config.get("prompts", [])
            enabled_prompts = [p for p in prompts if p.get("enabled", False)]

            if not enabled_prompts:
                await query.edit_message_text(
                    "âŒ **ÐÐµÐ¼Ð°Ñ” Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ**\n\n"
                    "Ð¡Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ ÑƒÐ²Ñ–Ð¼ÐºÐ½Ñ–Ñ‚ÑŒ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ, ÑÐºÑ– Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ð¾ Ð²Ð¸ÐºÐ¾Ð½Ð°Ñ‚Ð¸.",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ“‹ ÐŸÐ¾Ð²ÐµÑ€Ð½ÑƒÑ‚Ð¸ÑÑ Ð´Ð¾ ÑÐ¿Ð¸ÑÐºÑƒ", callback_data="schedule:list")]
                    ])
                )
                return

            # Show confirmation dialog
            message = (
                f"â–¶ï¸ **Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ð²ÑÑ– Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ?**\n\n"
                f"ðŸ“Š Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ: **{len(enabled_prompts)}**\n\n"
                "**Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð´Ð¾ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ:**\n"
            )

            for i, prompt in enumerate(enabled_prompts[:5], 1):
                title = prompt.get('title', 'Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð¸')
                message += f"{i}. {title}\n"

            if len(enabled_prompts) > 5:
                message += f"... Ñ‚Ð° Ñ‰Ðµ {len(enabled_prompts) - 5} Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ\n"

            message += (
                "\nâš ï¸ **Ð£Ð²Ð°Ð³Ð°:** Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð±ÑƒÐ´ÑƒÑ‚ÑŒ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ñ– Ð½ÐµÐ³Ð°Ð¹Ð½Ð¾,\n"
                "Ð½ÐµÐ·Ð°Ð»ÐµÐ¶Ð½Ð¾ Ð²Ñ–Ð´ Ñ€Ð¾Ð·ÐºÐ»Ð°Ð´Ñƒ.\n\n"
                "ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸?"
            )

            keyboard = [
                [
                    InlineKeyboardButton("âœ… Ð¢Ð°Ðº, Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸", callback_data="schedule:confirm_run_all"),
                    InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="schedule:list")
                ]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await query.edit_message_text(message, reply_markup=reply_markup)

        elif param == "confirm_run_all":
            # Handle confirmed run all tasks
            try:
                # Get the prompts manager and run tasks
                await query.edit_message_text(
                    "ðŸš€ **Ð—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ Ð²ÑÑ– Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ...**\n\n"
                    "â³ Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð·Ð°Ñ‡ÐµÐºÐ°Ð¹Ñ‚Ðµ..."
                )

                # Execute all enabled prompts
                config = await prompts_manager.load_prompts()
                prompts = config.get("prompts", [])
                enabled_prompts = [p for p in prompts if p.get("enabled", False)]

                executed_count = 0
                failed_count = 0

                for prompt in enabled_prompts:
                    try:
                        # Here you would call the actual execution logic
                        # For now, we'll just mark as executed
                        logger.info("Executing scheduled prompt",
                                  title=prompt.get('title', 'Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð¸'),
                                  user_id=query.from_user.id)

                        # TODO: Add actual prompt execution logic here
                        # await execute_prompt(prompt, context)

                        executed_count += 1
                    except Exception as e:
                        logger.error("Failed to execute prompt",
                                   title=prompt.get('title', 'Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð¸'),
                                   error=str(e))
                        failed_count += 1

                # Show results
                result_message = (
                    f"âœ… **Ð’Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾**\n\n"
                    f"ðŸ“ˆ Ð’Ð¸ÐºÐ¾Ð½Ð°Ð½Ð¾ ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾: **{executed_count}**\n"
                    f"âŒ ÐŸÐ¾Ð¼Ð¸Ð»Ð¾Ðº: **{failed_count}**\n\n"
                    f"ðŸ“‹ Ð’ÑÑ– Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ñ– Ð² Ð¾Ð±Ñ€Ð¾Ð±ÐºÑƒ."
                )

                if failed_count > 0:
                    result_message += f"\n\nâš ï¸ Ð”ÐµÑÐºÑ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð½Ðµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð²Ð¸ÐºÐ¾Ð½Ð°Ñ‚Ð¸. ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ð»Ð¾Ð³Ð¸."

                keyboard = [
                    [InlineKeyboardButton("ðŸ“‹ ÐŸÐ¾Ð²ÐµÑ€Ð½ÑƒÑ‚Ð¸ÑÑ Ð´Ð¾ ÑÐ¿Ð¸ÑÐºÑƒ", callback_data="schedule:list")]
                ]
                reply_markup = InlineKeyboardMarkup(keyboard)
                await query.edit_message_text(result_message, reply_markup=reply_markup)

            except Exception as e:
                logger.error("Error executing all tasks", error=str(e), user_id=query.from_user.id)
                await query.edit_message_text(
                    f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ**\n\n"
                    f"```\n{str(e)}\n```\n\n"
                    "Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ð°Ð±Ð¾ Ð·Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°.",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ“‹ ÐŸÐ¾Ð²ÐµÑ€Ð½ÑƒÑ‚Ð¸ÑÑ Ð´Ð¾ ÑÐ¿Ð¸ÑÐºÑƒ", callback_data="schedule:list")]
                    ])
                )

        elif param.startswith("time:"):
            # Handle time selection for task scheduling
            time_type = param.split(":", 1)[1]
            user_id = query.from_user.id

            if not context.user_data or not context.user_data.get('creating_task'):
                await query.edit_message_text(
                    "âŒ **Ð¡ÐµÑÑ–Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð·Ð°ÐºÑ–Ð½Ñ‡Ð¸Ð»Ð°ÑÑŒ**\n\n"
                    "ÐŸÐ¾Ñ‡Ð½Ñ–Ñ‚ÑŒ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ ÑÐ¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ:",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ“ Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:create_new")]
                    ])
                )
                return

            task_data = context.user_data['creating_task']
            task_data['schedule_type'] = time_type

            if time_type == "custom":
                # Ask user to input custom time
                task_data['step'] = 'custom_time'
                context.user_data['creating_task'] = task_data

                await query.edit_message_text(
                    "â° **ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ñ‡Ð°ÑÑƒ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ**\n\n"
                    "Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ñ‡Ð°Ñ Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ– **Ð“Ð“:Ð¥Ð¥** (24-Ð³Ð¾Ð´Ð¸Ð½Ð½Ð¸Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚)\n\n"
                    "**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸:**\n"
                    "â€¢ `08:30` - Ñ‰Ð¾Ñ€Ð°Ð½ÐºÑƒ Ð¾ 8:30\n"
                    "â€¢ `14:15` - Ñ‰Ð¾Ð´Ð½Ñ Ð¾ 14:15\n"
                    "â€¢ `23:00` - Ñ‰Ð¾Ð²ÐµÑ‡Ð¾Ñ€Ð° Ð¾ 23:00\n\n"
                    "ðŸ’¬ ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð· Ñ‡Ð°ÑÐ¾Ð¼:",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="schedule:cancel_create")]
                    ])
                )
            else:
                # Move to confirmation step
                task_data['step'] = 'confirm'
                context.user_data['creating_task'] = task_data

                from ..handlers.message import _show_task_confirmation
                await _show_task_confirmation(query, task_data)

        elif param == "confirm_task":
            # Handle task confirmation and creation
            user_id = query.from_user.id

            if not context.user_data or not context.user_data.get('creating_task'):
                await query.edit_message_text(
                    "âŒ **Ð¡ÐµÑÑ–Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð·Ð°ÐºÑ–Ð½Ñ‡Ð¸Ð»Ð°ÑÑŒ**\n\n"
                    "ÐŸÐ¾Ñ‡Ð½Ñ–Ñ‚ÑŒ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ ÑÐ¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ:",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ“ Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:create_new")]
                    ])
                )
                return

            task_data = context.user_data['creating_task']

            try:
                # Create new task using ScheduledPromptsManager
                from ..features.scheduled_prompts import ScheduledPromptsManager

                settings = context.bot_data.get("settings")
                if not settings:
                    await query.edit_message_text(
                        "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸**\n\n"
                        "ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸."
                    )
                    return

                prompts_manager = ScheduledPromptsManager(context.application, settings)
                config = await prompts_manager.load_prompts()

                # Generate unique task ID
                import uuid
                task_id = f"user_task_{uuid.uuid4().hex[:8]}"

                # Create task object
                new_task = {
                    "id": task_id,
                    "title": f"ÐšÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ†ÑŒÐºÐµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ ({task_data['schedule_type']})",
                    "description": task_data['prompt'][:100] + ("..." if len(task_data['prompt']) > 100 else ""),
                    "prompt": task_data['prompt'],
                    "enabled": True,
                    "schedule": {
                        "type": task_data['schedule_type'],
                        "time": task_data.get('custom_time', '08:00')
                    },
                    "auto_execute": True,
                    "auto_respond": True,
                    "created_by": user_id,
                    "created_at": datetime.now().isoformat()
                }

                # Add task to configuration
                if "prompts" not in config:
                    config["prompts"] = []
                config["prompts"].append(new_task)

                # Save updated configuration
                await prompts_manager.save_prompts(config)

                # Clear creation state
                context.user_data.pop("creating_task", None)

                # Show success message
                schedule_desc = {
                    'dnd': 'Ð¿Ñ–Ð´ Ñ‡Ð°Ñ DND Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ (23:00-08:00)',
                    'morning': 'Ñ‰Ð¾Ñ€Ð°Ð½ÐºÑƒ Ð¾ 08:00',
                    'evening': 'Ñ‰Ð¾Ð²ÐµÑ‡Ð¾Ñ€Ð° Ð¾ 20:00',
                    'daily': 'Ñ‰Ð¾Ð´ÐµÐ½Ð½Ð¾ Ð¾ 08:00',
                    'weekly': 'Ñ‰Ð¾Ñ‚Ð¸Ð¶Ð½Ñ (Ð¿Ð¾Ð½ÐµÐ´Ñ–Ð»Ð¾Ðº Ð¾ 09:00)',
                    'custom': f'Ñ‰Ð¾Ð´ÐµÐ½Ð½Ð¾ Ð¾ {task_data.get("custom_time", "Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ‡Ð°Ñ")}'
                }

                await query.edit_message_text(
                    f"âœ… **Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð¾ ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾!**\n\n"
                    f"**ðŸ“ Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ:** {task_data['prompt'][:150]}{'...' if len(task_data['prompt']) > 150 else ''}\n\n"
                    f"**â° Ð Ð¾Ð·ÐºÐ»Ð°Ð´:** {schedule_desc.get(task_data['schedule_type'], 'Ð½Ðµ Ð²ÐºÐ°Ð·Ð°Ð½Ð¾')}\n\n"
                    f"**ðŸ”§ ID:** `{task_id}`\n\n"
                    f"Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð±ÑƒÐ´Ðµ Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ÑÑŒ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð·Ð³Ñ–Ð´Ð½Ð¾ Ñ€Ð¾Ð·ÐºÐ»Ð°Ð´Ñƒ.",
                    reply_markup=InlineKeyboardMarkup([
                        [
                            InlineKeyboardButton("ðŸ“‹ ÐŸÐµÑ€ÐµÐ³Ð»ÑÐ½ÑƒÑ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:list"),
                            InlineKeyboardButton("âž• Ð©Ðµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:create_new")
                        ]
                    ])
                )

            except Exception as e:
                logger.error("Error creating scheduled task", error=str(e), user_id=user_id)
                await query.edit_message_text(
                    f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ**\n\n"
                    f"Ð’Ð¸Ð½Ð¸ÐºÐ»Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°: {str(e)}\n\n"
                    f"Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ.",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:list")]
                    ])
                )

        elif param == "edit_task":
            # Handle task editing (simple version - just restart creation)
            context.user_data.pop("creating_task", None)

            await query.edit_message_text(
                "âœï¸ **Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ**\n\n"
                "Ð”Ð»Ñ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ ÑÑ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð·Ð°Ð½Ð¾Ð²Ð¾ Ð· Ð½Ð¾Ð²Ð¸Ð¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸.\n\n"
                "ÐŸÐ¾Ñ‡Ð°Ñ‚Ð¸ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ ÑÐ¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ?",
                reply_markup=InlineKeyboardMarkup([
                    [
                        InlineKeyboardButton("ðŸ“ Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:create_new"),
                        InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:list")
                    ]
                ])
            )

        else:
            user_id = query.from_user.id
            await query.edit_message_text(
                await t(context, user_id, "callback_errors.unknown_action") + f": {param}"
            )
            
    except Exception as e:
        logger.error("Error in schedule callback", error=str(e))
        user_id = query.from_user.id
        await query.edit_message_text(
            await t(context, user_id, "errors.unexpected_error")
        )


async def _handle_settings_action(query, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle settings action."""
    user_id = query.from_user.id
    
    try:
        # Create settings keyboard
        keyboard = [
            [
                InlineKeyboardButton(await t(context, user_id, "buttons.help"), callback_data="action:help"),
                InlineKeyboardButton("ðŸ”™ " + await t(context, user_id, "buttons.back"), callback_data="action:quick_actions")
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        settings_text = await t(context, user_id, "commands.settings.title")
        description_text = await t(context, user_id, "commands.settings.description")
        
        await query.edit_message_text(
            f"âš™ï¸ **{settings_text}**\n\n{description_text}",
            reply_markup=reply_markup
        )
    except Exception as e:
        logger.error("Error in settings action", error=str(e))
        await query.edit_message_text(await t(context, user_id, "errors.unexpected_error"))


async def _handle_main_menu_action(query, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle main menu action - unified with start command."""
    user_id = query.from_user.id

    try:
        logger.info("ðŸ” DEBUG: Creating FULL main menu for user", user_id=user_id, function="main_menu_action")

        # Create unified main menu keyboard matching start command layout
        keyboard = [
            [
                InlineKeyboardButton(await t(context, user_id, "buttons.new_session"), callback_data="action:new_session"),
                InlineKeyboardButton(await t(context, user_id, "buttons.continue_session"), callback_data="action:continue")
            ],
            [
                InlineKeyboardButton(await t(context, user_id, "buttons.show_projects"), callback_data="action:show_projects"),
                InlineKeyboardButton(await t(context, user_id, "buttons.status"), callback_data="action:status")
            ],
            [
                InlineKeyboardButton(await t(context, user_id, "buttons.export"), callback_data="action:export"),
                InlineKeyboardButton(await t(context, user_id, "buttons.settings"), callback_data="action:settings")
            ],
            [
                InlineKeyboardButton(await t(context, user_id, "buttons.help"), callback_data="action:help"),
                InlineKeyboardButton(await t(context, user_id, "buttons.language_settings"), callback_data="lang:select")
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        # Build full welcome message like in start command
        welcome_text = await t(context, user_id, "commands.start.welcome", name=query.from_user.first_name)
        description_text = await t(context, user_id, "commands.start.description")
        available_commands_text = await t(context, user_id, "commands.start.available_commands")

        help_cmd_text = await t(context, user_id, "commands.start.help_cmd")
        new_cmd_text = await t(context, user_id, "commands.start.new_cmd")
        ls_cmd_text = await t(context, user_id, "commands.start.ls_cmd")
        cd_cmd_text = await t(context, user_id, "commands.start.cd_cmd")
        projects_cmd_text = await t(context, user_id, "commands.start.projects_cmd")
        status_cmd_text = await t(context, user_id, "commands.start.status_cmd")
        actions_cmd_text = await t(context, user_id, "commands.start.actions_cmd")
        git_cmd_text = await t(context, user_id, "commands.start.git_cmd")

        quick_start_text = await t(context, user_id, "commands.start.quick_start")
        quick_start_1_text = await t(context, user_id, "commands.start.quick_start_1")
        quick_start_2_text = await t(context, user_id, "commands.start.quick_start_2")
        quick_start_3_text = await t(context, user_id, "commands.start.quick_start_3")

        security_note_text = await t(context, user_id, "commands.start.security_note")
        usage_note_text = await t(context, user_id, "commands.start.usage_note")

        welcome_message = (
            f"{welcome_text}\n\n"
            f"{description_text}\n\n"
            f"{available_commands_text}\n"
            f"â€¢ `/help` - {help_cmd_text}\n"
            f"â€¢ `/new` - {new_cmd_text}\n"
            f"â€¢ `/ls` - {ls_cmd_text}\n"
            f"â€¢ `/cd <dir>` - {cd_cmd_text}\n"
            f"â€¢ `/projects` - {projects_cmd_text}\n"
            f"â€¢ `/status` - {status_cmd_text}\n"
            f"â€¢ `/actions` - {actions_cmd_text}\n"
            f"â€¢ `/git` - {git_cmd_text}\n\n"
            f"{quick_start_text}\n"
            f"1. {quick_start_1_text}\n"
            f"2. {quick_start_2_text}\n"
            f"3. {quick_start_3_text}\n\n"
            f"âš ï¸ {security_note_text}\n"
            f"ðŸ’¡ {usage_note_text}"
        )

        logger.info("Main menu created successfully", user_id=user_id, keyboard_rows=len(keyboard), total_buttons=sum(len(row) for row in keyboard))

        await query.edit_message_text(
            welcome_message,
            reply_markup=reply_markup
        )
    except Exception as e:
        logger.error("Error in main menu action", error=str(e), user_id=user_id, exc_info=True)
        try:
            await query.edit_message_text(await t(context, user_id, "errors.unexpected_error"))
        except Exception as nested_e:
            logger.error("Failed to send error message for main menu", error=str(nested_e), user_id=user_id)


def _format_file_size(size: int) -> str:
    """Format file size in human-readable format."""
    for unit in ["B", "KB", "MB", "GB"]:
        if size < 1024:
            return f"{size:.1f}{unit}" if unit != "B" else f"{size}B"
        size /= 1024
    return f"{size:.1f}TB"


# NEW CALLBACK HANDLERS FROM GROK ALL-FIX

async def handle_prompts_settings_callback(query, param: str, context: ContextTypes.DEFAULT_TYPE):
    """Handle 'ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ' button."""
    await query.answer()
    try:
        user_id = query.from_user.id
        settings_text = await t(context, user_id, "settings.title")
        await query.edit_message_text(
            text=settings_text,
            # reply_markup=get_settings_keyboard(query.from_user.id)  # TODO: implement
        )
        logger.info("Prompts settings callback", user_id=user_id)
    except Exception as e:
        await query.edit_message_text(await t(context, query.from_user.id, "errors.settings_failed"))
        logger.error("Settings callback error", error=str(e))

async def handle_save_code_callback(query, param: str, context: ContextTypes.DEFAULT_TYPE):
    """Handle 'Save Code' button."""
    await query.answer()
    try:
        user_id = query.from_user.id
        # Assuming storage save logic
        # from src.storage.facade import Storage
        # storage = context.application.bot_data.get('storage')
        # await storage.save_code(user_id, context.user_data.get('current_code', ''))
        await query.edit_message_text(await t(context, user_id, "session.save_complete"))
        logger.info("Code saved", user_id=user_id)
    except Exception as e:
        await query.edit_message_text(await t(context, query.from_user.id, "errors.save_failed", error=str(e)))

async def handle_continue_callback(query, param: str, context: ContextTypes.DEFAULT_TYPE):
    """Handle 'Continue Session' button - allows user to ask follow-up questions."""
    await query.answer()
    try:
        user_id = query.from_user.id

        # Remove buttons and prepare for continuation
        continue_text = await t(
            context, user_id, "buttons.continue_prompt",
            fallback="âœ… **Ð“Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð´Ð¾ Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶ÐµÐ½Ð½Ñ!**\n\n"
                     "ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð²Ð°ÑˆÐµ Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ Ð°Ð±Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚:\n"
                     "â€¢ Ð”Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ñ– ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð½Ñ Ñ‰Ð¾Ð´Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸\n"
                     "â€¢ Ð—Ð°Ð¿Ð¸Ñ‚ Ð½Ð° Ð²Ð¿Ñ€Ð¾Ð²Ð°Ð´Ð¶ÐµÐ½Ð½Ñ Ð·Ð¼Ñ–Ð½\n"
                     "â€¢ ÐŸÐ¸Ñ‚Ð°Ð½Ð½Ñ Ð¿Ñ€Ð¾ Ñ€Ñ–ÑˆÐµÐ½Ð½Ñ\n"
                     "â€¢ Ð†Ð½ÑˆÑ– Ð¿Ð¾Ð±Ð°Ð¶Ð°Ð½Ð½Ñ\n\n"
                     "_ÐžÑ‡Ñ–ÐºÑƒÑŽ Ð²Ð°ÑˆÐµ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ..._"
        )

        await query.edit_message_text(continue_text)

        # Set flag that user wants to continue conversation
        if not context.user_data:
            context.user_data = {}
        context.user_data['awaiting_continuation'] = True

    except Exception as e:
        error_text = await t(context, query.from_user.id, "errors.continue_failed", fallback="âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶ÐµÐ½Ð½Ñ Ð´Ñ–Ð°Ð»Ð¾Ð³Ñƒ")
        await query.edit_message_text(error_text)

async def handle_explain_callback(query, param: str, context: ContextTypes.DEFAULT_TYPE):
    """Handle 'Explain' button - asks Claude to explain the previous response."""
    await query.answer()
    try:
        user_id = query.from_user.id

        # Show processing message
        processing_text = await t(
            context, user_id, "explain.processing",
            fallback="ðŸ¤” **ÐŸÐ¾ÑÑÐ½ÑŽÑŽ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ–ÑˆÐµ...**\n\n_ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ Ð¿Ð¾Ð¿ÐµÑ€ÐµÐ´Ð½ÑŽ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ñ‚Ð° Ð³Ð¾Ñ‚ÑƒÑŽ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ðµ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð½Ñ..._"
        )
        await query.edit_message_text(processing_text)

        # Get Claude integration
        claude_integration = context.bot_data.get('claude_integration')
        if not claude_integration:
            error_text = await t(context, user_id, "errors.service_unavailable", fallback="âŒ Ð¡ÐµÑ€Ð²Ñ–Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹")
            await query.edit_message_text(error_text)
            return

        # Get current directory
        settings = context.bot_data.get("settings")
        if not settings:
            current_dir = Path.cwd()
        else:
            current_dir = context.user_data.get(
                'current_directory',
                settings.approved_directory
            ) if context.user_data else settings.approved_directory

        # Create explanation prompt in Ukrainian
        explain_prompt = (
            "Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð´Ð°Ð¹Ñ‚Ðµ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ðµ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð½Ñ Ð²Ð°ÑˆÐ¾Ñ— Ð¿Ð¾Ð¿ÐµÑ€ÐµÐ´Ð½ÑŒÐ¾Ñ— Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ–:\n\n"
            "1. **ÐŸÐ¾ÑÑÐ½Ñ–Ñ‚ÑŒ ÐºÐ¾Ð¶ÐµÐ½ ÐºÑ€Ð¾Ðº** ÑÐºÐ¸Ð¹ Ð²Ð¸ Ð·Ð°Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÐ²Ð°Ð»Ð¸\n"
            "2. **Ð§Ð¾Ð¼Ñƒ ÑÐ°Ð¼Ðµ Ñ‚Ð°ÐºÐ¸Ð¹ Ð¿Ñ–Ð´Ñ…Ñ–Ð´** Ñ” Ð½Ð°Ð¹ÐºÑ€Ð°Ñ‰Ð¸Ð¼?\n"
            "3. **Ð¯ÐºÑ– Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð¸** Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ñ–?\n"
            "4. **ÐŸÐ¾Ñ‚ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ– Ñ€Ð¸Ð·Ð¸ÐºÐ¸** Ñ‚Ð° ÑÐº Ñ—Ñ… ÑƒÐ½Ð¸ÐºÐ½ÑƒÑ‚Ð¸\n"
            "5. **Ð©Ð¾ Ð±ÑƒÐ´Ðµ Ð¿Ñ–ÑÐ»Ñ Ð²Ð¿Ñ€Ð¾Ð²Ð°Ð´Ð¶ÐµÐ½Ð½Ñ** Ð·Ð¼Ñ–Ð½?\n\n"
            "Ð”Ð°Ð¹Ñ‚Ðµ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ðµ Ñ‚Ð° Ð·Ñ€Ð¾Ð·ÑƒÐ¼Ñ–Ð»Ðµ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð½Ñ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ Ð¼Ð¾Ð²Ð¾ÑŽ."
        )

        # Run Claude command for explanation
        claude_response = await claude_integration.run_command(
            prompt=explain_prompt,
            working_directory=current_dir,
            user_id=user_id,
            session_id=context.user_data.get('claude_session_id') if context.user_data else None
        )

        if claude_response and claude_response.content:
            # Format the explanation response
            explanation_text = f"ðŸ’¡ **Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ðµ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð½Ñ:**\n\n{claude_response.content}"

            # Create new Continue button for further questions
            from telegram import InlineKeyboardButton, InlineKeyboardMarkup
            keyboard = InlineKeyboardMarkup([
                [InlineKeyboardButton("ðŸ”„ ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸ Ð´Ñ–Ð°Ð»Ð¾Ð³", callback_data="continue")]
            ])

            await query.edit_message_text(explanation_text, reply_markup=keyboard, parse_mode='Markdown')
        else:
            error_text = await t(context, user_id, "explain.no_response", fallback="âŒ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð½Ñ")
            await query.edit_message_text(error_text)

    except Exception as e:
        error_text = await t(context, query.from_user.id, "errors.explain_failed", fallback="âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð½Ñ Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð½Ñ")
        await query.edit_message_text(error_text)

async def handle_refresh_callback(query, param: str, context: ContextTypes.DEFAULT_TYPE):
    """Fixed: Hardcoded 'ðŸ”„ ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸'."""
    await query.answer()
    try:
        user_id = query.from_user.id
        refresh_text = await t(context, user_id, "buttons.refresh")
        current_status = await t(context, user_id, "status.title")
        await query.edit_message_text(refresh_text + "\n\n" + current_status)
    except Exception as e:
        from ..utils.error_handler import safe_user_error
        await safe_user_error(query, context, "errors.refresh_failed", e)


async def _handle_template_selection(query, template_type: str, context: ContextTypes.DEFAULT_TYPE):
    """Handle selection of task template."""
    user_id = query.from_user.id

    # Get task scheduler from context
    task_scheduler = context.bot_data.get("task_scheduler")
    if not task_scheduler:
        await query.edit_message_text(
            "âŒ **Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°**\n\n"
            "Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð½Ðµ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð°."
        )
        return

    try:
        # Get template configuration
        from ..features.task_scheduler import TaskScheduler

        template_configs = {
            "code_analysis": {
                "title": "ðŸ” ÐÐ½Ð°Ð»Ñ–Ð· ÐºÐ¾Ð´Ñƒ",
                "description": "ÐŸÐ¾Ð²Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ Ñ‚Ð° Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸",
                **TaskScheduler.create_code_analysis_task(
                    user_id,
                    str(context.user_data.get("current_directory", "/"))
                )
            },
            "report_generation": {
                "title": "ðŸ“Š Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ Ð·Ð²Ñ–Ñ‚Ñ–Ð²",
                "description": "Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð²Ñ–Ñ‚Ñ–Ð² Ñ‚Ð° ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸",
                "task_type": "report_generation",
                "prompt": """Ð—Ð³ÐµÐ½ÐµÑ€ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ð¸Ð¹ Ð·Ð²Ñ–Ñ‚ Ð¿Ñ€Ð¾ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚:

1. **Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÐºÐ¾Ð´Ñƒ**: ÐŸÑ–Ð´Ñ€Ð°Ñ…ÑƒÐ¹Ñ‚Ðµ Ñ€ÑÐ´ÐºÐ¸ ÐºÐ¾Ð´Ñƒ, Ñ„Ð°Ð¹Ð»Ð¸, ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¸
2. **Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ**: ÐžÐ¿Ð¸ÑˆÑ–Ñ‚ÑŒ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ñ‚Ð° Ð¾Ñ€Ð³Ð°Ð½Ñ–Ð·Ð°Ñ†Ñ–ÑŽ
3. **Ð—Ð°Ð»ÐµÐ¶Ð½Ð¾ÑÑ‚Ñ–**: ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ð½Ñ– Ð±Ñ–Ð±Ð»Ñ–Ð¾Ñ‚ÐµÐºÐ¸
4. **ÐŸÐ¾ÐºÑ€Ð¸Ñ‚Ñ‚Ñ Ñ‚ÐµÑÑ‚Ð°Ð¼Ð¸**: ÐžÑ†Ñ–Ð½Ñ–Ñ‚ÑŒ Ñ‚ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ (ÑÐºÑ‰Ð¾ Ñ”)
5. **ÐŸÑ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ**: Ð’Ð¸ÑÐ²Ñ–Ñ‚ÑŒ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸
6. **Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ—**: Ð”Ð°Ð¹Ñ‚Ðµ Ð¿Ð¾Ñ€Ð°Ð´Ð¸ Ñ‰Ð¾Ð´Ð¾ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ

Ð¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð·Ð²Ñ–Ñ‚ Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ– Markdown.""",
                "metadata": {"report_type": "comprehensive"}
            },
            "refactoring": {
                "title": "âš’ï¸ Ð ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³",
                "description": "ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ Ñ‚Ð° Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ ÐºÐ¾Ð´Ñƒ",
                **TaskScheduler.create_refactoring_task(user_id)
            },
            "documentation": {
                "title": "ðŸ“ Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ",
                "description": "Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ñ‚Ð° Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—",
                **TaskScheduler.create_documentation_task(user_id, "readme")
            },
            "security_audit": {
                "title": "ðŸ”’ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð±ÐµÐ·Ð¿ÐµÐºÐ¸",
                "description": "ÐÐ½Ð°Ð»Ñ–Ð· ÑƒÑ€Ð°Ð·Ð»Ð¸Ð²Ð¾ÑÑ‚ÐµÐ¹ Ñ‚Ð° Ð±ÐµÐ·Ð¿ÐµÐºÐ¸",
                **TaskScheduler.create_code_analysis_task(user_id, str(context.user_data.get("current_directory", "/")), "security")
            },
            "testing": {
                "title": "ðŸ§ª Ð¢ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ",
                "description": "Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ Ñ‚Ð° Ð·Ð°Ð¿ÑƒÑÐº Ñ‚ÐµÑÑ‚Ñ–Ð²",
                "task_type": "testing",
                "prompt": """Ð¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ Ñ‚Ð° Ð·Ð°Ð¿ÑƒÑÑ‚Ñ–Ñ‚ÑŒ Ñ‚ÐµÑÑ‚Ð¸ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ:

1. **ÐÐ½Ð°Ð»Ñ–Ð· Ð¿Ð¾ÐºÑ€Ð¸Ñ‚Ñ‚Ñ**: ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ñ–ÑÐ½ÑƒÑŽÑ‡Ñ– Ñ‚ÐµÑÑ‚Ð¸
2. **Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ Ñ‚ÐµÑÑ‚Ñ–Ð²**: Ð¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ Ð½Ð¾Ð²Ñ– unit-Ñ‚ÐµÑÑ‚Ð¸ Ð´Ð»Ñ Ð½ÐµÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¸Ñ… Ñ„ÑƒÐ½ÐºÑ†Ñ–Ð¹
3. **Ð†Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ð¹Ð½Ñ– Ñ‚ÐµÑÑ‚Ð¸**: Ð”Ð¾Ð´Ð°Ð¹Ñ‚Ðµ Ñ‚ÐµÑÑ‚Ð¸ Ð´Ð»Ñ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¸Ñ… ÑÑ†ÐµÐ½Ð°Ñ€Ñ–Ñ—Ð²
4. **Ð¢ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸**: ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ ÑƒÑ€Ð°Ð·Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ–
5. **Ð—Ð°Ð¿ÑƒÑÐº Ñ‚ÐµÑÑ‚Ñ–Ð²**: Ð’Ð¸ÐºÐ¾Ð½Ð°Ð¹Ñ‚Ðµ Ð²ÑÑ– Ñ‚ÐµÑÑ‚Ð¸ Ñ‚Ð° Ð¾Ð¿Ð¸ÑˆÑ–Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¸
6. **Ð—Ð²Ñ–Ñ‚**: Ð¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ Ð·Ð²Ñ–Ñ‚ Ð· Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–ÑÐ¼Ð¸

Ð—Ð¾ÑÐµÑ€ÐµÐ´ÑŒÑ‚ÐµÑÑ Ð½Ð° Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ– ÑÐºÐ¾ÑÑ‚Ñ– ÐºÐ¾Ð´Ñƒ Ñ‡ÐµÑ€ÐµÐ· Ñ‚ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ.""",
                "metadata": {"test_type": "comprehensive"}
            }
        }

        template_config = template_configs.get(template_type)
        if not template_config:
            await query.edit_message_text(
                "âŒ **ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¸Ð¹ ÑˆÐ°Ð±Ð»Ð¾Ð½**\n\n"
                f"Ð¨Ð°Ð±Ð»Ð¾Ð½ '{template_type}' Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾."
            )
            return

        # Show template details and confirmation
        message = (
            f"{template_config['title']}\n\n"
            f"**ÐžÐ¿Ð¸Ñ**: {template_config['description']}\n\n"
            f"**Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ**:\n{template_config['prompt'][:300]}...\n\n"
            "**ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¸ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ**:\n"
            "â€¢ ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ: âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾\n"
            "â€¢ ÐÐ²Ñ‚Ð¾Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ–: âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾\n"
            "â€¢ ÐŸÑ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚: ðŸ”¥ Ð’Ð¸ÑÐ¾ÐºÐ¸Ð¹\n\n"
            "_ÐŸÑ–Ð´Ñ‚Ð²ÐµÑ€Ð´Ñ–Ñ‚ÑŒ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ_"
        )

        keyboard = [
            [
                InlineKeyboardButton("âœ… Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data=f"schedule:confirm_template:{template_type}"),
                InlineKeyboardButton("âœï¸ Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸", callback_data=f"schedule:edit_template:{template_type}")
            ],
            [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:from_template")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        await query.edit_message_text(message, reply_markup=reply_markup)

    except Exception as e:
        logger.error("Error handling template selection", error=str(e), template_type=template_type)
        await query.edit_message_text(
            "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ ÑˆÐ°Ð±Ð»Ð¾Ð½Ñƒ**\n\n"
            f"Ð’Ð¸Ð½Ð¸ÐºÐ»Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð¾Ð±Ñ†Ñ– ÑˆÐ°Ð±Ð»Ð¾Ð½Ñƒ: {str(e)}"
        )


async def handle_quick_action_execution_callback(
    query, action_type: str, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle quick action execution callbacks - the new functional buttons."""
    user_id = query.from_user.id
    settings: Settings = context.bot_data["settings"]

    try:
        # Get Claude integration
        claude_integration: ClaudeIntegration = context.bot_data.get("claude_integration")
        if not claude_integration:
            error_text = await get_localized_text(context, user_id, "errors.claude_not_available")
            await query.edit_message_text(error_text, parse_mode=None)
            return

        current_dir = context.user_data.get(
            "current_directory", settings.approved_directory
        )

        # Show executing message
        executing_text = await get_localized_text(context, user_id, "messages.executing_action", action=action_type)
        await query.edit_message_text(executing_text, parse_mode=None)

        # Define action commands mapping
        action_commands = {
            "ls": "ls -la",
            "pwd": "pwd",
            "git_status": "git status",
            "git_diff": "git diff --color=never",
            "git_log": "git log --oneline -10",
            "grep": "grep -r \"TODO\\|FIXME\\|BUG\" . --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" || echo 'No TODO/FIXME/BUG found'",
            "find_files": "find . -type f -name \"*.py\" -o -name \"*.js\" -o -name \"*.ts\" | head -20",
            "disk_usage": "du -sh * 2>/dev/null | sort -hr | head -10",
            "processes": "ps aux | head -10"
        }

        # Get command for action
        command = action_commands.get(action_type)
        if not command:
            error_text = await get_localized_text(context, user_id, "errors.action_not_found", action=action_type)
            await query.edit_message_text(error_text, parse_mode=None)
            return

        # Execute command through Claude
        claude_response = await claude_integration.run_command(
            prompt=f"Ð’Ð¸ÐºÐ¾Ð½Ð°Ð¹ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ: {command}",
            working_directory=current_dir,
            user_id=user_id
        )

        if claude_response and claude_response.content:
            # Show results with Continue button
            result_text = f"âœ… **Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ {action_type}:**\n\n{claude_response.content}"

            # Truncate if too long
            if len(result_text) > 4000:
                result_text = result_text[:4000] + "...\n\n_(Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¾Ð±Ñ€Ñ–Ð·Ð°Ð½Ð¾)_"

            # Add action buttons
            keyboard = [
                [
                    InlineKeyboardButton("ðŸ”„ ÐŸÑ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸", callback_data="conversation:continue"),
                    InlineKeyboardButton("ðŸ“‹ ÐœÐµÐ½ÑŽ", callback_data="action:quick_actions")
                ]
            ]

            # Add specific action buttons based on action type
            if action_type == "ls":
                keyboard.insert(0, [
                    InlineKeyboardButton("ðŸ“– Ð§Ð¸Ñ‚Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»", callback_data="file_edit:select_read"),
                    InlineKeyboardButton("âœï¸ Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»", callback_data="file_edit:select_edit")
                ])
            elif action_type == "git_status":
                keyboard.insert(0, [
                    InlineKeyboardButton("ðŸ“Š Git diff", callback_data="quick_action:git_diff"),
                    InlineKeyboardButton("ðŸ“œ Git log", callback_data="quick_action:git_log")
                ])

            reply_markup = InlineKeyboardMarkup(keyboard)

            await query.edit_message_text(
                result_text,
                parse_mode=None,
                reply_markup=reply_markup
            )
        else:
            failed_text = await get_localized_text(context, user_id, "messages.action_failed", action=action_type)
            await query.edit_message_text(failed_text, parse_mode=None)

    except Exception as e:
        logger.error("Quick action execution failed", error=str(e), user_id=user_id, action_type=action_type)
        error_text = await get_localized_text(context, user_id, "errors.action_error", action=action_type, error=str(e))
        await query.edit_message_text(error_text, parse_mode=None)


async def handle_file_edit_callback(
    query, action_type: str, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle file editing workflow through Telegram interface."""
    user_id = query.from_user.id
    settings: Settings = context.bot_data["settings"]

    try:
        current_dir = context.user_data.get("current_directory", settings.approved_directory)

        if action_type == "select_read":
            # Step 1: Show file selection for reading
            await query.edit_message_text(
                "ðŸ“– **Ð§Ð¸Ñ‚Ð°Ð½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñƒ**\n\n"
                "ðŸ“ Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ ÑÐºÐ¸Ð¹ Ñ…Ð¾Ñ‡ÐµÑ‚Ðµ Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚Ð¸:\n\n"
                "**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸:**\n"
                "â€¢ `main.py`\n"
                "â€¢ `src/config.py` \n"
                "â€¢ `README.md`\n\n"
                "ðŸ’¬ ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð· Ð½Ð°Ð·Ð²Ð¾ÑŽ Ñ„Ð°Ð¹Ð»Ñƒ.",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="action:quick_actions")]
                ])
            )

            # Set state for waiting for filename
            context.user_data["file_action"] = {"type": "read", "step": "waiting_filename"}

        elif action_type == "select_edit":
            # Step 1: Show file selection for editing
            await query.edit_message_text(
                "âœï¸ **Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñƒ**\n\n"
                "ðŸ“ Ð’Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð½Ð°Ð·Ð²Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ ÑÐºÐ¸Ð¹ Ñ…Ð¾Ñ‡ÐµÑ‚Ðµ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸:\n\n"
                "**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸:**\n"
                "â€¢ `main.py`\n"
                "â€¢ `src/config.py`\n"
                "â€¢ `README.md`\n\n"
                "ðŸ”„ **ÐŸÑ€Ð¾Ñ†ÐµÑ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ:**\n"
                "1. Ð¯ Ð½Ð°Ð´Ñ–ÑˆÐ»ÑŽ Ð²Ð°Ð¼ Ñ„Ð°Ð¹Ð»\n"
                "2. Ð’Ð¸ Ñ€ÐµÐ´Ð°Ð³ÑƒÑ”Ñ‚Ðµ Ð¹Ð¾Ð³Ð¾ Ð² Ð·Ð¾Ð²Ð½Ñ–ÑˆÐ½ÑŒÐ¾Ð¼Ñƒ Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¾Ñ€Ñ–\n"
                "3. ÐÐ°Ð´ÑÐ¸Ð»Ð°Ñ”Ñ‚Ðµ Ð²Ñ–Ð´Ñ€ÐµÐ´Ð°Ð³Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ„Ð°Ð¹Ð» Ð½Ð°Ð·Ð°Ð´\n"
                "4. Ð¯ Ð·Ð±ÐµÑ€Ñ–Ð³Ð°ÑŽ Ð·Ð¼Ñ–Ð½Ð¸\n\n"
                "ðŸ’¬ ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð· Ð½Ð°Ð·Ð²Ð¾ÑŽ Ñ„Ð°Ð¹Ð»Ñƒ.",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸", callback_data="action:quick_actions")]
                ])
            )

            # Set state for waiting for filename
            context.user_data["file_action"] = {"type": "edit", "step": "waiting_filename"}

        elif action_type.startswith("download:"):
            # Step 2: Download file for editing
            filename = action_type.replace("download:", "")

            # Validate and read file
            file_path = current_dir / filename

            if not file_path.exists():
                await query.edit_message_text(
                    f"âŒ **Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾**\n\n"
                    f"Ð¤Ð°Ð¹Ð» `{filename}` Ð½Ðµ Ñ–ÑÐ½ÑƒÑ” Ð² Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñ–Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—.\n\n"
                    f"ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ð½Ð°Ð·Ð²Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ Ñ‚Ð° ÑÐ¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·.",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_edit")]
                    ])
                )
                return

            if not file_path.is_file():
                await query.edit_message_text(
                    f"âŒ **Ð¦Ðµ Ð½Ðµ Ñ„Ð°Ð¹Ð»**\n\n"
                    f"`{filename}` Ñ” Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ”ÑŽ, Ð° Ð½Ðµ Ñ„Ð°Ð¹Ð»Ð¾Ð¼.\n\n"
                    f"Ð’Ð¸Ð±ÐµÑ€Ñ–Ñ‚ÑŒ Ñ„Ð°Ð¹Ð» Ð´Ð»Ñ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ.",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_edit")]
                    ])
                )
                return

            # Check file size (Telegram limit ~50MB, but let's be conservative)
            file_size = file_path.stat().st_size
            if file_size > 20 * 1024 * 1024:  # 20MB limit
                await query.edit_message_text(
                    f"âŒ **Ð¤Ð°Ð¹Ð» Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ Ð²ÐµÐ»Ð¸ÐºÐ¸Ð¹**\n\n"
                    f"Ð¤Ð°Ð¹Ð» `{filename}` Ð¼Ð°Ñ” Ñ€Ð¾Ð·Ð¼Ñ–Ñ€ {_format_file_size(file_size)}.\n"
                    f"ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€ Ð´Ð»Ñ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ: 20MB.\n\n"
                    f"Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ Ñ–Ð½ÑˆÑ– Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸ Ð´Ð»Ñ Ð²ÐµÐ»Ð¸ÐºÐ¸Ñ… Ñ„Ð°Ð¹Ð»Ñ–Ð².",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_edit")]
                    ])
                )
                return

            try:
                # Send file to user for editing
                await query.edit_message_text(
                    f"ðŸ“¤ **ÐÐ°Ð´ÑÐ¸Ð»Ð°ÑŽ Ñ„Ð°Ð¹Ð» Ð´Ð»Ñ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ...**\n\n"
                    f"ðŸ“ Ð¤Ð°Ð¹Ð»: `{filename}`\n"
                    f"ðŸ“ Ð Ð¾Ð·Ð¼Ñ–Ñ€: {_format_file_size(file_size)}\n\n"
                    f"â³ Ð—Ð°Ñ‡ÐµÐºÐ°Ð¹Ñ‚Ðµ...",
                    parse_mode=None
                )

                # Send the file
                with open(file_path, 'rb') as file:
                    await query.message.reply_document(
                        document=file,
                        filename=filename,
                        caption=(
                            f"âœï¸ **Ð¤Ð°Ð¹Ð» Ð´Ð»Ñ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ**\n\n"
                            f"ðŸ“ ÐÐ°Ð·Ð²Ð°: `{filename}`\n"
                            f"ðŸ“ Ð Ð¾Ð·Ð¼Ñ–Ñ€: {_format_file_size(file_size)}\n\n"
                            f"ðŸ”„ **Ð¯Ðº Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸:**\n"
                            f"1. Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ñ‚Ðµ Ñ†ÐµÐ¹ Ñ„Ð°Ð¹Ð»\n"
                            f"2. Ð’Ñ–Ð´Ñ€ÐµÐ´Ð°Ð³ÑƒÐ¹Ñ‚Ðµ Ñƒ Ð²Ð°ÑˆÐ¾Ð¼Ñƒ Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¾Ñ€Ñ–\n"
                            f"3. ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð²Ñ–Ð´Ñ€ÐµÐ´Ð°Ð³Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ„Ð°Ð¹Ð» Ð½Ð°Ð·Ð°Ð´ ÑÐº Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚\n"
                            f"4. Ð¯ Ð·Ð±ÐµÑ€ÐµÐ¶Ñƒ Ð·Ð¼Ñ–Ð½Ð¸\n\n"
                            f"ðŸ’¾ ÐžÑ‡Ñ–ÐºÑƒÑŽ Ð²Ñ–Ð´Ñ€ÐµÐ´Ð°Ð³Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ„Ð°Ð¹Ð»..."
                        ),
                        parse_mode=None
                    )

                # Update state to wait for edited file
                context.user_data["file_action"] = {
                    "type": "edit",
                    "step": "waiting_edited_file",
                    "filename": filename,
                    "original_path": str(file_path)
                }

                # Update original message
                await query.edit_message_text(
                    f"âœ… **Ð¤Ð°Ð¹Ð» Ð½Ð°Ð´Ñ–ÑÐ»Ð°Ð½Ð¾**\n\n"
                    f"ðŸ“ Ð¤Ð°Ð¹Ð» `{filename}` Ð½Ð°Ð´Ñ–ÑÐ»Ð°Ð½Ð¾ Ð²Ð¸Ñ‰Ðµ.\n\n"
                    f"ðŸ“ Ð’Ñ–Ð´Ñ€ÐµÐ´Ð°Ð³ÑƒÐ¹Ñ‚Ðµ Ñ„Ð°Ð¹Ð» Ñ‚Ð° Ð½Ð°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð¹Ð¾Ð³Ð¾ Ð½Ð°Ð·Ð°Ð´ ÑÐº Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚.\n\n"
                    f"ðŸ’¡ **ÐŸÑ–Ð´ÐºÐ°Ð·ÐºÐ°:** ÐŸÐµÑ€ÐµÐºÐ¾Ð½Ð°Ð¹Ñ‚ÐµÑÑ Ñ‰Ð¾ Ð·Ð±ÐµÑ€ÐµÐ³Ð»Ð¸ Ñ„Ð°Ð¹Ð» Ð· Ñ‚Ñ–Ñ”ÑŽ Ð¶ Ð½Ð°Ð·Ð²Ð¾ÑŽ!",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("âŒ Ð¡ÐºÐ°ÑÑƒÐ²Ð°Ñ‚Ð¸ Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ", callback_data="file_edit:cancel")]
                    ])
                )

            except Exception as e:
                logger.error("File sending failed", error=str(e), filename=filename)
                await query.edit_message_text(
                    f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð½Ð°Ð´ÑÐ¸Ð»Ð°Ð½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñƒ**\n\n"
                    f"ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð½Ð°Ð´Ñ–ÑÐ»Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð» `{filename}`:\n"
                    f"```\n{str(e)}\n```\n\n"
                    f"Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ð°Ð±Ð¾ Ð²Ð¸Ð±ÐµÑ€Ñ–Ñ‚ÑŒ Ñ–Ð½ÑˆÐ¸Ð¹ Ñ„Ð°Ð¹Ð».",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="file_edit:select_edit")]
                    ])
                )

        elif action_type == "cancel":
            # Cancel file editing workflow
            context.user_data.pop("file_action", None)

            await query.edit_message_text(
                "âŒ **Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ð½Ð½Ñ ÑÐºÐ°ÑÐ¾Ð²Ð°Ð½Ð¾**\n\n"
                "ÐŸÐ¾Ð²ÐµÑ€Ñ‚Ð°Ñ”Ð¼Ð¾ÑÑŒ Ð´Ð¾ ÑˆÐ²Ð¸Ð´ÐºÐ¸Ñ… Ð´Ñ–Ð¹.",
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("ðŸ“‹ Ð¨Ð²Ð¸Ð´ÐºÑ– Ð´Ñ–Ñ—", callback_data="action:quick_actions")]
                ])
            )

        else:
            error_text = await get_localized_text(context, user_id, "errors.unknown_action")
            await query.edit_message_text(f"{error_text}: {action_type}")

    except Exception as e:
        logger.error("File edit callback failed", error=str(e), user_id=user_id, action_type=action_type)
        error_text = await get_localized_text(context, user_id, "errors.file_operation_failed", error=str(e))
        await query.edit_message_text(error_text, parse_mode=None)


# Registration function for callbacks
def register_callbacks(application):
    """Register all callback handlers."""
    from telegram.ext import CallbackQueryHandler

    # Register the main callback query handler
    application.add_handler(CallbackQueryHandler(handle_callback_query))

```

### bot/handlers/mcp_callbacks.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 18,921 Ð±Ð°Ð¹Ñ‚

```python
"""MCP Callback Handlers for Telegram Bot Inline Keyboards.

Handles all MCP-related callback queries from inline keyboards.
"""

import json
from typing import Any, Dict, Optional

import structlog
from telegram import InlineKeyboardButton, InlineKeyboardMarkup, Update
from telegram.ext import ContextTypes

from src.localization.util import t, get_user_id
from src.mcp.context_handler import MCPContextHandler
from src.mcp.exceptions import MCPError, MCPServerNotFoundError, MCPValidationError
from src.mcp.manager import MCPManager, MCPServerConfig
from src.mcp.server_configs import server_config_registry

logger = structlog.get_logger()


async def handle_mcp_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Route MCP callback queries to appropriate handlers."""
    query = update.callback_query
    await query.answer()

    user_id = get_user_id(update)
    if not user_id:
        return

    callback_data = query.data

    try:
        if callback_data.startswith("mcp_add_"):
            await _handle_add_callbacks(update, context, callback_data)
        elif callback_data.startswith("mcp_manage:"):
            await _handle_manage_callbacks(update, context, callback_data)
        elif callback_data.startswith("mcp_set_context:"):
            await _handle_context_callbacks(update, context, callback_data)
        elif callback_data.startswith("mcp_confirm_remove:"):
            await _handle_remove_callbacks(update, context, callback_data)
        elif callback_data in ["mcp_list", "mcp_refresh_all", "mcp_system_status", 
                             "mcp_select_context", "mcp_clear_context", "mcp_cancel"]:
            await _handle_general_callbacks(update, context, callback_data)
        else:
            logger.warning("Unknown MCP callback", callback_data=callback_data, user_id=user_id)

    except Exception as e:
        logger.error("Error handling MCP callback", 
                    callback_data=callback_data, user_id=user_id, error=str(e))
        await query.edit_message_text(
            await t(context, user_id, "mcp.errors.callback_failed", error=str(e))
        )


async def _handle_add_callbacks(update: Update, context: ContextTypes.DEFAULT_TYPE, callback_data: str) -> None:
    """Handle server addition callbacks."""
    query = update.callback_query
    user_id = get_user_id(update)

    mcp_manager: MCPManager = context.bot_data.get("mcp_manager")
    if not mcp_manager:
        await query.edit_message_text(await t(context, user_id, "mcp.errors.system_not_available"))
        return

    if callback_data == "mcp_add_wizard":
        # Show server type selection
        await _show_server_type_selection(update, context)

    elif callback_data.startswith("mcp_add_type:"):
        # Start server configuration wizard
        server_type = callback_data.split(":", 1)[1]
        await _start_server_wizard(update, context, server_type)


async def _handle_manage_callbacks(update: Update, context: ContextTypes.DEFAULT_TYPE, callback_data: str) -> None:
    """Handle server management callbacks."""
    query = update.callback_query
    user_id = get_user_id(update)

    server_name = callback_data.split(":", 1)[1]

    mcp_manager: MCPManager = context.bot_data.get("mcp_manager")
    if not mcp_manager:
        await query.edit_message_text(await t(context, user_id, "mcp.errors.system_not_available"))
        return

    # Get server info
    servers = await mcp_manager.get_user_servers(user_id)
    server = next((s for s in servers if s['server_name'] == server_name), None)

    if not server:
        await query.edit_message_text(
            await t(context, user_id, "mcp.errors.server_not_found", server_name=server_name)
        )
        return

    # Build management menu
    await _show_server_management_menu(update, context, server, mcp_manager)


async def _handle_context_callbacks(update: Update, context: ContextTypes.DEFAULT_TYPE, callback_data: str) -> None:
    """Handle context selection callbacks."""
    query = update.callback_query
    user_id = get_user_id(update)

    server_name = callback_data.split(":", 1)[1]

    mcp_context_handler: MCPContextHandler = context.bot_data.get("mcp_context_handler")
    if not mcp_context_handler:
        await query.edit_message_text(await t(context, user_id, "mcp.errors.system_not_available"))
        return

    try:
        await mcp_context_handler.set_active_context(user_id, server_name)
        await query.edit_message_text(
            await t(context, user_id, "mcp.select.success", server_name=server_name)
        )
    except (MCPServerNotFoundError, MCPError) as e:
        await query.edit_message_text(
            await t(context, user_id, "mcp.select.failed", error=str(e))
        )


async def _handle_remove_callbacks(update: Update, context: ContextTypes.DEFAULT_TYPE, callback_data: str) -> None:
    """Handle server removal callbacks."""
    query = update.callback_query
    user_id = get_user_id(update)

    server_name = callback_data.split(":", 1)[1]

    mcp_manager: MCPManager = context.bot_data.get("mcp_manager")
    if not mcp_manager:
        await query.edit_message_text(await t(context, user_id, "mcp.errors.system_not_available"))
        return

    try:
        success = await mcp_manager.remove_server(user_id, server_name)
        if success:
            await query.edit_message_text(
                await t(context, user_id, "mcp.remove.success", server_name=server_name)
            )
        else:
            await query.edit_message_text(
                await t(context, user_id, "mcp.remove.failed", error="Unknown error")
            )
    except Exception as e:
        await query.edit_message_text(
            await t(context, user_id, "mcp.remove.failed", error=str(e))
        )


async def _handle_general_callbacks(update: Update, context: ContextTypes.DEFAULT_TYPE, callback_data: str) -> None:
    """Handle general MCP callbacks."""
    query = update.callback_query
    user_id = get_user_id(update)

    if callback_data == "mcp_list":
        # Redirect to list command
        from .mcp_commands import mcplist_command
        await mcplist_command(update, context)

    elif callback_data == "mcp_system_status":
        # Redirect to status command
        from .mcp_commands import mcpstatus_command
        await mcpstatus_command(update, context)

    elif callback_data == "mcp_select_context":
        # Show context selection
        mcp_manager: MCPManager = context.bot_data.get("mcp_manager")
        mcp_context_handler: MCPContextHandler = context.bot_data.get("mcp_context_handler")

        if mcp_manager and mcp_context_handler:
            await _show_context_selection_menu(update, context, mcp_manager, mcp_context_handler)
        else:
            await query.edit_message_text(await t(context, user_id, "mcp.errors.system_not_available"))

    elif callback_data == "mcp_clear_context":
        # Clear active context
        mcp_context_handler: MCPContextHandler = context.bot_data.get("mcp_context_handler")

        if mcp_context_handler:
            await mcp_context_handler.clear_active_context(user_id)
            await query.edit_message_text(await t(context, user_id, "mcp.select.context_cleared"))
        else:
            await query.edit_message_text(await t(context, user_id, "mcp.errors.system_not_available"))

    elif callback_data == "mcp_refresh_all":
        # Refresh all server statuses
        await _refresh_all_servers(update, context)

    elif callback_data == "mcp_cancel":
        # Cancel current operation
        await query.edit_message_text(await t(context, user_id, "mcp.general.cancelled"))


# Helper functions for UI components

async def _show_server_type_selection(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Show server type selection menu."""
    query = update.callback_query
    user_id = get_user_id(update)

    templates = server_config_registry.get_template_list()

    keyboard = []
    for template in templates:
        keyboard.append([
            InlineKeyboardButton(
                template["display_name"],
                callback_data=f"mcp_add_type:{template['server_type']}"
            )
        ])

    keyboard.append([
        InlineKeyboardButton(
            await t(context, user_id, "mcp.buttons.cancel"),
            callback_data="mcp_cancel"
        )
    ])

    reply_markup = InlineKeyboardMarkup(keyboard)

    await query.edit_message_text(
        await t(context, user_id, "mcp.add.select_type"),
        reply_markup=reply_markup
    )


async def _start_server_wizard(update: Update, context: ContextTypes.DEFAULT_TYPE, server_type: str) -> None:
    """Start interactive server configuration wizard."""
    query = update.callback_query
    user_id = get_user_id(update)

    template = server_config_registry.get_template(server_type)
    if not template:
        await query.edit_message_text(
            await t(context, user_id, "mcp.add.invalid_type", server_type=server_type)
        )
        return

    # Initialize wizard state
    wizard_state = {
        "server_type": server_type,
        "template": template,
        "steps": template.get_setup_steps(),
        "current_step": 0,
        "user_inputs": {},
        "message_id": query.message.message_id
    }

    # Store wizard state in user data
    context.user_data["mcp_wizard"] = wizard_state

    # Show first step
    await _show_wizard_step(update, context, wizard_state)


async def _show_wizard_step(update: Update, context: ContextTypes.DEFAULT_TYPE, wizard_state: Dict[str, Any]) -> None:
    """Show current wizard step."""
    query = update.callback_query
    user_id = get_user_id(update)

    current_step = wizard_state["current_step"]
    steps = wizard_state["steps"]

    if current_step >= len(steps):
        # Wizard complete - build and add server
        await _complete_server_wizard(update, context, wizard_state)
        return

    step = steps[current_step]

    # Build step message
    title = await t(context, user_id, "mcp.add.wizard.title", 
                   server_type=wizard_state["template"].display_name)
    step_info = await t(context, user_id, "mcp.add.wizard.step", 
                       current=current_step + 1, total=len(steps))

    text_lines = [title, "", step_info, "", f"**{step['title']}**", step['description']]

    if step.get('help_text'):
        text_lines.extend(["", step['help_text']])

    # Create keyboard for input or show input prompt
    keyboard = []

    if step.get('default'):
        keyboard.append([
            InlineKeyboardButton(
                f"âœ… {step['default']}",
                callback_data=f"mcp_wizard_input:{step['default']}"
            )
        ])

    keyboard.extend([
        [InlineKeyboardButton(
            await t(context, user_id, "mcp.buttons.cancel"),
            callback_data="mcp_cancel"
        )]
    ])

    reply_markup = InlineKeyboardMarkup(keyboard)

    # Update message
    await query.edit_message_text(
        "\n".join(text_lines),
        reply_markup=reply_markup,
        parse_mode=None
    )

    # Set waiting for input flag
    wizard_state["waiting_for_input"] = True
    wizard_state["current_step_data"] = step


async def _complete_server_wizard(update: Update, context: ContextTypes.DEFAULT_TYPE, wizard_state: Dict[str, Any]) -> None:
    """Complete server configuration wizard."""
    query = update.callback_query
    user_id = get_user_id(update)

    template = wizard_state["template"]
    user_inputs = wizard_state["user_inputs"]

    try:
        # Validate configuration
        is_valid, error_msg = template.validate_config(user_inputs)
        if not is_valid:
            await query.edit_message_text(
                await t(context, user_id, "mcp.add.wizard.failed", error=error_msg)
            )
            return

        # Build server configuration
        server_config_dict = template.build_server_config(user_inputs)
        server_config = MCPServerConfig(**server_config_dict)

        # Add server via manager
        mcp_manager: MCPManager = context.bot_data.get("mcp_manager")
        if not mcp_manager:
            await query.edit_message_text(await t(context, user_id, "mcp.errors.system_not_available"))
            return

        success = await mcp_manager.add_server(user_id, server_config)

        if success:
            await query.edit_message_text(
                await t(context, user_id, "mcp.add.wizard.success", server_name=server_config.name)
            )
        else:
            await query.edit_message_text(
                await t(context, user_id, "mcp.add.wizard.failed", error="Unknown error")
            )

    except (MCPValidationError, MCPError) as e:
        await query.edit_message_text(
            await t(context, user_id, "mcp.add.wizard.failed", error=str(e))
        )
    finally:
        # Clear wizard state
        if context.user_data and "mcp_wizard" in context.user_data:
            del context.user_data["mcp_wizard"]


async def _show_server_management_menu(update: Update, context: ContextTypes.DEFAULT_TYPE, 
                                     server: Dict[str, Any], mcp_manager: MCPManager) -> None:
    """Show server management menu."""
    query = update.callback_query
    user_id = get_user_id(update)

    server_name = server['server_name']
    server_type = server['server_type']
    display_name = server.get('display_name', server_type)
    status = server['status']
    is_enabled = server['is_enabled']

    # Build info text
    title = await t(context, user_id, "mcp.manage.title", server_name=server_name)
    info = await t(context, user_id, "mcp.manage.server_info", 
                  server_type=display_name, status=status, enabled="âœ…" if is_enabled else "âŒ")

    text_lines = [title, "", info]

    if server.get('last_status_check'):
        last_check = server['last_status_check'].strftime('%d.%m %H:%M')
        text_lines.append(await t(context, user_id, "mcp.manage.last_check", time=last_check))

    if server.get('error_message'):
        error_msg = server['error_message'][:100]
        text_lines.append(await t(context, user_id, "mcp.manage.error_details", error=error_msg))

    # Build keyboard
    keyboard = []

    if is_enabled:
        keyboard.append([
            InlineKeyboardButton(
                await t(context, user_id, "mcp.buttons.disable_server"),
                callback_data=f"mcp_disable:{server_name}"
            )
        ])
    else:
        keyboard.append([
            InlineKeyboardButton(
                await t(context, user_id, "mcp.buttons.enable_server"),
                callback_data=f"mcp_enable:{server_name}"
            )
        ])

    keyboard.extend([
        [
            InlineKeyboardButton(
                await t(context, user_id, "mcp.buttons.test_connection"),
                callback_data=f"mcp_test:{server_name}"
            ),
            InlineKeyboardButton(
                await t(context, user_id, "mcp.buttons.refresh_status"),
                callback_data=f"mcp_refresh:{server_name}"
            )
        ],
        [
            InlineKeyboardButton(
                await t(context, user_id, "mcp.buttons.remove_server"),
                callback_data=f"mcp_confirm_remove:{server_name}"
            )
        ],
        [
            InlineKeyboardButton(
                "â¬…ï¸ " + await t(context, user_id, "mcp.buttons.back_to_list"),
                callback_data="mcp_list"
            )
        ]
    ])

    reply_markup = InlineKeyboardMarkup(keyboard)

    await query.edit_message_text(
        "\n".join(text_lines),
        reply_markup=reply_markup,
        parse_mode=None
    )


async def _show_context_selection_menu(update: Update, context: ContextTypes.DEFAULT_TYPE,
                                     mcp_manager: MCPManager, mcp_context_handler: MCPContextHandler) -> None:
    """Show context selection menu."""
    query = update.callback_query
    user_id = get_user_id(update)

    # Get enabled servers
    servers = await mcp_manager.get_user_servers(user_id)
    enabled_servers = [s for s in servers if s['is_enabled']]

    if not enabled_servers:
        await query.edit_message_text(await t(context, user_id, "mcp.select.no_enabled_servers"))
        return

    # Get current active context
    active_context = await mcp_context_handler.get_active_context(user_id)
    active_server = active_context.get('selected_server') if active_context else None

    keyboard = []
    for server in enabled_servers:
        server_name = server['server_name']
        display_name = server.get('display_name', server['server_type'])

        # Mark active server
        text = f"ðŸŽ¯ {display_name}" if server_name == active_server else display_name

        keyboard.append([
            InlineKeyboardButton(
                text,
                callback_data=f"mcp_set_context:{server_name}"
            )
        ])

    # Add clear context option if there is an active context
    if active_context:
        keyboard.append([
            InlineKeyboardButton(
                await t(context, user_id, "mcp.buttons.clear_context"),
                callback_data="mcp_clear_context"
            )
        ])

    reply_markup = InlineKeyboardMarkup(keyboard)

    await query.edit_message_text(
        await t(context, user_id, "mcp.select.choose_context"),
        reply_markup=reply_markup
    )


async def _refresh_all_servers(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Refresh status of all servers."""
    query = update.callback_query
    user_id = get_user_id(update)

    mcp_manager: MCPManager = context.bot_data.get("mcp_manager")
    if not mcp_manager:
        await query.edit_message_text(await t(context, user_id, "mcp.errors.system_not_available"))
        return

    # Show loading message
    await query.edit_message_text(await t(context, user_id, "mcp.status.checking"))

    try:
        # Get all user servers
        servers = await mcp_manager.get_user_servers(user_id)

        # Refresh status for each enabled server
        refresh_count = 0
        for server in servers:
            if server['is_enabled']:
                try:
                    await mcp_manager.get_server_status(user_id, server['server_name'])
                    refresh_count += 1
                except Exception as e:
                    logger.error("Failed to refresh server status", 
                               server_name=server['server_name'], error=str(e))

        # Redirect back to list
        from .mcp_commands import mcplist_command
        await mcplist_command(update, context)

    except Exception as e:
        await query.edit_message_text(
            await t(context, user_id, "mcp.errors.refresh_failed", error=str(e))
        )

```

### bot/handlers/command.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 151,986 Ð±Ð°Ð¹Ñ‚

```python
"""Command handlers for bot operations."""

import structlog
import asyncio
import re
import pexpect
import time
from datetime import datetime, timedelta
from typing import cast, Optional, Tuple
from telegram import InlineKeyboardButton, InlineKeyboardMarkup, Update
from telegram.ext import ContextTypes

from ...claude.facade import ClaudeIntegration
from ...config.settings import Settings
from ...security.audit import AuditLogger
from ...security.validators import SecurityValidator
from ...localization.util import t, get_user_id, get_effective_message
from ..utils.error_handler import safe_user_error, safe_critical_error
from datetime import datetime
from pathlib import Path
import uuid

logger = structlog.get_logger()


def safe_terminate_process(process: Optional[pexpect.spawn]) -> None:
    """Ð‘ÐµÐ·Ð¿ÐµÑ‡Ð½Ð¾ Ð·Ð°Ð²ÐµÑ€ÑˆÑƒÑ” Ð¿Ñ€Ð¾Ñ†ÐµÑ pexpect."""
    if not process:
        return
    try:
        if process.isalive():
            process.terminate(force=True)
    except Exception as e:
        logger.debug("Error terminating process", error=str(e))
        try:
            process.close()
        except:
            pass


# Pexpect functions for Claude CLI authentication
async def claude_auth_with_pexpect(timeout: int = 30) -> Tuple[bool, str, Optional[pexpect.spawn]]:
    """
    Ð—Ð°Ñ…Ð¾Ð¿Ð»ÑŽÑ” URL Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð· ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸ claude login Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑŽÑ‡Ð¸ pexpect.
    
    Args:
        timeout: ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ‡Ð°Ñ Ð¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð½Ñ Ð² ÑÐµÐºÑƒÐ½Ð´Ð°Ñ…
        
    Returns:
        Tuple Ð· (ÑƒÑÐ¿Ñ–Ñ…, URL_Ð°Ð±Ð¾_Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°, Ð¿Ñ€Ð¾Ñ†ÐµÑ_pexpect)
    """
    try:
        logger.info("Starting claude login with pexpect")
        
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°Ñ”Ð¼Ð¾ Ð¿Ñ€Ð¾Ñ†ÐµÑ claude login Ð· Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ¾ÑŽ UTF-8
        child = pexpect.spawn('claude login', encoding='utf-8', timeout=timeout)
        
        # ÐŸÐ°Ñ‚ÐµÑ€Ð½Ð¸ Ð´Ð»Ñ Ð¿Ð¾ÑˆÑƒÐºÑƒ Ð² Ð²Ð¸Ð²Ð¾Ð´Ñ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸
        patterns = [
            r'https://claude\.ai/[^\s]*',      # Claude.ai URL
            r'https://[^\s]*anthropic[^\s]*', # Anthropic URL
            r'https://[^\s]+',                # Ð‘ÑƒÐ´ÑŒ-ÑÐºÐ¸Ð¹ HTTPS URL
            r'Please visit:?\s*(https://[^\s]+)',  # "Please visit: URL"
            r'Go to:?\s*(https://[^\s]+)',    # "Go to: URL"
            pexpect.TIMEOUT,
            pexpect.EOF
        ]
        
        url = None
        output_buffer = ""
        start_time = time.time()
        
        logger.info("Waiting for authentication URL...")
        
        while time.time() - start_time < timeout:
            try:
                # ÐžÑ‡Ñ–ÐºÑƒÑ”Ð¼Ð¾ Ð½Ð° Ð¾Ð´Ð¸Ð½ Ð· Ð¿Ð°Ñ‚ÐµÑ€Ð½Ñ–Ð²
                index = child.expect(patterns, timeout=5)
                
                # Ð—Ð±Ð¸Ñ€Ð°Ñ”Ð¼Ð¾ Ð²Ð¸Ð²Ñ–Ð´
                if child.before:
                    output_buffer += child.before
                if child.after and index < 5:
                    output_buffer += child.after
                
                logger.debug("Pattern matched", index=index, output_snippet=output_buffer[-200:])
                
                if index < 5:  # Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ URL Ð¿Ð°Ñ‚ÐµÑ€Ð½
                    # Ð’Ð¸Ñ‚ÑÐ³ÑƒÑ”Ð¼Ð¾ Ð²ÑÑ– URL Ð· Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‡ÐµÐ½Ð¾Ð³Ð¾ Ð²Ð¸Ð²Ð¾Ð´Ñƒ
                    url_matches = re.findall(r'https://[^\s]+', output_buffer)
                    
                    if url_matches:
                        # ÐŸÑ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚: Claude.ai > Anthropic > Ñ–Ð½ÑˆÑ– HTTPS
                        for match in url_matches:
                            if 'claude.ai' in match and ('auth' in match or 'login' in match):
                                url = match
                                break
                        if not url:
                            for match in url_matches:
                                if 'anthropic' in match:
                                    url = match
                                    break
                        if not url:
                            url = url_matches[0]  # ÐŸÐµÑ€ÑˆÐ¸Ð¹ HTTPS URL
                        
                        # ÐžÑ‡Ð¸Ñ‰ÑƒÑ”Ð¼Ð¾ URL Ð²Ñ–Ð´ Ð·Ð°Ð¹Ð²Ð¸Ñ… ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ–Ð²
                        url = url.rstrip('.,;)')
                        
                        logger.info("Authentication URL captured", url=url)
                        return True, url, child
                        
                elif index == 5:  # TIMEOUT
                    logger.debug("Timeout waiting for pattern, continuing...")
                    continue
                    
                elif index == 6:  # EOF
                    logger.warning("Process ended unexpectedly", output=output_buffer)
                    break
                    
            except pexpect.TIMEOUT:
                # Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÑ”Ð¼Ð¾ Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹ Ð²Ð¸Ð²Ñ–Ð´
                try:
                    available = child.read_nonblocking(size=1024, timeout=0.1)
                    if available:
                        output_buffer += available
                        logger.debug("Read additional output", content=available[:100])
                except:
                    pass
                continue
                
        # Ð¯ÐºÑ‰Ð¾ Ð´Ñ–Ð¹ÑˆÐ»Ð¸ ÑÑŽÐ´Ð¸ - Ð½Ðµ Ð·Ð½Ð°Ð¹ÑˆÐ»Ð¸ URL
        logger.error("No authentication URL found", output=output_buffer)
        return False, f"No authentication URL found in output: {output_buffer}", child
        
    except Exception as e:
        logger.error("Error starting claude login", error=str(e))
        return False, f"Error starting claude login: {str(e)}", None


async def send_auth_code(child: pexpect.spawn, code: str, timeout: int = 30) -> Tuple[bool, str]:
    """
    Ð’Ñ–Ð´Ð¿Ñ€Ð°Ð²Ð»ÑÑ” ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð² Ð¿Ñ€Ð¾Ñ†ÐµÑ claude login.
    
    Args:
        child: ÐŸÑ€Ð¾Ñ†ÐµÑ pexpect
        code: ÐšÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð²Ñ–Ð´ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð°
        timeout: ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ‡Ð°Ñ Ð¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð½Ñ
        
    Returns:
        Tuple Ð· (ÑƒÑÐ¿Ñ–Ñ…, Ð²Ð¸Ð²Ñ–Ð´_Ð°Ð±Ð¾_Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°)
    """
    try:
        logger.info("Sending authentication code")
        
        # Ð’Ñ–Ð´Ð¿Ñ€Ð°Ð²Ð»ÑÑ”Ð¼Ð¾ ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—
        child.sendline(code)
        
        # ÐŸÐ°Ñ‚ÐµÑ€Ð½Ð¸ Ð´Ð»Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñƒ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—
        patterns = [
            r'(?i)(success|successful|authenticated|complete)',  # Ð£ÑÐ¿Ñ–Ñ…
            r'(?i)(error|failed|invalid|expired|wrong)',        # ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°
            r'(?i)(rate limit|too many|quota|limit exceeded)',  # Ð›Ñ–Ð¼Ñ–Ñ‚Ð¸
            pexpect.TIMEOUT,
            pexpect.EOF
        ]
        
        output = ""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            try:
                index = child.expect(patterns, timeout=5)
                
                # Ð—Ð±Ð¸Ñ€Ð°Ñ”Ð¼Ð¾ Ð²ÑÑ Ð²Ð¸Ð²Ñ–Ð´
                if child.before:
                    output += child.before
                if child.after and index < 3:
                    output += child.after
                
                logger.debug("Auth response pattern", index=index, output_snippet=output[-200:])
                
                if index == 0:  # Ð£ÑÐ¿Ñ–Ñ…
                    logger.info("Authentication successful")
                    child.close()
                    return True, output
                    
                elif index == 1:  # ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—
                    logger.warning("Authentication failed", error=output)
                    child.close()
                    return False, output
                    
                elif index == 2:  # Ð›Ñ–Ð¼Ñ–Ñ‚Ð¸ API
                    logger.warning("Rate limit or quota issue", output=output)
                    child.close()
                    return False, output
                    
                elif index == 3:  # TIMEOUT
                    continue
                    
                elif index == 4:  # EOF
                    child.close()
                    # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ exit ÐºÐ¾Ð´
                    if child.exitstatus == 0:
                        logger.info("Process exited successfully")
                        return True, output
                    else:
                        logger.warning("Process exited with error", exit_code=child.exitstatus)
                        return False, f"Process exited with code {child.exitstatus}: {output}"
                        
            except pexpect.TIMEOUT:
                logger.debug("Waiting for auth response...")
                continue
                
        # Timeout Ð´Ð¾ÑÑÐ³Ð½ÑƒÑ‚Ð¾
        logger.error("Authentication timeout", output=output)
        child.close()
        return False, f"Authentication timed out after {timeout}s: {output}"
        
    except Exception as e:
        logger.error("Error during authentication", error=str(e))
        if child and child.isalive():
            child.close()
        return False, f"Error during authentication: {str(e)}"


async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /start command."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message or not update.effective_user:
        return
    
    # Get localization components from bot data
    localization = context.bot_data.get("localization")
    user_language_storage = context.bot_data.get("user_language_storage")
    
    if localization and user_language_storage:
        # Build localized welcome message
        welcome_text = await t(context, user_id, "commands.start.welcome", name=update.effective_user.first_name)
        description_text = await t(context, user_id, "commands.start.description")
        available_commands_text = await t(context, user_id, "commands.start.available_commands")
        
        help_cmd_text = await t(context, user_id, "commands.start.help_cmd")
        new_cmd_text = await t(context, user_id, "commands.start.new_cmd")
        ls_cmd_text = await t(context, user_id, "commands.start.ls_cmd")
        cd_cmd_text = await t(context, user_id, "commands.start.cd_cmd")
        projects_cmd_text = await t(context, user_id, "commands.start.projects_cmd")
        status_cmd_text = await t(context, user_id, "commands.start.status_cmd")
        actions_cmd_text = await t(context, user_id, "commands.start.actions_cmd")
        git_cmd_text = await t(context, user_id, "commands.start.git_cmd")
        
        quick_start_text = await t(context, user_id, "commands.start.quick_start")
        quick_start_1_text = await t(context, user_id, "commands.start.quick_start_1")
        quick_start_2_text = await t(context, user_id, "commands.start.quick_start_2")
        quick_start_3_text = await t(context, user_id, "commands.start.quick_start_3")
        
        security_note_text = await t(context, user_id, "commands.start.security_note")
        usage_note_text = await t(context, user_id, "commands.start.usage_note")
        
        welcome_message = (
            f"{welcome_text}\n\n"
            f"{description_text}\n\n"
            f"{available_commands_text}\n"
            f"â€¢ `/help` - {help_cmd_text}\n"
            f"â€¢ `/new` - {new_cmd_text}\n"
            f"â€¢ `/ls` - {ls_cmd_text}\n"
            f"â€¢ `/cd <dir>` - {cd_cmd_text}\n"
            f"â€¢ `/projects` - {projects_cmd_text}\n"
            f"â€¢ `/status` - {status_cmd_text}\n"
            f"â€¢ `/actions` - {actions_cmd_text}\n"
            f"â€¢ `/git` - {git_cmd_text}\n\n"
            f"{quick_start_text}\n"
            f"1. {quick_start_1_text}\n"
            f"2. {quick_start_2_text}\n"
            f"3. {quick_start_3_text}\n\n"
            f"{security_note_text}\n"
            f"{usage_note_text}"
        )
        
        # Localized button texts
        show_projects_text = await t(context, user_id, "buttons.show_projects")
        get_help_text = await t(context, user_id, "buttons.get_help")
        new_session_text = await t(context, user_id, "buttons.new_session")
        check_status_text = await t(context, user_id, "buttons.check_status")
        language_settings_text = await t(context, user_id, "buttons.language_settings")
        
        # Enhanced unified menu with all essential functions
        continue_session_text = await t(context, user_id, "buttons.continue_session")
        export_session_text = await t(context, user_id, "buttons.export")
        settings_text = await t(context, user_id, "buttons.settings")

        keyboard = [
            [
                InlineKeyboardButton(new_session_text, callback_data="action:new_session"),
                InlineKeyboardButton(continue_session_text, callback_data="action:continue"),
            ],
            [
                InlineKeyboardButton(show_projects_text, callback_data="action:show_projects"),
                InlineKeyboardButton(check_status_text, callback_data="action:status"),
            ],
            [
                InlineKeyboardButton(export_session_text, callback_data="action:export"),
                InlineKeyboardButton(settings_text, callback_data="action:settings"),
            ],
            [
                InlineKeyboardButton(get_help_text, callback_data="action:help"),
                InlineKeyboardButton(language_settings_text, callback_data="lang:select"),
            ]
        ]
    else:
        # Fallback to English if localization is not available
        welcome_message = (
            f"ðŸ‘‹ Welcome to Claude Code Telegram Bot, {update.effective_user.first_name}!\n\n"
            f"ðŸ¤– I help you access Claude Code remotely through Telegram.\n\n"
            f"**Available Commands:**\n"
            f"â€¢ `/help` - Show detailed help\n"
            f"â€¢ `/new` - Start a new Claude session\n"
            f"â€¢ `/ls` - List files in current directory\n"
            f"â€¢ `/cd <dir>` - Change directory\n"
            f"â€¢ `/projects` - Show available projects\n"
            f"â€¢ `/status` - Show session status\n"
            f"â€¢ `/actions` - Show quick actions\n"
            f"â€¢ `/git` - Git repository commands\n\n"
            f"**Quick Start:**\n"
            f"1. Use `/projects` to see available projects\n"
            f"2. Use `/cd <project>` to navigate to a project\n"
            f"3. Send any message to start coding with Claude!\n\n"
            f"ðŸ”’ Your access is secured and all actions are logged.\n"
            f"ðŸ“Š Use `/status` to check your usage limits."
        )
        
        keyboard = [
            [
                InlineKeyboardButton(await t(context, user_id, "buttons.new_session"), callback_data="action:new_session"),
                InlineKeyboardButton(await t(context, user_id, "buttons.continue"), callback_data="action:continue"),
            ],
            [
                InlineKeyboardButton(await t(context, user_id, "buttons.show_projects"), callback_data="action:show_projects"),
                InlineKeyboardButton(await t(context, user_id, "buttons.check_status"), callback_data="action:status"),
            ],
            [
                InlineKeyboardButton(await t(context, user_id, "buttons.export"), callback_data="action:export"),
                InlineKeyboardButton(await t(context, user_id, "buttons.settings"), callback_data="action:settings"),
            ],
            [
                InlineKeyboardButton(await t(context, user_id, "buttons.get_help"), callback_data="action:help"),
                InlineKeyboardButton(await t(context, user_id, "buttons.language_settings"), callback_data="lang:select"),
            ],
        ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    await message.reply_text(
        welcome_message, parse_mode=None, reply_markup=reply_markup
    )

    # Log command
    audit_logger = context.bot_data.get("audit_logger")
    if audit_logger:
        audit_logger_typed = cast(AuditLogger, audit_logger)
        await audit_logger_typed.log_command(
            user_id=user_id, command="start", args=[], success=True
        )


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /help command with localization."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
    
    # Get localized help text - try to get combined help or build from components
    localization = context.bot_data.get("localization")
    user_language_storage = context.bot_data.get("user_language_storage")
    
    if localization and user_language_storage:
        # Try to get full help text from translations
        user_lang = await user_language_storage.get_user_language(user_id) 
        if not user_lang:
            user_lang = "uk"  # Default to Ukrainian
        help_data = localization.translations.get(user_lang, {}).get("commands", {}).get("help", {})
        
        if help_data:
            # Build help text from individual components
            parts = []
            if "title" in help_data:
                parts.append(help_data["title"])
                parts.append("")
            
            if "navigation_title" in help_data:
                parts.append(help_data["navigation_title"])
                parts.extend([
                    f"â€¢ `/ls` - {help_data.get('ls_desc', 'List files and directories')}",
                    f"â€¢ `/cd <directory>` - {help_data.get('cd_desc', 'Change to directory')}",
                    f"â€¢ `/pwd` - {help_data.get('pwd_desc', 'Show current directory')}",
                    f"â€¢ `/projects` - {help_data.get('projects_desc', 'Show available projects')}",
                    ""
                ])
            
            if "session_title" in help_data:
                parts.append(help_data["session_title"])
                parts.extend([
                    f"â€¢ `/new` - {help_data.get('new_desc', 'Start new Claude session')}",
                    f"â€¢ `/continue [message]` - {help_data.get('continue_desc', 'Continue last session')}",
                    f"â€¢ `/end` - {help_data.get('end_desc', 'End current session')}",
                    f"â€¢ `/status` - {help_data.get('status_desc', 'Show session and usage status')}",
                    f"â€¢ `/export` - {help_data.get('export_desc', 'Export session history')}",
                    f"â€¢ `/actions` - {help_data.get('actions_desc', 'Show context-aware quick actions')}",
                    f"â€¢ `/git` - {help_data.get('git_desc', 'Git repository information')}",
                    ""
                ])
            
            if "usage_title" in help_data:
                parts.append(help_data["usage_title"])
                parts.extend([
                    f"â€¢ {help_data.get('usage_cd', 'cd myproject - Enter project directory')}",
                    f"â€¢ {help_data.get('usage_ls', 'ls - See what is in current directory')}",
                    f"â€¢ {help_data.get('usage_code', 'Create a simple Python script - Ask Claude to code')}",
                    f"â€¢ {help_data.get('usage_file', 'Send a file to have Claude review it')}",
                    ""
                ])
            
            if "tips_title" in help_data:
                parts.append(help_data["tips_title"])
                parts.extend([
                    f"â€¢ {help_data.get('tips_specific', 'Use specific, clear requests for best results')}",
                    f"â€¢ {help_data.get('tips_status', 'Check `/status` to monitor your usage')}",
                    f"â€¢ {help_data.get('tips_buttons', 'Use quick action buttons when available')}",
                ])
            
            help_text = "\n".join(parts)
        else:
            # Fallback to English
            help_text = await t(context, user_id, "commands.help.title")
    else:
        # Ultimate fallback
        help_text = (
            "ðŸ¤– **Claude Code Telegram Bot Help**\n\n"
            "â€¢ `/new` - Start new Claude session\n"
            "â€¢ `/help` - Show this help\n"
            "â€¢ `/status` - Show session status\n"
            "â€¢ `/ls` - List files\n"
            "â€¢ `/cd <dir>` - Change directory"
        )

    await message.reply_text(help_text, parse_mode=None)


async def new_session(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /new command."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    settings = context.bot_data.get("settings")
    if not settings:
        await message.reply_text(await t(context, user_id, "errors.settings_not_available"))
        return
    settings_typed = cast(Settings, settings)

    # For now, we'll use a simple session concept
    # This will be enhanced when we implement proper session management

    # Get current directory (default to approved directory)
    current_dir = context.user_data.get(
        "current_directory", settings_typed.approved_directory
    ) if context.user_data else settings_typed.approved_directory
    relative_path = current_dir.relative_to(settings_typed.approved_directory)

    # Clear any existing session data
    if context.user_data:
        context.user_data["claude_session_id"] = None
        context.user_data["session_started"] = True

    # Get localized button texts
    localization = context.bot_data.get("localization")
    user_language_storage = context.bot_data.get("user_language_storage")
    
    if localization and user_language_storage:
        start_coding_btn = await t(context, user_id, "commands_extended.new_session.button_start_coding")
        change_project_btn = await t(context, user_id, "commands_extended.new_session.button_change_project")
        quick_actions_btn = await t(context, user_id, "commands_extended.new_session.button_quick_actions")
        help_btn = await t(context, user_id, "commands_extended.new_session.button_help")
    else:
        start_coding_btn = "ðŸ“ Start Coding"
        change_project_btn = "ðŸ“ Change Project"
        quick_actions_btn = "ðŸ“‹ Quick Actions"
        help_btn = "â“ Help"
    
    keyboard = [
        [
            InlineKeyboardButton(
                start_coding_btn, callback_data="action:start_coding"
            ),
            InlineKeyboardButton(
                change_project_btn, callback_data="action:show_projects"
            ),
        ],
        [
            InlineKeyboardButton(
                quick_actions_btn, callback_data="action:quick_actions"
            ),
            InlineKeyboardButton(help_btn, callback_data="action:help"),
        ],
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    # Get localized text for new session message
    if localization and user_language_storage:
        title = await t(context, user_id, "commands_extended.new_session.title")
        working_dir_msg = await t(context, user_id, "commands_extended.new_session.working_directory", relative_path=str(relative_path))
        ready_msg = await t(context, user_id, "commands_extended.new_session.ready_message")
        
        new_session_message = f"{title}\n\n{working_dir_msg}\n\n{ready_msg}"
    else:
        new_session_message = (
            f"ðŸ†• **New Claude Code Session**\n\n"
            f"ðŸ“‚ Working directory: `{relative_path}/`\n\n"
            f"Ready to help you code! Send me a message to get started, or use the buttons below:"
        )
    
    await message.reply_text(
        new_session_message,
        parse_mode=None,
        reply_markup=reply_markup,
    )


async def continue_session(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /continue command with optional prompt."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    settings = context.bot_data.get("settings")
    if not settings:
        await message.reply_text(await t(context, user_id, "errors.settings_not_available"))
        return
    settings_typed = cast(Settings, settings)
    
    claude_integration = context.bot_data.get("claude_integration")
    audit_logger = context.bot_data.get("audit_logger")

    # Parse optional prompt from command arguments
    prompt = " ".join(context.args) if context.args else None

    current_dir = context.user_data.get(
        "current_directory", settings_typed.approved_directory
    ) if context.user_data else settings_typed.approved_directory

    status_msg = None
    try:
        if not claude_integration:
            # Get localized error message
            localization = context.bot_data.get("localization")
            user_language_storage = context.bot_data.get("user_language_storage")
            
            if localization and user_language_storage:
                error_msg = await t(context, user_id, "errors.claude_not_available")
            else:
                error_msg = "âŒ **Claude Integration Not Available**\n\nClaude integration is not properly configured."
            
            await message.reply_text(error_msg)
            return

        # Check if there's an existing session in user context
        claude_session_id = context.user_data.get("claude_session_id") if context.user_data else None

        if claude_session_id:
            # We have a session in context, continue it directly
            # Get localized continuation messages
            localization = context.bot_data.get("localization")
            user_language_storage = context.bot_data.get("user_language_storage")
            
            if localization and user_language_storage:
                continuing_title = await t(context, user_id, "commands_extended.continue_session.continuing")
                session_id_msg = await t(context, user_id, "commands_extended.continue_session.session_id", session_id=claude_session_id[:8])
                directory_msg = await t(context, user_id, "commands_extended.continue_session.directory", relative_path=str(current_dir.relative_to(settings_typed.approved_directory)))
                
                if prompt:
                    process_msg = await t(context, user_id, "commands_extended.continue_session.processing_message")
                else:
                    process_msg = await t(context, user_id, "commands_extended.continue_session.continuing_message")
                
                status_text = f"{continuing_title}\n\n{session_id_msg}\n{directory_msg}\n\n{process_msg}"
            else:
                status_text = (
                    f"ðŸ”„ **Continuing Session**\n\n"
                    f"Session ID: `{claude_session_id[:8]}...`\n"
                    f"Directory: `{current_dir.relative_to(settings_typed.approved_directory)}/`\n\n"
                    f"{'Processing your message...' if prompt else 'Continuing where you left off...'}"
                )
            
            status_msg = await message.reply_text(
                status_text,
                parse_mode=None,
            )

            # Continue with the existing session
            if claude_integration:
                claude_integration_typed = cast(ClaudeIntegration, claude_integration)
                claude_response = await claude_integration_typed.run_command(
                    prompt=prompt or "",
                    working_directory=current_dir,
                    user_id=user_id,
                    session_id=claude_session_id,
                )
            else:
                claude_response = None
        else:
            # No session in context, try to find the most recent session
            # Get localized session search messages
            localization = context.bot_data.get("localization")
            user_language_storage = context.bot_data.get("user_language_storage")
            if localization and user_language_storage:
                looking_title = await t(context, user_id, "commands_extended.continue_session.looking_for_session")
                searching_msg = await t(context, user_id, "commands_extended.continue_session.searching_message")
                search_text = f"{looking_title}\n\n{searching_msg}"
            else:
                search_text = (
                    "ðŸ” **Looking for Recent Session**\n\n"
                    "Searching for your most recent session in this directory..."
                )
            
            status_msg = await message.reply_text(
                search_text,
                parse_mode=None,
            )

            if claude_integration:
                claude_integration_typed = cast(ClaudeIntegration, claude_integration)
                claude_response = await claude_integration_typed.continue_session(
                    user_id=user_id,
                    working_directory=current_dir,
                    prompt=prompt,
                )
            else:
                claude_response = None

        if claude_response:
            # Update session ID in context
            if context.user_data:
                context.user_data["claude_session_id"] = claude_response.session_id

            # Delete status message and send response
            await status_msg.delete()

            # Format and send Claude's response
            from ..utils.formatting import ResponseFormatter

            formatter = ResponseFormatter(settings_typed)
            formatted_messages = formatter.format_claude_response(str(claude_response))

            for msg in formatted_messages:
                await message.reply_text(
                    str(msg),
                    parse_mode=None,
                )

            # Log successful continue
            if audit_logger:
                audit_logger_typed = cast(AuditLogger, audit_logger)
                await audit_logger_typed.log_command(
                    user_id=user_id,
                    command="continue",
                    args=context.args or [],
                    success=True,
                )

        else:
            # No session found to continue
            await status_msg.edit_text(
                "âŒ **No Session Found**\n\n"
                f"No recent Claude session found in this directory.\n"
                f"Directory: `{current_dir.relative_to(settings_typed.approved_directory)}/`\n\n"
                f"**What you can do:**\n"
                f"â€¢ Use `/new` to start a fresh session\n"
                f"â€¢ Use `/status` to check your sessions\n"
                f"â€¢ Navigate to a different directory with `/cd`",
                parse_mode=None,
                reply_markup=InlineKeyboardMarkup(
                    [
                        [
                            InlineKeyboardButton(
                                "ðŸ†• New Session", callback_data="action:new_session"
                            ),
                            InlineKeyboardButton(
                                "ðŸ“Š Status", callback_data="action:status"
                            ),
                        ]
                    ]
                ),
            )

    except Exception as e:
        error_msg = str(e)
        logger.error("Error in continue command", error=error_msg, user_id=user_id)

        # Delete status message if it exists
        try:
            if 'status_msg' in locals() and status_msg:
                await status_msg.delete()
        except Exception as e:
            logger.warning("Failed to delete status message", error=str(e))

        # Send error response
        await message.reply_text(
            f"âŒ **Error Continuing Session**\n\n"
            f"An error occurred while trying to continue your session:\n\n"
            f"`{error_msg}`\n\n"
            f"**Suggestions:**\n"
            f"â€¢ Try starting a new session with `/new`\n"
            f"â€¢ Check your session status with `/status`\n"
            f"â€¢ Contact support if the issue persists",
            parse_mode=None,
        )

        # Log failed continue
        if audit_logger:
            audit_logger_typed = cast(AuditLogger, audit_logger)
            await audit_logger_typed.log_command(
                user_id=user_id,
                command="continue",
                args=context.args or [],
                success=False,
            )


async def list_files(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /ls command."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    settings = context.bot_data.get("settings")
    if not settings:
        await message.reply_text(await t(context, user_id, "errors.settings_not_available"))
        return
    settings_typed = cast(Settings, settings)
    
    audit_logger = context.bot_data.get("audit_logger")

    # Get current directory
    current_dir = context.user_data.get(
        "current_directory", settings_typed.approved_directory
    ) if context.user_data else settings_typed.approved_directory

    try:
        # List directory contents
        items = []
        directories = []
        files = []

        for item in sorted(current_dir.iterdir()):
            # Skip hidden files (starting with .)
            if item.name.startswith("."):
                continue

            if item.is_dir():
                directories.append(f"ðŸ“ {item.name}/")
            else:
                # Get file size
                try:
                    size = item.stat().st_size
                    size_str = _format_file_size(size)
                    files.append(f"ðŸ“„ {item.name} ({size_str})")
                except OSError:
                    files.append(f"ðŸ“„ {item.name}")

        # Combine directories first, then files
        items = directories + files

        # Format response
        relative_path = current_dir.relative_to(settings_typed.approved_directory)
        if not items:
            ls_message = f"ðŸ“‚ `{relative_path}/`\n\n_(empty directory)_"
        else:
            ls_message = f"ðŸ“‚ `{relative_path}/`\n\n"

            # Limit items shown to prevent message being too long
            max_items = 50
            if len(items) > max_items:
                shown_items = items[:max_items]
                ls_message += "\n".join(shown_items)
                ls_message += f"\n\n_... and {len(items) - max_items} more items_"
            else:
                ls_message += "\n".join(items)

        # Add navigation buttons if not at root
        keyboard = []
        if current_dir != settings_typed.approved_directory:
            keyboard.append(
                [
                    InlineKeyboardButton(await t(context, user_id, "buttons.go_up"), callback_data="cd:.."),
                    InlineKeyboardButton(await t(context, user_id, "buttons.root"), callback_data="cd:/"),
                ]
            )

        keyboard.append(
            [
                InlineKeyboardButton(await t(context, user_id, "buttons.refresh"), callback_data="action:refresh_ls"),
                InlineKeyboardButton(
                    await t(context, user_id, "buttons.projects"), callback_data="action:show_projects"
                ),
            ]
        )

        reply_markup = InlineKeyboardMarkup(keyboard) if keyboard else None

        await message.reply_text(
            ls_message, parse_mode=None, reply_markup=reply_markup
        )

        # Log successful command
        if audit_logger:
            audit_logger_typed = cast(AuditLogger, audit_logger)
            await audit_logger_typed.log_command(user_id, "ls", [], True)

    except Exception as e:
        error_msg = f"âŒ Error listing directory: {str(e)}"
        await message.reply_text(error_msg)

        # Log failed command
        if audit_logger:
            audit_logger_typed = cast(AuditLogger, audit_logger)
            await audit_logger_typed.log_command(user_id, "ls", [], False)

        logger.error("Error in list_files command", error=str(e), user_id=user_id)


async def change_directory(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /cd command."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    settings = context.bot_data.get("settings")
    if not settings:
        await message.reply_text(await t(context, user_id, "errors.settings_not_available"))
        return
    settings_typed = cast(Settings, settings)
    
    security_validator = context.bot_data.get("security_validator")
    audit_logger = context.bot_data.get("audit_logger")

    # Parse arguments
    if not context.args:
        await message.reply_text(
            "**Usage:** `/cd <directory>`\n\n"
            "**Examples:**\n"
            "â€¢ `/cd myproject` - Enter subdirectory\n"
            "â€¢ `/cd ..` - Go up one level\n"
            "â€¢ `/cd /` - Go to root of approved directory\n\n"
            "**Tips:**\n"
            "â€¢ Use `/ls` to see available directories\n"
            "â€¢ Use `/projects` to see all projects",
            parse_mode=None,
        )
        return

    target_path = " ".join(context.args)
    current_dir = context.user_data.get(
        "current_directory", settings_typed.approved_directory
    ) if context.user_data else settings_typed.approved_directory

    try:
        # Validate path using security validator
        if security_validator:
            security_validator_typed = cast(SecurityValidator, security_validator)
            valid, resolved_path, error = security_validator_typed.validate_path(
                target_path, current_dir
            )

            if not valid:
                await message.reply_text(f"âŒ **Access Denied**\n\n{error}")

                # Log security violation
                if audit_logger:
                    audit_logger_typed = cast(AuditLogger, audit_logger)
                    await audit_logger_typed.log_security_violation(
                        user_id=user_id,
                        violation_type="path_traversal_attempt",
                        details=f"Attempted path: {target_path}",
                        severity="medium",
                    )
                return
        else:
            # Fallback validation without security validator
            if target_path == "/":
                resolved_path = settings_typed.approved_directory
            elif target_path == "..":
                resolved_path = current_dir.parent
                if not str(resolved_path).startswith(str(settings_typed.approved_directory)):
                    resolved_path = settings_typed.approved_directory
            else:
                resolved_path = current_dir / target_path
                resolved_path = resolved_path.resolve()

        # Check if directory exists and is actually a directory
        if not resolved_path or not resolved_path.exists():
            await message.reply_text(
                f"âŒ **Directory Not Found**\n\n`{target_path}` does not exist."
            )
            return

        if not resolved_path.is_dir():
            await message.reply_text(
                f"âŒ **Not a Directory**\n\n`{target_path}` is not a directory."
            )
            return

        # Update current directory in user data
        if context.user_data:
            context.user_data["current_directory"] = resolved_path
            # Clear Claude session on directory change
            context.user_data["claude_session_id"] = None

        # Send confirmation
        relative_path = resolved_path.relative_to(settings_typed.approved_directory)
        await message.reply_text(
            f"âœ… **Directory Changed**\n\n"
            f"ðŸ“‚ Current directory: `{relative_path}/`\n\n"
            f"ðŸ”„ Claude session cleared. Send a message to start coding in this directory.",
            parse_mode=None,
        )

        # Log successful command
        if audit_logger:
            audit_logger_typed = cast(AuditLogger, audit_logger)
            await audit_logger_typed.log_command(user_id, "cd", [target_path], True)

    except Exception as e:
        error_msg = f"âŒ **Error changing directory**\n\n{str(e)}"
        await message.reply_text(error_msg, parse_mode=None)

        # Log failed command
        if audit_logger:
            audit_logger_typed = cast(AuditLogger, audit_logger)
            await audit_logger_typed.log_command(user_id, "cd", [target_path], False)

        logger.error("Error in change_directory command", error=str(e), user_id=user_id)


async def print_working_directory(
    update: Update, context: ContextTypes.DEFAULT_TYPE
) -> None:
    """Handle /pwd command."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    settings = context.bot_data.get("settings")
    if not settings:
        await message.reply_text(await t(context, user_id, "errors.settings_not_available"))
        return
    settings_typed = cast(Settings, settings)
    
    current_dir = context.user_data.get(
        "current_directory", settings_typed.approved_directory
    ) if context.user_data else settings_typed.approved_directory

    relative_path = current_dir.relative_to(settings_typed.approved_directory)
    absolute_path = str(current_dir)

    # Add quick navigation buttons
    keyboard = [
        [
            InlineKeyboardButton("ðŸ“ List Files", callback_data="action:ls"),
            InlineKeyboardButton("ðŸ“‹ Projects", callback_data="action:show_projects"),
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    await message.reply_text(
        f"ðŸ“ **Current Directory**\n\n"
        f"Relative: `{relative_path}/`\n"
        f"Absolute: `{absolute_path}`",
        parse_mode=None,
        reply_markup=reply_markup,
    )


async def show_projects(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /projects command."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    settings = context.bot_data.get("settings")
    if not settings:
        await message.reply_text(await t(context, user_id, "errors.settings_not_available"))
        return
    settings_typed = cast(Settings, settings)

    try:
        # Get directories in approved directory (these are "projects")
        projects = []
        for item in sorted(settings_typed.approved_directory.iterdir()):
            if item.is_dir() and not item.name.startswith("."):
                projects.append(item.name)

        if not projects:
            await message.reply_text(
                "ðŸ“ **No Projects Found**\n\n"
                "No subdirectories found in your approved directory.\n"
                "Create some directories to organize your projects!"
            )
            return

        # Create inline keyboard with project buttons
        keyboard = []
        for i in range(0, len(projects), 2):
            row = []
            for j in range(2):
                if i + j < len(projects):
                    project = projects[i + j]
                    row.append(
                        InlineKeyboardButton(
                            f"ðŸ“ {project}", callback_data=f"cd:{project}"
                        )
                    )
            keyboard.append(row)

        # Add navigation buttons
        keyboard.append(
            [
                InlineKeyboardButton("ðŸ  Go to Root", callback_data="cd:/"),
                InlineKeyboardButton(
                    "ðŸ”„ Refresh", callback_data="action:show_projects"
                ),
            ]
        )

        reply_markup = InlineKeyboardMarkup(keyboard)

        project_list = "\n".join([f"â€¢ `{project}/`" for project in projects])

        await message.reply_text(
            f"ðŸ“ **Available Projects**\n\n"
            f"{project_list}\n\n"
            f"Click a project below to navigate to it:",
            parse_mode=None,
            reply_markup=reply_markup,
        )

    except Exception as e:
        await message.reply_text(f"âŒ Error loading projects: {str(e)}")
        logger.error("Error in show_projects command", error=str(e), user_id=user_id)


async def session_status(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /status command."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    settings = context.bot_data.get("settings")
    if not settings:
        await message.reply_text(await t(context, user_id, "errors.settings_not_available"))
        return
    settings_typed = cast(Settings, settings)

    # Get session info
    claude_session_id = context.user_data.get("claude_session_id") if context.user_data else None
    current_dir = context.user_data.get(
        "current_directory", settings_typed.approved_directory
    ) if context.user_data else settings_typed.approved_directory
    relative_path = current_dir.relative_to(settings_typed.approved_directory)

    # Get rate limiter info if available
    rate_limiter = context.bot_data.get("rate_limiter")
    usage_info = ""
    if rate_limiter:
        try:
            user_status = rate_limiter.get_user_status(user_id)
            cost_usage = user_status.get("cost_usage", {})
            current_cost = cost_usage.get("current", 0.0)
            cost_limit = cost_usage.get("limit", settings_typed.claude_max_cost_per_user)
            cost_percentage = (current_cost / cost_limit) * 100 if cost_limit > 0 else 0

            usage_info = f"ðŸ’° Usage: ${current_cost:.2f} / ${cost_limit:.2f} ({cost_percentage:.0f}%)\n"
        except Exception:
            usage_info = "ðŸ’° Usage: _Unable to retrieve_\n"

    # Format status message
    status_lines = [
        "ðŸ“Š **Session Status**",
        "",
        f"ðŸ“‚ Directory: `{relative_path}/`",
        f"ðŸ¤– Claude Session: {'âœ… Active' if claude_session_id else 'âŒ None'}",
        usage_info.rstrip(),
        f"ðŸ• Last Update: {message.date.strftime('%H:%M:%S UTC') if message.date else 'Unknown'}",
    ]

    if claude_session_id:
        status_lines.append(f"ðŸ†” Session ID: `{claude_session_id[:8]}...`")

    # Add action buttons
    keyboard = []
    if claude_session_id:
        keyboard.append(
            [
                InlineKeyboardButton("ðŸ”„ Continue", callback_data="action:continue"),
                InlineKeyboardButton(
                    "ðŸ†• New Session", callback_data="action:new_session"
                ),
            ]
        )
    else:
        keyboard.append(
            [
                InlineKeyboardButton(
                    "ðŸ†• Start Session", callback_data="action:new_session"
                )
            ]
        )

    keyboard.append(
        [
            InlineKeyboardButton("ðŸ“¤ Export", callback_data="action:export"),
            InlineKeyboardButton("ðŸ”„ Refresh", callback_data="action:refresh_status"),
        ]
    )

    reply_markup = InlineKeyboardMarkup(keyboard)

    await message.reply_text(
        "\n".join(status_lines), parse_mode=None, reply_markup=reply_markup
    )


async def export_session(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /export command."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    features = context.bot_data.get("features")

    # Check if session export is available
    session_exporter = features.get_session_export() if features else None

    if not session_exporter:
        await message.reply_text(
            "ðŸ“¤ **Export Session**\n\n"
            "Session export functionality is not available.\n\n"
            "**Planned features:**\n"
            "â€¢ Export conversation history\n"
            "â€¢ Save session state\n"
            "â€¢ Share conversations\n"
            "â€¢ Create session backups"
        )
        return

    # Get current session
    claude_session_id = context.user_data.get("claude_session_id") if context.user_data else None

    if not claude_session_id:
        await message.reply_text(
            "âŒ **No Active Session**\n\n"
            "There's no active Claude session to export.\n\n"
            "**What you can do:**\n"
            "â€¢ Start a new session with `/new`\n"
            "â€¢ Continue an existing session with `/continue`\n"
            "â€¢ Check your status with `/status`"
        )
        return

    # Create export format selection keyboard
    keyboard = [
        [
            InlineKeyboardButton("ðŸ“ Markdown", callback_data="export:markdown"),
            InlineKeyboardButton("ðŸŒ HTML", callback_data="export:html"),
        ],
        [
            InlineKeyboardButton("ðŸ“‹ JSON", callback_data="export:json"),
            InlineKeyboardButton("âŒ Cancel", callback_data="export:cancel"),
        ],
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    await message.reply_text(
        "ðŸ“¤ **Export Session**\n\n"
        f"Ready to export session: `{claude_session_id[:8]}...`\n\n"
        "**Choose export format:**",
        parse_mode=None,
        reply_markup=reply_markup,
    )


async def end_session(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /end command to terminate the current session."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    settings = context.bot_data.get("settings")
    if not settings:
        await message.reply_text(await t(context, user_id, "errors.settings_not_available"))
        return
    settings_typed = cast(Settings, settings)

    # Check if there's an active session
    claude_session_id = context.user_data.get("claude_session_id") if context.user_data else None

    if not claude_session_id:
        await message.reply_text(
            "â„¹ï¸ **No Active Session**\n\n"
            "There's no active Claude session to end.\n\n"
            "**What you can do:**\n"
            "â€¢ Use `/new` to start a new session\n"
            "â€¢ Use `/status` to check your session status\n"
            "â€¢ Send any message to start a conversation"
        )
        return

    # Get current directory for display
    current_dir = context.user_data.get(
        "current_directory", settings_typed.approved_directory
    ) if context.user_data else settings_typed.approved_directory
    relative_path = current_dir.relative_to(settings_typed.approved_directory)

    # Clear session data
    if context.user_data:
        context.user_data["claude_session_id"] = None
        context.user_data["session_started"] = False
        context.user_data["last_message"] = None

    # Create full main menu keyboard (8 buttons in 4 rows)
    keyboard = [
        [
            InlineKeyboardButton(await t(context, user_id, "buttons.new_session"), callback_data="action:new_session"),
            InlineKeyboardButton(await t(context, user_id, "buttons.continue_session"), callback_data="action:continue")
        ],
        [
            InlineKeyboardButton(await t(context, user_id, "buttons.show_projects"), callback_data="action:show_projects"),
            InlineKeyboardButton(await t(context, user_id, "buttons.status"), callback_data="action:status")
        ],
        [
            InlineKeyboardButton(await t(context, user_id, "buttons.export"), callback_data="action:export"),
            InlineKeyboardButton(await t(context, user_id, "buttons.settings"), callback_data="action:settings")
        ],
        [
            InlineKeyboardButton(await t(context, user_id, "buttons.help"), callback_data="action:help"),
            InlineKeyboardButton(await t(context, user_id, "buttons.language_settings"), callback_data="lang:select")
        ]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    await message.reply_text(
        "âœ… **Session Ended**\n\n"
        f"Your Claude session has been terminated.\n\n"
        f"**Current Status:**\n"
        f"â€¢ Directory: `{relative_path}/`\n"
        f"â€¢ Session: None\n"
        f"â€¢ Ready for new commands\n\n"
        f"**Main Menu:**\n"
        f"Choose your next action from the full menu below, or send any message to begin a new conversation.",
        parse_mode=None,
        reply_markup=reply_markup,
    )

    logger.info("Session ended by user", user_id=user_id, session_id=claude_session_id)


async def quick_actions(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /actions command to show quick actions."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    settings = context.bot_data.get("settings")
    if not settings:
        await message.reply_text(await t(context, user_id, "errors.settings_not_available"))
        return
    settings_typed = cast(Settings, settings)
    
    features = context.bot_data.get("features")

    if not features or not features.is_enabled("quick_actions"):
        await message.reply_text(
            "âŒ **Quick Actions Disabled**\n\n"
            "Quick actions feature is not enabled.\n"
            "Contact your administrator to enable this feature."
        )
        return

    # Get current directory
    current_dir = context.user_data.get(
        "current_directory", settings_typed.approved_directory
    ) if context.user_data else settings_typed.approved_directory

    try:
        quick_action_manager = features.get_quick_actions()
        if not quick_action_manager:
            await message.reply_text(
                "âŒ **Quick Actions Unavailable**\n\n"
                "Quick actions service is not available."
            )
            return

        # Get context-aware actions
        actions = await quick_action_manager.get_suggestions(
            session_data={"working_directory": str(current_dir), "user_id": user_id}
        )

        if not actions:
            await message.reply_text(
                "ðŸ¤– **No Actions Available**\n\n"
                "No quick actions are available for the current context.\n\n"
                "**Try:**\n"
                "â€¢ Navigating to a project directory with `/cd`\n"
                "â€¢ Creating some code files\n"
                "â€¢ Starting a Claude session with `/new`"
            )
            return

        # Create inline keyboard with localization
        # user_id already defined above
        localization = context.bot_data.get("localization")
        user_language_storage = context.bot_data.get("user_language_storage")
        user_lang = None
        
        if user_language_storage:
            try:
                user_lang = await user_language_storage.get_user_language(user_id)
            except Exception as e:
                logger.warning("Failed to get user language", user_id=user_id, error=str(e))
                user_lang = "en"  # fallback to English
        
        keyboard = quick_action_manager.create_inline_keyboard(
            actions, columns=2, localization=localization, user_lang=user_lang
        )

        # Get localized title for quick actions
        title_text = await t(context, user_id, "quick_actions.title")
        
        relative_path = current_dir.relative_to(settings_typed.approved_directory)
        message_text = f"{title_text}\n\nðŸ“‚ Context: `{relative_path}/`"
        
        await message.reply_text(
            message_text,
            parse_mode=None,
            reply_markup=keyboard,
        )

    except Exception as e:
        error_text = await t(context, user_id, "errors.quick_actions_unavailable")
        await message.reply_text(error_text, parse_mode=None)
        logger.error("Error in quick_actions command", error=str(e), user_id=user_id)


async def git_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /git command to show git repository information."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    settings = context.bot_data.get("settings")
    if not settings:
        await message.reply_text(await t(context, user_id, "errors.settings_not_available"))
        return
    settings_typed = cast(Settings, settings)
    
    features = context.bot_data.get("features")

    if not features or not features.is_enabled("git"):
        await message.reply_text(
            "âŒ **Git Integration Disabled**\n\n"
            "Git integration feature is not enabled.\n"
            "Contact your administrator to enable this feature."
        )
        return

    # Get current directory
    current_dir = context.user_data.get(
        "current_directory", settings_typed.approved_directory
    ) if context.user_data else settings_typed.approved_directory

    try:
        git_integration = features.get_git_integration()
        if not git_integration:
            await message.reply_text(
                "âŒ **Git Integration Unavailable**\n\n"
                "Git integration service is not available."
            )
            return

        # Check if current directory is a git repository
        if not (current_dir / ".git").exists():
            await message.reply_text(
                f"ðŸ“‚ **Not a Git Repository**\n\n"
                f"Current directory `{current_dir.relative_to(settings_typed.approved_directory)}/` is not a git repository.\n\n"
                f"**Options:**\n"
                f"â€¢ Navigate to a git repository with `/cd`\n"
                f"â€¢ Initialize a new repository (ask Claude to help)\n"
                f"â€¢ Clone an existing repository (ask Claude to help)"
            )
            return

        # Get git status
        git_status = await git_integration.get_status(current_dir)

        # Format status message
        relative_path = current_dir.relative_to(settings_typed.approved_directory)
        status_message = f"ðŸ”— **Git Repository Status**\n\n"
        status_message += f"ðŸ“‚ Directory: `{relative_path}/`\n"
        status_message += f"ðŸŒ¿ Branch: `{git_status.branch}`\n"

        if git_status.ahead > 0:
            status_message += f"â¬†ï¸ Ahead: {git_status.ahead} commits\n"
        if git_status.behind > 0:
            status_message += f"â¬‡ï¸ Behind: {git_status.behind} commits\n"

        # Show file changes
        if not git_status.is_clean:
            status_message += f"\n**Changes:**\n"
            if git_status.modified:
                status_message += f"ðŸ“ Modified: {len(git_status.modified)} files\n"
            if git_status.added:
                status_message += f"âž• Added: {len(git_status.added)} files\n"
            if git_status.deleted:
                status_message += f"âž– Deleted: {len(git_status.deleted)} files\n"
            if git_status.untracked:
                status_message += f"â“ Untracked: {len(git_status.untracked)} files\n"
        else:
            status_message += "\nâœ… Working directory clean\n"

        # Create action buttons
        keyboard = [
            [
                InlineKeyboardButton("ðŸ“Š Show Diff", callback_data="git:diff"),
                InlineKeyboardButton("ðŸ“œ Show Log", callback_data="git:log"),
            ],
            [
                InlineKeyboardButton("ðŸ”„ Refresh", callback_data="git:status"),
                InlineKeyboardButton("ðŸ“ Files", callback_data="action:ls"),
            ],
        ]

        reply_markup = InlineKeyboardMarkup(keyboard)

        await message.reply_text(
            status_message, parse_mode=None, reply_markup=reply_markup
        )

    except Exception as e:
        await message.reply_text(f"âŒ **Git Error**\n\n{str(e)}")
        logger.error("Error in git_command", error=str(e), user_id=user_id)


def _format_file_size(size: int) -> str:
    """Format file size in human-readable format."""
    size_float = float(size)
    for unit in ["B", "KB", "MB", "GB"]:
        if size_float < 1024:
            return f"{size_float:.1f}{unit}" if unit != "B" else f"{int(size_float)}B"
        size_float /= 1024
    return f"{size_float:.1f}TB"


async def schedules_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """List and manage scheduled tasks."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    try:
        from ..features.scheduled_prompts import ScheduledPromptsManager
        
        # Get application from context
        application = context.application
        settings = context.bot_data.get("settings")
        
        if not application or not settings:
            await message.reply_text(
                "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸**\n"
                "ÐÐµÐ¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿ Ð´Ð¾ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ–Ð² ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸"
            )
            return
            
        prompts_manager = ScheduledPromptsManager(application, settings)
        config = await prompts_manager.load_prompts()
        prompts = config.get("prompts", [])
        system_settings = config.get("settings", {})
        
        if not prompts:
            keyboard = [[
                InlineKeyboardButton("âž• Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:add"),
                InlineKeyboardButton("âš™ï¸ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ", callback_data="schedule:settings")
            ]]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await message.reply_text(
                "ðŸ“‹ **ÐŸÐ»Ð°Ð½Ð¾Ð²Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð½ÐµÐ¼Ð°Ñ”**\n\n"
                "Ð¦Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ\n"
                "Ð¿Ñ–Ð´ Ñ‡Ð°Ñ DND Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ (23:00-08:00).\n\n"
                "ðŸ”§ Ð”Ð¾Ð´Ð°Ð¹Ñ‚Ðµ Ð¿ÐµÑ€ÑˆÐµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð´Ð»Ñ Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸",
                reply_markup=reply_markup
            )
            return
        
        # Build message with prompts list
        enabled_count = sum(1 for p in prompts if p.get("enabled", False))
        system_status = "âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð°" if system_settings.get("enabled", False) else "âŒ Ð’Ð¸Ð¼ÐºÐ½ÐµÐ½Ð°"
        
        message_text = (
            f"ðŸ“‹ **ÐŸÐ»Ð°Ð½Ð¾Ð²Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ** ({len(prompts)})\n"
            f"ðŸ”§ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð°: {system_status} | ÐÐºÑ‚Ð¸Ð²Ð½Ð¸Ñ…: {enabled_count}\n\n"
        )
        
        for i, prompt in enumerate(prompts[:10], 1):  # Show first 10
            status_icon = "âœ…" if prompt.get("enabled", False) else "âŒ"
            schedule = prompt.get("schedule", {})
            schedule_info = f"{schedule.get('type', 'daily')} Ð¾ {schedule.get('time', '02:00')}"
            
            message_text += (
                f"{i}. {status_icon} **{prompt.get('title', 'Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð¸')}**\n"
                f"   ðŸ“… {schedule_info}\n"
                f"   ðŸ“ {prompt.get('description', 'Ð‘ÐµÐ· Ð¾Ð¿Ð¸ÑÑƒ')[:50]}{'...' if len(prompt.get('description', '')) > 50 else ''}\n\n"
            )
        
        if len(prompts) > 10:
            message_text += f"... Ñ‚Ð° Ñ‰Ðµ {len(prompts) - 10} Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ\n\n"
            
        # Add control buttons
        keyboard = [
            [
                InlineKeyboardButton("âž• Ð”Ð¾Ð´Ð°Ñ‚Ð¸", callback_data="schedule:add"),
                InlineKeyboardButton("ðŸ“ Ð ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸", callback_data="schedule:edit")
            ],
            [
                InlineKeyboardButton("âš™ï¸ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ", callback_data="schedule:settings"),
                InlineKeyboardButton("ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°", callback_data="schedule:stats")
            ],
            [
                InlineKeyboardButton("ðŸ”„ ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸", callback_data="schedule:refresh"),
                InlineKeyboardButton("â–¶ï¸ Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ð²ÑÑ–", callback_data="schedule:run_all")
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await message.reply_text(message_text, reply_markup=reply_markup)
        
    except Exception as e:
        logger.error("Error in schedules command", error=str(e))
        await message.reply_text(
            "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°**\n"
            f"ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ: {str(e)}"
        )


async def add_schedule_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Add new scheduled task."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    try:
        # Create inline keyboard for adding new task
        keyboard = [
            [InlineKeyboardButton("ðŸ“ Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ", callback_data="schedule:create_new")],
            [InlineKeyboardButton("ðŸ“‹ Ð—Ñ– ÑˆÐ°Ð±Ð»Ð¾Ð½Ñƒ", callback_data="schedule:from_template")],
            [InlineKeyboardButton("ðŸ”™ ÐÐ°Ð·Ð°Ð´", callback_data="schedule:list")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        message_text = (
            "âž• **Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð¿Ð»Ð°Ð½Ð¾Ð²Ðµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ**\n\n"
            "ÐŸÐ»Ð°Ð½Ð¾Ð²Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð²Ð¸ÐºÐ¾Ð½ÑƒÑŽÑ‚ÑŒÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾\n"
            "Ð¿Ñ–Ð´ Ñ‡Ð°Ñ DND Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ (23:00-08:00)\n"
            "ÐºÐ¾Ð»Ð¸ Claude CLI Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð° Ñ‚Ð° ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ñ– Ð½Ðµ Ð¿Ñ€Ð°Ñ†ÑŽÑŽÑ‚ÑŒ.\n\n"
            "**Ð¢Ð¸Ð¿Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ:**\n"
            "â€¢ ðŸ” ÐÐ½Ð°Ð»Ñ–Ð· ÐºÐ¾Ð´Ñƒ Ñ‚Ð° Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸\n"
            "â€¢ ðŸ“Š Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ Ð·Ð²Ñ–Ñ‚Ñ–Ð²\n"
            "â€¢ ðŸ§¹ Ð ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³ Ñ‚Ð° Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ\n"
            "â€¢ ðŸ“ ÐžÐ½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—\n"
            "â€¢ ðŸ”’ ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð±ÐµÐ·Ð¿ÐµÐºÐ¸\n\n"
            "ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ ÑÐ¿Ð¾ÑÑ–Ð± ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ:"
        )
        
        await message.reply_text(message_text, reply_markup=reply_markup)
        
    except Exception as e:
        logger.error("Error in add_schedule command", error=str(e))
        await message.reply_text(
            "âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°**\n"
            f"ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð²Ñ–Ð´ÐºÑ€Ð¸Ñ‚Ð¸ Ð¼ÐµÐ½ÑŽ Ð´Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ: {str(e)}"
        )


# ========== MISSING CRITICAL COMMAND HANDLERS ==========

async def status_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Show bot and session status."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
    
    try:
        status_text = await t(context, user_id, "status.title")
        current_dir = await t(context, user_id, "status.directory", directory=str(Path.cwd()))
        claude_active = "ðŸ¤– Ð¡ÐµÑÑ–Ñ Claude: âœ… ÐÐºÑ‚Ð¸Ð²Ð½Ð°" if context.user_data.get('claude_session_active') else await t(context, user_id, "status.claude_session_inactive")
        
        full_status = f"{status_text}\n\n{current_dir}\n{claude_active}"
        await message.reply_text(full_status)
        logger.info("Status command executed", user_id=user_id)
    except Exception as e:
        await safe_user_error(update, context, "errors.status_failed", e)
        logger.error("Status handler error", error=str(e), user_id=user_id)

async def help_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Show help information."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
    
    try:
        help_text = await t(context, user_id, "help.title")
        commands_list = await t(context, user_id, "help.commands")
        await message.reply_text(f"{help_text}\n\n{commands_list}")
        logger.info("Help command executed", user_id=user_id)
    except Exception as e:
        await safe_user_error(update, context, "errors.help_failed", e)

async def new_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Start new Claude session."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
    
    try:
        await message.reply_text(await t(context, user_id, "session.new_started"))
        # Reset session in context.user_data
        if context.user_data:
            context.user_data['claude_session_id'] = None
            context.user_data['claude_session_active'] = False
        await message.reply_text(await t(context, user_id, "session.cleared"))
        logger.info("New session started", user_id=user_id)
    except Exception as e:
        await safe_user_error(update, context, "errors.session_new_failed", e)

async def actions_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Show available quick actions."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
    
    try:
        actions_text = await t(context, user_id, "actions.title")
        await message.reply_text(actions_text)
    except Exception as e:
        await safe_user_error(update, context, "errors.actions_failed", e)

async def pwd_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Show current directory."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
    
    try:
        pwd_text = await t(context, user_id, "pwd.title", directory=str(Path.cwd()))
        await message.reply_text(pwd_text)
    except Exception as e:
        await safe_user_error(update, context, "errors.pwd_failed", e)

async def projects_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Show project list."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
    
    try:
        projects_text = await t(context, user_id, "projects.title", count=0)
        await message.reply_text(projects_text)
    except Exception as e:
        await safe_user_error(update, context, "errors.projects_failed", e)


# FIXED: Git command (line ~1241 - mixed language fix)
async def git_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Git operations - fixed error handling."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    try:
        # Existing git logic...
        git_text = await t(context, user_id, "commands.git.title")
        await message.reply_text(f"ðŸ”— **{git_text}**")
    except Exception as e:
        error_msg = await t(context, user_id, "errors.git_operation_failed", error=str(e))
        await message.reply_text(error_msg)
        logger.error("Git operation failed", error=str(e), user_id=user_id)


def extract_auth_url(output: str) -> str:
    """Extract authentication URL from claude login output."""
    # Look for URLs in the output
    url_pattern = r'https://[^\s]+'
    urls = re.findall(url_pattern, output)
    for url in urls:
        if 'anthropic.com' in url or 'claude.ai' in url:
            return url
    return ""


def extract_reset_time(error_text: str) -> str:
    """Extract reset time from rate limit error."""
    # Look for reset time patterns in error messages
    patterns = [
        r'reset at (\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})',
        r'try again at (\d{2}:\d{2})',
        r'available at (\d+:\d+)',
        r'reset in (\d+) minutes',
        r'after (\d+:\d{2})'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, error_text, re.IGNORECASE)
        if match:
            return match.group(1)
    
    return "Ð½ÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¾"


def analyze_claude_error(error_text: str, stderr: str = "") -> tuple[str, dict]:
    """Analyze Claude CLI error and return appropriate message key and format args."""
    full_error = f"{error_text} {stderr}".lower()
    
    # Rate limiting patterns
    rate_limit_patterns = [
        "rate limit", "too many requests", "429", "quota exceeded",
        "requests per", "try again later", "temporary limit"
    ]
    
    # Quota/billing patterns  
    quota_patterns = [
        "usage limit", "billing", "plan limit", "daily limit",
        "monthly usage", "account limit", "subscription"
    ]
    
    # Network patterns
    network_patterns = [
        "network", "connection", "timeout", "dns", "unreachable",
        "connection refused", "connection reset", "no internet"
    ]
    
    # Server error patterns
    server_patterns = [
        "500", "502", "503", "504", "internal server error",
        "bad gateway", "service unavailable", "gateway timeout"
    ]
    
    # Invalid code patterns
    invalid_patterns = [
        "invalid code", "invalid token", "expired token", "wrong code",
        "authentication failed", "invalid authorization"
    ]
    
    if any(pattern in full_error for pattern in rate_limit_patterns):
        reset_time = extract_reset_time(full_error)
        return "commands.claude.error_rate_limit", {"reset_time": reset_time}
    
    elif any(pattern in full_error for pattern in quota_patterns):
        return "commands.claude.error_quota", {}
    
    elif any(pattern in full_error for pattern in network_patterns):
        return "commands.claude.error_network", {}
    
    elif any(pattern in full_error for pattern in server_patterns):
        return "commands.claude.error_server", {}
    
    elif any(pattern in full_error for pattern in invalid_patterns):
        return "commands.claude.error_invalid_code", {}
    
    else:
        return "commands.claude.error_generic", {}


# New Claude login helper functions
async def extract_auth_url_from_claude_login() -> Tuple[bool, str, Optional[pexpect.spawn]]:
    """Ð—Ð°Ð¿ÑƒÑÐºÐ°Ñ” `claude login` Ñ‚Ð° Ð²Ð¸Ñ‚ÑÐ³ÑƒÑ” URL Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—."""
    try:
        logger.info("Starting claude login to extract auth URL")

        # Ð—Ð°Ð¿ÑƒÑÐºÐ°Ñ”Ð¼Ð¾ Ð¿Ñ€Ð¾Ñ†ÐµÑ claude login
        child = pexpect.spawn('claude login', encoding='utf-8', timeout=30)

        # ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½Ð¸ Ð´Ð»Ñ Ð¿Ð¾ÑˆÑƒÐºÑƒ URL
        url_patterns = [
            r'https://claude\.ai/login\?[^\s]*',  # Claude login URL
            r'https://[^\s]*anthropic[^\s]*',     # Anthropic URL
            r'https://[^\s]+',                    # Ð‘ÑƒÐ´ÑŒ-ÑÐºÐ¸Ð¹ HTTPS URL
            pexpect.TIMEOUT,
            pexpect.EOF
        ]

        output_buffer = ""
        start_time = time.time()

        while time.time() - start_time < 30:  # 30 ÑÐµÐºÑƒÐ½Ð´ timeout
            try:
                index = child.expect(url_patterns, timeout=5)

                # Ð—Ð±Ð¸Ñ€Ð°Ñ”Ð¼Ð¾ Ð²ÐµÑÑŒ Ð²Ð¸Ð²Ñ–Ð´
                if child.before:
                    output_buffer += child.before
                if child.after and index < 3:  # URL Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾
                    output_buffer += child.after

                logger.debug("Claude login output", index=index, output=output_buffer[-200:])

                if index < 3:  # URL Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾
                    # Ð’Ð¸Ñ‚ÑÐ³ÑƒÑ”Ð¼Ð¾ URL Ð· output_buffer
                    url_match = re.search(r'https://[^\s]+', output_buffer)
                    if url_match:
                        auth_url = url_match.group(0)
                        logger.info("Auth URL extracted successfully", url=auth_url[:50] + "...")
                        return True, auth_url, child

                elif index == 3:  # TIMEOUT
                    continue

                elif index == 4:  # EOF
                    break

            except pexpect.TIMEOUT:
                continue

        # Ð¯ÐºÑ‰Ð¾ URL Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾, Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ð¼Ð¾ Ð²ÐµÑÑŒ output
        url_match = re.search(r'https://[^\s]+', output_buffer)
        if url_match:
            auth_url = url_match.group(0)
            logger.info("Auth URL found in buffer", url=auth_url[:50] + "...")
            return True, auth_url, child

        logger.error("No auth URL found in claude login output", output=output_buffer)
        try:
            if child and child.isalive():
                child.terminate(force=True)
        except:
            pass
        return False, f"No authentication URL found. Output: {output_buffer}", None

    except Exception as e:
        logger.error("Error extracting auth URL", error=str(e))
        try:
            if 'child' in locals() and child and child.isalive():
                child.terminate(force=True)
        except:
            pass
        return False, f"Error starting claude login: {str(e)}", None


async def submit_auth_code_to_claude(child: pexpect.spawn, auth_code: str) -> Tuple[bool, str]:
    """ÐÐ°Ð´ÑÐ¸Ð»Ð°Ñ” ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð´Ð¾ Ð¿Ñ€Ð¾Ñ†ÐµÑÑƒ claude login."""
    try:
        logger.info("Submitting auth code to claude login")

        # ÐÐ°Ð´ÑÐ¸Ð»Ð°Ñ”Ð¼Ð¾ ÐºÐ¾Ð´
        child.sendline(auth_code)

        # ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½Ð¸ Ð´Ð»Ñ Ð¾Ñ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð½Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñƒ
        result_patterns = [
            r'(?i)success',           # Ð£ÑÐ¿Ñ–Ñ…
            r'(?i)authenticated',     # ÐÐ²Ñ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ¾Ð²Ð°Ð½Ð¾
            r'(?i)logged.*in',        # Ð—Ð°Ð»Ð¾Ð³Ñ–Ð½ÐµÐ½Ð¾
            r'(?i)invalid.*code',     # ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ ÐºÐ¾Ð´
            r'(?i)expired.*code',     # ÐšÐ¾Ð´ Ð¿Ñ€Ð¾ÑÑ€Ð¾Ñ‡ÐµÐ½Ð¸Ð¹
            r'(?i)error',             # ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°
            r'(?i)failed',            # ÐÐµÐ²Ð´Ð°Ñ‡Ð°
            pexpect.TIMEOUT,
            pexpect.EOF
        ]

        output_buffer = ""
        start_time = time.time()

        while time.time() - start_time < 60:  # 60 ÑÐµÐºÑƒÐ½Ð´ Ð½Ð° Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–ÑŽ
            try:
                index = child.expect(result_patterns, timeout=10)

                # Ð—Ð±Ð¸Ñ€Ð°Ñ”Ð¼Ð¾ Ð²Ð¸Ð²Ñ–Ð´
                if child.before:
                    output_buffer += child.before
                if child.after and index < 7:
                    output_buffer += child.after

                logger.debug("Auth code response", index=index, output=output_buffer[-200:])

                if index in [0, 1, 2]:  # Ð£ÑÐ¿Ñ–Ñ…
                    logger.info("Authentication successful")
                    safe_terminate_process(child)
                    return True, "Authentication successful"

                elif index in [3, 4, 5, 6]:  # ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°
                    logger.warning("Authentication failed", output=output_buffer)
                    safe_terminate_process(child)
                    return False, f"Authentication failed: {output_buffer}"

                elif index == 7:  # TIMEOUT
                    continue

                elif index == 8:  # EOF
                    # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ exit code
                    if child.exitstatus == 0:
                        logger.info("Process exited successfully")
                        return True, "Authentication completed successfully"
                    else:
                        logger.warning("Process exited with error", exit_code=child.exitstatus)
                        return False, f"Process failed with exit code {child.exitstatus}: {output_buffer}"

            except pexpect.TIMEOUT:
                logger.debug("Waiting for auth response...")
                continue

        # Timeout
        logger.error("Authentication timeout", output=output_buffer)
        safe_terminate_process(child)
        return False, f"Authentication timed out: {output_buffer}"

    except Exception as e:
        logger.error("Error submitting auth code", error=str(e))
        safe_terminate_process(child)
        return False, f"Error during authentication: {str(e)}"


async def check_claude_auth_status() -> Tuple[bool, str]:
    """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ” Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Claude CLI."""
    try:
        logger.info("Checking Claude CLI auth status")

        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ñ„Ð°Ð¹Ð» Ð· ÐºÑ€ÐµÐ´ÐµÐ½ÑˆÐ¸Ð°Ð»Ð°Ð¼Ð¸
        credentials_path = Path.home() / ".claude" / ".credentials.json"

        if not credentials_path.exists():
            return False, "Ð¤Ð°Ð¹Ð» ÐºÑ€ÐµÐ´ÐµÐ½ÑˆÐ¸Ð°Ð»Ñ–Ð² Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾"

        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ñ‚ÐµÑ€Ð¼Ñ–Ð½ Ð´Ñ–Ñ— Ñ‚Ð¾ÐºÐµÐ½Ñƒ
        import json
        try:
            with open(credentials_path, 'r') as f:
                creds = json.load(f)
                oauth_data = creds.get("claudeAiOauth", {})
                expires_at = oauth_data.get("expiresAt", 0)
                current_time = time.time() * 1000

                if expires_at == 0:
                    return False, "ÐÐµÐºÐ¾Ñ€ÐµÐºÑ‚Ð½Ñ– ÐºÑ€ÐµÐ´ÐµÐ½ÑˆÐ¸Ð°Ð»Ð¸ (Ð½ÐµÐ¼Ð°Ñ” expiresAt)"

                if current_time >= expires_at:
                    return False, f"Ð¢Ð¾ÐºÐµÐ½ Ð¿Ñ€Ð¾ÑÑ€Ð¾Ñ‡ÐµÐ½Ð¸Ð¹"

                # Ð¯ÐºÑ‰Ð¾ Ñ‚Ð¾ÐºÐµÐ½ Ð²Ð°Ð»Ñ–Ð´Ð½Ð¸Ð¹ Ð¿Ð¾ Ñ‡Ð°ÑÑƒ, Ð¿Ñ€Ð¸Ð¿ÑƒÑÐºÐ°Ñ”Ð¼Ð¾ Ñ‰Ð¾ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ Ð¿Ñ€Ð°Ñ†ÑŽÑ”
                hours_remaining = (expires_at - current_time) / (1000 * 3600)
                return True, f"ÐÐ²Ñ‚Ð¾Ñ€Ð¸Ð·Ð¾Ð²Ð°Ð½Ð¸Ð¹ (Ð·Ð°Ð»Ð¸ÑˆÐ¸Ð»Ð¾ÑÑŒ {hours_remaining:.1f} Ð³Ð¾Ð´Ð¸Ð½)"

        except (json.JSONDecodeError, KeyError) as e:
            return False, f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ñ‡Ð¸Ñ‚Ð°Ð½Ð½Ñ ÐºÑ€ÐµÐ´ÐµÐ½ÑˆÐ¸Ð°Ð»Ñ–Ð²: {str(e)}"

    except Exception as e:
        logger.error("Error checking auth status", error=str(e))
        return False, f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸: {str(e)}"


async def login_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """ÐžÐ±Ñ€Ð¾Ð±Ð»ÑÑ” ÐºÐ¾Ð¼Ð°Ð½Ð´Ñƒ /login Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Claude CLI."""
    user_id = update.effective_user.id
    message = update.effective_message

    if not user_id or not message:
        return

    try:
        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ñ‡Ð¸ Ð½Ðµ Ð¾Ñ‡Ñ–ÐºÑƒÑ”Ð¼Ð¾ Ð²Ð¶Ðµ ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—
        if context.user_data.get('claude_auth_waiting'):
            await message.reply_text(
                "â³ **Ð’Ð¶Ðµ Ð¾Ñ‡Ñ–ÐºÑƒÑŽ ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—**\n\n"
                "ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð· Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð° Ð°Ð±Ð¾ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /cancel Ð´Ð»Ñ ÑÐºÐ°ÑÑƒÐ²Ð°Ð½Ð½Ñ."
            )
            return

        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—
        await message.reply_text("ðŸ” **ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑŽ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—...**")

        is_auth, status_msg = await check_claude_auth_status()

        if is_auth:
            await message.reply_text(
                f"âœ… **Claude CLI Ð²Ð¶Ðµ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð¾Ð²Ð°Ð½Ð¸Ð¹**\n\n"
                f"ðŸ“Š Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: {status_msg}\n\n"
                f"ÐÐ²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ Ð½Ðµ Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ð°!"
            )
            return

        # ÐŸÐ¾Ñ‡Ð¸Ð½Ð°Ñ”Ð¼Ð¾ Ð¿Ñ€Ð¾Ñ†ÐµÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—
        await message.reply_text(
            f"âŒ **Claude CLI Ð½Ðµ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð¾Ð²Ð°Ð½Ð¸Ð¹**\n\n"
            f"ðŸ“Š Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: {status_msg}\n\n"
            f"ðŸš€ ÐŸÐ¾Ñ‡Ð¸Ð½Ð°ÑŽ Ð¿Ñ€Ð¾Ñ†ÐµÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—..."
        )

        # Ð’Ð¸Ñ‚ÑÐ³ÑƒÑ”Ð¼Ð¾ URL Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—
        success, result, child = await extract_auth_url_from_claude_login()

        if not success:
            await message.reply_text(
                f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð¿ÑƒÑÐºÑƒ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—**\n\n"
                f"```\n{result}\n```\n\n"
                f"Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð· Ð°Ð±Ð¾ Ð·Ð²ÐµÑ€Ð½Ñ–Ñ‚ÑŒÑÑ Ð´Ð¾ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°."
            )
            return

        # Ð—Ð±ÐµÑ€Ñ–Ð³Ð°Ñ”Ð¼Ð¾ Ð¿Ñ€Ð¾Ñ†ÐµÑ Ð´Ð»Ñ Ð¿Ð¾Ð´Ð°Ð»ÑŒÑˆÐ¾Ð³Ð¾ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ
        context.user_data['claude_auth_waiting'] = True
        context.user_data['claude_auth_process'] = child
        context.user_data['claude_auth_url'] = result

        # ÐÐ°Ð´ÑÐ¸Ð»Ð°Ñ”Ð¼Ð¾ Ñ–Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ñ–Ñ— ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ñƒ
        auth_url = result
        instructions = (
            f"ðŸ” **ÐÐ²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ Claude CLI**\n\n"
            f"**ÐšÑ€Ð¾Ðº 1:** Ð’Ñ–Ð´ÐºÑ€Ð¸Ð¹Ñ‚Ðµ Ñ†Ðµ Ð¿Ð¾ÑÐ¸Ð»Ð°Ð½Ð½Ñ Ñƒ Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ñ–:\n"
            f"ðŸ‘† {auth_url}\n\n"
            f"**ÐšÑ€Ð¾Ðº 2:** Ð£Ð²Ñ–Ð¹Ð´Ñ–Ñ‚ÑŒ Ñƒ ÑÐ²Ñ–Ð¹ Ð°ÐºÐ°ÑƒÐ½Ñ‚ Claude\n\n"
            f"**ÐšÑ€Ð¾Ðº 3:** Ð¡ÐºÐ¾Ð¿Ñ–ÑŽÐ¹Ñ‚Ðµ ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—\n\n"
            f"**ÐšÑ€Ð¾Ðº 4:** ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ ÐºÐ¾Ð´ Ñƒ Ñ†Ðµ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ\n\n"
            f"â³ **ÐžÑ‡Ñ–ÐºÑƒÑŽ ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—...**\n\n"
            f"ðŸ’¡ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /cancel Ð´Ð»Ñ ÑÐºÐ°ÑÑƒÐ²Ð°Ð½Ð½Ñ"
        )

        await message.reply_text(instructions)

        logger.info("Claude login process started", user_id=user_id, url_length=len(auth_url))

    except Exception as e:
        logger.error("Error in login command", error=str(e), user_id=user_id, exc_info=True)

        # ÐžÑ‡Ð¸Ñ‰ÑƒÑ”Ð¼Ð¾ ÑÑ‚Ð°Ð½ Ð² Ñ€Ð°Ð·Ñ– Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ¸
        context.user_data.pop('claude_auth_waiting', None)
        if 'claude_auth_process' in context.user_data:
            try:
                context.user_data['claude_auth_process'].close()
            except:
                pass
            context.user_data.pop('claude_auth_process', None)

        await message.reply_text(
            f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸**\n\n"
            f"```\n{str(e)}\n```\n\n"
            f"Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ñ‰Ðµ Ñ€Ð°Ð·."
        )


# Alias for backward compatibility
async def claude_auth_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Deprecated: Use /login instead. Redirects to login_command."""
    await login_command(update, context)


async def handle_claude_auth_code(update: Update, context: ContextTypes.DEFAULT_TYPE) -> bool:
    """
    ÐžÐ±Ñ€Ð¾Ð±Ð»ÑÑ” Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð· ÐºÐ¾Ð´Ð¾Ð¼ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—.
    Returns: True ÑÐºÑ‰Ð¾ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð¾Ð±Ñ€Ð¾Ð±Ð»ÐµÐ½Ð¾ ÑÐº ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—, False Ñ–Ð½Ð°ÐºÑˆÐµ
    """
    user_id = update.effective_user.id
    message = update.effective_message

    if not user_id or not message or not message.text:
        return False

    # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ñ‡Ð¸ Ð¾Ñ‡Ñ–ÐºÑƒÑ”Ð¼Ð¾ ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—
    if not context.user_data.get('claude_auth_waiting'):
        return False

    auth_code = message.text.strip()

    # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ ÐºÐ¾Ð´Ñƒ (Ð·Ð°Ð·Ð²Ð¸Ñ‡Ð°Ð¹ Ñ†Ðµ Ð´Ð¾Ð²Ð³Ð¸Ð¹ Ñ€ÑÐ´Ð¾Ðº)
    if len(auth_code) < 10:
        await message.reply_text(
            "ðŸ¤” **ÐšÐ¾Ð´ Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¹**\n\n"
            "ÐšÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð·Ð°Ð·Ð²Ð¸Ñ‡Ð°Ð¹ Ð´Ð¾Ð²Ð³Ð¸Ð¹ Ñ€ÑÐ´Ð¾Ðº.\n"
            "ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ñ‚Ð° Ð½Ð°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¸Ð¹ ÐºÐ¾Ð´.\n\n"
            "ðŸ’¡ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /cancel Ð´Ð»Ñ ÑÐºÐ°ÑÑƒÐ²Ð°Ð½Ð½Ñ"
        )
        return True

    try:
        await message.reply_text("ðŸ”„ **ÐžÐ±Ñ€Ð¾Ð±Ð»ÑÑŽ ÐºÐ¾Ð´ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—...**")

        # ÐžÑ‚Ñ€Ð¸Ð¼ÑƒÑ”Ð¼Ð¾ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¸Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑ
        child = context.user_data.get('claude_auth_process')
        if not child or not child.isalive():
            await message.reply_text(
                "âŒ **Ð¡ÐµÑÑ–Ñ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð²Ñ‚Ñ€Ð°Ñ‡ÐµÐ½Ð°**\n\n"
                "ÐŸÑ€Ð¾Ñ†ÐµÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ð±Ñ–Ð»ÑŒÑˆÐµ Ð½Ðµ Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¹.\n"
                "Ð’Ð¸ÐºÐ¾Ð½Ð°Ð¹Ñ‚Ðµ /login Ð·Ð½Ð¾Ð²Ñƒ."
            )
            # ÐžÑ‡Ð¸Ñ‰ÑƒÑ”Ð¼Ð¾ ÑÑ‚Ð°Ð½
            context.user_data.pop('claude_auth_waiting', None)
            context.user_data.pop('claude_auth_process', None)
            return True

        # ÐÐ°Ð´ÑÐ¸Ð»Ð°Ñ”Ð¼Ð¾ ÐºÐ¾Ð´ Ð´Ð¾ Claude CLI
        success, result = await submit_auth_code_to_claude(child, auth_code)

        # ÐžÑ‡Ð¸Ñ‰ÑƒÑ”Ð¼Ð¾ ÑÑ‚Ð°Ð½ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—
        context.user_data.pop('claude_auth_waiting', None)
        context.user_data.pop('claude_auth_process', None)
        context.user_data.pop('claude_auth_url', None)

        if success:
            await message.reply_text(
                f"âœ… **ÐÐ²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ ÑƒÑÐ¿Ñ–ÑˆÐ½Ð°!**\n\n"
                f"ðŸŽ‰ Claude CLI Ñ‚ÐµÐ¿ÐµÑ€ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð¾Ð²Ð°Ð½Ð¸Ð¹\n"
                f"ðŸ“Š Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: {result}\n\n"
                f"Ð¢ÐµÐ¿ÐµÑ€ Ð²Ð¸ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‚Ð¸ÑÑ Ð²ÑÑ–Ð¼Ð° Ñ„ÑƒÐ½ÐºÑ†Ñ–ÑÐ¼Ð¸ Ð±Ð¾Ñ‚Ð°!"
            )
            logger.info("Claude CLI authentication successful", user_id=user_id)
        else:
            await message.reply_text(
                f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—**\n\n"
                f"```\n{result}\n```\n\n"
                f"Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ /login Ð·Ð½Ð¾Ð²Ñƒ Ð· Ð½Ð¾Ð²Ð¸Ð¼ ÐºÐ¾Ð´Ð¾Ð¼."
            )
            logger.warning("Claude CLI authentication failed", user_id=user_id, error=result)

        return True

    except Exception as e:
        logger.error("Error processing auth code", error=str(e), user_id=user_id, exc_info=True)

        # ÐžÑ‡Ð¸Ñ‰ÑƒÑ”Ð¼Ð¾ ÑÑ‚Ð°Ð½
        context.user_data.pop('claude_auth_waiting', None)
        if 'claude_auth_process' in context.user_data:
            try:
                context.user_data['claude_auth_process'].close()
            except:
                pass
            context.user_data.pop('claude_auth_process', None)

        await message.reply_text(
            f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ ÐºÐ¾Ð´Ñƒ**\n\n"
            f"```\n{str(e)}\n```\n\n"
            f"Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ /login Ð·Ð½Ð¾Ð²Ñƒ."
        )
        return True


async def cancel_auth_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Ð¡ÐºÐ°ÑÐ¾Ð²ÑƒÑ” Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—."""
    user_id = update.effective_user.id
    message = update.effective_message

    if not user_id or not message:
        return

    if not context.user_data.get('claude_auth_waiting'):
        await message.reply_text(
            "â„¹ï¸ **ÐÐµÐ¼Ð°Ñ” Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ñ†ÐµÑÑƒ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—**\n\n"
            "ÐÐµÐ¼Ð°Ñ” Ñ‰Ð¾ ÑÐºÐ°ÑÐ¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸."
        )
        return

    try:
        # Ð—Ð°ÐºÑ€Ð¸Ð²Ð°Ñ”Ð¼Ð¾ Ð¿Ñ€Ð¾Ñ†ÐµÑ ÑÐºÑ‰Ð¾ Ð²Ñ–Ð½ Ñ”
        if 'claude_auth_process' in context.user_data:
            process = context.user_data['claude_auth_process']
            safe_terminate_process(process)
            context.user_data.pop('claude_auth_process', None)

        # ÐžÑ‡Ð¸Ñ‰ÑƒÑ”Ð¼Ð¾ ÑÑ‚Ð°Ð½
        context.user_data.pop('claude_auth_waiting', None)
        context.user_data.pop('claude_auth_url', None)

        await message.reply_text(
            "âœ… **ÐÐ²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ ÑÐºÐ°ÑÐ¾Ð²Ð°Ð½Ð°**\n\n"
            "ÐŸÑ€Ð¾Ñ†ÐµÑ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Claude CLI ÑÐºÐ°ÑÐ¾Ð²Ð°Ð½Ð¾.\n"
            "Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /login Ð´Ð»Ñ Ð½Ð¾Ð²Ð¾Ñ— ÑÐ¿Ñ€Ð¾Ð±Ð¸."
        )

        logger.info("Claude CLI authentication cancelled", user_id=user_id)

    except Exception as e:
        logger.error("Error cancelling auth", error=str(e), user_id=user_id)
        await message.reply_text(
            f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÑÐºÐ°ÑÑƒÐ²Ð°Ð½Ð½Ñ**\n\n"
            f"```\n{str(e)}\n```"
        )


# Registration function for handlers
def register_handlers(application):
    """Register all command handlers."""
    from telegram.ext import CommandHandler
    
    # Register all command handlers
    application.add_handler(CommandHandler("start", start_command))
    application.add_handler(CommandHandler("help", help_handler))
    application.add_handler(CommandHandler("new", new_handler))
    application.add_handler(CommandHandler("status", status_handler))
    application.add_handler(CommandHandler("actions", actions_handler))
    application.add_handler(CommandHandler("pwd", pwd_handler))
    application.add_handler(CommandHandler("projects", projects_handler))
    application.add_handler(CommandHandler("ls", list_files))
    application.add_handler(CommandHandler("cd", change_directory))
    application.add_handler(CommandHandler("continue", continue_session))
    application.add_handler(CommandHandler("end", end_session))
    application.add_handler(CommandHandler("export", export_session))
    application.add_handler(CommandHandler("git", git_handler))
    application.add_handler(CommandHandler("claude", claude_auth_command))
    application.add_handler(CommandHandler("schedules", schedules_command))
    application.add_handler(CommandHandler("add_schedule", add_schedule_command))


async def img_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /img command for image processing."""
    # Get the image handler instance from bot data
    image_handler = context.bot_data.get('image_command_handler')
    if image_handler:
        await image_handler.handle_img_command(update, context)
    else:
        # Fallback error message
        user_id = get_user_id(update)
        message = get_effective_message(update)
        if user_id and message:
            error_text = await t(context, user_id, "errors.image_processing_disabled")
            await message.reply_text(error_text)


async def restart_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /restart command to restart the bot."""
    import subprocess
    import os

    user_id = get_user_id(update)
    message = get_effective_message(update)

    if not user_id or not message:
        return

    try:
        # Check if user has admin privileges or is authorized
        auth_manager = context.bot_data.get("auth_manager")
        if auth_manager and not auth_manager.is_authenticated(user_id):
            access_denied_text = await t(context, user_id, "commands.restart.access_denied")
            await message.reply_text(access_denied_text)
            return

        # Send confirmation message
        restarting_text = await t(context, user_id, "commands.restart.restarting")
        status_msg = await message.reply_text(restarting_text)

        # Run the restart script
        script_path = "/home/vokov/claude-notifer-and-bot/restart-bot.sh"
        if os.path.exists(script_path):
            # Execute restart script in background
            subprocess.Popen([script_path], cwd="/home/vokov/claude-notifer-and-bot")

            # The current process will be killed by the script, so this might not send
            initiated_text = await t(context, user_id, "commands.restart.initiated")
            await status_msg.edit_text(initiated_text)
        else:
            script_not_found_text = await t(context, user_id, "commands.restart.script_not_found")
            await status_msg.edit_text(script_not_found_text)

    except Exception as e:
        logger.error("Error in restart command", error=str(e), user_id=user_id)
        failed_text = await t(context, user_id, "commands.restart.failed")
        await message.reply_text(f"{failed_text}\n\nError: {str(e)}")


async def audit_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð°ÑƒÐ´Ð¸Ñ‚ Ð±Ð¾Ñ‚Ð°"""
    user_id = get_user_id(update)
    message = get_effective_message(update)

    if not user_id or not message:
        return

    logger.info("Starting intelligent bot audit", user_id=user_id)

    try:
        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð¿Ñ€Ð°Ð²Ð° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ñƒ (Ñ‚Ñ–Ð»ÑŒÐºÐ¸ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð¸)
        auth_manager = context.bot_data.get("auth_manager")
        if not auth_manager or not auth_manager.is_authenticated(user_id):
            await message.reply_text("âŒ Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ð·Ð°Ð±Ð¾Ñ€Ð¾Ð½ÐµÐ½Ð¾. ÐÑƒÐ´Ð¸Ñ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹ Ñ‚Ñ–Ð»ÑŒÐºÐ¸ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°Ð¼.")
            return

        # ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ñ–Ð² ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸
        message_text = message.text or ""
        parts = message_text.split()

        focus_area = None
        if len(parts) > 1:
            focus_area = parts[1].lower()
            if focus_area not in ["callbacks", "localization", "security", "architecture", "quick"]:
                await message.reply_text(
                    "âŒ ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð° Ð¾Ð±Ð»Ð°ÑÑ‚ÑŒ Ð°ÑƒÐ´Ð¸Ñ‚Ñƒ.\n\n"
                    "Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ð¾Ð¿Ñ†Ñ–Ñ—:\n"
                    "â€¢ `/audit` - Ð¿Ð¾Ð²Ð½Ð¸Ð¹ Ð°ÑƒÐ´Ð¸Ñ‚\n"
                    "â€¢ `/audit quick` - ÑˆÐ²Ð¸Ð´ÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð·\n"
                    "â€¢ `/audit callbacks` - Ð°Ð½Ð°Ð»Ñ–Ð· callback handlers\n"
                    "â€¢ `/audit localization` - Ð°Ð½Ð°Ð»Ñ–Ð· Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´Ñ–Ð²\n"
                    "â€¢ `/audit security` - Ð°Ð½Ð°Ð»Ñ–Ð· Ð±ÐµÐ·Ð¿ÐµÐºÐ¸\n"
                    "â€¢ `/audit architecture` - Ð°Ð½Ð°Ð»Ñ–Ð· Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸"
                )
                return

        # ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾ Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¾Ðº Ð°ÑƒÐ´Ð¸Ñ‚Ñƒ
        if focus_area == "quick":
            status_text = "ðŸ” **Ð¨Ð²Ð¸Ð´ÐºÐ¸Ð¹ Ð°ÑƒÐ´Ð¸Ñ‚ ÐºÐ¾Ð´Ñƒ...**\n\nÐ—Ð°Ð¿ÑƒÑÐºÐ°ÑŽ Ð±Ð°Ð·Ð¾Ð²Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð·..."
        elif focus_area:
            status_text = f"ðŸ” **Ð¤Ð¾ÐºÑƒÑÐ¾Ð²Ð°Ð½Ð¸Ð¹ Ð°ÑƒÐ´Ð¸Ñ‚: {focus_area}**\n\nÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ {focus_area}..."
        else:
            status_text = "ðŸ” **ÐŸÐ¾Ð²Ð½Ð¸Ð¹ Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð°ÑƒÐ´Ð¸Ñ‚**\n\nÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ ÐºÐ¾Ð´, Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ñ‚Ð° Ð»Ð¾Ð³Ñ–ÐºÑƒ..."

        status_msg = await message.reply_text(status_text)

        # ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Claude Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–ÑŽ
        claude_integration = context.bot_data.get("claude_integration")
        settings = context.bot_data.get("settings")

        if not settings:
            await status_msg.edit_text("âŒ ÐšÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ Ð±Ð¾Ñ‚Ð° Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°")
            return

        # Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€
        from ..features.intelligent_auditor import IntelligentTelegramBotAuditor, format_audit_report

        auditor = IntelligentTelegramBotAuditor(
            project_root=str(settings.approved_directory),
            claude_integration=claude_integration if focus_area != "quick" else None
        )

        # ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð´Ð»Ñ ÑˆÐ²Ð¸Ð´ÐºÐ¾Ð³Ð¾ Ð°ÑƒÐ´Ð¸Ñ‚Ñƒ
        if focus_area == "quick":
            auditor.analysis_config["enable_claude_analysis"] = False
            auditor.analysis_config["group_similar_issues"] = False

        await status_msg.edit_text(f"{status_text}\n\nâ³ Ð’Ð¸ÐºÐ¾Ð½ÑƒÑŽ Ð°Ð½Ð°Ð»Ñ–Ð· ÐºÐ¾Ð´Ñƒ...")

        # Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ð°ÑƒÐ´Ð¸Ñ‚
        result = await auditor.run_audit(focus_area)

        # Ð—Ð³ÐµÐ½ÐµÑ€ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð²Ñ–Ñ‚
        report = format_audit_report(result)

        # Ð’Ñ–Ð´Ð¿Ñ€Ð°Ð²Ð¸Ñ‚Ð¸ Ð·Ð²Ñ–Ñ‚
        if len(report) > 4096:
            # Ð Ð¾Ð·Ð±Ð¸Ñ‚Ð¸ Ð½Ð° Ñ‡Ð°ÑÑ‚Ð¸Ð½Ð¸ Ð´Ð»Ñ Telegram
            chunks = [report[i:i+4000] for i in range(0, len(report), 4000)]

            await status_msg.edit_text(f"âœ… **ÐÑƒÐ´Ð¸Ñ‚ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾!**\n\nÐ—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ {result.total_issues} Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼.\nÐ’Ñ–Ð´Ð¿Ñ€Ð°Ð²Ð»ÑÑŽ Ð·Ð²Ñ–Ñ‚...")

            for i, chunk in enumerate(chunks):
                if i == 0:
                    await message.reply_text(chunk, parse_mode=None)
                else:
                    await message.reply_text(f"**Ð§Ð°ÑÑ‚Ð¸Ð½Ð° {i+1}:**\n\n{chunk}", parse_mode=None)

                if i < len(chunks) - 1:
                    await asyncio.sleep(1)  # Ð£Ð½Ð¸ÐºÐ½ÑƒÑ‚Ð¸ rate limit
        else:
            await status_msg.edit_text(report, parse_mode=None)

        # Ð”Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ð´Ð»Ñ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¸Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼
        critical_issues = [i for i in result.issues if i.severity == "CRITICAL"]
        if critical_issues and focus_area != "quick":
            await message.reply_text(
                f"ðŸš¨ **Ð£Ð’ÐÐ“Ð!** Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ {len(critical_issues)} ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¸Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼.\n\n"
                f"Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÑŽ Ð½ÐµÐ³Ð°Ð¹Ð½Ð¾ Ð²Ð¸Ð¿Ñ€Ð°Ð²Ð¸Ñ‚Ð¸ Ñ†Ñ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸, Ð¾ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ð²Ð¾Ð½Ð¸ Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð²Ð¿Ð»Ð¸Ð²Ð°Ñ‚Ð¸ Ð½Ð° Ñ€Ð¾Ð±Ð¾Ñ‚Ñƒ Ð±Ð¾Ñ‚Ð°."
            )

        logger.info("Audit completed",
                   user_id=user_id,
                   total_issues=result.total_issues,
                   critical=result.critical_count,
                   focus_area=focus_area)

    except Exception as e:
        logger.error("Error in audit command", error=str(e), user_id=user_id, exc_info=True)
        error_msg = f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ñ–Ð´ Ñ‡Ð°Ñ Ð°ÑƒÐ´Ð¸Ñ‚Ñƒ**\n\n`{str(e)}`"

        try:
            await status_msg.edit_text(error_msg)
        except:
            await message.reply_text(error_msg)


async def dracon_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """DRACON-YAML bot logic modeling command."""
    user_id = get_user_id(update)
    message = get_effective_message(update)

    if not message:
        logger.warning("No message in dracon command", user_id=user_id)
        return

    logger.info("DRACON command invoked", user_id=user_id)

    try:
        from ..features.dracon_yaml import DraconYamlProcessor, EXAMPLE_MENU_SCHEMA
        from ..features.dracon_storage import DraconStorageManager

        # Parse command arguments
        args = context.args if context.args else []
        command_text = " ".join(args) if args else ""

        # Initialize storage manager
        settings = context.bot_data.get("settings")
        if not settings:
            await message.reply_text("âŒ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð±Ð¾Ñ‚Ð° Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–")
            return

        storage = DraconStorageManager(str(settings.approved_directory))

        # Show help if no arguments
        if not command_text or command_text.lower() in ["help", "Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð°"]:
            help_text = """ðŸ”§ **Enhanced DRACON-YAML Bot Logic Modeling**

DRACON (Ð”Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ðµ Ð ÑƒÑÑÐºÐ¸Ðµ ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹, ÐšÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÐžÐ±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÑŽÑ‚ ÐÐ°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚ÑŒ) - Ð¿Ñ€Ð¾Ñ„ÐµÑÑ–Ð¹Ð½Ð° ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¼Ð¾Ð´ÐµÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð»Ð¾Ð³Ñ–ÐºÐ¸ Ð±Ð¾Ñ‚Ð° Ð· Ð²Ñ–Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¼Ð¸ Ð´Ñ–Ð°Ð³Ñ€Ð°Ð¼Ð°Ð¼Ð¸.

**ÐžÑÐ½Ð¾Ð²Ð½Ñ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸:**
â€¢ `/dracon help` - Ð¦Ñ Ð´Ð¾Ð²Ñ–Ð´ÐºÐ°
â€¢ `/dracon example` - ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´ ÑÑ…ÐµÐ¼Ð¸
â€¢ `/dracon analyze <yaml>` - ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÐ²Ð°Ñ‚Ð¸ YAML-ÑÑ…ÐµÐ¼Ñƒ
â€¢ `/dracon generate <yaml>` - Ð—Ð³ÐµÐ½ÐµÑ€ÑƒÐ²Ð°Ñ‚Ð¸ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¸
â€¢ `/dracon validate <yaml>` - ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ ÑÑ…ÐµÐ¼Ñƒ
â€¢ `/dracon diagram <category> <filename>` - ðŸŽ¨ Ð’Ñ–Ð·ÑƒÐ°Ð»ÑŒÐ½Ð° Ð´Ñ–Ð°Ð³Ñ€Ð°Ð¼Ð°

**Ð¤Ð°Ð¹Ð»Ð¾Ð²Ñ– Ð¾Ð¿ÐµÑ€Ð°Ñ†Ñ–Ñ—:**
â€¢ `/dracon list [category]` - Ð¡Ð¿Ð¸ÑÐ¾Ðº Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¸Ñ… ÑÑ…ÐµÐ¼
â€¢ `/dracon load <category> <filename>` - Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ð¸Ñ‚Ð¸ ÑÑ…ÐµÐ¼Ñƒ
â€¢ `/dracon save <category> <name>` - Ð—Ð±ÐµÑ€ÐµÐ³Ñ‚Ð¸ ÑÑ…ÐµÐ¼Ñƒ
â€¢ `/dracon copy <from_cat> <filename> <to_cat>` - ÐšÐ¾Ð¿Ñ–ÑŽÐ²Ð°Ñ‚Ð¸ ÑÑ…ÐµÐ¼Ñƒ
â€¢ `/dracon delete <category> <filename>` - Ð’Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸ ÑÑ…ÐµÐ¼Ñƒ
â€¢ `/dracon stats` - Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð·Ð±ÐµÑ€Ñ–Ð³Ð°Ð½Ð½Ñ

**ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ— ÑÑ…ÐµÐ¼:**
ðŸ“ `reverse` - Ð¡Ñ…ÐµÐ¼Ð¸ Ð· Ñ€ÐµÐ²ÐµÑ€Ñ-Ñ–Ð½Ð¶Ð¸Ð½Ñ–Ñ€Ð¸Ð½Ð³Ñƒ
ðŸ“ `build` - Ð‘Ð°Ð·Ð¾Ð²Ñ– ÑÑ…ÐµÐ¼Ð¸ Ð´Ð»Ñ Ñ€Ð¾Ð·Ð±ÑƒÐ´Ð¾Ð²Ð¸
ðŸ“ `audit` - Ð¡Ñ…ÐµÐ¼Ð¸ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ
ðŸ“ `library` - Ð‘Ñ–Ð±Ð»Ñ–Ð¾Ñ‚ÐµÐºÐ° ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ–Ð²
ðŸ“ `active` - ÐÐºÑ‚Ð¸Ð²Ð½Ñ– ÑÑ…ÐµÐ¼Ð¸
ðŸ“ `archive` - ÐÑ€Ñ…Ñ–Ð²Ð½Ñ– Ð²ÐµÑ€ÑÑ–Ñ—

**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´:**
```
/dracon save reverse my_bot_schema
/dracon list reverse
/dracon load reverse my_bot_schema_20241219_143022.yaml
```"""

            await message.reply_text(help_text, parse_mode="Markdown")
            return

        # Handle visual diagram generation
        if command_text.lower().startswith("diagram"):
            parts = command_text.split()
            if len(parts) < 3:
                await message.reply_text("âŒ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ: `/dracon diagram <category> <filename>`")
                return

            category = parts[1]
            filename = parts[2]

            try:
                # Load schema
                schema_content = storage.load_schema(category, filename)
                if not schema_content:
                    await message.reply_text(f"âŒ Ð¡Ñ…ÐµÐ¼Ð° `{filename}` Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð² ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ— `{category}`")
                    return

                # Process with enhanced processor
                from ..features.dracon_enhanced import EnhancedDraconProcessor
                processor = EnhancedDraconProcessor()

                # Create temporary file for processing
                temp_file = storage.temp_dir / f"temp_{filename}"
                with open(temp_file, 'w', encoding='utf-8') as f:
                    f.write(schema_content)

                # Process schema
                result = await processor.process_schema_file(temp_file)

                if not result["success"]:
                    error_msg = "âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ ÑÑ…ÐµÐ¼Ð¸:\n" + "\n".join(result.get("errors", []))
                    await message.reply_text(error_msg)
                    return

                # Send visual diagram if available
                if result.get("svg_diagram"):
                    try:
                        # Convert SVG to PNG for Telegram
                        import io
                        from PIL import Image
                        import cairosvg

                        png_data = cairosvg.svg2png(bytestring=result["svg_diagram"].encode('utf-8'))

                        await message.reply_photo(
                            photo=io.BytesIO(png_data),
                            caption=f"ðŸ“Š **Ð’Ñ–Ð·ÑƒÐ°Ð»ÑŒÐ½Ð° ÑÑ…ÐµÐ¼Ð°:** {result['metadata']['name']}\n"
                                   f"ðŸ”§ Ð’ÑƒÐ·Ð»Ñ–Ð²: {result['metadata']['node_count']}\n"
                                   f"âž¡ï¸ Ð—'Ñ”Ð´Ð½Ð°Ð½ÑŒ: {result['metadata']['edge_count']}\n"
                                   f"âš¡ Ð¡ÐºÐ»Ð°Ð´Ð½Ñ–ÑÑ‚ÑŒ: {result['metadata']['complexity']}"
                        )
                    except Exception as e:
                        logger.warning("Failed to convert SVG to PNG", error=str(e))
                        # Fallback to text description
                        await message.reply_text(
                            f"ðŸ“Š **Ð¡Ñ…ÐµÐ¼Ð° Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ð°:** {result['metadata']['name']}\n"
                            f"ðŸ”§ Ð’ÑƒÐ·Ð»Ñ–Ð²: {result['metadata']['node_count']}\n"
                            f"âž¡ï¸ Ð—'Ñ”Ð´Ð½Ð°Ð½ÑŒ: {result['metadata']['edge_count']}\n"
                            f"âš¡ Ð¡ÐºÐ»Ð°Ð´Ð½Ñ–ÑÑ‚ÑŒ: {result['metadata']['complexity']}\n\n"
                            f"*Ð’Ñ–Ð·ÑƒÐ°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð° (Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±ÐµÐ½ cairosvg)*"
                        )

                # Cleanup
                temp_file.unlink(missing_ok=True)

            except Exception as e:
                logger.error("Diagram generation failed", error=str(e))
                await message.reply_text(f"âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ— Ð´Ñ–Ð°Ð³Ñ€Ð°Ð¼Ð¸: {str(e)}")
            return

        # Handle file operations first
        if command_text.lower().startswith("list"):
            parts = command_text.split()
            category = parts[1] if len(parts) > 1 else None

            try:
                schemas = storage.list_schemas(category)

                if not any(schemas.values()):
                    await message.reply_text("ðŸ“ **ÐÐµÐ¼Ð°Ñ” Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¸Ñ… ÑÑ…ÐµÐ¼**\n\nÐ’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸ Ð´Ð»Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ñ‚Ð° Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ ÑÑ…ÐµÐ¼.")
                    return

                report = "ðŸ“‹ **Ð—Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ñ– DRACON Ð¡Ñ…ÐµÐ¼Ð¸**\n\n"

                for cat, schema_list in schemas.items():
                    if not schema_list:
                        continue

                    report += f"ðŸ“ **{cat}** ({len(schema_list)} ÑÑ…ÐµÐ¼):\n"
                    for schema in schema_list[:5]:  # Show first 5
                        report += f"â€¢ `{schema['filename']}`\n"
                        if 'metadata' in schema and 'description' in schema['metadata']:
                            report += f"  ðŸ“ {schema['metadata']['description'][:50]}...\n"
                        report += f"  ðŸ“… {schema['created'][:10]}\n"

                    if len(schema_list) > 5:
                        report += f"  ... Ñ‚Ð° Ñ‰Ðµ {len(schema_list) - 5} ÑÑ…ÐµÐ¼\n"
                    report += "\n"

                await message.reply_text(report)

            except Exception as e:
                await message.reply_text(f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð½Ñ ÑÐ¿Ð¸ÑÐºÑƒ:**\n\n`{str(e)}`")
            return

        elif command_text.lower().startswith("load"):
            parts = command_text.split()
            if len(parts) < 3:
                await message.reply_text("âŒ **Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ:** `/dracon load <category> <filename>`")
                return

            category, filename = parts[1], parts[2]

            try:
                schema_yaml, metadata = storage.load_schema(category, filename)

                # Show schema info
                info = f"âœ… **Ð¡Ñ…ÐµÐ¼Ð° Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð°:** `{filename}`\n"
                info += f"ðŸ“ ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ: `{category}`\n"

                if metadata:
                    if 'description' in metadata:
                        info += f"ðŸ“ ÐžÐ¿Ð¸Ñ: {metadata['description']}\n"
                    if 'saved_at' in metadata:
                        info += f"ðŸ“… Ð—Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¾: {metadata['saved_at'][:10]}\n"

                await message.reply_text(info)

                # Send schema content
                await message.reply_text(f"ðŸ“‹ **Ð’Ð¼Ñ–ÑÑ‚ ÑÑ…ÐµÐ¼Ð¸:**\n\n```yaml\n{schema_yaml}\n```", parse_mode="Markdown")

            except Exception as e:
                await message.reply_text(f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ:**\n\n`{str(e)}`")
            return

        elif command_text.lower().startswith("stats"):
            try:
                stats = storage.get_storage_stats()

                report = f"ðŸ“Š **Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° DRACON Ð¡Ñ…Ð¾Ð²Ð¸Ñ‰Ð°**\n\n"
                report += f"**Ð—Ð°Ð³Ð°Ð»ÑŒÐ½Ð° Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ñ:**\n"
                report += f"â€¢ Ð’ÑÑŒÐ¾Ð³Ð¾ ÑÑ…ÐµÐ¼: {stats['total_schemas']}\n"
                report += f"â€¢ Ð—Ð°Ð³Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€: {stats['total_size'] / 1024:.1f} KB\n\n"

                report += f"**ÐŸÐ¾ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–ÑÑ…:**\n"
                for category, info in stats['categories'].items():
                    report += f"ðŸ“ {category}: {info['count']} ÑÑ…ÐµÐ¼ ({info['size'] / 1024:.1f} KB)\n"

                if stats['newest_schema']:
                    from pathlib import Path
                    report += f"\nðŸ†• ÐÐ°Ð¹Ð½Ð¾Ð²Ñ–ÑˆÐ°: `{Path(stats['newest_schema']).name}`\n"
                if stats['oldest_schema']:
                    report += f"ðŸ“œ ÐÐ°Ð¹ÑÑ‚Ð°Ñ€Ñ–ÑˆÐ°: `{Path(stats['oldest_schema']).name}`"

                await message.reply_text(report)

            except Exception as e:
                await message.reply_text(f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸:**\n\n`{str(e)}`")
            return

        elif command_text.lower().startswith("copy"):
            parts = command_text.split()
            if len(parts) < 4:
                await message.reply_text("âŒ **Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ:** `/dracon copy <source_category> <filename> <target_category>`")
                return

            source_cat, filename, target_cat = parts[1], parts[2], parts[3]

            try:
                new_path = storage.copy_schema(source_cat, filename, target_cat)
                await message.reply_text(f"âœ… **Ð¡Ñ…ÐµÐ¼Ñƒ ÑÐºÐ¾Ð¿Ñ–Ð¹Ð¾Ð²Ð°Ð½Ð¾!**\n\nðŸ“‚ Ð—: `{source_cat}/{filename}`\nðŸ“ Ð”Ð¾: `{target_cat}/{Path(new_path).name}`")

            except Exception as e:
                await message.reply_text(f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÐºÐ¾Ð¿Ñ–ÑŽÐ²Ð°Ð½Ð½Ñ:**\n\n`{str(e)}`")
            return

        elif command_text.lower().startswith("delete"):
            parts = command_text.split()
            if len(parts) < 3:
                await message.reply_text("âŒ **Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ:** `/dracon delete <category> <filename>`")
                return

            category, filename = parts[1], parts[2]

            try:
                storage.delete_schema(category, filename, archive_first=True)
                await message.reply_text(f"âœ… **Ð¡Ñ…ÐµÐ¼Ñƒ Ð²Ð¸Ð´Ð°Ð»ÐµÐ½Ð¾!**\n\nðŸ“ ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ: `{category}`\nðŸ“„ Ð¤Ð°Ð¹Ð»: `{filename}`\nðŸ’¾ Ð—Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¾ Ð² Ð°Ñ€Ñ…Ñ–Ð²Ñ–")

            except Exception as e:
                await message.reply_text(f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð¸Ð´Ð°Ð»ÐµÐ½Ð½Ñ:**\n\n`{str(e)}`")
            return

        elif command_text.lower().startswith("save"):
            parts = command_text.split()
            if len(parts) < 3:
                await message.reply_text("âŒ **Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ:** `/dracon save <category> <name> [yaml_content]`\n\nÐÐ±Ð¾ Ð½Ð°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ YAML ÑÑ…ÐµÐ¼Ñƒ Ð¿Ñ–ÑÐ»Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸.")
                return

            category, name = parts[1], parts[2]

            # Check if YAML content is provided in same message
            remaining_text = " ".join(parts[3:]) if len(parts) > 3 else ""

            if "version:" in remaining_text and ("nodes:" in remaining_text or "edges:" in remaining_text):
                yaml_content = remaining_text
            else:
                await message.reply_text(f"ðŸ“ **ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ YAML ÑÑ…ÐµÐ¼Ñƒ Ð´Ð»Ñ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ Ð² ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–ÑŽ `{category}` Ð· Ñ–Ð¼'ÑÐ¼ `{name}`:**")
                # Store pending save operation in user context
                if not hasattr(context, 'user_data'):
                    context.user_data = {}
                context.user_data['pending_save'] = {'category': category, 'name': name}
                return

            try:
                # Create metadata
                metadata = {
                    'name': name,
                    'description': f"DRACON schema saved via bot interface",
                    'created_by': user_id,
                    'source': 'bot_interface'
                }

                file_path, filename = storage.save_schema(yaml_content, category, name, metadata)
                await message.reply_text(f"âœ… **Ð¡Ñ…ÐµÐ¼Ñƒ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¾!**\n\nðŸ“ ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ: `{category}`\nðŸ“„ Ð¤Ð°Ð¹Ð»: `{filename}`\nðŸ’¾ Ð¨Ð»ÑÑ…: `{file_path}`")

            except Exception as e:
                await message.reply_text(f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ:**\n\n`{str(e)}`")
            return

        # Handle different subcommands
        if command_text.lower().startswith("example"):
            await message.reply_text(
                "ðŸ“‹ **ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´ DRACON ÑÑ…ÐµÐ¼Ð¸:**\n\n```yaml\n" +
                EXAMPLE_MENU_SCHEMA +
                "\n```",
                parse_mode="Markdown"
            )
            return

        # Process YAML content from user message
        yaml_content = None

        # Check if user sent YAML in the same message
        if "version:" in command_text and ("nodes:" in command_text or "edges:" in command_text):
            yaml_content = command_text
        else:
            # Ask user to send YAML content
            await message.reply_text(
                "ðŸ“ **ÐÐ°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ YAML-ÑÑ…ÐµÐ¼Ñƒ DRACON Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ:**\n\n"
                "Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹Ñ‚Ðµ `/dracon example` Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ³Ð»ÑÐ´Ñƒ Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´Ñƒ ÑÑ…ÐµÐ¼Ð¸."
            )
            return

        # Initialize processor
        processor = DraconYamlProcessor()

        # Determine action
        action = "analyze"  # default
        if command_text.lower().startswith("generate"):
            action = "generate"
            yaml_content = command_text[8:].strip()  # Remove "generate"
        elif command_text.lower().startswith("validate"):
            action = "validate"
            yaml_content = command_text[8:].strip()  # Remove "validate"
        elif command_text.lower().startswith("analyze"):
            yaml_content = command_text[7:].strip()  # Remove "analyze"

        # Show processing status
        status_msg = await message.reply_text("ðŸ”„ **ÐžÐ±Ñ€Ð¾Ð±Ð»ÑÑŽ DRACON ÑÑ…ÐµÐ¼Ñƒ...**\n\nÐ—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÑŽ Ñ‚Ð° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑŽ YAML...")

        # Process based on action
        if action == "validate":
            try:
                schema = processor.load_schema(yaml_content)
                await status_msg.edit_text(
                    f"âœ… **Ð¡Ñ…ÐµÐ¼Ð° Ð²Ð°Ð»Ñ–Ð´Ð½Ð°!**\n\n"
                    f"ðŸ“‹ ÐÐ°Ð·Ð²Ð°: {schema.name}\n"
                    f"ðŸ“ ÐžÐ¿Ð¸Ñ: {schema.description or 'ÐÐµ Ð²ÐºÐ°Ð·Ð°Ð½Ð¾'}\n"
                    f"ðŸ”— Ð’ÑƒÐ·Ð»Ñ–Ð²: {len(schema.nodes)}\n"
                    f"âž¡ï¸ Ð—Ð²'ÑÐ·ÐºÑ–Ð²: {len(schema.edges)}"
                )
            except Exception as e:
                await status_msg.edit_text(f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð°Ð»Ñ–Ð´Ð°Ñ†Ñ–Ñ—:**\n\n`{str(e)}`")
            return

        elif action == "generate":
            await status_msg.edit_text("ðŸ”„ **Ð“ÐµÐ½ÐµÑ€ÑƒÑŽ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¸...**\n\nÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ ÑÑ…ÐµÐ¼Ñƒ Ñ‚Ð° ÑÑ‚Ð²Ð¾Ñ€ÑŽÑŽ ÐºÐ¾Ð´...")

            components = await processor.generate_components(yaml_content)

            if not components:
                await status_msg.edit_text("âŒ **ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð·Ð³ÐµÐ½ÐµÑ€ÑƒÐ²Ð°Ñ‚Ð¸ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¸**")
                return

            # Show generated components
            report = f"âœ… **Ð—Ð³ÐµÐ½ÐµÑ€Ð¾Ð²Ð°Ð½Ð¾ {len(components)} ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ–Ð²:**\n\n"

            for comp in components[:5]:  # Show first 5 components
                report += f"ðŸ”§ **{comp.type}**: `{comp.name}`\n"
                if comp.properties.get('description'):
                    report += f"   ðŸ“ {comp.properties['description']}\n"
                report += "\n"

            if len(components) > 5:
                report += f"... Ñ‚Ð° Ñ‰Ðµ {len(components) - 5} ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ–Ð²\n\n"

            report += "ðŸ’¾ ÐšÐ¾Ð´ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ–Ð² Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ð¹ Ð´Ð¾ Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ—!"

            await status_msg.edit_text(report)

            # Send code examples for first few components
            for i, comp in enumerate(components[:3]):
                await message.reply_text(
                    f"**{comp.type}: {comp.name}**\n\n```python\n{comp.code}\n```",
                    parse_mode="Markdown"
                )
                if i < 2:
                    await asyncio.sleep(1)  # Avoid rate limit

            return

        # Default: analyze
        await status_msg.edit_text("ðŸ”„ **ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ Ð³Ñ€Ð°Ñ„...**\n\nÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑŽ Ñ‚Ð¾Ð¿Ð¾Ð»Ð¾Ð³Ñ–ÑŽ Ñ‚Ð° Ð»Ð¾Ð³Ñ–Ñ‡Ð½Ñƒ Ñ†Ñ–Ð»Ñ–ÑÐ½Ñ–ÑÑ‚ÑŒ...")

        # Perform analysis
        result = await processor.analyze_graph(yaml_content)

        # Generate analysis report
        report = f"ðŸ“Š **ÐÐ½Ð°Ð»Ñ–Ð· DRACON ÑÑ…ÐµÐ¼Ð¸**\n\n"

        if result.is_valid:
            report += "âœ… **Ð¡Ñ…ÐµÐ¼Ð° Ð²Ð°Ð»Ñ–Ð´Ð½Ð° Ñ‚Ð° Ð³Ð¾Ñ‚Ð¾Ð²Ð° Ð´Ð¾ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ!**\n\n"
        else:
            report += "âš ï¸ **Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ Ð² ÑÑ…ÐµÐ¼Ñ–:**\n\n"

        # Status indicators
        report += f"ðŸ”’ Ð—Ð°Ð¼ÐºÐ½ÐµÐ½Ð¸Ð¹ Ð³Ñ€Ð°Ñ„: {'âœ…' if result.is_closed else 'âŒ'}\n"
        report += f"ðŸŽ¯ Ð”Ð¾ÑÑÐ¶Ð½Ñ–ÑÑ‚ÑŒ: {'âœ…' if result.is_reachable else 'âŒ'}\n\n"

        # Issues
        if result.issues:
            report += "ðŸ”´ **ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð¸:**\n"
            for issue in result.issues[:5]:
                report += f"â€¢ {issue}\n"
            if len(result.issues) > 5:
                report += f"... Ñ‚Ð° Ñ‰Ðµ {len(result.issues) - 5} Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼\n"
            report += "\n"

        # Warnings
        if result.warnings:
            report += "ðŸŸ¡ **ÐŸÐ¾Ð¿ÐµÑ€ÐµÐ´Ð¶ÐµÐ½Ð½Ñ:**\n"
            for warning in result.warnings[:3]:
                report += f"â€¢ {warning}\n"
            report += "\n"

        # Suggestions
        if result.suggestions:
            report += "ðŸ’¡ **Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ—:**\n"
            for suggestion in result.suggestions[:3]:
                report += f"â€¢ {suggestion}\n"
            report += "\n"

        # Components summary
        total_components = sum(len(comps) for comps in result.components.values())
        if total_components > 0:
            report += f"ðŸ”§ **ÐšÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¸:** {total_components} ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ–Ð² Ð³Ð¾Ñ‚Ð¾Ð²Ñ– Ð´Ð¾ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ—\n"
            for comp_type, items in result.components.items():
                if items:
                    report += f"   â€¢ {comp_type}: {len(items)}\n"

        await status_msg.edit_text(report)

        # Send Claude analysis if available
        if result.claude_analysis and len(result.claude_analysis) > 100:
            claude_report = f"ðŸ¤– **ÐÐ½Ð°Ð»Ñ–Ð· Claude:**\n\n{result.claude_analysis}"

            if len(claude_report) > 4096:
                # Split into chunks
                chunks = [claude_report[i:i+4000] for i in range(0, len(claude_report), 4000)]
                for i, chunk in enumerate(chunks):
                    await message.reply_text(chunk)
                    if i < len(chunks) - 1:
                        await asyncio.sleep(1)
            else:
                await message.reply_text(claude_report)

        logger.info("DRACON analysis completed",
                   user_id=user_id,
                   is_valid=result.is_valid,
                   issues_count=len(result.issues),
                   components_count=total_components)

    except Exception as e:
        logger.error("Error in DRACON command", error=str(e), user_id=user_id, exc_info=True)
        error_msg = f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° DRACON:**\n\n`{str(e)}`"

        try:
            await message.reply_text(error_msg)
        except:
            # Fallback if message fails
            pass


async def refactor_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Reverse engineer bot code into DRACON schemas for refactoring."""
    user_id = get_user_id(update)
    message = get_effective_message(update)

    if not message:
        logger.warning("No message in refactor command", user_id=user_id)
        return

    logger.info("Refactor command invoked", user_id=user_id)

    try:
        # Check admin access
        auth_manager = context.bot_data.get("auth_manager")
        if not auth_manager or not auth_manager.is_authenticated(user_id):
            await message.reply_text("âŒ Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ð·Ð°Ð±Ð¾Ñ€Ð¾Ð½ÐµÐ½Ð¾. Ð ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹ Ñ‚Ñ–Ð»ÑŒÐºÐ¸ Ð°Ð´Ð¼Ñ–Ð½Ñ–ÑÑ‚Ñ€Ð°Ñ‚Ð¾Ñ€Ð°Ð¼.")
            return

        from ..features.dracon_reverse_engineer import DraconReverseEngineer
        from ..features.dracon_storage import DraconStorageManager

        # Parse command arguments
        args = context.args if context.args else []
        command_text = " ".join(args) if args else ""

        # Show help if no arguments
        if not command_text or command_text.lower() in ["help", "Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð°"]:
            help_text = """ðŸ”„ **DRACON Ð ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð¸**

Ð—Ð²Ð¾Ñ€Ð¾Ñ‚Ð½Ð¸Ð¹ Ñ–Ð½Ð¶Ð¸Ð½Ñ–Ñ€Ð¸Ð½Ð³ Ñ–ÑÐ½ÑƒÑŽÑ‡Ð¾Ð³Ð¾ ÐºÐ¾Ð´Ñƒ Ð±Ð¾Ñ‚Ð° Ð² DRACON ÑÑ…ÐµÐ¼Ð¸ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÑ€Ð½Ñ–Ð·Ð°Ñ†Ñ–Ñ— Ñ‚Ð° Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ.

**ÐšÐ¾Ð¼Ð°Ð½Ð´Ð¸:**
â€¢ `/refactor help` - Ð¦Ñ Ð´Ð¾Ð²Ñ–Ð´ÐºÐ°
â€¢ `/refactor analyze` - ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÐ²Ð°Ñ‚Ð¸ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ð±Ð¾Ñ‚Ð°
â€¢ `/refactor generate` - Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ DRACON ÑÑ…ÐµÐ¼Ñƒ Ð· ÐºÐ¾Ð´Ñƒ
â€¢ `/refactor suggest` - Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ— Ð· Ñ€ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³Ñƒ
â€¢ `/refactor handlers` - ÐÐ½Ð°Ð»Ñ–Ð· Ñ‚Ñ–Ð»ÑŒÐºÐ¸ handlers
â€¢ `/refactor flows` - ÐÐ½Ð°Ð»Ñ–Ð· Ð»Ð¾Ð³Ñ–Ñ‡Ð½Ð¸Ñ… Ð¿Ð¾Ñ‚Ð¾ÐºÑ–Ð²

**ÐŸÑ€Ð¾Ñ†ÐµÑ:**
1. ðŸ“– ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð²ÑÑ–Ñ… Python Ñ„Ð°Ð¹Ð»Ñ–Ð² Ð· handlers
2. ðŸ” Ð’Ð¸ÑÐ²Ð»ÐµÐ½Ð½Ñ Ð»Ð¾Ð³Ñ–Ñ‡Ð½Ð¸Ñ… Ð·Ð²'ÑÐ·ÐºÑ–Ð² Ð¼Ñ–Ð¶ Ñ„ÑƒÐ½ÐºÑ†Ñ–ÑÐ¼Ð¸
3. ðŸ§  Ð†Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ð· Claude
4. ðŸ“Š Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ DRACON ÑÑ…ÐµÐ¼Ð¸
5. ðŸ’¡ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ— Ð· Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ

**Ð©Ð¾ Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÑ”Ñ‚ÑŒÑÑ:**
â€¢ Command handlers Ñ‚Ð° callback handlers
â€¢ Ð›Ð¾Ð³Ñ–Ñ‡Ð½Ñ– Ð¿Ð¾Ñ‚Ð¾ÐºÐ¸ Ð¼Ñ–Ð¶ Ñ„ÑƒÐ½ÐºÑ†Ñ–ÑÐ¼Ð¸
â€¢ Ð¡ÐºÐ»Ð°Ð´Ð½Ñ–ÑÑ‚ÑŒ ÐºÐ¾Ð´Ñƒ Ñ‚Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ¸
â€¢ ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½Ð¸ Ð½Ð°Ð²Ñ–Ð³Ð°Ñ†Ñ–Ñ— Ñ‚Ð° ÑÑ‚Ð°Ð½Ð¸
â€¢ ÐœÐ¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ð¼Ð¾Ð´ÐµÑ€Ð½Ñ–Ð·Ð°Ñ†Ñ–Ñ—"""

            await message.reply_text(help_text, parse_mode="Markdown")
            return

        # Get settings for project root
        settings = context.bot_data.get("settings")
        if not settings:
            await message.reply_text("âŒ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð±Ð¾Ñ‚Ð° Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–")
            return

        # Show processing status
        status_msg = await message.reply_text("ðŸ”„ **ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ð±Ð¾Ñ‚Ð°...**\n\nÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Python Ñ„Ð°Ð¹Ð»Ñ–Ð² Ñ‚Ð° Ð²Ð¸ÑÐ²Ð»ÐµÐ½Ð½Ñ handlers...")

        # Initialize reverse engineer and storage
        claude_integration = context.bot_data.get("claude_integration")
        engineer = DraconReverseEngineer(str(settings.approved_directory), claude_integration)
        storage = DraconStorageManager(str(settings.approved_directory))

        # Determine analysis type
        if command_text.lower().startswith("handlers"):
            await status_msg.edit_text("ðŸ”„ **ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ handlers...**\n\nÐ’Ð¸ÑÐ²Ð»ÑÑŽ command Ñ‚Ð° callback handlers...")

            # Focus only on handlers analysis
            architecture = await engineer.analyze_bot_architecture(focus_path="src/bot/handlers")

            # Generate handlers report
            report = f"ðŸ“‹ **ÐÐ½Ð°Ð»Ñ–Ð· Handlers**\n\n"
            report += f"**Ð—Ð°Ð³Ð°Ð»ÑŒÐ½Ð° ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:**\n"
            report += f"â€¢ Handlers: {len(architecture.handlers)}\n"
            report += f"â€¢ Ð›Ð¾Ð³Ñ–Ñ‡Ð½Ð¸Ñ… Ð·Ð²'ÑÐ·ÐºÑ–Ð²: {len(architecture.flows)}\n"
            report += f"â€¢ Ð¢Ð¾Ñ‡Ð¾Ðº Ð²Ñ…Ð¾Ð´Ñƒ: {len(architecture.entry_points)}\n"
            report += f"â€¢ Ð’Ñ–Ð´Ð¾ÐºÑ€ÐµÐ¼Ð»ÐµÐ½Ð¸Ñ… handlers: {len(architecture.orphaned_handlers)}\n\n"

            # Show complexity distribution
            complexity = architecture.complexity_metrics['complexity_distribution']
            report += f"**Ð Ð¾Ð·Ð¿Ð¾Ð´Ñ–Ð» ÑÐºÐ»Ð°Ð´Ð½Ð¾ÑÑ‚Ñ–:**\n"
            report += f"â€¢ ÐŸÑ€Ð¾ÑÑ‚Ñ–: {complexity['simple']}\n"
            report += f"â€¢ Ð¡ÐµÑ€ÐµÐ´Ð½Ñ–: {complexity['medium']}\n"
            report += f"â€¢ Ð¡ÐºÐ»Ð°Ð´Ð½Ñ–: {complexity['complex']}\n\n"

            # Show handler types
            handler_types = architecture.complexity_metrics['handler_types']
            report += f"**Ð¢Ð¸Ð¿Ð¸ handlers:**\n"
            for htype, count in handler_types.items():
                report += f"â€¢ {htype}: {count}\n"

            await status_msg.edit_text(report)

        elif command_text.lower().startswith("flows"):
            await status_msg.edit_text("ðŸ”„ **ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ Ð»Ð¾Ð³Ñ–Ñ‡Ð½Ñ– Ð¿Ð¾Ñ‚Ð¾ÐºÐ¸...**\n\nÐ’Ñ–Ð´ÑÑ‚ÐµÐ¶ÑƒÑŽ Ð·Ð²'ÑÐ·ÐºÐ¸ Ð¼Ñ–Ð¶ handlers...")

            architecture = await engineer.analyze_bot_architecture()

            # Generate flows report
            report = f"ðŸ”— **ÐÐ½Ð°Ð»Ñ–Ð· Ð›Ð¾Ð³Ñ–Ñ‡Ð½Ð¸Ñ… ÐŸÐ¾Ñ‚Ð¾ÐºÑ–Ð²**\n\n"
            report += f"**Ð—Ð°Ð³Ð°Ð»ÑŒÐ½Ð° ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:**\n"
            report += f"â€¢ Ð’ÑÑŒÐ¾Ð³Ð¾ Ð¿Ð¾Ñ‚Ð¾ÐºÑ–Ð²: {len(architecture.flows)}\n"
            report += f"â€¢ Handlers: {len(architecture.handlers)}\n"
            report += f"â€¢ Ð¢Ð¾Ñ‡ÐºÐ¸ Ð²Ñ…Ð¾Ð´Ñƒ: {len(architecture.entry_points)}\n\n"

            if architecture.flows:
                report += f"**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸ Ð¿Ð¾Ñ‚Ð¾ÐºÑ–Ð²:**\n"
                for flow in architecture.flows[:5]:
                    report += f"â€¢ {flow.from_handler} â†’ {flow.to_handler}\n"
                    if flow.trigger_value:
                        report += f"  Trigger: {flow.trigger_value}\n"

                if len(architecture.flows) > 5:
                    report += f"... Ñ‚Ð° Ñ‰Ðµ {len(architecture.flows) - 5} Ð¿Ð¾Ñ‚Ð¾ÐºÑ–Ð²\n"
            else:
                report += "âŒ **Ð›Ð¾Ð³Ñ–Ñ‡Ð½Ð¸Ñ… Ð¿Ð¾Ñ‚Ð¾ÐºÑ–Ð² Ð½Ðµ Ð²Ð¸ÑÐ²Ð»ÐµÐ½Ð¾**\n"
                report += "Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÑ”Ñ‚ÑŒÑÑ Ð´Ð¾Ð´Ð°Ñ‚Ð¸ Ð±Ñ–Ð»ÑŒÑˆÐµ Ñ–Ð½Ñ‚ÐµÑ€Ð°ÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– Ð¼Ñ–Ð¶ handlers."

            await status_msg.edit_text(report)

        elif command_text.lower().startswith("suggest"):
            await status_msg.edit_text("ðŸ”„ **Ð“ÐµÐ½ÐµÑ€ÑƒÑŽ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ—...**\n\nÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ...")

            architecture = await engineer.analyze_bot_architecture()
            suggestions = await engineer.suggest_refactoring(architecture)

            # Save suggestions to audit directory
            try:
                suggestions_metadata = {
                    'name': 'refactoring_suggestions',
                    'description': f"Refactoring suggestions for bot with {len(architecture.handlers)} handlers",
                    'created_by': user_id,
                    'source': 'refactoring_analysis',
                    'suggestions': suggestions,
                    'handlers_analyzed': len(architecture.handlers),
                    'flows_analyzed': len(architecture.flows)
                }

                import json
                suggestions_yaml = f"""# Refactoring Suggestions Report
# Generated: {datetime.now().isoformat()}
# User: {user_id}

suggestions:
{json.dumps(suggestions, indent=2, ensure_ascii=False)}

architecture_summary:
  handlers: {len(architecture.handlers)}
  flows: {len(architecture.flows)}
  complexity_metrics: {architecture.complexity_metrics}
"""

                storage.save_schema(suggestions_yaml, 'audit', 'refactoring_suggestions', suggestions_metadata)

            except Exception as e:
                logger.warning("Failed to save refactoring suggestions", error=str(e))

            # Generate suggestions report
            report = f"ðŸ’¡ **Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ— Ð· Ð ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³Ñƒ**\n\n"

            # Complexity issues
            if suggestions['complexity_issues']:
                report += f"ðŸ”´ **ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ ÑÐºÐ»Ð°Ð´Ð½Ð¾ÑÑ‚Ñ– ({len(suggestions['complexity_issues'])}):**\n"
                for issue in suggestions['complexity_issues'][:3]:
                    report += f"â€¢ {issue['handler']}: {issue['issue']}\n"
                    report += f"  ðŸ’¡ {issue['recommendation']}\n"
                report += "\n"

            # Flow improvements
            if suggestions['flow_improvements']:
                report += f"ðŸ”— **ÐŸÐ¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ Ð¿Ð¾Ñ‚Ð¾ÐºÑ–Ð²:**\n"
                for improvement in suggestions['flow_improvements']:
                    report += f"â€¢ {improvement['issue']}\n"
                    report += f"  ðŸ’¡ {improvement['recommendation']}\n"
                report += "\n"

            # Modernization opportunities
            if suggestions['modernization_opportunities']:
                report += f"ðŸš€ **ÐœÐ¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ð¼Ð¾Ð´ÐµÑ€Ð½Ñ–Ð·Ð°Ñ†Ñ–Ñ—:**\n"
                for opportunity in suggestions['modernization_opportunities']:
                    report += f"â€¢ {opportunity['opportunity']}\n"
                    report += f"  ðŸ’¡ {opportunity['recommendation']}\n"
                report += "\n"

            if not any(suggestions.values()):
                report += "ðŸŽ‰ **Ð§ÑƒÐ´Ð¾Ð²Ð¾!** ÐÑ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ð±Ð¾Ñ‚Ð° Ð²Ð¸Ð³Ð»ÑÐ´Ð°Ñ” Ð´Ð¾Ð±Ñ€Ðµ Ð¾Ñ€Ð³Ð°Ð½Ñ–Ð·Ð¾Ð²Ð°Ð½Ð¾ÑŽ."

            await status_msg.edit_text(report)

        elif command_text.lower().startswith("generate"):
            await status_msg.edit_text("ðŸ”„ **Ð“ÐµÐ½ÐµÑ€ÑƒÑŽ DRACON ÑÑ…ÐµÐ¼Ñƒ...**\n\nÐ—Ð²Ð¾Ñ€Ð¾Ñ‚Ð½Ð¸Ð¹ Ñ–Ð½Ð¶Ð¸Ð½Ñ–Ñ€Ð¸Ð½Ð³ ÐºÐ¾Ð´Ñƒ Ð² YAML...")

            architecture = await engineer.analyze_bot_architecture()
            schema_yaml = await engineer.generate_dracon_schema(architecture, "Reverse Engineered Bot")

            # Automatically save to reverse directory
            try:
                metadata = {
                    'name': 'reverse_engineered_bot',
                    'description': f"Reverse engineered DRACON schema with {len(architecture.handlers)} handlers and {len(architecture.flows)} flows",
                    'created_by': user_id,
                    'source': 'reverse_engineering',
                    'handlers_count': len(architecture.handlers),
                    'flows_count': len(architecture.flows),
                    'complexity_metrics': architecture.complexity_metrics
                }

                file_path, filename = storage.save_schema(schema_yaml, 'reverse', 'bot_architecture', metadata)

                # Also save analysis metadata
                analysis_metadata = {
                    'analysis_type': 'full_reverse_engineering',
                    'handlers': [{'name': h.name, 'type': h.handler_type, 'complexity': h.complexity_score} for h in architecture.handlers],
                    'flows': [{'from': f.from_handler, 'to': f.to_handler, 'type': f.trigger_type} for f in architecture.flows],
                    'suggestions_count': len((await engineer.suggest_refactoring(architecture))['complexity_issues']),
                    'created_by': user_id,
                    'timestamp': datetime.now().isoformat()
                }

                analysis_path = file_path.replace('.yaml', '_analysis.json')
                with open(analysis_path, 'w', encoding='utf-8') as f:
                    import json
                    json.dump(analysis_metadata, f, indent=2, ensure_ascii=False)

                # Send schema with save confirmation
                await status_msg.edit_text(f"âœ… **DRACON ÑÑ…ÐµÐ¼Ð° Ð·Ð³ÐµÐ½ÐµÑ€Ð¾Ð²Ð°Ð½Ð° Ñ‚Ð° Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð°!**\n\n"
                                         f"ðŸ“Š Ð’ÑƒÐ·Ð»Ñ–Ð²: {len(architecture.handlers) + 2}\n"
                                         f"ðŸ”— Ð—Ð²'ÑÐ·ÐºÑ–Ð²: {len(architecture.flows)}\n"
                                         f"ðŸ’¾ Ð—Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¾: `drn/reverse/{filename}`\n"
                                         f"ðŸ“‹ Ð“Ð¾Ñ‚Ð¾Ð²Ð° Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ Ñ‚Ð° Ð¼Ð¾Ð´ÐµÑ€Ð½Ñ–Ð·Ð°Ñ†Ñ–Ñ—")

            except Exception as e:
                logger.error("Failed to save reverse engineered schema", error=str(e))
                await status_msg.edit_text(f"âœ… **DRACON ÑÑ…ÐµÐ¼Ð° Ð·Ð³ÐµÐ½ÐµÑ€Ð¾Ð²Ð°Ð½Ð°!**\n\n"
                                         f"ðŸ“Š Ð’ÑƒÐ·Ð»Ñ–Ð²: {len(architecture.handlers) + 2}\n"
                                         f"ðŸ”— Ð—Ð²'ÑÐ·ÐºÑ–Ð²: {len(architecture.flows)}\n"
                                         f"âš ï¸ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ: {str(e)}")

            # Send YAML content
            await message.reply_text(
                f"ðŸ“‹ **Ð—Ð³ÐµÐ½ÐµÑ€Ð¾Ð²Ð°Ð½Ð° DRACON ÑÑ…ÐµÐ¼Ð°:**\n\n```yaml\n{schema_yaml}\n```",
                parse_mode="Markdown"
            )

            # Suggest next steps with file operations
            await message.reply_text(
                "ðŸ”§ **ÐÐ°ÑÑ‚ÑƒÐ¿Ð½Ñ– ÐºÑ€Ð¾ÐºÐ¸:**\n\n"
                "â€¢ `/dracon list reverse` - ÐŸÐµÑ€ÐµÐ³Ð»ÑÐ½ÑƒÑ‚Ð¸ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ñ– ÑÑ…ÐµÐ¼Ð¸\n"
                f"â€¢ `/dracon load reverse {filename}` - Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ð¸Ñ‚Ð¸ ÑÑ…ÐµÐ¼Ñƒ\n"
                "â€¢ `/dracon analyze` - ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ñƒ ÑÑ…ÐµÐ¼Ñƒ\n"
                "â€¢ `/dracon save build my_framework` - Ð—Ð±ÐµÑ€ÐµÐ³Ñ‚Ð¸ ÑÐº Ñ„Ñ€ÐµÐ¹Ð¼Ð²Ð¾Ñ€Ðº\n"
                "â€¢ `/refactor suggest` - ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ— Ð· Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ"
            )

        else:
            # Default: comprehensive analysis
            await status_msg.edit_text("ðŸ”„ **ÐŸÐ¾Ð²Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸...**\n\nÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ñ„Ð°Ð¹Ð»Ñ–Ð², Ð°Ð½Ð°Ð»Ñ–Ð· Ð»Ð¾Ð³Ñ–ÐºÐ¸, Claude Ð°Ð½Ð°Ð»Ñ–Ð·...")

            architecture = await engineer.analyze_bot_architecture()

            # Generate comprehensive report
            report = f"ðŸ“Š **ÐÐ½Ð°Ð»Ñ–Ð· ÐÑ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸ Ð‘Ð¾Ñ‚Ð°**\n\n"

            # Basic stats
            report += f"**ÐžÑÐ½Ð¾Ð²Ð½Ð° ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:**\n"
            report += f"â€¢ Handlers: {len(architecture.handlers)}\n"
            report += f"â€¢ Ð›Ð¾Ð³Ñ–Ñ‡Ð½Ð¸Ñ… Ð¿Ð¾Ñ‚Ð¾ÐºÑ–Ð²: {len(architecture.flows)}\n"
            report += f"â€¢ Ð¢Ð¾Ñ‡Ð¾Ðº Ð²Ñ…Ð¾Ð´Ñƒ: {len(architecture.entry_points)}\n"
            report += f"â€¢ Ð¡ÐµÑ€ÐµÐ´Ð½Ñ ÑÐºÐ»Ð°Ð´Ð½Ñ–ÑÑ‚ÑŒ: {architecture.complexity_metrics['average_complexity']}\n\n"

            # Architecture quality
            quality_score = "Ð”Ð¾Ð±Ñ€Ð°" if len(architecture.orphaned_handlers) < 3 else "ÐŸÐ¾Ñ‚Ñ€ÐµÐ±ÑƒÑ” Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ"
            report += f"**Ð¯ÐºÑ–ÑÑ‚ÑŒ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸:** {quality_score}\n\n"

            # Issues summary
            error_handling_ratio = architecture.complexity_metrics['has_error_handling'] / len(architecture.handlers)
            if error_handling_ratio < 0.5:
                report += f"âš ï¸ **ÐŸÐ¾Ð¿ÐµÑ€ÐµÐ´Ð¶ÐµÐ½Ð½Ñ:** ÐÐ¸Ð·ÑŒÐºÐ¸Ð¹ Ñ€Ñ–Ð²ÐµÐ½ÑŒ Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð¿Ð¾Ð¼Ð¸Ð»Ð¾Ðº ({error_handling_ratio:.0%})\n"

            if architecture.orphaned_handlers:
                report += f"âš ï¸ **ÐŸÐ¾Ð¿ÐµÑ€ÐµÐ´Ð¶ÐµÐ½Ð½Ñ:** {len(architecture.orphaned_handlers)} Ð²Ñ–Ð´Ð¾ÐºÑ€ÐµÐ¼Ð»ÐµÐ½Ð¸Ñ… handlers\n"

            report += f"\nðŸ’¡ **Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ—:**\n"
            report += f"â€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ `/refactor generate` Ð´Ð»Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ DRACON ÑÑ…ÐµÐ¼Ð¸\n"
            report += f"â€¢ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ `/refactor suggest` Ð´Ð»Ñ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ñ… Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ð¹\n"
            report += f"â€¢ Ð Ð¾Ð·Ð³Ð»ÑÐ½ÑŒÑ‚Ðµ Ð¼Ð¾Ð´ÐµÑ€Ð½Ñ–Ð·Ð°Ñ†Ñ–ÑŽ ÑÐºÐ»Ð°Ð´Ð½Ð¸Ñ… handlers"

            await status_msg.edit_text(report)

            # Send Claude analysis if available
            if architecture.claude_analysis and len(architecture.claude_analysis) > 100:
                claude_report = f"ðŸ¤– **ÐÐ½Ð°Ð»Ñ–Ð· Claude:**\n\n{architecture.claude_analysis}"

                if len(claude_report) > 4096:
                    chunks = [claude_report[i:i+4000] for i in range(0, len(claude_report), 4000)]
                    for i, chunk in enumerate(chunks):
                        await message.reply_text(chunk)
                        if i < len(chunks) - 1:
                            await asyncio.sleep(1)
                else:
                    await message.reply_text(claude_report)

        logger.info("Refactor analysis completed",
                   user_id=user_id,
                   handlers_count=len(architecture.handlers),
                   flows_count=len(architecture.flows))

    except Exception as e:
        logger.error("Error in refactor command", error=str(e), user_id=user_id, exc_info=True)
        error_msg = f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ñ€ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°:**\n\n`{str(e)}`"

        try:
            await message.reply_text(error_msg)
        except:
            # Fallback if message fails
            pass



async def schedule_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Alias for schedules_command - manage scheduled tasks."""
    await schedules_command(update, context)


async def claude_status_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """ÐšÐ¾Ð¼Ð°Ð½Ð´Ð° /claude_status - Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ Claude CLI."""
    user_id = update.effective_user.id
    message = get_effective_message(update)

    logger.info("Claude status command started", user_id=user_id)

    try:
        # ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ availability monitor
        availability_monitor = context.bot_data.get("claude_availability_monitor")
        if not availability_monitor:
            await message.reply_text(
                "âŒ **ÐœÐ¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Claude Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹**\n\n"
                "Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¼Ð¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ñƒ Ð½Ðµ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð°.",
                parse_mode=None
            )
            return

        # ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑ "Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾"
        status_msg = await message.reply_text(
            await t(context, user_id, "claude_status.checking"),
            parse_mode=None
        )

        # Ð’Ð¸ÐºÐ¾Ð½Ð°Ñ‚Ð¸ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñƒ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÑƒ
        is_available, details = await availability_monitor.check_availability_with_details()

        # ÐŸÐ¾Ð±ÑƒÐ´ÑƒÐ²Ð°Ñ‚Ð¸ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ðµ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ
        status_lines = []
        status_lines.append(await t(context, user_id, "claude_status.title"))
        status_lines.append("")

        # ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ
        current_status = await t(context, user_id, "claude_status.current_status")
        status_message = details.get("status_message", "â“ ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¾")
        status_lines.append(f"**{current_status}** {status_message}")

        # ÐžÑÑ‚Ð°Ð½Ð½Ñ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ°
        last_check = await t(context, user_id, "claude_status.last_check")
        check_time = details.get("last_check")
        if check_time:
            from zoneinfo import ZoneInfo
            kyiv_time = check_time.astimezone(ZoneInfo("Europe/Kyiv"))
            status_lines.append(f"**{last_check}** {kyiv_time.strftime('%H:%M:%S')}")

        # ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð· Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ
        if "estimated_recovery" in details:
            recovery_text = await t(context, user_id, "claude_status.recovery_prediction")
            status_lines.append(f"**{recovery_text}** {details['estimated_recovery']}")

        status_lines.append("")
        status_lines.append(await t(context, user_id, "claude_status.check_again"))

        # Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ ÐºÐ½Ð¾Ð¿ÐºÐ¸
        keyboard = [
            [
                InlineKeyboardButton("ðŸ”„ ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸", callback_data="claude_status:refresh"),
                InlineKeyboardButton("ðŸ“Š Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ", callback_data="claude_status:history")
            ],
            [
                InlineKeyboardButton("ðŸ”” Ð¡Ð¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½Ð½Ñ", callback_data="claude_status:notifications"),
                InlineKeyboardButton("âš™ï¸ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ", callback_data="claude_status:settings")
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        full_message = "\n".join(status_lines)

        await status_msg.edit_text(full_message, reply_markup=reply_markup, parse_mode=None)

        logger.info("Claude status displayed", user_id=user_id, is_available=is_available)

    except Exception as e:
        logger.error("Error in claude_status command", error=str(e), user_id=user_id, exc_info=True)
        await safe_critical_error(message, context, e, "claude_status")


async def claude_notifications_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """ÐšÐ¾Ð¼Ð°Ð½Ð´Ð° /claude_notifications - ÐºÐµÑ€ÑƒÐ²Ð°Ð½Ð½Ñ ÑÐ¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½Ð½ÑÐ¼Ð¸ Ð¿Ñ€Ð¾ ÑÑ‚Ð°Ñ‚ÑƒÑ."""
    user_id = update.effective_user.id
    message = get_effective_message(update)

    logger.info("Claude notifications command started", user_id=user_id)

    try:
        settings: Settings = context.bot_data["settings"]

        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ñ– Ð½Ð°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ
        notifications_enabled = settings.claude_availability.enabled
        notify_chats = settings.claude_availability.notify_chat_ids
        check_interval = settings.claude_availability.check_interval_seconds

        # ÐŸÐ¾Ð±ÑƒÐ´ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ
        status_lines = []
        status_lines.append("âš™ï¸ **ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ ÑÐ¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½ÑŒ Claude**")
        status_lines.append("")

        if notifications_enabled:
            status_lines.append("ðŸ”” **Ð¡Ñ‚Ð°Ñ‚ÑƒÑ:** âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾")
        else:
            status_lines.append("ðŸ”” **Ð¡Ñ‚Ð°Ñ‚ÑƒÑ:** âŒ Ð’Ð¸Ð¼ÐºÐ½ÐµÐ½Ð¾")

        if notify_chats:
            chat_count = len(notify_chats)
            status_lines.append(f"ðŸ“¢ **Ð“Ñ€ÑƒÐ¿Ð¸ ÑÐ¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½ÑŒ:** {chat_count} Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð¾")
        else:
            status_lines.append("ðŸ“¢ **Ð“Ñ€ÑƒÐ¿Ð¸ ÑÐ¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½ÑŒ:** ÐÐµ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð¾")

        status_lines.append(f"â° **Ð†Ð½Ñ‚ÐµÑ€Ð²Ð°Ð» Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸:** {check_interval // 60} Ñ…Ð²Ð¸Ð»Ð¸Ð½")
        status_lines.append("")

        # Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–ÑŽ Ð¿Ñ€Ð¾ Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ–
        status_lines.append("ðŸ’¡ **ÐœÐ¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– ÑÐ¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½ÑŒ:**")
        status_lines.append("â€¢ ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ñ– Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–ÑÑ‚ÑŒ")
        status_lines.append("â€¢ Ð¡Ð¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾ Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸")
        status_lines.append("â€¢ ÐŸÑ€Ð¾Ð³Ð½Ð¾Ð· Ñ‡Ð°ÑÑƒ Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ")
        status_lines.append("â€¢ Ð ÐµÐ¶Ð¸Ð¼ DND (Ð±ÐµÐ· ÑÐ¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½ÑŒ Ð²Ð½Ð¾Ñ‡Ñ–)")

        # Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ ÐºÐ½Ð¾Ð¿ÐºÐ¸
        keyboard = []

        if notifications_enabled:
            keyboard.append([InlineKeyboardButton("âŒ Ð’Ð¸Ð¼ÐºÐ½ÑƒÑ‚Ð¸ ÑÐ¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½Ð½Ñ", callback_data="claude_notifications:disable")])
        else:
            keyboard.append([InlineKeyboardButton("âœ… Ð£Ð²Ñ–Ð¼ÐºÐ½ÑƒÑ‚Ð¸ ÑÐ¿Ð¾Ð²Ñ–Ñ‰ÐµÐ½Ð½Ñ", callback_data="claude_notifications:enable")])

        keyboard.extend([
            [
                InlineKeyboardButton("ðŸ“Š Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ", callback_data="claude_notifications:history"),
                InlineKeyboardButton("ðŸ”„ Ð¡Ñ‚Ð°Ñ‚ÑƒÑ", callback_data="claude_status:refresh")
            ],
            [InlineKeyboardButton("â¬…ï¸ ÐÐ°Ð·Ð°Ð´", callback_data="claude_status:main")]
        ])

        reply_markup = InlineKeyboardMarkup(keyboard)
        full_message = "\n".join(status_lines)

        await message.reply_text(full_message, reply_markup=reply_markup, parse_mode=None)

        logger.info("Claude notifications settings displayed", user_id=user_id, enabled=notifications_enabled)

    except Exception as e:
        logger.error("Error in claude_notifications command", error=str(e), user_id=user_id, exc_info=True)
        await safe_critical_error(message, context, e, "claude_notifications")


async def claude_history_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """ÐšÐ¾Ð¼Ð°Ð½Ð´Ð° /claude_history - Ñ–ÑÑ‚Ð¾Ñ€Ñ–Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ– Ð·Ð° 24 Ð³Ð¾Ð´Ð¸Ð½Ð¸."""
    user_id = update.effective_user.id
    message = get_effective_message(update)

    logger.info("Claude history command started", user_id=user_id)

    try:
        # ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ "Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ"
        status_msg = await message.reply_text("ðŸ“Š Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÑŽ Ñ–ÑÑ‚Ð¾Ñ€Ñ–ÑŽ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ–...", parse_mode=None)

        # Ð§Ð¸Ñ‚Ð°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð» transitions.jsonl
        from pathlib import Path
        import json
        from datetime import datetime, timedelta
        from zoneinfo import ZoneInfo

        transitions_file = Path("./data/transitions.jsonl")

        if not transitions_file.exists():
            await status_msg.edit_text(
                "ðŸ“Š **Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ– Claude**\n\n"
                "âŒ Ð¤Ð°Ð¹Ð» Ñ–ÑÑ‚Ð¾Ñ€Ñ–Ñ— Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾.\n"
                "ÐœÐ¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð±ÑƒÐ´Ðµ ÑÑ‚Ð²Ð¾Ñ€ÑŽÐ²Ð°Ñ‚Ð¸ Ñ–ÑÑ‚Ð¾Ñ€Ñ–ÑŽ Ð· Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¸Ñ… Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€Ð¾Ðº.",
                parse_mode=None
            )
            return

        # Ð§Ð¸Ñ‚Ð°Ñ‚Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð½Ñ– 24 Ð³Ð¾Ð´Ð¸Ð½Ð¸
        now = datetime.now(ZoneInfo("UTC"))
        cutoff_time = now - timedelta(hours=24)

        transitions = []
        try:
            with open(transitions_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        record = json.loads(line.strip())
                        record_time = datetime.fromisoformat(record['timestamp'])
                        if record_time >= cutoff_time:
                            transitions.append(record)
                    except (json.JSONDecodeError, KeyError, ValueError):
                        continue
        except Exception as e:
            logger.error(f"Error reading transitions file: {e}")

        # ÐŸÐ¾Ð±ÑƒÐ´ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð²Ñ–Ñ‚
        report_lines = []
        report_lines.append("ðŸ“Š **Ð†ÑÑ‚Ð¾Ñ€Ñ–Ñ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ– Claude Ð·Ð° 24 Ð³Ð¾Ð´Ð¸Ð½Ð¸**")
        report_lines.append("")

        if not transitions:
            report_lines.append("â„¹ï¸ Ð—Ð¼Ñ–Ð½ ÑÑ‚Ð°Ñ‚ÑƒÑÑƒ Ð·Ð° Ð¾ÑÑ‚Ð°Ð½Ð½Ñ– 24 Ð³Ð¾Ð´Ð¸Ð½Ð¸ Ð½Ðµ Ð±ÑƒÐ»Ð¾.")
        else:
            report_lines.append(f"ðŸ“ˆ **Ð’ÑÑŒÐ¾Ð³Ð¾ Ð·Ð¼Ñ–Ð½ ÑÑ‚Ð°Ñ‚ÑƒÑÑƒ:** {len(transitions)}")
            report_lines.append("")

            # ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð¾ÑÑ‚Ð°Ð½Ð½Ñ– 5 Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ñ–Ð²
            recent_transitions = sorted(transitions, key=lambda x: x['timestamp'], reverse=True)[:5]

            report_lines.append("ðŸ•’ **ÐžÑÑ‚Ð°Ð½Ð½Ñ– Ð·Ð¼Ñ–Ð½Ð¸:**")
            for i, trans in enumerate(recent_transitions):
                try:
                    trans_time = datetime.fromisoformat(trans['timestamp'])
                    kyiv_time = trans_time.astimezone(ZoneInfo("Europe/Kyiv"))

                    from_state = trans.get('from', 'unknown')
                    to_state = trans.get('to', 'unknown')

                    # ÐŸÐµÑ€ÐµÐºÐ»Ð°ÑÑ‚Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑÐ¸
                    state_translations = {
                        'available': 'ðŸŸ¢ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹',
                        'limited': 'â³ Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð¸Ð¹',
                        'unavailable': 'ðŸ”´ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹',
                        'auth_error': 'ðŸ”‘ Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ—'
                    }

                    from_emoji = state_translations.get(from_state, f"â“ {from_state}")
                    to_emoji = state_translations.get(to_state, f"â“ {to_state}")

                    time_str = kyiv_time.strftime('%H:%M')
                    report_lines.append(f"{i+1}. **{time_str}** {from_emoji} â†’ {to_emoji}")

                    # Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ñ‚Ñ€Ð¸Ð²Ð°Ð»Ñ–ÑÑ‚ÑŒ ÑÐºÑ‰Ð¾ Ñ”
                    if 'duration_unavailable' in trans and trans['duration_unavailable']:
                        duration_minutes = int(trans['duration_unavailable'] / 60)
                        if duration_minutes > 0:
                            report_lines.append(f"   â±ï¸ _ÐÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–ÑÑ‚ÑŒ: {duration_minutes} Ñ…Ð²_")

                except (ValueError, KeyError) as e:
                    logger.warning(f"Error processing transition: {e}")
                    continue

        report_lines.append("")
        report_lines.append("ðŸ”„ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /claude_status Ð´Ð»Ñ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ ÑÑ‚Ð°Ñ‚ÑƒÑÑƒ")

        # Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ ÐºÐ½Ð¾Ð¿ÐºÐ¸
        keyboard = [
            [
                InlineKeyboardButton("ðŸ”„ ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸", callback_data="claude_status:history"),
                InlineKeyboardButton("ðŸ“Š Ð¡Ñ‚Ð°Ñ‚ÑƒÑ", callback_data="claude_status:refresh")
            ],
            [InlineKeyboardButton("â¬…ï¸ ÐÐ°Ð·Ð°Ð´", callback_data="claude_status:main")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        full_report = "\n".join(report_lines)

        await status_msg.edit_text(full_report, reply_markup=reply_markup, parse_mode=None)

        logger.info("Claude history displayed", user_id=user_id, transitions_count=len(transitions))

    except Exception as e:
        logger.error("Error in claude_history command", error=str(e), user_id=user_id, exc_info=True)
        await safe_critical_error(message, context, e, "claude_history")

```

### bot/handlers/task_commands.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 12,851 Ð±Ð°Ð¹Ñ‚

```python
"""Task scheduler command handlers."""

import structlog
from telegram import Update
from telegram.ext import ContextTypes

logger = structlog.get_logger()


async def task_queue_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Manage automated task queue."""
    user_id = update.effective_user.id
    message = update.effective_message

    logger.info("Task queue command", user_id=user_id)

    try:
        # Get task scheduler from context
        task_scheduler = context.bot_data.get("task_scheduler")
        if not task_scheduler:
            await message.reply_text(
                "âŒ **Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°**\n\n"
                "Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð½Ðµ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð°."
            )
            return

        # Parse command arguments
        args = context.args
        if not args:
            # Show task queue status
            pending_tasks = await task_scheduler.get_user_tasks(user_id, "pending")
            running_tasks = task_scheduler.get_running_tasks()
            stats = await task_scheduler.get_task_statistics(user_id)

            message_text = (
                f"ðŸ“‹ **Ð§ÐµÑ€Ð³Ð° Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¸Ñ… Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ**\n\n"
                f"ðŸ‘¤ ÐšÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡: {user_id}\n"
                f"ðŸ“Š **Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:**\n"
                f"â€¢ ÐžÑ‡Ñ–ÐºÑƒÑŽÑ‚ÑŒ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ: {len(pending_tasks)}\n"
                f"â€¢ Ð’Ð¸ÐºÐ¾Ð½ÑƒÑŽÑ‚ÑŒÑÑ Ð·Ð°Ñ€Ð°Ð·: {len(running_tasks)}\n"
                f"â€¢ Ð’ÑÑŒÐ¾Ð³Ð¾ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð¾: {stats.get('completed', 0)}\n"
                f"â€¢ ÐŸÐ¾Ð¼Ð¸Ð»Ð¾Ðº: {stats.get('failed', 0)}\n\n"
            )

            if pending_tasks:
                message_text += "ðŸ•’ **Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð² Ñ‡ÐµÑ€Ð·Ñ–:**\n"
                for task in pending_tasks[:5]:  # Show first 5
                    message_text += f"â€¢ {task.task_type} (Ð¿Ñ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚: {task.priority})\n"
                if len(pending_tasks) > 5:
                    message_text += f"... Ñ‚Ð° Ñ‰Ðµ {len(pending_tasks) - 5} Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ\n"
                message_text += "\n"

            message_text += (
                "**ÐšÐ¾Ð¼Ð°Ð½Ð´Ð¸:**\n"
                "â€¢ `/tasks add <type>` - Ð´Ð¾Ð´Ð°Ñ‚Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ\n"
                "â€¢ `/tasks run` - Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ñ‡ÐµÑ€Ð³Ñƒ\n"
                "â€¢ `/tasks clear` - Ð¾Ñ‡Ð¸ÑÑ‚Ð¸Ñ‚Ð¸ Ñ‡ÐµÑ€Ð³Ñƒ\n"
                "â€¢ `/tasks templates` - Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¸"
            )

            await message.reply_text(message_text)
            return

        command = args[0].lower()

        if command == "add":
            if len(args) < 2:
                await message.reply_text(
                    "âŒ **Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ:** `/tasks add <type> [prompt]`\n\n"
                    "**Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– Ñ‚Ð¸Ð¿Ð¸:**\n"
                    "â€¢ `analysis` - Ð°Ð½Ð°Ð»Ñ–Ð· ÐºÐ¾Ð´Ñƒ\n"
                    "â€¢ `documentation` - Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ\n"
                    "â€¢ `refactoring` - Ñ€ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³\n"
                    "â€¢ `security` - Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð±ÐµÐ·Ð¿ÐµÐºÐ¸\n"
                    "â€¢ `testing` - Ñ‚ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ\n"
                    "â€¢ `custom` - Ð²Ð»Ð°ÑÐ½Ðµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ"
                )
                return

            task_type = args[1]
            custom_prompt = " ".join(args[2:]) if len(args) > 2 else None

            # Create task based on type
            if task_type == "custom" and custom_prompt:
                task_id = await task_scheduler.add_scheduled_task(
                    user_id=user_id,
                    task_type="custom",
                    prompt=custom_prompt,
                    auto_execute=True,
                    auto_respond=True
                )
            else:
                # Use template
                from ..features.task_scheduler import TaskScheduler
                current_dir = context.user_data.get("current_directory", "/")

                if task_type == "analysis":
                    template = TaskScheduler.create_code_analysis_task(user_id, str(current_dir))
                elif task_type == "documentation":
                    template = TaskScheduler.create_documentation_task(user_id, "readme")
                elif task_type == "refactoring":
                    template = TaskScheduler.create_refactoring_task(user_id)
                elif task_type == "security":
                    template = TaskScheduler.create_code_analysis_task(user_id, str(current_dir), "security")
                elif task_type == "testing":
                    template = {
                        "task_type": "testing",
                        "prompt": "Ð¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ Ñ‚ÐµÑÑ‚Ð¸ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ Ñ‚Ð° Ð·Ð°Ð¿ÑƒÑÑ‚Ñ–Ñ‚ÑŒ Ñ—Ñ…. ÐÐ°Ð´Ð°Ð¹Ñ‚Ðµ Ð·Ð²Ñ–Ñ‚ Ð¿Ñ€Ð¾ Ð¿Ð¾ÐºÑ€Ð¸Ñ‚Ñ‚Ñ Ñ‚Ð° Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ—.",
                        "metadata": {"test_type": "comprehensive"}
                    }
                else:
                    await message.reply_text(f"âŒ **ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¸Ð¹ Ñ‚Ð¸Ð¿ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ:** {task_type}")
                    return

                task_id = await task_scheduler.add_scheduled_task(
                    user_id=user_id,
                    task_type=template["task_type"],
                    prompt=template["prompt"],
                    auto_execute=True,
                    auto_respond=True,
                    metadata=template.get("metadata", {})
                )

            await message.reply_text(
                f"âœ… **Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð´Ð¾Ð´Ð°Ð½Ð¾ Ð´Ð¾ Ñ‡ÐµÑ€Ð³Ð¸**\n\n"
                f"ðŸ†” ID: {task_id}\n"
                f"ðŸ“‹ Ð¢Ð¸Ð¿: {task_type}\n"
                f"ðŸ¤– ÐÐ²Ñ‚Ð¾Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ: Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾\n\n"
                f"_Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð±ÑƒÐ´Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð¾ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð¿Ñ€Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ– Claude CLI_"
            )

        elif command == "run":
            # Execute task queue manually
            await message.reply_text("ðŸš€ **Ð—Ð°Ð¿ÑƒÑÐº Ñ‡ÐµÑ€Ð³Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ...**")
            results = await task_scheduler.execute_task_queue(user_id)

            result_message = (
                f"âœ… **Ð§ÐµÑ€Ð³Ð° Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð°**\n\n"
                f"ðŸŽ¯ Ð’Ð¸ÐºÐ¾Ð½Ð°Ð½Ð¾: {results['executed']}\n"
                f"âŒ ÐŸÐ¾Ð¼Ð¸Ð»Ð¾Ðº: {results['failed']}\n"
                f"â­ï¸ ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾: {results['skipped']}"
            )

            await message.reply_text(result_message)

        elif command == "clear":
            # Clear task queue
            deleted_count = await task_scheduler.clear_user_tasks(user_id, "pending")

            await message.reply_text(
                f"ðŸ—‘ï¸ **Ð§ÐµÑ€Ð³Ð° Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð°**\n\n"
                f"Ð’Ð¸Ð´Ð°Ð»ÐµÐ½Ð¾ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ: {deleted_count}"
            )

        elif command == "templates":
            # Show available templates
            templates_text = (
                "ðŸ“‹ **Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– ÑˆÐ°Ð±Ð»Ð¾Ð½Ð¸ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ**\n\n"
                "ðŸ” **analysis** - ÐŸÐ¾Ð²Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· ÐºÐ¾Ð´Ñƒ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ\n"
                "ðŸ“ **documentation** - Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—\n"
                "âš’ï¸ **refactoring** - Ð ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³ Ñ‚Ð° Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ\n"
                "ðŸ”’ **security** - ÐÐ½Ð°Ð»Ñ–Ð· Ð±ÐµÐ·Ð¿ÐµÐºÐ¸ Ñ‚Ð° ÑƒÑ€Ð°Ð·Ð»Ð¸Ð²Ð¾ÑÑ‚ÐµÐ¹\n"
                "ðŸ§ª **testing** - Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ñ‚Ð° Ð·Ð°Ð¿ÑƒÑÐº Ñ‚ÐµÑÑ‚Ñ–Ð²\n"
                "ðŸŽ¯ **custom** - Ð’Ð»Ð°ÑÐ½Ðµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð· Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¾Ð¼\n\n"
                "**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ:**\n"
                "`/tasks add analysis`\n"
                "`/tasks add custom Ð¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ API Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–ÑŽ`"
            )

            await message.reply_text(templates_text)

        else:
            await message.reply_text(
                f"âŒ **ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð° ÐºÐ¾Ð¼Ð°Ð½Ð´Ð°:** {command}\n\n"
                "Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸: add, run, clear, templates"
            )

    except Exception as e:
        logger.error("Error in task queue command", error=str(e), user_id=user_id, exc_info=True)
        await message.reply_text(
            f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸:**\n\n`{str(e)}`"
        )


async def auto_mode_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Toggle automation mode for scheduled tasks."""
    user_id = update.effective_user.id
    message = update.effective_message

    logger.info("Auto mode command", user_id=user_id)

    try:
        # Get task scheduler from context
        task_scheduler = context.bot_data.get("task_scheduler")
        if not task_scheduler:
            await message.reply_text(
                "âŒ **Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°**\n\n"
                "Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð½Ðµ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ð°."
            )
            return

        args = context.args
        if not args:
            # Show current auto mode status
            await message.reply_text(
                "ðŸ¤– **Ð ÐµÐ¶Ð¸Ð¼ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ—**\n\n"
                "**ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ ÑÑ‚Ð°Ð½:** Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð¾ âœ…\n\n"
                "**Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ—:**\n"
                "â€¢ ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Ð¿Ñ€Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ– Claude\n"
                "â€¢ ÐÐ²Ñ‚Ð¾Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð½Ð° ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ– Ð·Ð°Ð¿Ð¸Ñ‚Ð¸\n"
                "â€¢ ÐŸÐ¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð² DND Ð¿ÐµÑ€Ñ–Ð¾Ð´\n\n"
                "**ÐšÐ¾Ð¼Ð°Ð½Ð´Ð¸:**\n"
                "`/auto on` - ÑƒÐ²Ñ–Ð¼ÐºÐ½ÑƒÑ‚Ð¸ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–ÑŽ\n"
                "`/auto off` - Ð²Ð¸Ð¼ÐºÐ½ÑƒÑ‚Ð¸ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–ÑŽ\n"
                "`/auto status` - Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ"
            )
            return

        command = args[0].lower()

        if command in ["on", "enable", "ÑƒÐ²Ñ–Ð¼ÐºÐ½ÑƒÑ‚Ð¸"]:
            await message.reply_text(
                "âœ… **ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ ÑƒÐ²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð°**\n\n"
                "ðŸ¤– Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð±ÑƒÐ´ÑƒÑ‚ÑŒ Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾\n"
                "ðŸ“ ÐÐ²Ñ‚Ð¾Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð°ÐºÑ‚Ð¸Ð²Ð¾Ð²Ð°Ð½Ñ–\n"
                "ðŸ“¢ ÐŸÐ¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð½Ð°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ñ–\n\n"
                "_Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð³Ð¾Ñ‚Ð¾Ð²Ð° Ð´Ð¾ Ð°Ð²Ñ‚Ð¾Ð½Ð¾Ð¼Ð½Ð¾Ñ— Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸_"
            )

        elif command in ["off", "disable", "Ð²Ð¸Ð¼ÐºÐ½ÑƒÑ‚Ð¸"]:
            await message.reply_text(
                "âŒ **ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ Ð²Ð¸Ð¼ÐºÐ½ÐµÐ½Ð°**\n\n"
                "â¸ï¸ ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð·ÑƒÐ¿Ð¸Ð½ÐµÐ½Ð¾\n"
                "ðŸ“ ÐÐ²Ñ‚Ð¾Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ– Ð´ÐµÐ°ÐºÑ‚Ð¸Ð²Ð¾Ð²Ð°Ð½Ñ–\n"
                "ðŸ”• ÐŸÐ¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð²Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ñ–\n\n"
                "_Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð¿Ñ€Ð°Ñ†ÑŽÑ” Ð² Ñ€ÑƒÑ‡Ð½Ð¾Ð¼Ñƒ Ñ€ÐµÐ¶Ð¸Ð¼Ñ–_"
            )

        elif command in ["status", "ÑÑ‚Ð°Ñ‚ÑƒÑ"]:
            running_tasks = task_scheduler.get_running_tasks()
            stats = await task_scheduler.get_task_statistics()

            status_text = (
                "ðŸ“Š **Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ—**\n\n"
                "ðŸ¤– **ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ:** Ð£Ð²Ñ–Ð¼ÐºÐ½ÐµÐ½Ð° âœ…\n"
                "ðŸ“ **ÐÐ²Ñ‚Ð¾Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ñ–:** ÐÐºÑ‚Ð¸Ð²Ð½Ñ– âœ…\n"
                "ðŸ“¢ **ÐŸÐ¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ:** ÐÐ°Ð»Ð°ÑˆÑ‚Ð¾Ð²Ð°Ð½Ñ– âœ…\n\n"
                f"ðŸƒ **ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð° Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ:**\n"
                f"â€¢ Ð’Ð¸ÐºÐ¾Ð½ÑƒÑ”Ñ‚ÑŒÑÑ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ: {len(running_tasks)}\n"
                f"â€¢ ÐžÑ‡Ñ–ÐºÑƒÑŽÑ‚ÑŒ: {stats.get('pending', 0)}\n"
                f"â€¢ Ð’Ð¸ÐºÐ¾Ð½Ð°Ð½Ð¾ ÑÑŒÐ¾Ð³Ð¾Ð´Ð½Ñ–: {stats.get('completed', 0)}\n\n"
                "ðŸ’¡ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ `/tasks` Ð´Ð»Ñ ÐºÐµÑ€ÑƒÐ²Ð°Ð½Ð½Ñ Ñ‡ÐµÑ€Ð³Ð¾ÑŽ"
            )

            await message.reply_text(status_text)

        else:
            await message.reply_text(
                f"âŒ **ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ð° ÐºÐ¾Ð¼Ð°Ð½Ð´Ð°:** {command}\n\n"
                "Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ– ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸: on, off, status"
            )

    except Exception as e:
        logger.error("Error in auto mode command", error=str(e), user_id=user_id, exc_info=True)
        await message.reply_text(
            f"âŒ **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸:**\n\n`{str(e)}`"
        )


async def schedule_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Schedule tasks for automated execution (alias for schedules command)."""
    from .command import schedules_command

    logger.info("Schedule command redirecting to schedules", user_id=update.effective_user.id)

    # Redirect to working schedules system
    await schedules_command(update, context)

```

### bot/handlers/dnd_prompts.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 12,559 Ð±Ð°Ð¹Ñ‚

```python
"""
DND Prompts Command Handlers - ÐžÐ±Ñ€Ð¾Ð±Ð½Ð¸ÐºÐ¸ ÐºÐ¾Ð¼Ð°Ð½Ð´ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ DND Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°Ð¼Ð¸
"""

import structlog
from typing import cast
from telegram import InlineKeyboardButton, InlineKeyboardMarkup, Update
from telegram.ext import ContextTypes
from pathlib import Path

from ...localization.util import t, get_user_id, get_effective_message
from ..features.dnd_prompt_manager import DNDPromptManager, DNDPrompt
from datetime import datetime

logger = structlog.get_logger()

async def dnd_prompts_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /dnd_prompts command - manage DND prompts."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    try:
        # ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²
        settings = context.bot_data.get("settings")
        if not settings:
            await message.reply_text("âŒ ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–")
            return
            
        data_dir = Path("./data")
        prompt_manager = DNDPromptManager(data_dir)
        await prompt_manager.load_prompts()
        
        prompts = await prompt_manager.list_prompts()
        
        if not prompts:
            # Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð·Ñ€Ð°Ð·ÐºÐ¾Ð²Ñ– Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¸
            await prompt_manager.create_sample_prompts()
            prompts = await prompt_manager.list_prompts()
        
        # Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð¼ÐµÐ½ÑŽ ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ
        keyboard = [
            [
                InlineKeyboardButton(await t(context, user_id, "buttons.create_prompt"), callback_data="dnd:create"),
                InlineKeyboardButton(await t(context, user_id, "buttons.prompts_list"), callback_data="dnd:list")
            ],
            [
                InlineKeyboardButton(await t(context, user_id, "buttons.settings"), callback_data="dnd:settings"),
                InlineKeyboardButton(await t(context, user_id, "buttons.statistics"), callback_data="dnd:stats")
            ],
            [
                InlineKeyboardButton("ðŸ“¤ Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚", callback_data="dnd:export"),
                InlineKeyboardButton("ðŸ“¥ Ð†Ð¼Ð¿Ð¾Ñ€Ñ‚", callback_data="dnd:import")
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        message_text = f"""ðŸŒ™ **DND Prompts Manager**

ðŸ“Š **Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°:**
â€¢ Ð’ÑÑŒÐ¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²: {len(prompts)}
â€¢ ÐÐºÑ‚Ð¸Ð²Ð½Ð¸Ñ…: {len([p for p in prompts if p.enabled])}
â€¢ ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ð¹: {len(set(p.category for p in prompts))}

ðŸ•’ **DND Ð¿ÐµÑ€Ñ–Ð¾Ð´:** 23:00 - 08:00
ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚Ð¸ Ð²Ð¸ÐºÐ¾Ð½ÑƒÑŽÑ‚ÑŒÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ ÐºÐ¾Ð»Ð¸ Claude CLI Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð° Ñ‚Ð° ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ñ– Ð½Ðµ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ–.

**ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ Ð´Ñ–ÑŽ:**"""
        
        await message.reply_text(message_text, reply_markup=reply_markup)
        
    except Exception as e:
        logger.error("Error in dnd_prompts command", error=str(e), user_id=user_id)
        await message.reply_text("âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ DND Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²")

async def create_dnd_prompt_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /create_dnd_prompt command - create new DND prompt."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    try:
        # Ð†Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ñ–Ñ— Ð´Ð»Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ
        instructions = """ðŸ“ **Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ DND Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ**

Ð”Ð»Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ, Ð½Ð°Ð´Ñ–ÑˆÐ»Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ–:

```
TITLE: ÐÐ°Ð·Ð²Ð° Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ
DESCRIPTION: ÐžÐ¿Ð¸Ñ Ñ‰Ð¾ Ñ€Ð¾Ð±Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
CATEGORY: ÐºÐ¾Ð´-ÑÐºÐ¾ÑÑ‚ÑŒ|Ð±ÐµÐ·Ð¿ÐµÐºÐ°|Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ|Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ
PRIORITY: 1-10
DURATION: Ñ…Ð²Ð¸Ð»Ð¸Ð½Ð¸
TAGS: Ñ‚ÐµÐ³1,Ñ‚ÐµÐ³2,Ñ‚ÐµÐ³3

--- PROMPT ---
Ð¢ÑƒÑ‚ Ñ–Ð´Ðµ ÑÐ°Ð¼ Ñ‚ÐµÐºÑÑ‚ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ Ñƒ markdown Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ–.

ÐœÐ¾Ð¶ÐµÑ‚Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸ Claude CLI:
- Read Ð´Ð»Ñ Ñ‡Ð¸Ñ‚Ð°Ð½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñ–Ð²
- Write Ð´Ð»Ñ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ñ„Ð°Ð¹Ð»Ñ–Ð²  
- Bash Ð´Ð»Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´
- Grep Ð´Ð»Ñ Ð¿Ð¾ÑˆÑƒÐºÑƒ

ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ:
ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ ÐºÐ¾Ð´ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ Ñ‚Ð° ÑÑ‚Ð²Ð¾Ñ€Ð¸ Ð·Ð²Ñ–Ñ‚ Ð· Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–ÑÐ¼Ð¸...
```

**ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´:**"""
        
        example = """```
TITLE: Ð©Ð¾Ð´ÐµÐ½Ð½Ð¸Ð¹ ÐºÐ¾Ð´-Ñ€ÐµÐ²ÑŽ
DESCRIPTION: ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ð·Ð¼Ñ–Ð½ Ð·Ð° Ð´ÐµÐ½ÑŒ
CATEGORY: ÐºÐ¾Ð´-ÑÐºÐ¾ÑÑ‚ÑŒ
PRIORITY: 8
DURATION: 30
TAGS: git,code-review,analysis

--- PROMPT ---
Ð’Ð¸ÐºÐ¾Ð½Ð°Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ð·Ð¼Ñ–Ð½ Ñƒ git Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ñ— Ð·Ð° Ð¾ÑÑ‚Ð°Ð½Ð½Ñ–Ð¹ Ð´ÐµÐ½ÑŒ:

1. `git log --oneline --since="1 day ago"`
2. `git diff HEAD~1..HEAD`
3. ÐŸÑ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ð¹ Ð·Ð¼Ñ–Ð½ÐµÐ½Ñ– Ñ„Ð°Ð¹Ð»Ð¸ Ñ‡ÐµÑ€ÐµÐ· Read
4. Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸ Ð·Ð²Ñ–Ñ‚ Ð· Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–ÑÐ¼Ð¸

Ð—Ð¾ÑÐµÑ€ÐµÐ´ÑŒÑÑ Ð½Ð°:
- Ð¯ÐºÐ¾ÑÑ‚Ñ– ÐºÐ¾Ð´Ñƒ
- ÐŸÐ¾Ñ‚ÐµÐ½Ñ†Ñ–Ð¹Ð½Ð¸Ñ… Ð±Ð°Ð³Ð°Ñ…
- ÐŸÐ¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½ÑÑ… Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸
```"""

        keyboard = [
            [InlineKeyboardButton(await t(context, user_id, "buttons.prompt_templates"), callback_data="dnd:templates")],
            [InlineKeyboardButton(await t(context, user_id, "buttons.back_to_menu"), callback_data="dnd:menu")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await message.reply_text(f"{instructions}\n\n{example}", reply_markup=reply_markup)
        
        # Ð—Ð±ÐµÑ€ÐµÐ³Ñ‚Ð¸ ÑÑ‚Ð°Ð½ Ð´Ð»Ñ Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¾Ð³Ð¾ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ
        context.user_data['creating_dnd_prompt'] = True
        
    except Exception as e:
        logger.error("Error in create_dnd_prompt command", error=str(e), user_id=user_id)
        await message.reply_text("âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ")

async def handle_dnd_prompt_creation(update: Update, context: ContextTypes.DEFAULT_TYPE) -> bool:
    """Handle DND prompt creation from user message."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message or not message.text:
        return False
        
    # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ñ‡Ð¸ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡ ÑÑ‚Ð²Ð¾Ñ€ÑŽÑ” Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
    if not context.user_data.get('creating_dnd_prompt'):
        return False
    
    try:
        text = message.text.strip()
        
        # ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ
        lines = text.split('\n')
        metadata = {}
        prompt_content = ""
        
        parsing_prompt = False
        
        for line in lines:
            line = line.strip()
            
            if line == "--- PROMPT ---":
                parsing_prompt = True
                continue
                
            if parsing_prompt:
                prompt_content += line + "\n"
            elif ':' in line:
                key, value = line.split(':', 1)
                key = key.strip().lower()
                value = value.strip()
                
                if key == 'title':
                    metadata['title'] = value
                elif key == 'description':
                    metadata['description'] = value
                elif key == 'category':
                    metadata['category'] = value
                elif key == 'priority':
                    metadata['priority'] = int(value)
                elif key == 'duration':
                    metadata['estimated_duration'] = int(value)
                elif key == 'tags':
                    metadata['tags'] = [t.strip() for t in value.split(',')]
        
        # Ð’Ð°Ð»Ñ–Ð´Ð°Ñ†Ñ–Ñ
        if not metadata.get('title'):
            await message.reply_text("âŒ ÐÐµ Ð²ÐºÐ°Ð·Ð°Ð½Ð¾ TITLE Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ")
            return True
            
        if not prompt_content.strip():
            await message.reply_text("âŒ ÐÐµ Ð²ÐºÐ°Ð·Ð°Ð½Ð¾ Ñ‚ÐµÐºÑÑ‚ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ Ð¿Ñ–ÑÐ»Ñ --- PROMPT ---")
            return True
        
        # Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
        prompt_id = metadata['title'].lower().replace(' ', '_').replace('-', '_')
        prompt_id = ''.join(c for c in prompt_id if c.isalnum() or c == '_')
        
        dnd_prompt = DNDPrompt(
            id=prompt_id,
            title=metadata.get('title', 'ÐÐ¾Ð²Ð¸Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚'),
            description=metadata.get('description', ''),
            prompt_content=prompt_content.strip(),
            tags=metadata.get('tags', []),
            priority=metadata.get('priority', 5),
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat(),
            category=metadata.get('category', 'general'),
            estimated_duration=metadata.get('estimated_duration', 30)
        )
        
        # Ð—Ð±ÐµÑ€ÐµÐ³Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
        data_dir = Path("./data")
        prompt_manager = DNDPromptManager(data_dir)
        
        success = await prompt_manager.add_prompt(dnd_prompt)
        
        if success:
            await message.reply_text(f"""âœ… **ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð¾ ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾!**

**ID:** `{prompt_id}`
**ÐÐ°Ð·Ð²Ð°:** {dnd_prompt.title}
**ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ:** {dnd_prompt.category}
**ÐŸÑ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚:** {dnd_prompt.priority}/10
**Ð¢Ñ€Ð¸Ð²Ð°Ð»Ñ–ÑÑ‚ÑŒ:** {dnd_prompt.estimated_duration} Ñ…Ð²

ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¾ Ñƒ Ñ„Ð°Ð¹Ð» `data/dnd_prompts/{prompt_id}.md`

Ð’Ñ–Ð½ Ð±ÑƒÐ´Ðµ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð²Ð¸ÐºÐ¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ÑÑ Ð¿Ñ–Ð´ Ñ‡Ð°Ñ DND Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ.""")
        else:
            await message.reply_text("âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ. ÐœÐ¾Ð¶Ð»Ð¸Ð²Ð¾ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð· Ñ‚Ð°ÐºÐ¸Ð¼ ID Ð²Ð¶Ðµ Ñ–ÑÐ½ÑƒÑ”.")
        
        # ÐžÑ‡Ð¸ÑÑ‚Ð¸Ñ‚Ð¸ ÑÑ‚Ð°Ð½
        context.user_data['creating_dnd_prompt'] = False
        return True
        
    except Exception as e:
        logger.error("Error handling DND prompt creation", error=str(e), user_id=user_id)
        await message.reply_text("âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð±Ñ€Ð¾Ð±ÐºÐ¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ. ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚.")
        context.user_data['creating_dnd_prompt'] = False
        return True

async def list_dnd_prompts(update: Update, context: ContextTypes.DEFAULT_TYPE, category: str = None) -> None:
    """Show list of DND prompts."""
    user_id = get_user_id(update)
    message = get_effective_message(update)
    
    if not user_id or not message:
        return
        
    try:
        data_dir = Path("./data")
        prompt_manager = DNDPromptManager(data_dir)
        await prompt_manager.load_prompts()
        
        prompts = await prompt_manager.list_prompts(category=category)
        
        if not prompts:
            await message.reply_text(f"ðŸ“‹ ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð² Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾{f' Ð² ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ— {category}' if category else ''}")
            return
        
        # Ð“Ñ€ÑƒÐ¿ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð° ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–ÑÐ¼Ð¸
        by_category = {}
        for prompt in prompts:
            if prompt.category not in by_category:
                by_category[prompt.category] = []
            by_category[prompt.category].append(prompt)
        
        message_text = f"ðŸ“‹ **DND ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚Ð¸** ({len(prompts)})\n\n"
        
        for cat, cat_prompts in by_category.items():
            message_text += f"**ðŸ“‚ {cat.upper()}** ({len(cat_prompts)})\n"
            
            for prompt in cat_prompts[:5]:  # ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚Ð¸ Ð¿ÐµÑ€ÑˆÑ– 5
                status = "âœ…" if prompt.enabled else "âŒ"
                message_text += f"{status} **{prompt.title}** (P:{prompt.priority}, {prompt.estimated_duration}Ð¼)\n"
                message_text += f"   _{prompt.description[:60]}..._\n"
            
            if len(cat_prompts) > 5:
                message_text += f"   ... Ñ‚Ð° Ñ‰Ðµ {len(cat_prompts) - 5} Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²\n"
            
            message_text += "\n"
        
        keyboard = [
            [InlineKeyboardButton(await t(context, user_id, "buttons.create_new"), callback_data="dnd:create")],
            [InlineKeyboardButton(await t(context, user_id, "buttons.back_simple"), callback_data="dnd:menu")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await message.reply_text(message_text, reply_markup=reply_markup)
        
    except Exception as e:
        logger.error("Error listing DND prompts", error=str(e), user_id=user_id)
        await message.reply_text("âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ ÑÐ¿Ð¸ÑÐºÑƒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²")

```

### bot/handlers/mcp_commands.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 20,314 Ð±Ð°Ð¹Ñ‚

```python
"""MCP Command Handlers for Telegram Bot.

Handles all MCP-related commands: /mcpadd, /mcplist, /mcpselect, /mcpask, /mcpremove, /mcpstatus
"""

import asyncio
from typing import Dict, List, Optional

import structlog
from telegram import InlineKeyboardButton, InlineKeyboardMarkup, Update
from telegram.ext import ContextTypes

from src.localization.util import t, get_user_id
from src.mcp.context_handler import MCPContextHandler
from src.mcp.exceptions import (
    MCPContextError,
    MCPError,
    MCPServerNotFoundError,
    MCPValidationError,
)
from src.mcp.manager import MCPManager, MCPServerConfig
from src.mcp.server_configs import server_config_registry

logger = structlog.get_logger()


async def mcpadd_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /mcpadd command - Add new MCP server."""
    user_id = get_user_id(update)
    message = update.effective_message

    if not user_id or not message:
        return

    try:
        mcp_manager: MCPManager = context.bot_data.get("mcp_manager")
        if not mcp_manager:
            await message.reply_text(await t(context, user_id, "mcp.errors.system_not_available"))
            return

        # Check if user provided server type as argument
        args = context.args or []

        if args:
            # Quick add with command line arguments
            await _handle_quick_add(update, context, args[0], mcp_manager)
        else:
            # Interactive wizard
            await _show_server_type_selection(update, context, mcp_manager)

    except Exception as e:
        logger.error("Error in mcpadd command", user_id=user_id, error=str(e))
        await message.reply_text(await t(context, user_id, "mcp.errors.add_failed", error=str(e)))


async def mcplist_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /mcplist command - List user's MCP servers."""
    user_id = get_user_id(update)
    message = update.effective_message

    if not user_id or not message:
        return

    try:
        mcp_manager: MCPManager = context.bot_data.get("mcp_manager")
        if not mcp_manager:
            await message.reply_text(await t(context, user_id, "mcp.errors.system_not_available"))
            return

        # Get user's servers
        servers = await mcp_manager.get_user_servers(user_id)

        if not servers:
            # No servers configured
            keyboard = [
                [InlineKeyboardButton(
                    await t(context, user_id, "mcp.buttons.add_first_server"), 
                    callback_data="mcp_add_wizard"
                )]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)

            await message.reply_text(
                await t(context, user_id, "mcp.list.no_servers"),
                reply_markup=reply_markup
            )
            return

        # Build servers list
        text_lines = [await t(context, user_id, "mcp.list.title")]
        text_lines.append("")

        keyboard = []
        for server in servers:
            # Status emoji
            if server['is_enabled']:
                if server['status'] == 'active':
                    status_emoji = "âœ…"
                elif server['status'] == 'error':
                    status_emoji = "âŒ"
                else:
                    status_emoji = "ðŸ”§"
            else:
                status_emoji = "âšª"

            server_name = server['server_name']
            display_name = server.get('display_name', server['server_type'])

            text_lines.append(f"{status_emoji} **{server_name}** - {display_name}")

            if server['status'] == 'active':
                text_lines.append(f"   {await t(context, user_id, 'mcp.list.status_active')}")
            elif server['status'] == 'error':
                error_msg = server.get('error_message', 'Unknown error')[:50]
                text_lines.append(f"   {await t(context, user_id, 'mcp.list.status_error', error=error_msg)}")
            elif not server['is_enabled']:
                text_lines.append(f"   {await t(context, user_id, 'mcp.list.status_disabled')}")
            else:
                text_lines.append(f"   {await t(context, user_id, 'mcp.list.status_inactive')}")

            if server.get('last_used'):
                last_used = server['last_used'].strftime('%d.%m %H:%M')
                text_lines.append(f"   {await t(context, user_id, 'mcp.list.last_used', time=last_used)}")

            text_lines.append("")

            # Add server control button
            keyboard.append([
                InlineKeyboardButton(
                    f"âš™ï¸ {server_name}",
                    callback_data=f"mcp_manage:{server_name}"
                )
            ])

        # Add control buttons
        keyboard.extend([
            [
                InlineKeyboardButton(
                    await t(context, user_id, "mcp.buttons.add_server"),
                    callback_data="mcp_add_wizard"
                ),
                InlineKeyboardButton(
                    await t(context, user_id, "mcp.buttons.refresh_status"),
                    callback_data="mcp_refresh_all"
                )
            ],
            [
                InlineKeyboardButton(
                    await t(context, user_id, "mcp.buttons.system_status"),
                    callback_data="mcp_system_status"
                )
            ]
        ])

        reply_markup = InlineKeyboardMarkup(keyboard)

        await message.reply_text(
            "\n".join(text_lines),
            reply_markup=reply_markup,
            parse_mode=None
        )

    except Exception as e:
        logger.error("Error in mcplist command", user_id=user_id, error=str(e))
        await message.reply_text(await t(context, user_id, "mcp.errors.list_failed", error=str(e)))


async def mcpselect_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /mcpselect command - Select active MCP context."""
    user_id = get_user_id(update)
    message = update.effective_message

    if not user_id or not message:
        return

    try:
        mcp_context_handler: MCPContextHandler = context.bot_data.get("mcp_context_handler")
        mcp_manager: MCPManager = context.bot_data.get("mcp_manager")

        if not mcp_context_handler or not mcp_manager:
            await message.reply_text(await t(context, user_id, "mcp.errors.system_not_available"))
            return

        args = context.args or []

        if args:
            # Direct selection
            server_name = args[0]
            try:
                await mcp_context_handler.set_active_context(user_id, server_name)
                await message.reply_text(
                    await t(context, user_id, "mcp.select.success", server_name=server_name)
                )
            except (MCPServerNotFoundError, MCPContextError) as e:
                await message.reply_text(
                    await t(context, user_id, "mcp.select.failed", error=str(e))
                )
        else:
            # Show selection menu
            await _show_context_selection_menu(update, context, mcp_manager, mcp_context_handler)

    except Exception as e:
        logger.error("Error in mcpselect command", user_id=user_id, error=str(e))
        await message.reply_text(await t(context, user_id, "mcp.errors.select_failed", error=str(e)))


async def mcpask_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /mcpask command - Execute query with MCP context."""
    user_id = get_user_id(update)
    message = update.effective_message

    if not user_id or not message:
        return

    try:
        mcp_context_handler: MCPContextHandler = context.bot_data.get("mcp_context_handler")

        if not mcp_context_handler:
            await message.reply_text(await t(context, user_id, "mcp.errors.system_not_available"))
            return

        # Get query from command arguments
        query = " ".join(context.args or [])
        if not query:
            await message.reply_text(await t(context, user_id, "mcp.ask.no_query"))
            return

        # Check active context
        active_context = await mcp_context_handler.get_active_context(user_id)
        if not active_context:
            # Show context selection
            await _show_context_selection_for_query(update, context, query)
            return

        # Execute query
        await _execute_mcp_query(update, context, query, mcp_context_handler)

    except Exception as e:
        logger.error("Error in mcpask command", user_id=user_id, error=str(e))
        await message.reply_text(await t(context, user_id, "mcp.errors.ask_failed", error=str(e)))


async def mcpremove_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /mcpremove command - Remove MCP server."""
    user_id = get_user_id(update)
    message = update.effective_message

    if not user_id or not message:
        return

    try:
        mcp_manager: MCPManager = context.bot_data.get("mcp_manager")
        if not mcp_manager:
            await message.reply_text(await t(context, user_id, "mcp.errors.system_not_available"))
            return

        args = context.args or []

        if args:
            # Direct removal with confirmation
            server_name = args[0]
            keyboard = [
                [
                    InlineKeyboardButton(
                        await t(context, user_id, "mcp.buttons.confirm_remove"),
                        callback_data=f"mcp_confirm_remove:{server_name}"
                    ),
                    InlineKeyboardButton(
                        await t(context, user_id, "mcp.buttons.cancel"),
                        callback_data="mcp_cancel"
                    )
                ]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)

            await message.reply_text(
                await t(context, user_id, "mcp.remove.confirm", server_name=server_name),
                reply_markup=reply_markup
            )
        else:
            # Show removal selection menu
            await _show_removal_selection_menu(update, context, mcp_manager)

    except Exception as e:
        logger.error("Error in mcpremove command", user_id=user_id, error=str(e))
        await message.reply_text(await t(context, user_id, "mcp.errors.remove_failed", error=str(e)))


async def mcpstatus_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Handle /mcpstatus command - Show system status."""
    user_id = get_user_id(update)
    message = update.effective_message

    if not user_id or not message:
        return

    try:
        mcp_manager: MCPManager = context.bot_data.get("mcp_manager")
        mcp_context_handler: MCPContextHandler = context.bot_data.get("mcp_context_handler")

        if not mcp_manager or not mcp_context_handler:
            await message.reply_text(await t(context, user_id, "mcp.errors.system_not_available"))
            return

        # Show status loading message
        status_msg = await message.reply_text(await t(context, user_id, "mcp.status.checking"))

        # Get system status
        servers = await mcp_manager.get_user_servers(user_id)
        active_context = await mcp_context_handler.get_active_context(user_id)
        context_summary = await mcp_context_handler.get_context_summary(user_id)

        # Build status message
        text_lines = [await t(context, user_id, "mcp.status.title")]
        text_lines.append("")

        # Claude CLI status (placeholder - would need actual check)
        text_lines.append(f"ðŸ¤– Claude CLI: âœ… {await t(context, user_id, 'mcp.status.connected')}")

        # Active context
        if active_context:
            server_name = active_context['selected_server']
            display_name = active_context.get('display_name', server_name)
            text_lines.append(f"ðŸŽ¯ {await t(context, user_id, 'mcp.status.active_context', context=display_name)}")
        else:
            text_lines.append(f"ðŸŽ¯ {await t(context, user_id, 'mcp.status.no_context')}")

        # Servers summary
        enabled_count = len([s for s in servers if s['is_enabled']])
        active_count = len([s for s in servers if s['status'] == 'active'])

        text_lines.append(f"ðŸ“Š {await t(context, user_id, 'mcp.status.servers_summary', total=len(servers), enabled=enabled_count, active=active_count)}")
        text_lines.append("")

        # Usage statistics
        if context_summary.get("recent_usage"):
            usage = context_summary["recent_usage"]["overall"]
            total_queries = usage.get("total_queries", 0)
            success_rate = (usage.get("successful_queries", 0) / total_queries * 100) if total_queries > 0 else 0
            avg_time = usage.get("avg_response_time", 0)
            total_cost = usage.get("total_cost", 0)

            text_lines.append(f"ðŸ“ˆ {await t(context, user_id, 'mcp.status.usage_stats')}")
            text_lines.append(f"   â€¢ {await t(context, user_id, 'mcp.status.queries_count', count=total_queries)}")
            text_lines.append(f"   â€¢ {await t(context, user_id, 'mcp.status.success_rate', rate=f'{success_rate:.1f}')}")
            if avg_time:
                text_lines.append(f"   â€¢ {await t(context, user_id, 'mcp.status.avg_response', time=f'{avg_time:.1f}')}")
            if total_cost > 0:
                text_lines.append(f"   â€¢ {await t(context, user_id, 'mcp.status.total_cost', cost=f'{total_cost:.4f}')}")

        # Control buttons
        keyboard = [
            [
                InlineKeyboardButton(
                    await t(context, user_id, "mcp.buttons.list_servers"),
                    callback_data="mcp_list"
                ),
                InlineKeyboardButton(
                    await t(context, user_id, "mcp.buttons.select_context"),
                    callback_data="mcp_select_context"
                )
            ],
            [
                InlineKeyboardButton(
                    await t(context, user_id, "mcp.buttons.refresh_status"),
                    callback_data="mcp_refresh_all"
                )
            ]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)

        await status_msg.edit_text(
            "\n".join(text_lines),
            reply_markup=reply_markup,
            parse_mode=None
        )

    except Exception as e:
        logger.error("Error in mcpstatus command", user_id=user_id, error=str(e))
        await message.reply_text(await t(context, user_id, "mcp.errors.status_failed", error=str(e)))


# Helper functions for interactive wizards and menus

async def _show_server_type_selection(update: Update, context: ContextTypes.DEFAULT_TYPE, mcp_manager: MCPManager) -> None:
    """Show server type selection menu."""
    user_id = get_user_id(update)
    message = update.effective_message

    templates = server_config_registry.get_template_list()

    keyboard = []
    for template in templates:
        keyboard.append([
            InlineKeyboardButton(
                template["display_name"],
                callback_data=f"mcp_add_type:{template['server_type']}"
            )
        ])

    # Add cancel button
    keyboard.append([
        InlineKeyboardButton(
            await t(context, user_id, "mcp.buttons.cancel"),
            callback_data="mcp_cancel"
        )
    ])

    reply_markup = InlineKeyboardMarkup(keyboard)

    await message.reply_text(
        await t(context, user_id, "mcp.add.select_type"),
        reply_markup=reply_markup
    )


async def _show_context_selection_menu(update: Update, context: ContextTypes.DEFAULT_TYPE, 
                                     mcp_manager: MCPManager, mcp_context_handler: MCPContextHandler) -> None:
    """Show context selection menu."""
    user_id = get_user_id(update)
    message = update.effective_message

    # Get enabled servers
    servers = await mcp_manager.get_user_servers(user_id)
    enabled_servers = [s for s in servers if s['is_enabled']]

    if not enabled_servers:
        await message.reply_text(await t(context, user_id, "mcp.select.no_enabled_servers"))
        return

    # Get current active context
    active_context = await mcp_context_handler.get_active_context(user_id)
    active_server = active_context.get('selected_server') if active_context else None

    keyboard = []
    for server in enabled_servers:
        server_name = server['server_name']
        display_name = server.get('display_name', server['server_type'])

        # Mark current active server
        text = f"ðŸŽ¯ {display_name}" if server_name == active_server else display_name

        keyboard.append([
            InlineKeyboardButton(
                text,
                callback_data=f"mcp_set_context:{server_name}"
            )
        ])

    # Add clear context option if there is an active context
    if active_context:
        keyboard.append([
            InlineKeyboardButton(
                await t(context, user_id, "mcp.buttons.clear_context"),
                callback_data="mcp_clear_context"
            )
        ])

    reply_markup = InlineKeyboardMarkup(keyboard)

    await message.reply_text(
        await t(context, user_id, "mcp.select.choose_context"),
        reply_markup=reply_markup
    )


async def _execute_mcp_query(update: Update, context: ContextTypes.DEFAULT_TYPE, 
                           query: str, mcp_context_handler: MCPContextHandler) -> None:
    """Execute MCP query with active context."""
    user_id = get_user_id(update)
    message = update.effective_message

    # Show processing message
    processing_msg = await message.reply_text(
        await t(context, user_id, "mcp.ask.processing", query=query[:50])
    )

    try:
        # Get current directory from user data
        settings = context.bot_data.get("settings")
        current_dir = context.user_data.get("current_directory", settings.approved_directory)
        session_id = context.user_data.get("claude_session_id")

        # Execute contextual query
        claude_response = await mcp_context_handler.execute_contextual_query(
            user_id=user_id,
            query=query,
            working_directory=str(current_dir),
            session_id=session_id
        )

        # Update session ID
        context.user_data["claude_session_id"] = claude_response.session_id

        # Delete processing message
        await processing_msg.delete()

        # Send response
        from ...utils.formatting import ResponseFormatter
        formatter = ResponseFormatter(settings)
        formatted_messages = formatter.format_claude_response(claude_response.content)

        for i, msg in enumerate(formatted_messages):
            await message.reply_text(
                msg.text,
                parse_mode=msg.parse_mode,
                reply_markup=msg.reply_markup,
                reply_to_message_id=message.message_id if i == 0 else None
            )
            if i < len(formatted_messages) - 1:
                await asyncio.sleep(0.5)

    except MCPContextError as e:
        await processing_msg.edit_text(
            await t(context, user_id, "mcp.ask.context_error", error=str(e))
        )
    except Exception as e:
        logger.error("MCP query execution failed", user_id=user_id, query=query[:100], error=str(e))
        await processing_msg.edit_text(
            await t(context, user_id, "mcp.ask.execution_error", error=str(e))
        )


async def _handle_quick_add(update: Update, context: ContextTypes.DEFAULT_TYPE, 
                          server_type: str, mcp_manager: MCPManager) -> None:
    """Handle quick server addition."""
    user_id = get_user_id(update)
    message = update.effective_message

    template = server_config_registry.get_template(server_type)
    if not template:
        await message.reply_text(
            await t(context, user_id, "mcp.add.invalid_type", server_type=server_type)
        )
        return

    await message.reply_text(
        await t(context, user_id, "mcp.add.quick_not_supported", server_type=server_type)
    )

    # Start interactive wizard
    await _show_server_type_selection(update, context, mcp_manager)

```

### bot/features/auto_responder.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 11,344 Ð±Ð°Ð¹Ñ‚

```python
"""Auto-responder for Claude CLI system prompts."""

import re
import structlog
from typing import Dict, List, Optional, Tuple

logger = structlog.get_logger()


class AutoResponder:
    """Automatically responds to Claude CLI system prompts during task execution."""

    def __init__(self):
        """Initialize auto-responder with predefined response patterns."""
        self.response_patterns = self._initialize_response_patterns()
        self.confirmation_responses = self._initialize_confirmation_responses()
        self.enabled = True

    def _initialize_response_patterns(self) -> Dict[str, str]:
        """Initialize patterns that should trigger auto-responses."""
        return {
            # Confirmation prompts
            r"(?i)(do\s+you\s+want\s+to\s+continue|continue\s*\?|proceed\s*\?)": "yes",
            r"(?i)(are\s+you\s+sure|confirm|confirmation)": "yes",
            r"(?i)(yes\s*/\s*no|y\s*/\s*n|\[y/n\])": "y",

            # File operations
            r"(?i)(overwrite|replace)\s+.*\s*\?": "yes",
            r"(?i)(create\s+file|create\s+directory).*\s*\?": "yes",
            r"(?i)(delete|remove)\s+.*\s*\?": "yes",

            # Git operations
            r"(?i)(commit\s+changes|add\s+files).*\s*\?": "yes",
            r"(?i)(push\s+to\s+remote|pull\s+from\s+remote).*\s*\?": "yes",

            # Package/dependency management
            r"(?i)(install\s+packages|update\s+dependencies).*\s*\?": "yes",
            r"(?i)(upgrade\s+packages|downgrade\s+packages).*\s*\?": "yes",

            # Permission/authentication
            r"(?i)(allow\s+access|grant\s+permission).*\s*\?": "yes",
            r"(?i)(authenticate|login).*\s*\?": "yes",

            # System operations
            r"(?i)(restart\s+service|reload\s+configuration).*\s*\?": "yes",
            r"(?i)(apply\s+changes|save\s+configuration).*\s*\?": "yes",

            # Time/wait prompts
            r"(?i)(press\s+enter|press\s+any\s+key)": "\n",
            r"(?i)(wait\s+for|continue\s+when\s+ready)": "\n",

            # Ukrainian patterns
            r"(?i)(Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸|Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶ÑƒÐ²Ð°Ñ‚Ð¸).*\s*\?": "Ñ‚Ð°Ðº",
            r"(?i)(Ð²Ð¸\s+Ð²Ð¿ÐµÐ²Ð½ÐµÐ½Ñ–|Ð¿Ñ–Ð´Ñ‚Ð²ÐµÑ€Ð´Ð¶ÐµÐ½Ð½Ñ).*\s*\s*\?": "Ñ‚Ð°Ðº",
            r"(?i)(Ñ‚Ð°Ðº\s*/\s*Ð½Ñ–|Ñ‚\s*/\s*Ð½|\[Ñ‚/Ð½\])": "Ñ‚",
            r"(?i)(Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿Ð¸ÑÐ°Ñ‚Ð¸|Ð·Ð°Ð¼Ñ–Ð½Ð¸Ñ‚Ð¸).*\s*\?": "Ñ‚Ð°Ðº",
            r"(?i)(ÑÑ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸\s+Ñ„Ð°Ð¹Ð»|ÑÑ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸\s+ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³).*\s*\?": "Ñ‚Ð°Ðº",
            r"(?i)(Ð²Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸|Ð²Ð¸Ð»ÑƒÑ‡Ð¸Ñ‚Ð¸).*\s*\?": "Ñ‚Ð°Ðº",
        }

    def _initialize_confirmation_responses(self) -> Dict[str, List[str]]:
        """Initialize contextual confirmation responses."""
        return {
            "file_operations": ["yes", "y", "Ñ‚Ð°Ðº", "Ñ‚"],
            "git_operations": ["yes", "y", "Ñ‚Ð°Ðº", "Ñ‚"],
            "package_management": ["yes", "y", "Ñ‚Ð°Ðº", "Ñ‚"],
            "system_operations": ["yes", "y", "Ñ‚Ð°Ðº", "Ñ‚"],
            "general_confirmation": ["yes", "y", "Ñ‚Ð°Ðº", "Ñ‚"],
            "continue_prompts": ["", "\n", "Ñ‚Ð°Ðº", "yes"],
        }

    def should_auto_respond(self, message: str, context: Optional[str] = None) -> bool:
        """Determine if message requires an auto-response."""
        if not self.enabled:
            return False

        # Check if message contains any response patterns
        for pattern in self.response_patterns.keys():
            if re.search(pattern, message):
                logger.debug("Auto-response pattern matched", pattern=pattern, message=message[:100])
                return True

        # Check for other indicators that suggest user input is needed
        if self._is_input_prompt(message):
            logger.debug("Input prompt detected", message=message[:100])
            return True

        return False

    def get_auto_response(self, message: str, context: Optional[str] = None) -> str:
        """Generate automatic response for the given message."""
        if not self.enabled:
            return ""

        # Try pattern matching first
        for pattern, response in self.response_patterns.items():
            if re.search(pattern, message):
                logger.info("Auto-responding with pattern", pattern=pattern, response=response)
                return response

        # Contextual responses based on content analysis
        response = self._analyze_and_respond(message, context)
        if response:
            logger.info("Auto-responding with analysis", message=message[:100], response=response)
            return response

        # Default safe response for confirmation prompts
        if self._is_confirmation_prompt(message):
            default_response = "yes"
            logger.info("Auto-responding with default", response=default_response)
            return default_response

        # Last resort - enter key for continue prompts
        logger.info("Auto-responding with enter key")
        return "\n"

    def _is_input_prompt(self, message: str) -> bool:
        """Check if message is asking for user input."""
        input_indicators = [
            r"(?i)enter\s+",
            r"(?i)input\s+",
            r"(?i)type\s+",
            r"(?i)provide\s+",
            r"(?i)specify\s+",
            r"\?\s*$",  # Ends with question mark
            r":\s*$",   # Ends with colon
            r">\s*$",   # Ends with greater than
            r"\[.*\]\s*$",  # Ends with brackets
            # Ukrainian
            r"(?i)Ð²Ð²ÐµÐ´Ñ–Ñ‚ÑŒ\s+",
            r"(?i)Ð½Ð°Ð´Ð°Ð¹Ñ‚Ðµ\s+",
            r"(?i)Ð²ÐºÐ°Ð¶Ñ–Ñ‚ÑŒ\s+",
        ]

        return any(re.search(pattern, message) for pattern in input_indicators)

    def _is_confirmation_prompt(self, message: str) -> bool:
        """Check if message is asking for confirmation."""
        confirmation_indicators = [
            r"(?i)(yes|no)",
            r"(?i)(y/n)",
            r"(?i)confirm",
            r"(?i)sure",
            r"(?i)proceed",
            r"(?i)continue",
            r"(?i)agree",
            # Ukrainian
            r"(?i)(Ñ‚Ð°Ðº|Ð½Ñ–)",
            r"(?i)(Ñ‚/Ð½)",
            r"(?i)Ð¿Ñ–Ð´Ñ‚Ð²ÐµÑ€Ð´Ð¸Ñ‚Ð¸",
            r"(?i)Ð²Ð¿ÐµÐ²Ð½ÐµÐ½Ñ–",
            r"(?i)Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸",
            r"(?i)Ð·Ð³Ð¾Ð´Ð½Ñ–",
        ]

        return any(re.search(pattern, message) for pattern in confirmation_indicators)

    def _analyze_and_respond(self, message: str, context: Optional[str] = None) -> Optional[str]:
        """Analyze message content and generate contextual response."""
        message_lower = message.lower()

        # File operation context
        if any(word in message_lower for word in ["file", "directory", "folder", "create", "delete", "modify"]):
            if any(word in message_lower for word in ["overwrite", "replace", "exists"]):
                return "yes"  # Safe to overwrite in automated context

        # Git operation context
        if any(word in message_lower for word in ["git", "commit", "push", "pull", "merge", "branch"]):
            if any(word in message_lower for word in ["push", "commit", "add"]):
                return "yes"  # Proceed with git operations

        # Package management context
        if any(word in message_lower for word in ["install", "update", "upgrade", "package", "dependency"]):
            return "yes"  # Proceed with package operations

        # Permission/security context (be more cautious)
        if any(word in message_lower for word in ["permission", "security", "auth", "login", "password"]):
            # For auth prompts, we might need specific handling
            if "password" in message_lower or "token" in message_lower:
                return None  # Don't auto-respond to password prompts
            return "yes"

        # Time-based operations
        if any(word in message_lower for word in ["wait", "timeout", "retry", "continue"]):
            return "yes"

        return None

    def configure_patterns(self, custom_patterns: Dict[str, str]) -> None:
        """Configure custom response patterns."""
        self.response_patterns.update(custom_patterns)
        logger.info("Updated auto-response patterns", new_patterns=custom_patterns)

    def add_pattern(self, pattern: str, response: str) -> None:
        """Add a single response pattern."""
        self.response_patterns[pattern] = response
        logger.info("Added auto-response pattern", pattern=pattern, response=response)

    def remove_pattern(self, pattern: str) -> bool:
        """Remove a response pattern."""
        if pattern in self.response_patterns:
            del self.response_patterns[pattern]
            logger.info("Removed auto-response pattern", pattern=pattern)
            return True
        return False

    def enable(self) -> None:
        """Enable auto-responses."""
        self.enabled = True
        logger.info("Auto-responder enabled")

    def disable(self) -> None:
        """Disable auto-responses."""
        self.enabled = False
        logger.info("Auto-responder disabled")

    def get_status(self) -> Dict[str, any]:
        """Get current auto-responder status."""
        return {
            "enabled": self.enabled,
            "pattern_count": len(self.response_patterns),
            "patterns": list(self.response_patterns.keys())
        }

    def test_response(self, message: str, context: Optional[str] = None) -> Tuple[bool, str]:
        """Test what response would be generated for a message."""
        should_respond = self.should_auto_respond(message, context)
        response = ""

        if should_respond:
            response = self.get_auto_response(message, context)

        return should_respond, response

    def get_safe_responses(self) -> List[str]:
        """Get list of responses considered safe for automation."""
        return [
            "yes", "y", "Ñ‚Ð°Ðº", "Ñ‚",
            "no", "n", "Ð½Ñ–", "Ð½",
            "\n", "", "continue", "Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸"
        ]

    def is_dangerous_prompt(self, message: str) -> bool:
        """Check if prompt might be dangerous to auto-respond to."""
        dangerous_indicators = [
            r"(?i)(delete\s+all|remove\s+everything|format\s+disk)",
            r"(?i)(sudo\s+rm|rm\s+-rf)",
            r"(?i)(drop\s+database|truncate\s+table)",
            r"(?i)(factory\s+reset|system\s+restore)",
            r"(?i)(password|secret|key|token)",
            # Ukrainian
            r"(?i)(Ð²Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸\s+Ð²ÑÐµ|Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸\s+Ð´Ð¸ÑÐº)",
            r"(?i)(Ð¿Ð°Ñ€Ð¾Ð»ÑŒ|ÑÐµÐºÑ€ÐµÑ‚|ÐºÐ»ÑŽÑ‡|Ñ‚Ð¾ÐºÐµÐ½)",
        ]

        return any(re.search(pattern, message) for pattern in dangerous_indicators)

    def validate_response_safety(self, message: str, response: str) -> bool:
        """Validate if the auto-response is safe for the given prompt."""
        # Never auto-respond to dangerous prompts
        if self.is_dangerous_prompt(message):
            logger.warning("Dangerous prompt detected, blocking auto-response", message=message[:100])
            return False

        # Check if response is in safe list
        if response.lower().strip() not in [r.lower() for r in self.get_safe_responses()]:
            logger.warning("Unsafe auto-response detected", response=response, message=message[:100])
            return False

        return True

```

### bot/features/scheduled_prompts.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 26,083 Ð±Ð°Ð¹Ñ‚

```python
"""Scheduled prompts system for automated task execution during DND periods."""

import asyncio
import json
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Dict, Any, List
from zoneinfo import ZoneInfo

import structlog
from telegram import Bot
from telegram.ext import Application

from src.config.settings import Settings

logger = structlog.get_logger(__name__)


class ScheduledPromptsManager:
    """Manages automated prompt execution during DND periods."""

    def __init__(self, application: Application, settings: Settings):
        """Initialize the scheduled prompts manager."""
        self.application = application
        self.settings = settings
        self.bot: Bot = application.bot
        self.prompts_file = Path("./data/scheduled_prompts.json")
        self.execution_log = Path("./data/prompt_executions.jsonl")
        self.is_executing = False
        
        # Ensure files exist
        self._init_files()
    
    def _init_files(self):
        """Initialize prompt files if they don't exist."""
        data_dir = Path("./data")
        data_dir.mkdir(exist_ok=True)
        
        if not self.prompts_file.exists():
            default_prompts = {
                "prompts": [
                    {
                        "id": "daily_code_review",
                        "title": "Ð©Ð¾Ð´ÐµÐ½Ð½Ð¸Ð¹ Ð¾Ð³Ð»ÑÐ´ ÐºÐ¾Ð´Ñƒ",
                        "description": "ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ ÐºÐ¾Ð´ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ Ñ‚Ð° Ð·Ð°Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ",
                        "prompt": "ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ð¾ÑÑ‚Ð°Ð½Ð½Ñ– Ð·Ð¼Ñ–Ð½Ð¸ Ð² Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ– Ñ‚Ð° Ð·Ð°Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÐ¹ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸, Ð±ÐµÐ·Ð¿ÐµÐºÐ¸ Ñ‚Ð° Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–",
                        "enabled": True,
                        "schedule": {
                            "type": "daily",
                            "time": "02:00",
                            "timezone": "Europe/Kyiv"
                        },
                        "conditions": {
                            "claude_available": True,
                            "dnd_period": True,
                            "no_user_activity_hours": 2
                        }
                    },
                    {
                        "id": "documentation_update", 
                        "title": "ÐžÐ½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—",
                        "description": "ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ README Ñ‚Ð° ÐºÐ¾Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ñ–Ð²",
                        "prompt": "ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ Ñ‚Ð° Ð¾Ð½Ð¾Ð²Ñ–Ñ‚ÑŒ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–ÑŽ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ, Ð¾ÑÐ¾Ð±Ð»Ð¸Ð²Ð¾ README.md Ñ‚Ð° ÐºÐ¾Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ñ– Ð² ÐºÐ¾Ð´Ñ–",
                        "enabled": True,
                        "schedule": {
                            "type": "weekly",
                            "day": "sunday",
                            "time": "03:00",
                            "timezone": "Europe/Kyiv"
                        },
                        "conditions": {
                            "claude_available": True,
                            "dnd_period": True,
                            "no_user_activity_hours": 4
                        }
                    }
                ],
                "settings": {
                    "max_execution_time_minutes": 30,
                    "retry_attempts": 3,
                    "notification_chat_ids": [],
                    "enabled": True,
                    "auto_response": {
                        "enabled": True,
                        "default_response": "y",
                        "custom_responses": {
                            "commit": "y",
                            "create": "y",
                            "delete": "n",
                            "overwrite": "y",
                            "proceed": "y"
                        }
                    }
                }
            }
            self.prompts_file.write_text(json.dumps(default_prompts, ensure_ascii=False, indent=2))
        
        if not self.execution_log.exists():
            self.execution_log.touch()
    
    async def load_prompts(self) -> Dict[str, Any]:
        """Load prompts configuration from file."""
        try:
            import aiofiles
            async with aiofiles.open(self.prompts_file, 'r', encoding='utf-8') as f:
                content = await f.read()
                return json.loads(content)
        except Exception as e:
            logger.error(f"Failed to load prompts configuration: {e}")
            return {"prompts": [], "settings": {"enabled": False}}
    
    async def save_prompts(self, config: Dict[str, Any]):
        """Save prompts configuration to file."""
        try:
            import aiofiles
            async with aiofiles.open(self.prompts_file, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(config, ensure_ascii=False, indent=2))
        except Exception as e:
            logger.error(f"Failed to save prompts configuration: {e}")
    
    async def log_execution(self, prompt_id: str, status: str, output: Optional[str] = None, error: Optional[str] = None):
        """Log prompt execution result."""
        record = {
            "timestamp": datetime.now(ZoneInfo("UTC")).isoformat(),
            "prompt_id": prompt_id,
            "status": status,  # "started", "completed", "failed", "skipped"
            "output": output,
            "error": error,
            "execution_time": None
        }
        
        try:
            import aiofiles
            async with aiofiles.open(self.execution_log, "a", encoding="utf-8") as f:
                await f.write(json.dumps(record, ensure_ascii=False) + "\n")
        except Exception as e:
            logger.error(f"Failed to log execution: {e}")
    
    def _is_dnd_time(self) -> bool:
        """Check if current time is within DND window."""
        now = datetime.now(ZoneInfo("Europe/Kyiv")).time()
        dnd_start = self.settings.claude_availability.dnd_start
        dnd_end = self.settings.claude_availability.dnd_end

        if dnd_start > dnd_end:  # e.g., 23:00â€“08:00
            return now >= dnd_start or now < dnd_end
        else:
            return dnd_start <= now < dnd_end
    
    async def _check_claude_availability(self) -> bool:
        """Check if Claude CLI is available."""
        try:
            import os
            env = os.environ.copy()
            env['PATH'] = f"/home/claudebot/.local/bin:{env.get('PATH', '')}"
            
            proc = await asyncio.create_subprocess_shell(
                "claude auth status",
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                env=env,
            )
            
            stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=10)
            return proc.returncode == 0
            
        except Exception:
            return False
    
    async def _check_user_activity(self, hours: int) -> bool:
        """Check if there was user activity in the last N hours."""
        # Check recent bot interactions from logs or database
        # For now, simple implementation checking file modification times
        try:
            data_dir = Path("./data")
            cutoff_time = datetime.now() - timedelta(hours=hours)
            
            for file_path in data_dir.glob("*.db"):
                if file_path.stat().st_mtime > cutoff_time.timestamp():
                    return True
            
            return False
        except Exception:
            return False
    
    async def _execute_claude_prompt(self, prompt: str, working_dir: str = "/app/target_project", prompt_title: str = "ÐÐµÐ²Ñ–Ð´Ð¾Ð¼Ðµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ") -> tuple[bool, str]:
        """Execute a Claude CLI prompt with auto-response capability."""
        try:
            import os
            import pexpect
            import asyncio
            from concurrent.futures import ThreadPoolExecutor

            env = os.environ.copy()
            env['PATH'] = f"/home/claudebot/.local/bin:{env.get('PATH', '')}"

            # Load auto-response settings
            config = await self.load_prompts()
            auto_response_settings = config.get("settings", {}).get("auto_response", {})
            auto_response_enabled = auto_response_settings.get("enabled", True)
            default_response = auto_response_settings.get("default_response", "y")
            custom_responses = auto_response_settings.get("custom_responses", {})

            # Run pexpect in a thread to avoid blocking
            def run_interactive_claude():
                try:
                    # Start Claude CLI with interactive session
                    child = pexpect.spawn(
                        'bash',
                        ['-c', f'cd {working_dir} && claude'],
                        env=env,
                        timeout=1800,  # 30 minutes timeout
                        encoding='utf-8'
                    )

                    # Send the prompt
                    child.sendline(prompt)

                    output_lines = []

                    while True:
                        try:
                            # Wait for output or interactive prompts
                            index = child.expect([
                                pexpect.EOF,
                                pexpect.TIMEOUT,
                                r'(?i)\(y/n\)',  # Yes/No questions
                                r'(?i)continue\s*\?',  # Continue questions
                                r'(?i)proceed\s*\?',  # Proceed questions
                                r'(?i)confirm\s*\?',  # Confirm questions
                                r'(?i)do you want',  # "Do you want to..." questions
                                r'(?i)should i',  # "Should I..." questions
                                r'(?i)would you like',  # "Would you like to..." questions
                                r'(?i)press enter',  # Press enter prompts
                                r'.*',  # Any other output
                            ], timeout=30)

                            if index == 0:  # EOF
                                break
                            elif index == 1:  # TIMEOUT
                                logger.warning("Claude CLI timeout waiting for response")
                                break
                            elif index in [2, 3, 4, 5, 6, 7, 8]:  # Interactive prompts
                                # Capture the question
                                question = child.before + child.after
                                output_lines.append(question)

                                if auto_response_enabled:
                                    # Determine response based on question content
                                    response = default_response
                                    question_lower = question.lower()

                                    # Check for custom responses
                                    for keyword, custom_response in custom_responses.items():
                                        if keyword.lower() in question_lower:
                                            response = custom_response
                                            break

                                    # Special handling for dangerous operations
                                    if any(danger_word in question_lower for danger_word in ['delete', 'remove', 'destroy', 'drop']):
                                        response = custom_responses.get('delete', 'n')

                                    child.sendline(response)
                                    logger.info(f"Auto-responded '{response}' to Claude prompt: {question.strip()}")
                                else:
                                    # If auto-response is disabled, default to 'n' for safety
                                    child.sendline('n')
                                    logger.warning("Auto-response disabled, defaulting to 'n' for safety")

                            elif index == 9:  # Press enter
                                # Auto-press enter
                                child.sendline('')
                                logger.info("Auto-pressed enter for Claude prompt")

                            elif index == 10:  # Regular output
                                output_lines.append(child.before + child.after)

                        except pexpect.TIMEOUT:
                            # If we timeout waiting, just continue
                            logger.debug("Timeout waiting for Claude response, continuing...")
                            break
                        except pexpect.EOF:
                            break

                    # Get any remaining output
                    try:
                        child.read_nonblocking(size=1000, timeout=1)
                    except:
                        pass

                    # Close the session
                    child.close()

                    # Combine all output
                    full_output = ''.join(output_lines)

                    return child.exitstatus == 0, full_output

                except Exception as e:
                    logger.error(f"Error in interactive Claude session: {e}")
                    return False, f"Interactive session error: {str(e)}"

            # Run in thread pool to avoid blocking the event loop
            with ThreadPoolExecutor() as executor:
                future = executor.submit(run_interactive_claude)
                success, output = await asyncio.get_event_loop().run_in_executor(None, lambda: future.result())

            if success:
                # Save result to .md file
                await self._save_execution_result(prompt, prompt_title, output)
                return True, output
            else:
                return False, output

        except Exception as e:
            logger.error(f"Error executing Claude prompt: {e}")
            return False, f"Execution error: {str(e)}"

    async def _save_execution_result(self, prompt: str, prompt_title: str, result: str):
        """Save execution result to .md file with task citation."""
        try:
            import aiofiles
            from pathlib import Path

            # Create results directory structure
            results_dir = Path("./data/task_results")
            results_dir.mkdir(parents=True, exist_ok=True)

            # Generate filename with timestamp
            timestamp = datetime.now(ZoneInfo("Europe/Kyiv")).strftime("%Y%m%d_%H%M%S")
            safe_title = "".join(c for c in prompt_title if c.isalnum() or c in (' ', '-', '_')).rstrip()
            safe_title = safe_title.replace(' ', '_')[:50]  # Limit length and replace spaces
            filename = f"{timestamp}_{safe_title}.md"
            filepath = results_dir / filename

            # Format content with task citation at the beginning
            content = f"""# Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ

## Ð¦Ð¸Ñ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ
**ÐÐ°Ð·Ð²Ð°:** {prompt_title}
**ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚:** {prompt}
**Ð§Ð°Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ:** {datetime.now(ZoneInfo("Europe/Kyiv")).strftime("%d.%m.%Y %H:%M:%S")}
**Ð¤Ð°Ð¹Ð» Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñƒ:** {filename}

---

## Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ

{result}

---

*Ð—Ð³ÐµÐ½ÐµÑ€Ð¾Ð²Ð°Ð½Ð¾ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¾ÑŽ Ð¿Ð»Ð°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ Claude Code Telegram Bot*
"""

            # Save to file
            async with aiofiles.open(filepath, 'w', encoding='utf-8') as f:
                await f.write(content)

            logger.info(f"Execution result saved to: {filepath}")

        except Exception as e:
            logger.error(f"Failed to save execution result: {e}")

    async def _should_execute_prompt(self, prompt: Dict[str, Any]) -> tuple[bool, str]:
        """Check if a prompt should be executed based on conditions."""
        if not prompt.get("enabled", False):
            return False, "Prompt disabled"
        
        conditions = prompt.get("conditions", {})
        
        # Check Claude availability
        if conditions.get("claude_available", False):
            if not await self._check_claude_availability():
                return False, "Claude CLI not available"
        
        # Check DND period
        if conditions.get("dnd_period", False):
            if not self._is_dnd_time():
                return False, "Not in DND period"
        
        # Check user activity
        no_activity_hours = conditions.get("no_user_activity_hours", 0)
        if no_activity_hours > 0:
            if await self._check_user_activity(no_activity_hours):
                return False, f"User activity detected within {no_activity_hours} hours"
        
        return True, "All conditions met"
    
    def _is_time_to_execute(self, prompt: Dict[str, Any]) -> bool:
        """Check if it's time to execute the prompt based on schedule."""
        schedule = prompt.get("schedule", {})
        if not schedule:
            return False
        
        timezone = ZoneInfo(schedule.get("timezone", "Europe/Kyiv"))
        now = datetime.now(timezone)
        
        schedule_type = schedule.get("type", "daily")
        target_time_str = schedule.get("time", "02:00")
        
        try:
            target_time = datetime.strptime(target_time_str, "%H:%M").time()
        except ValueError:
            logger.error(f"Invalid time format in schedule: {target_time_str}")
            return False
        
        if schedule_type == "daily":
            # Check if we're within 5 minutes of target time
            target_datetime = datetime.combine(now.date(), target_time, tzinfo=timezone)
            time_diff = abs((now - target_datetime).total_seconds())
            return time_diff < 300  # 5 minutes tolerance
            
        elif schedule_type == "weekly":
            target_day = schedule.get("day", "sunday").lower()
            day_map = {
                "monday": 0, "tuesday": 1, "wednesday": 2, "thursday": 3,
                "friday": 4, "saturday": 5, "sunday": 6
            }
            
            if target_day not in day_map:
                logger.error(f"Invalid day in schedule: {target_day}")
                return False
            
            if now.weekday() == day_map[target_day]:
                target_datetime = datetime.combine(now.date(), target_time, tzinfo=timezone)
                time_diff = abs((now - target_datetime).total_seconds())
                return time_diff < 300  # 5 minutes tolerance
        
        return False
    
    async def execute_scheduled_prompt(self, prompt: Dict[str, Any]) -> bool:
        """Execute a single scheduled prompt."""
        prompt_id = prompt.get("id", "unknown")
        logger.info(f"Starting execution of scheduled prompt: {prompt_id}")
        
        await self.log_execution(prompt_id, "started")
        
        try:
            # Check conditions
            should_execute, reason = await self._should_execute_prompt(prompt)
            if not should_execute:
                logger.info(f"Skipping prompt {prompt_id}: {reason}")
                await self.log_execution(prompt_id, "skipped", error=reason)
                return False
            
            # Execute the prompt
            prompt_text = prompt.get("prompt", "")
            prompt_title = prompt.get("title", "ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ")
            success, output = await self._execute_claude_prompt(prompt_text, "/app/target_project", prompt_title)
            
            if success:
                logger.info(f"Successfully executed prompt {prompt_id}")
                await self.log_execution(prompt_id, "completed", output=output[:1000])  # Truncate for logging
                
                # Send notification if configured
                config = await self.load_prompts()
                notification_chats = config.get("settings", {}).get("notification_chat_ids", [])
                if notification_chats:
                    message = (
                        f"ðŸ¤– **ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð¾**\n"
                        f"ðŸ“‹ {prompt.get('title', prompt_id)}\n"
                        f"â° {datetime.now(ZoneInfo('Europe/Kyiv')).strftime('%H:%M')}\n"
                        f"âœ… Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: Ð£ÑÐ¿Ñ–ÑˆÐ½Ð¾"
                    )
                    for chat_id in notification_chats:
                        try:
                            await self.bot.send_message(chat_id=chat_id, text=message, parse_mode=None)
                        except Exception as e:
                            logger.error(f"Failed to send notification to {chat_id}: {e}")
                
                return True
            else:
                logger.error(f"Failed to execute prompt {prompt_id}: {output}")
                await self.log_execution(prompt_id, "failed", error=output)
                return False
                
        except Exception as e:
            logger.error(f"Error executing prompt {prompt_id}: {e}")
            await self.log_execution(prompt_id, "failed", error=str(e))
            return False
    
    async def check_and_execute_prompts(self, context):
        """Main task to check and execute scheduled prompts."""
        if self.is_executing:
            logger.debug("Prompt execution already in progress, skipping")
            return
        
        config = await self.load_prompts()
        if not config.get("settings", {}).get("enabled", False):
            return
        
        prompts = config.get("prompts", [])
        if not prompts:
            return
        
        # Check if any prompts need execution
        prompts_to_execute = []
        for prompt in prompts:
            if self._is_time_to_execute(prompt):
                prompts_to_execute.append(prompt)
        
        if not prompts_to_execute:
            return
        
        logger.info(f"Found {len(prompts_to_execute)} prompts ready for execution")
        
        self.is_executing = True
        try:
            for prompt in prompts_to_execute:
                await self.execute_scheduled_prompt(prompt)
                # Add delay between prompts to avoid overwhelming the system
                await asyncio.sleep(30)
        finally:
            self.is_executing = False
    
    async def get_execution_stats(self) -> dict:
        """Get execution statistics."""
        try:
            if not self.execution_log.exists():
                return {
                    "total_executions": 0,
                    "successful": 0,
                    "failed": 0,
                    "avg_duration": 0,
                    "last_execution": "ÐÐµÐ¼Ð°Ñ”",
                    "system_active": False
                }
            
            # Read and parse execution log
            total_executions = 0
            successful = 0
            failed = 0
            durations = []
            last_execution = None
            
            with open(self.execution_log, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        entry = json.loads(line.strip())
                        total_executions += 1
                        
                        if entry.get("status") == "success":
                            successful += 1
                        else:
                            failed += 1
                            
                        if "duration" in entry:
                            durations.append(entry["duration"])
                            
                        if "timestamp" in entry:
                            last_execution = entry["timestamp"]
                            
                    except json.JSONDecodeError:
                        continue
            
            # Calculate average duration
            avg_duration = sum(durations) / len(durations) if durations else 0
            
            # Format last execution time
            if last_execution:
                try:
                    dt = datetime.fromisoformat(last_execution.replace('Z', '+00:00'))
                    last_execution = dt.strftime("%d.%m.%Y %H:%M")
                except:
                    pass
            
            # Check if system is active (not in DND and Claude available)
            system_active = self._is_dnd_time() and not self.is_executing
            
            return {
                "total_executions": total_executions,
                "successful": successful,
                "failed": failed,
                "avg_duration": avg_duration,
                "last_execution": last_execution or "ÐÐµÐ¼Ð°Ñ”",
                "system_active": system_active
            }
            
        except Exception as e:
            logger.error(f"Error getting execution stats: {e}")
            return {
                "total_executions": 0,
                "successful": 0,
                "failed": 0,
                "avg_duration": 0,
                "last_execution": "ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°",
                "system_active": False
            }


async def setup_scheduled_prompts(application: Application, settings: Settings):
    """Set up scheduled prompts system."""
    manager = ScheduledPromptsManager(application, settings)
    
    # Check if job_queue is available
    if application.job_queue is None:
        logger.warning("JobQueue not available - scheduled prompts will not run")
        return
    
    # Add periodic task - check every 5 minutes
    application.job_queue.run_repeating(
        manager.check_and_execute_prompts,
        interval=300,  # 5 minutes
        first=60,  # First check after 1 minute
        name="scheduled_prompts_checker"
    )
    
    logger.info("âœ… Scheduled prompts system enabled. Check interval: 5 minutes")
    return manager

```

### bot/features/__init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 306 Ð±Ð°Ð¹Ñ‚

```python
"""Bot features package"""

from .conversation_mode import ConversationContext, ConversationEnhancer
from .file_handler import CodebaseAnalysis, FileHandler, ProcessedFile

__all__ = [
    "FileHandler",
    "ProcessedFile",
    "CodebaseAnalysis",
    "ConversationEnhancer",
    "ConversationContext",
]

```

### bot/features/registry.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 4,981 Ð±Ð°Ð¹Ñ‚

```python
"""
Central feature registry and management
"""

from typing import Any, Dict, Optional

import structlog

from src.config.settings import Settings
from src.security.validators import SecurityValidator
from src.storage.facade import Storage

from .conversation_mode import ConversationEnhancer
from .file_handler import FileHandler
from .git_integration import GitIntegration
from .image_handler import ImageHandler
from .quick_actions import QuickActionManager
from .session_export import SessionExporter

logger = structlog.get_logger(__name__)


class FeatureRegistry:
    """Manage all bot features"""

    def __init__(self, config: Settings, storage: Storage, security: SecurityValidator):
        self.config = config
        self.storage = storage
        self.security = security
        self.features: Dict[str, Any] = {}

        # Initialize features based on config
        self._initialize_features()

    def _initialize_features(self):
        """Initialize enabled features"""
        logger.info("Initializing bot features")

        # File upload handling - conditionally enabled
        if self.config.enable_file_uploads:
            try:
                self.features["file_handler"] = FileHandler(
                    config=self.config, security=self.security
                )
                logger.info("File handler feature enabled")
            except Exception as e:
                logger.error("Failed to initialize file handler", error=str(e))

        # Git integration - conditionally enabled
        if self.config.enable_git_integration:
            try:
                self.features["git"] = GitIntegration(settings=self.config)
                logger.info("Git integration feature enabled")
            except Exception as e:
                logger.error("Failed to initialize git integration", error=str(e))

        # Quick actions - conditionally enabled
        if self.config.enable_quick_actions:
            try:
                self.features["quick_actions"] = QuickActionManager()
                logger.info("Quick actions feature enabled")
            except Exception as e:
                logger.error("Failed to initialize quick actions", error=str(e))

        # Session export - always enabled
        try:
            self.features["session_export"] = SessionExporter(storage=self.storage)
            logger.info("Session export feature enabled")
        except Exception as e:
            logger.error("Failed to initialize session export", error=str(e))

        # Image handling - always enabled
        try:
            self.features["image_handler"] = ImageHandler(config=self.config)
            logger.info("Image handler feature enabled")
        except Exception as e:
            logger.error("Failed to initialize image handler", error=str(e))

        # Conversation enhancements - always enabled
        try:
            self.features["conversation"] = ConversationEnhancer()
            logger.info("Conversation enhancer feature enabled")
        except Exception as e:
            logger.error("Failed to initialize conversation enhancer", error=str(e))

        logger.info(
            "Feature initialization complete",
            enabled_features=list(self.features.keys()),
        )

    def get_feature(self, name: str) -> Optional[Any]:
        """Get feature by name"""
        return self.features.get(name)

    def is_enabled(self, feature_name: str) -> bool:
        """Check if feature is enabled"""
        return feature_name in self.features

    def get_file_handler(self) -> Optional[FileHandler]:
        """Get file handler feature"""
        return self.get_feature("file_handler")

    def get_git_integration(self) -> Optional[GitIntegration]:
        """Get git integration feature"""
        return self.get_feature("git")

    def get_quick_actions(self) -> Optional[QuickActionManager]:
        """Get quick actions feature"""
        return self.get_feature("quick_actions")

    def get_session_export(self) -> Optional[SessionExporter]:
        """Get session export feature"""
        return self.get_feature("session_export")

    def get_image_handler(self) -> Optional[ImageHandler]:
        """Get image handler feature"""
        return self.get_feature("image_handler")

    def get_conversation_enhancer(self) -> Optional[ConversationEnhancer]:
        """Get conversation enhancer feature"""
        return self.get_feature("conversation")

    def get_enabled_features(self) -> Dict[str, Any]:
        """Get all enabled features"""
        return self.features.copy()

    def shutdown(self):
        """Shutdown all features"""
        logger.info("Shutting down features")

        # Clear conversation contexts
        conversation = self.get_conversation_enhancer()
        if conversation:
            conversation.conversation_contexts.clear()

        # Clear feature registry
        self.features.clear()

        logger.info("Feature shutdown complete")

```

### bot/features/session_export.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 8,641 Ð±Ð°Ð¹Ñ‚

```python
"""Session export functionality for exporting chat history in various formats."""

import json
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import Dict, Optional

from src.storage.facade import Storage
from src.utils.constants import MAX_SESSION_LENGTH


class ExportFormat(Enum):
    """Supported export formats."""

    MARKDOWN = "markdown"
    JSON = "json"
    HTML = "html"


@dataclass
class ExportedSession:
    """Exported session data."""

    format: ExportFormat
    content: str
    filename: str
    mime_type: str
    size_bytes: int
    created_at: datetime


class SessionExporter:
    """Handles exporting chat sessions in various formats."""

    def __init__(self, storage: Storage):
        """Initialize exporter with storage dependency.

        Args:
            storage: Storage facade for session data access
        """
        self.storage = storage

    async def export_session(
        self,
        user_id: int,
        session_id: str,
        format: ExportFormat = ExportFormat.MARKDOWN,
    ) -> ExportedSession:
        """Export a session in the specified format.

        Args:
            user_id: User ID
            session_id: Session ID to export
            format: Export format (markdown, json, html)

        Returns:
            ExportedSession with exported content

        Raises:
            ValueError: If session not found or invalid format
        """
        # Get session data
        session = await self.storage.get_session(user_id, session_id)
        if not session:
            raise ValueError(f"Session {session_id} not found")

        # Get session messages
        messages = await self.storage.get_session_messages(
            session_id, limit=MAX_SESSION_LENGTH
        )

        # Export based on format
        if format == ExportFormat.MARKDOWN:
            content = await self._export_markdown(session, messages)
            mime_type = "text/markdown"
            extension = "md"
        elif format == ExportFormat.JSON:
            content = await self._export_json(session, messages)
            mime_type = "application/json"
            extension = "json"
        elif format == ExportFormat.HTML:
            content = await self._export_html(session, messages)
            mime_type = "text/html"
            extension = "html"
        else:
            raise ValueError(f"Unsupported export format: {format}")

        # Create filename
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        filename = f"session_{session_id[:8]}_{timestamp}.{extension}"

        return ExportedSession(
            format=format,
            content=content,
            filename=filename,
            mime_type=mime_type,
            size_bytes=len(content.encode()),
            created_at=datetime.utcnow(),
        )

    async def _export_markdown(self, session: dict, messages: list) -> str:
        """Export session as Markdown.

        Args:
            session: Session metadata
            messages: List of messages

        Returns:
            Markdown formatted content
        """
        lines = []

        # Header
        lines.append(f"# Claude Code Session Export")
        lines.append(f"\n**Session ID:** `{session['id']}`")
        lines.append(f"**Created:** {session['created_at']}")
        if session.get("updated_at"):
            lines.append(f"**Last Updated:** {session['updated_at']}")
        lines.append(f"**Message Count:** {len(messages)}")
        lines.append("\n---\n")

        # Messages
        for msg in messages:
            timestamp = msg["created_at"]
            role = "You" if msg["role"] == "user" else "Claude"
            content = msg["content"]

            lines.append(f"### {role} - {timestamp}")
            lines.append(f"\n{content}\n")
            lines.append("---\n")

        return "\n".join(lines)

    async def _export_json(self, session: dict, messages: list) -> str:
        """Export session as JSON.

        Args:
            session: Session metadata
            messages: List of messages

        Returns:
            JSON formatted content
        """
        export_data = {
            "session": {
                "id": session["id"],
                "user_id": session["user_id"],
                "created_at": session["created_at"].isoformat(),
                "updated_at": (
                    session.get("updated_at", "").isoformat()
                    if session.get("updated_at")
                    else None
                ),
                "message_count": len(messages),
            },
            "messages": [
                {
                    "id": msg["id"],
                    "role": msg["role"],
                    "content": msg["content"],
                    "created_at": msg["created_at"].isoformat(),
                }
                for msg in messages
            ],
        }

        return json.dumps(export_data, indent=2, ensure_ascii=False)

    async def _export_html(self, session: dict, messages: list) -> str:
        """Export session as HTML.

        Args:
            session: Session metadata
            messages: List of messages

        Returns:
            HTML formatted content
        """
        # Convert markdown content to HTML-safe format
        markdown_content = await self._export_markdown(session, messages)
        html_content = self._markdown_to_html(markdown_content)

        # HTML template
        template = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Claude Code Session - {session['id'][:8]}</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .container {{
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        h1 {{
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }}
        h3 {{
            color: #34495e;
            margin-top: 20px;
        }}
        code {{
            background-color: #f8f8f8;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
        }}
        pre {{
            background-color: #f8f8f8;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }}
        .metadata {{
            background-color: #f0f7ff;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
        }}
        .message {{
            margin: 20px 0;
            padding: 15px;
            border-left: 4px solid #3498db;
            background-color: #f9f9f9;
        }}
        .message.claude {{
            border-left-color: #2ecc71;
        }}
        .timestamp {{
            color: #7f8c8d;
            font-size: 0.9em;
        }}
        hr {{
            border: none;
            border-top: 1px solid #e1e4e8;
            margin: 30px 0;
        }}
    </style>
</head>
<body>
    <div class="container">
        {html_content}
    </div>
</body>
</html>"""

        return template

    def _markdown_to_html(self, markdown: str) -> str:
        """Convert markdown to HTML.

        Simple conversion for basic markdown elements.

        Args:
            markdown: Markdown content

        Returns:
            HTML content
        """
        html = markdown

        # Headers
        html = html.replace("# ", "<h1>").replace("\n\n", "</h1>\n\n", 1)
        html = html.replace("### ", "<h3>").replace("\n", "</h3>\n", 3)

        # Bold
        import re

        html = re.sub(r"\*\*([^*]+)\*\*", r"<strong>\1</strong>", html)

        # Code blocks
        html = re.sub(r"`([^`]+)`", r"<code>\1</code>", html)

        # Line breaks and paragraphs
        html = html.replace("\n\n", "</p>\n<p>")
        html = f"<p>{html}</p>"

        # Clean up empty paragraphs
        html = html.replace("<p></p>", "")
        html = html.replace("<p><h", "<h")
        html = html.replace("</h1></p>", "</h1>")
        html = html.replace("</h3></p>", "</h3>")

        # Horizontal rules
        html = html.replace("<p>---</p>", "<hr>")

        return html

```

### bot/features/image_handler.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 5,555 Ð±Ð°Ð¹Ñ‚

```python
"""
Handle image uploads for UI/screenshot analysis

Features:
- OCR for text extraction
- UI element detection
- Image description
- Diagram analysis
"""

import base64
from dataclasses import dataclass
from typing import Dict, Optional

from telegram import PhotoSize

from src.config import Settings


@dataclass
class ProcessedImage:
    """Processed image result"""

    prompt: str
    image_type: str
    base64_data: str
    size: int
    metadata: Dict[str, any] = None


class ImageHandler:
    """Process image uploads"""

    def __init__(self, config: Settings):
        self.config = config
        self.supported_formats = {".png", ".jpg", ".jpeg", ".gif", ".webp"}

    async def process_image(
        self, photo: PhotoSize, caption: Optional[str] = None
    ) -> ProcessedImage:
        """Process uploaded image"""

        # Download image
        file = await photo.get_file()
        image_bytes = await file.download_as_bytearray()

        # Detect image type
        image_type = self._detect_image_type(image_bytes)

        # Create appropriate prompt
        if image_type == "screenshot":
            prompt = self._create_screenshot_prompt(caption)
        elif image_type == "diagram":
            prompt = self._create_diagram_prompt(caption)
        elif image_type == "ui_mockup":
            prompt = self._create_ui_prompt(caption)
        else:
            prompt = self._create_generic_prompt(caption)

        # Convert to base64 for Claude (if supported in future)
        base64_image = base64.b64encode(image_bytes).decode("utf-8")

        return ProcessedImage(
            prompt=prompt,
            image_type=image_type,
            base64_data=base64_image,
            size=len(image_bytes),
            metadata={
                "format": self._detect_format(image_bytes),
                "has_caption": caption is not None,
            },
        )

    def _detect_image_type(self, image_bytes: bytes) -> str:
        """Detect type of image"""
        # Simple heuristic based on image characteristics
        # In practice, could use ML model for better detection

        # For now, return generic type
        return "screenshot"

    def _detect_format(self, image_bytes: bytes) -> str:
        """Detect image format from magic bytes"""
        # Check magic bytes for common formats
        if image_bytes.startswith(b"\x89PNG"):
            return "png"
        elif image_bytes.startswith(b"\xff\xd8\xff"):
            return "jpeg"
        elif image_bytes.startswith(b"GIF87a") or image_bytes.startswith(b"GIF89a"):
            return "gif"
        elif image_bytes.startswith(b"RIFF") and b"WEBP" in image_bytes[:12]:
            return "webp"
        else:
            return "unknown"

    def _create_screenshot_prompt(self, caption: Optional[str]) -> str:
        """Create prompt for screenshot analysis"""
        base_prompt = """I'm sharing a screenshot with you. Please analyze it and help me with:

1. Identifying what application or website this is from
2. Understanding the UI elements and their purpose
3. Any issues or improvements you notice
4. Answering any specific questions I have

"""
        if caption:
            base_prompt += f"Specific request: {caption}"

        return base_prompt

    def _create_diagram_prompt(self, caption: Optional[str]) -> str:
        """Create prompt for diagram analysis"""
        base_prompt = """I'm sharing a diagram with you. Please help me:

1. Understand the components and their relationships
2. Identify the type of diagram (flowchart, architecture, etc.)
3. Explain any technical concepts shown
4. Suggest improvements or clarifications

"""
        if caption:
            base_prompt += f"Specific request: {caption}"

        return base_prompt

    def _create_ui_prompt(self, caption: Optional[str]) -> str:
        """Create prompt for UI mockup analysis"""
        base_prompt = """I'm sharing a UI mockup with you. Please analyze:

1. The layout and visual hierarchy
2. User experience considerations
3. Accessibility aspects
4. Implementation suggestions
5. Any potential improvements

"""
        if caption:
            base_prompt += f"Specific request: {caption}"

        return base_prompt

    def _create_generic_prompt(self, caption: Optional[str]) -> str:
        """Create generic image analysis prompt"""
        base_prompt = """I'm sharing an image with you. Please analyze it and provide relevant insights.

"""
        if caption:
            base_prompt += f"Context: {caption}"

        return base_prompt

    def supports_format(self, filename: str) -> bool:
        """Check if image format is supported"""
        if not filename:
            return False

        # Extract extension
        parts = filename.lower().split(".")
        if len(parts) < 2:
            return False

        extension = f".{parts[-1]}"
        return extension in self.supported_formats

    async def validate_image(self, image_bytes: bytes) -> tuple[bool, Optional[str]]:
        """Validate image data"""
        # Check size
        max_size = 10 * 1024 * 1024  # 10MB
        if len(image_bytes) > max_size:
            return False, "Image too large (max 10MB)"

        # Check format
        format_type = self._detect_format(image_bytes)
        if format_type == "unknown":
            return False, "Unsupported image format"

        # Basic validity check
        if len(image_bytes) < 100:  # Too small to be a real image
            return False, "Invalid image data"

        return True, None

```

### bot/features/dracon_storage.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 17,914 Ð±Ð°Ð¹Ñ‚

```python
"""DRACON Schema Storage and File Management System.

This module provides structured file system management for DRACON schemas
with automatic directory creation, versioning, and metadata tracking.

Directory Structure:
- drn/reverse/  - Schemas from reverse engineering
- drn/build/    - Base schemas for system framework development
- drn/audit/    - Testing and validation schemas
- drn/library/  - Reusable schema components
- drn/active/   - Currently active schemas
- drn/archive/  - Historical schema versions
"""

import json
import os
import shutil
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import structlog
import yaml

logger = structlog.get_logger()


class DraconStorageManager:
    """Manages DRACON schema file storage and organization."""

    def __init__(self, base_path: str):
        """Initialize storage manager."""
        self.base_path = Path(base_path)
        self.drn_root = self.base_path / "drn"
        self.logger = logger.bind(component="dracon_storage")

        # Define directory structure
        self.directories = {
            'reverse': self.drn_root / "reverse",    # Reverse engineering results
            'build': self.drn_root / "build",       # Base framework schemas
            'audit': self.drn_root / "audit",       # Testing schemas
            'library': self.drn_root / "library",   # Reusable components
            'active': self.drn_root / "active",     # Currently active schemas
            'archive': self.drn_root / "archive",   # Historical versions
            'temp': self.drn_root / "temp",         # Temporary work files
            'export': self.drn_root / "export",     # Export formats (png, svg, etc.)
        }

        # Initialize directories
        self._ensure_directories()

    def _ensure_directories(self) -> None:
        """Create directory structure if it doesn't exist."""
        try:
            for dir_name, dir_path in self.directories.items():
                dir_path.mkdir(parents=True, exist_ok=True)
                self.logger.debug("Directory ensured", directory=dir_name, path=str(dir_path))

                # Create README files for documentation
                readme_path = dir_path / "README.md"
                if not readme_path.exists():
                    self._create_directory_readme(dir_name, readme_path)

            self.logger.info("DRACON directory structure initialized", root=str(self.drn_root))
        except Exception as e:
            self.logger.error("Failed to create directory structure", error=str(e))
            raise

    def _create_directory_readme(self, dir_name: str, readme_path: Path) -> None:
        """Create README file for directory documentation."""
        readme_content = {
            'reverse': """# DRACON Reverse Engineering Schemas

This directory contains DRACON schemas generated from reverse engineering existing bot code.

## File Naming Convention:
- `{project_name}_reverse_{timestamp}.yaml` - Main reverse engineered schema
- `{project_name}_analysis_{timestamp}.json` - Analysis metadata
- `{project_name}_suggestions_{timestamp}.json` - Refactoring suggestions

## Usage:
- Review reverse engineered schemas for understanding current architecture
- Use as baseline for refactoring and modernization
- Compare with build/ schemas for migration planning
""",
            'build': """# DRACON Build Schemas

Base schemas for system framework development and architecture planning.

## File Types:
- `framework_*.yaml` - Core framework patterns
- `template_*.yaml` - Reusable templates
- `pattern_*.yaml` - Common design patterns

## Usage:
- Starting point for new bot development
- Reference architectures and best practices
- Template schemas for rapid prototyping
""",
            'audit': """# DRACON Audit Schemas

Testing and validation schemas for quality assurance.

## File Types:
- `test_*.yaml` - Test case schemas
- `validation_*.yaml` - Validation rule sets
- `benchmark_*.yaml` - Performance benchmarks

## Usage:
- Schema validation testing
- Performance analysis
- Quality assurance workflows
""",
            'library': """# DRACON Component Library

Reusable schema components and modules.

## File Types:
- `component_*.yaml` - Individual components
- `module_*.yaml` - Component groups
- `pattern_*.yaml` - Interaction patterns

## Usage:
- Import components into larger schemas
- Standardized building blocks
- Consistent design patterns
""",
            'active': """# Active DRACON Schemas

Currently active and deployed schemas.

## File Types:
- `current_*.yaml` - Active production schemas
- `staging_*.yaml` - Staging environment schemas
- `dev_*.yaml` - Development schemas

## Usage:
- Current system state representation
- Production deployment tracking
- Environment-specific configurations
""",
            'archive': """# DRACON Schema Archive

Historical versions and backup schemas.

## File Naming:
- `{schema_name}_v{version}_{timestamp}.yaml`
- `backup_{original_name}_{timestamp}.yaml`

## Usage:
- Version history tracking
- Rollback capabilities
- Change analysis
""",
            'temp': """# Temporary DRACON Files

Working directory for temporary schema operations.

## File Types:
- `work_*.yaml` - Work in progress schemas
- `merge_*.yaml` - Schema merge operations
- `convert_*.yaml` - Format conversion temporary files

## Note:
Files in this directory may be automatically cleaned up.
""",
            'export': """# DRACON Export Formats

Generated visual and export formats of schemas.

## File Types:
- `{schema_name}.png` - Visual diagrams
- `{schema_name}.svg` - Vector graphics
- `{schema_name}.json` - JSON export
- `{schema_name}.md` - Documentation export

## Usage:
- Visual representation of schemas
- Documentation generation
- Presentation materials
"""
        }

        content = readme_content.get(dir_name, f"# DRACON {dir_name.title()} Directory\n\nAutomatically generated directory for DRACON schemas.")
        readme_path.write_text(content, encoding='utf-8')

    def save_schema(self, schema_yaml: str, category: str, name: str, metadata: Optional[Dict[str, Any]] = None) -> Tuple[str, str]:
        """Save DRACON schema to appropriate directory."""
        if category not in self.directories:
            raise ValueError(f"Unknown category: {category}. Available: {list(self.directories.keys())}")

        # Generate filename with timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{name}_{timestamp}.yaml"
        file_path = self.directories[category] / filename

        try:
            # Save YAML schema
            file_path.write_text(schema_yaml, encoding='utf-8')

            # Save metadata if provided
            if metadata:
                metadata_path = file_path.with_suffix('.json')
                metadata['saved_at'] = datetime.now().isoformat()
                metadata['category'] = category
                metadata['file_path'] = str(file_path)

                with open(metadata_path, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, indent=2, ensure_ascii=False)

            self.logger.info("Schema saved", category=category, name=name, path=str(file_path))
            return str(file_path), filename

        except Exception as e:
            self.logger.error("Failed to save schema", error=str(e), category=category, name=name)
            raise

    def load_schema(self, category: str, filename: str) -> Tuple[str, Optional[Dict[str, Any]]]:
        """Load DRACON schema and its metadata."""
        if category not in self.directories:
            raise ValueError(f"Unknown category: {category}")

        file_path = self.directories[category] / filename
        if not file_path.exists():
            raise FileNotFoundError(f"Schema not found: {file_path}")

        try:
            # Load YAML schema
            schema_yaml = file_path.read_text(encoding='utf-8')

            # Load metadata if exists
            metadata_path = file_path.with_suffix('.json')
            metadata = None
            if metadata_path.exists():
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)

            self.logger.info("Schema loaded", category=category, filename=filename)
            return schema_yaml, metadata

        except Exception as e:
            self.logger.error("Failed to load schema", error=str(e), category=category, filename=filename)
            raise

    def list_schemas(self, category: Optional[str] = None) -> Dict[str, List[Dict[str, Any]]]:
        """List all schemas in category or all categories."""
        results = {}

        categories = [category] if category and category in self.directories else self.directories.keys()

        for cat in categories:
            cat_path = self.directories[cat]
            schemas = []

            for yaml_file in cat_path.glob("*.yaml"):
                schema_info = {
                    'filename': yaml_file.name,
                    'created': datetime.fromtimestamp(yaml_file.stat().st_ctime).isoformat(),
                    'modified': datetime.fromtimestamp(yaml_file.stat().st_mtime).isoformat(),
                    'size': yaml_file.stat().st_size
                }

                # Add metadata if available
                metadata_path = yaml_file.with_suffix('.json')
                if metadata_path.exists():
                    try:
                        with open(metadata_path, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                            schema_info['metadata'] = metadata
                    except:
                        pass

                schemas.append(schema_info)

            # Sort by creation time (newest first)
            schemas.sort(key=lambda x: x['created'], reverse=True)
            results[cat] = schemas

        return results

    def archive_schema(self, category: str, filename: str, new_version: Optional[str] = None) -> str:
        """Archive a schema to the archive directory."""
        source_path = self.directories[category] / filename
        if not source_path.exists():
            raise FileNotFoundError(f"Schema not found: {source_path}")

        # Generate archive filename
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        base_name = source_path.stem
        version = new_version or "auto"
        archive_name = f"{base_name}_v{version}_{timestamp}.yaml"
        archive_path = self.directories['archive'] / archive_name

        try:
            # Copy schema to archive
            shutil.copy2(source_path, archive_path)

            # Copy metadata if exists
            metadata_source = source_path.with_suffix('.json')
            if metadata_source.exists():
                metadata_archive = archive_path.with_suffix('.json')
                shutil.copy2(metadata_source, metadata_archive)

            self.logger.info("Schema archived", original=str(source_path), archive=str(archive_path))
            return str(archive_path)

        except Exception as e:
            self.logger.error("Failed to archive schema", error=str(e))
            raise

    def delete_schema(self, category: str, filename: str, archive_first: bool = True) -> bool:
        """Delete a schema, optionally archiving it first."""
        source_path = self.directories[category] / filename
        if not source_path.exists():
            raise FileNotFoundError(f"Schema not found: {source_path}")

        try:
            # Archive before deletion if requested
            if archive_first:
                self.archive_schema(category, filename)

            # Delete schema file
            source_path.unlink()

            # Delete metadata if exists
            metadata_path = source_path.with_suffix('.json')
            if metadata_path.exists():
                metadata_path.unlink()

            self.logger.info("Schema deleted", category=category, filename=filename, archived=archive_first)
            return True

        except Exception as e:
            self.logger.error("Failed to delete schema", error=str(e))
            raise

    def copy_schema(self, source_category: str, filename: str, target_category: str, new_name: Optional[str] = None) -> str:
        """Copy schema between categories."""
        source_path = self.directories[source_category] / filename
        if not source_path.exists():
            raise FileNotFoundError(f"Schema not found: {source_path}")

        target_name = new_name or filename
        target_path = self.directories[target_category] / target_name

        try:
            # Copy schema
            shutil.copy2(source_path, target_path)

            # Copy metadata if exists
            metadata_source = source_path.with_suffix('.json')
            if metadata_source.exists():
                metadata_target = target_path.with_suffix('.json')
                shutil.copy2(metadata_source, metadata_target)

                # Update metadata with new location
                with open(metadata_target, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                metadata['copied_from'] = str(source_path)
                metadata['copied_at'] = datetime.now().isoformat()
                metadata['category'] = target_category

                with open(metadata_target, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, indent=2, ensure_ascii=False)

            self.logger.info("Schema copied", source=str(source_path), target=str(target_path))
            return str(target_path)

        except Exception as e:
            self.logger.error("Failed to copy schema", error=str(e))
            raise

    def export_schema_visual(self, category: str, filename: str, format: str = 'png') -> str:
        """Export schema as visual diagram (placeholder for future implementation)."""
        # This would integrate with diagram generation tools
        source_path = self.directories[category] / filename
        if not source_path.exists():
            raise FileNotFoundError(f"Schema not found: {source_path}")

        export_name = f"{source_path.stem}.{format}"
        export_path = self.directories['export'] / export_name

        # Placeholder - would implement actual diagram generation
        export_path.write_text(f"# Visual export placeholder for {filename}\n# Format: {format}\n# Generated: {datetime.now().isoformat()}")

        self.logger.info("Schema visual export created", source=str(source_path), export=str(export_path))
        return str(export_path)

    def get_storage_stats(self) -> Dict[str, Any]:
        """Get storage statistics and usage information."""
        stats = {
            'total_schemas': 0,
            'total_size': 0,
            'categories': {},
            'oldest_schema': None,
            'newest_schema': None
        }

        oldest_time = None
        newest_time = None

        for category, path in self.directories.items():
            yaml_files = list(path.glob("*.yaml"))
            category_size = sum(f.stat().st_size for f in yaml_files)

            stats['categories'][category] = {
                'count': len(yaml_files),
                'size': category_size
            }

            stats['total_schemas'] += len(yaml_files)
            stats['total_size'] += category_size

            # Track oldest and newest
            for yaml_file in yaml_files:
                file_time = yaml_file.stat().st_ctime
                if oldest_time is None or file_time < oldest_time:
                    oldest_time = file_time
                    stats['oldest_schema'] = str(yaml_file)
                if newest_time is None or file_time > newest_time:
                    newest_time = file_time
                    stats['newest_schema'] = str(yaml_file)

        return stats

    def cleanup_temp_files(self, max_age_hours: int = 24) -> int:
        """Clean up temporary files older than specified hours."""
        import time

        temp_path = self.directories['temp']
        current_time = time.time()
        max_age_seconds = max_age_hours * 3600
        cleaned_count = 0

        for temp_file in temp_path.iterdir():
            if temp_file.is_file():
                file_age = current_time - temp_file.stat().st_mtime
                if file_age > max_age_seconds:
                    try:
                        temp_file.unlink()
                        cleaned_count += 1
                        self.logger.debug("Temp file cleaned", file=str(temp_file))
                    except Exception as e:
                        self.logger.warning("Failed to clean temp file", file=str(temp_file), error=str(e))

        self.logger.info("Temp file cleanup completed", cleaned=cleaned_count)
        return cleaned_count

    def validate_schema_integrity(self) -> Dict[str, List[str]]:
        """Validate integrity of all stored schemas."""
        issues = {
            'invalid_yaml': [],
            'missing_metadata': [],
            'corrupted_files': []
        }

        for category, path in self.directories.items():
            for yaml_file in path.glob("*.yaml"):
                try:
                    # Test YAML parsing
                    content = yaml_file.read_text(encoding='utf-8')
                    yaml.safe_load(content)

                    # Check for metadata
                    metadata_path = yaml_file.with_suffix('.json')
                    if not metadata_path.exists():
                        issues['missing_metadata'].append(str(yaml_file))

                except yaml.YAMLError:
                    issues['invalid_yaml'].append(str(yaml_file))
                except Exception:
                    issues['corrupted_files'].append(str(yaml_file))

        return issues

```

### bot/features/dracon_renderer.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 23,299 Ð±Ð°Ð¹Ñ‚

```python
"""
DRACON Visual Renderer - SVG/PNG Generation Engine

This module provides professional-quality visual rendering of DRACON schemas
with support for multiple output formats, themes, and layout algorithms.
"""

import xml.etree.ElementTree as ET
from xml.dom import minidom
import math
from typing import Dict, List, Tuple, Any, Optional
from pathlib import Path
import logging
from dataclasses import dataclass
import colorsys

from dracon_types import (
    DraconSchema, DraconNode, DraconEdge, NodeType, EdgeType,
    Position, Size, RenderOptions, DEFAULT_COLORS, DRACON_ICONS
)

logger = logging.getLogger(__name__)


@dataclass
class LayoutResult:
    """Result of layout algorithm"""
    nodes: Dict[str, Position]
    edges: Dict[str, List[Position]]
    bounds: Tuple[float, float, float, float]  # min_x, min_y, max_x, max_y


class DraconTheme:
    """Theme configuration for DRACON rendering"""

    def __init__(self, name: str = "default"):
        self.name = name
        self.colors = DEFAULT_COLORS.copy()
        self.fonts = {
            'default': 'Arial, sans-serif',
            'title': 'Arial Black, sans-serif',
            'code': 'Courier New, monospace'
        }
        self.styles = {
            'stroke_width': 2,
            'node_padding': 10,
            'font_size': 12,
            'grid_size': 20,
            'arrow_size': 8
        }

    def get_node_color(self, node_type: NodeType) -> str:
        """Get color for node type"""
        return self.colors.get(node_type.value, self.colors.get('action', '#7ed321'))

    def get_contrast_color(self, bg_color: str) -> str:
        """Get contrasting text color for background"""
        # Convert hex to RGB
        hex_color = bg_color.lstrip('#')
        rgb = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))

        # Calculate luminance
        luminance = (0.299 * rgb[0] + 0.587 * rgb[1] + 0.114 * rgb[2]) / 255

        return '#000000' if luminance > 0.5 else '#ffffff'


class SugiyamaLayoutAlgorithm:
    """Sugiyama algorithm for hierarchical layout"""

    def __init__(self, schema: DraconSchema):
        self.schema = schema
        self.layers = []
        self.node_positions = {}
        self.edge_paths = {}

    def calculate_layout(self) -> LayoutResult:
        """Calculate hierarchical layout using Sugiyama algorithm"""
        # Step 1: Cycle removal (if needed)
        self._remove_cycles()

        # Step 2: Layer assignment
        self._assign_layers()

        # Step 3: Crossing reduction
        self._reduce_crossings()

        # Step 4: Coordinate assignment
        self._assign_coordinates()

        # Calculate bounds
        bounds = self._calculate_bounds()

        return LayoutResult(
            nodes=self.node_positions,
            edges=self.edge_paths,
            bounds=bounds
        )

    def _remove_cycles(self):
        """Remove cycles in the graph (simplified implementation)"""
        # For DRACON schemas, cycles should be rare due to structured nature
        # This is a placeholder for more sophisticated cycle detection
        pass

    def _assign_layers(self):
        """Assign nodes to layers based on topological ordering"""
        # Find entry points (nodes with no incoming edges)
        incoming_count = {node.id: 0 for node in self.schema.nodes}

        for edge in self.schema.edges:
            incoming_count[edge.to_node] += 1

        # Start with entry points
        current_layer = [node.id for node.id, count in incoming_count.items() if count == 0]
        if not current_layer:
            # If no entry points, start with first node
            current_layer = [self.schema.nodes[0].id] if self.schema.nodes else []

        layer_index = 0
        processed = set()

        while current_layer:
            self.layers.append(current_layer.copy())
            next_layer = []

            for node_id in current_layer:
                processed.add(node_id)

                # Find all nodes that this node connects to
                for edge in self.schema.edges:
                    if edge.from_node == node_id and edge.to_node not in processed:
                        # Check if all prerequisites for target node are met
                        target_ready = True
                        for other_edge in self.schema.edges:
                            if (other_edge.to_node == edge.to_node and 
                                other_edge.from_node not in processed):
                                target_ready = False
                                break

                        if target_ready and edge.to_node not in next_layer:
                            next_layer.append(edge.to_node)

            current_layer = next_layer
            layer_index += 1

            # Safety break to prevent infinite loops
            if layer_index > len(self.schema.nodes):
                break

    def _reduce_crossings(self):
        """Reduce edge crossings between layers (simplified)"""
        # This is a simplified version - full implementation would use
        # barycenter heuristic or other crossing reduction algorithms

        for i in range(len(self.layers) - 1):
            # Calculate barycenter for each node in next layer
            layer = self.layers[i + 1]
            barycenters = {}

            for node_id in layer:
                connected_positions = []
                for edge in self.schema.edges:
                    if edge.to_node == node_id:
                        from_layer = self.layers[i]
                        if edge.from_node in from_layer:
                            connected_positions.append(from_layer.index(edge.from_node))

                if connected_positions:
                    barycenters[node_id] = sum(connected_positions) / len(connected_positions)
                else:
                    barycenters[node_id] = len(layer) / 2

            # Sort layer by barycenter
            self.layers[i + 1] = sorted(layer, key=lambda x: barycenters.get(x, 0))

    def _assign_coordinates(self):
        """Assign final coordinates to nodes"""
        layer_height = 150  # Vertical spacing between layers
        node_width = 120   # Horizontal spacing between nodes
        start_y = 50

        for layer_index, layer in enumerate(self.layers):
            y = start_y + layer_index * layer_height

            # Calculate total width needed for this layer
            total_width = len(layer) * node_width
            start_x = -total_width / 2  # Center the layer

            for node_index, node_id in enumerate(layer):
                x = start_x + node_index * node_width
                self.node_positions[node_id] = Position(x, y)

        # Calculate edge paths
        self._calculate_edge_paths()

    def _calculate_edge_paths(self):
        """Calculate paths for edges with control points"""
        for edge in self.schema.edges:
            from_pos = self.node_positions.get(edge.from_node)
            to_pos = self.node_positions.get(edge.to_node)

            if from_pos and to_pos:
                # Simple straight line for now
                # More sophisticated routing could be implemented
                self.edge_paths[edge.id] = [from_pos, to_pos]

    def _calculate_bounds(self) -> Tuple[float, float, float, float]:
        """Calculate bounding box of the layout"""
        if not self.node_positions:
            return (0, 0, 100, 100)

        x_coords = [pos.x for pos in self.node_positions.values()]
        y_coords = [pos.y for pos in self.node_positions.values()]

        margin = 100
        return (
            min(x_coords) - margin,
            min(y_coords) - margin,
            max(x_coords) + margin,
            max(y_coords) + margin
        )


class SVGRenderer:
    """SVG rendering engine for DRACON schemas"""

    def __init__(self, theme: DraconTheme = None):
        self.theme = theme or DraconTheme()
        self.svg_root = None
        self.defs = None

    def render_schema(self, schema: DraconSchema, options: RenderOptions) -> str:
        """Render DRACON schema to SVG string"""
        # Calculate layout
        layout_algorithm = SugiyamaLayoutAlgorithm(schema)
        layout = layout_algorithm.calculate_layout()

        # Create SVG root
        self._create_svg_root(layout.bounds, options)

        # Add definitions (gradients, patterns, markers)
        self._add_definitions()

        # Draw grid if enabled
        if options.show_grid:
            self._draw_grid(layout.bounds)

        # Draw edges first (so they appear behind nodes)
        for edge in schema.edges:
            self._draw_edge(edge, layout)

        # Draw nodes
        for node in schema.nodes:
            self._draw_node(node, layout, options)

        # Convert to string
        return self._svg_to_string()

    def _create_svg_root(self, bounds: Tuple[float, float, float, float], options: RenderOptions):
        """Create SVG root element"""
        min_x, min_y, max_x, max_y = bounds
        width = max_x - min_x
        height = max_y - min_y

        self.svg_root = ET.Element('svg', {
            'xmlns': 'http://www.w3.org/2000/svg',
            'xmlns:xlink': 'http://www.w3.org/1999/xlink',
            'width': str(options.width),
            'height': str(options.height),
            'viewBox': f'{min_x} {min_y} {width} {height}',
            'style': f'background-color: {self.theme.colors.get("background", "#ffffff")}'
        })

    def _add_definitions(self):
        """Add SVG definitions for reusable elements"""
        self.defs = ET.SubElement(self.svg_root, 'defs')

        # Arrow marker for edges
        arrow_marker = ET.SubElement(self.defs, 'marker', {
            'id': 'arrowhead',
            'markerWidth': '10',
            'markerHeight': '7',
            'refX': '9',
            'refY': '3.5',
            'orient': 'auto'
        })

        ET.SubElement(arrow_marker, 'polygon', {
            'points': '0 0, 10 3.5, 0 7',
            'fill': self.theme.colors.get('edge', '#666666')
        })

        # Node gradients
        for node_type in NodeType:
            base_color = self.theme.get_node_color(node_type)
            lighter_color = self._lighten_color(base_color, 0.3)

            gradient = ET.SubElement(self.defs, 'linearGradient', {
                'id': f'gradient-{node_type.value}',
                'x1': '0%',
                'y1': '0%',
                'x2': '0%',
                'y2': '100%'
            })

            ET.SubElement(gradient, 'stop', {
                'offset': '0%',
                'stop-color': lighter_color
            })

            ET.SubElement(gradient, 'stop', {
                'offset': '100%',
                'stop-color': base_color
            })

    def _draw_grid(self, bounds: Tuple[float, float, float, float]):
        """Draw background grid"""
        min_x, min_y, max_x, max_y = bounds
        grid_size = self.theme.styles['grid_size']

        grid_group = ET.SubElement(self.svg_root, 'g', {
            'class': 'grid',
            'opacity': '0.1'
        })

        # Vertical lines
        x = min_x - (min_x % grid_size)
        while x <= max_x:
            ET.SubElement(grid_group, 'line', {
                'x1': str(x),
                'y1': str(min_y),
                'x2': str(x),
                'y2': str(max_y),
                'stroke': '#cccccc',
                'stroke-width': '1'
            })
            x += grid_size

        # Horizontal lines
        y = min_y - (min_y % grid_size)
        while y <= max_y:
            ET.SubElement(grid_group, 'line', {
                'x1': str(min_x),
                'y1': str(y),
                'x2': str(max_x),
                'y2': str(y),
                'stroke': '#cccccc',
                'stroke-width': '1'
            })
            y += grid_size

    def _draw_node(self, node: DraconNode, layout: LayoutResult, options: RenderOptions):
        """Draw a DRACON node"""
        position = layout.nodes.get(node.id)
        if not position:
            return

        # Create node group
        node_group = ET.SubElement(self.svg_root, 'g', {
            'class': f'node node-{node.node_type.value}',
            'id': f'node-{node.id}'
        })

        # Get node styling
        base_color = self.theme.get_node_color(node.node_type)
        text_color = self.theme.get_contrast_color(base_color)

        # Draw node shape based on type
        if node.node_type == NodeType.TITLE:
            self._draw_title_node(node_group, position, node, base_color)
        elif node.node_type == NodeType.ACTION:
            self._draw_action_node(node_group, position, node, base_color)
        elif node.node_type == NodeType.QUESTION:
            self._draw_question_node(node_group, position, node, base_color)
        elif node.node_type == NodeType.CASE:
            self._draw_case_node(node_group, position, node, base_color)
        else:
            self._draw_default_node(node_group, position, node, base_color)

        # Add text if enabled
        if options.show_labels:
            text_content = node.properties.get('text', node.id)
            if text_content:
                self._add_node_text(node_group, position, text_content, text_color)

    def _draw_title_node(self, group: ET.Element, pos: Position, node: DraconNode, color: str):
        """Draw a title node (rounded rectangle)"""
        width = node.size.width
        height = node.size.height

        ET.SubElement(group, 'rect', {
            'x': str(pos.x - width/2),
            'y': str(pos.y - height/2),
            'width': str(width),
            'height': str(height),
            'rx': '10',
            'ry': '10',
            'fill': f'url(#gradient-{node.node_type.value})',
            'stroke': self.theme.colors.get('border', '#000000'),
            'stroke-width': str(self.theme.styles['stroke_width'])
        })

    def _draw_action_node(self, group: ET.Element, pos: Position, node: DraconNode, color: str):
        """Draw an action node (rectangle)"""
        width = node.size.width
        height = node.size.height

        ET.SubElement(group, 'rect', {
            'x': str(pos.x - width/2),
            'y': str(pos.y - height/2),
            'width': str(width),
            'height': str(height),
            'fill': f'url(#gradient-{node.node_type.value})',
            'stroke': self.theme.colors.get('border', '#000000'),
            'stroke-width': str(self.theme.styles['stroke_width'])
        })

    def _draw_question_node(self, group: ET.Element, pos: Position, node: DraconNode, color: str):
        """Draw a question node (diamond)"""
        width = node.size.width
        height = node.size.height

        points = f"{pos.x},{pos.y - height/2} {pos.x + width/2},{pos.y} {pos.x},{pos.y + height/2} {pos.x - width/2},{pos.y}"

        ET.SubElement(group, 'polygon', {
            'points': points,
            'fill': f'url(#gradient-{node.node_type.value})',
            'stroke': self.theme.colors.get('border', '#000000'),
            'stroke-width': str(self.theme.styles['stroke_width'])
        })

    def _draw_case_node(self, group: ET.Element, pos: Position, node: DraconNode, color: str):
        """Draw a case node (hexagon)"""
        width = node.size.width
        height = node.size.height

        # Create hexagon points
        points = []
        for i in range(6):
            angle = i * math.pi / 3
            x = pos.x + (width/2) * math.cos(angle)
            y = pos.y + (height/2) * math.sin(angle)
            points.append(f"{x},{y}")

        ET.SubElement(group, 'polygon', {
            'points': ' '.join(points),
            'fill': f'url(#gradient-{node.node_type.value})',
            'stroke': self.theme.colors.get('border', '#000000'),
            'stroke-width': str(self.theme.styles['stroke_width'])
        })

    def _draw_default_node(self, group: ET.Element, pos: Position, node: DraconNode, color: str):
        """Draw default node shape (rectangle)"""
        self._draw_action_node(group, pos, node, color)

    def _add_node_text(self, group: ET.Element, pos: Position, text: str, color: str):
        """Add text to a node"""
        # Split text into lines if too long
        max_chars_per_line = 12
        lines = []
        words = text.split()
        current_line = ""

        for word in words:
            if len(current_line + " " + word) <= max_chars_per_line:
                current_line = current_line + " " + word if current_line else word
            else:
                if current_line:
                    lines.append(current_line)
                current_line = word

        if current_line:
            lines.append(current_line)

        # Add text elements
        line_height = self.theme.styles['font_size'] + 2
        total_height = len(lines) * line_height
        start_y = pos.y - total_height/2 + line_height/2

        for i, line in enumerate(lines):
            ET.SubElement(group, 'text', {
                'x': str(pos.x),
                'y': str(start_y + i * line_height),
                'text-anchor': 'middle',
                'dominant-baseline': 'middle',
                'font-family': self.theme.fonts['default'],
                'font-size': str(self.theme.styles['font_size']),
                'fill': color
            }).text = line

    def _draw_edge(self, edge: DraconEdge, layout: LayoutResult):
        """Draw an edge connection"""
        path_points = layout.edges.get(edge.id, [])
        if len(path_points) < 2:
            return

        # Create edge group
        edge_group = ET.SubElement(self.svg_root, 'g', {
            'class': f'edge edge-{edge.edge_type.value}',
            'id': f'edge-{edge.id}'
        })

        # Draw path
        path_d = f"M {path_points[0].x},{path_points[0].y}"
        for point in path_points[1:]:
            path_d += f" L {point.x},{point.y}"

        # Get edge style
        stroke_color = self.theme.colors.get('edge', '#666666')
        stroke_width = self.theme.styles['stroke_width']

        # Special styling for different edge types
        if edge.edge_type == EdgeType.FALSE:
            stroke_color = '#d32f2f'
        elif edge.edge_type == EdgeType.TRUE:
            stroke_color = '#388e3c'

        path_element = ET.SubElement(edge_group, 'path', {
            'd': path_d,
            'stroke': stroke_color,
            'stroke-width': str(stroke_width),
            'fill': 'none',
            'marker-end': 'url(#arrowhead)'
        })

        # Add dashed line for conditional edges
        if edge.condition:
            path_element.set('stroke-dasharray', '5,5')

        # Add label if present
        if edge.label:
            mid_point = self._get_path_midpoint(path_points)
            ET.SubElement(edge_group, 'text', {
                'x': str(mid_point.x),
                'y': str(mid_point.y - 5),
                'text-anchor': 'middle',
                'font-family': self.theme.fonts['default'],
                'font-size': str(self.theme.styles['font_size'] - 2),
                'fill': stroke_color
            }).text = edge.label

    def _get_path_midpoint(self, points: List[Position]) -> Position:
        """Get midpoint of path"""
        if len(points) == 2:
            return Position(
                (points[0].x + points[1].x) / 2,
                (points[0].y + points[1].y) / 2
            )
        else:
            # For multi-point paths, return middle point
            mid_index = len(points) // 2
            return points[mid_index]

    def _lighten_color(self, hex_color: str, factor: float) -> str:
        """Lighten a hex color by a factor"""
        hex_color = hex_color.lstrip('#')
        rgb = tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))

        # Convert to HSL, increase lightness, convert back
        h, l, s = colorsys.rgb_to_hls(rgb[0]/255, rgb[1]/255, rgb[2]/255)
        l = min(1.0, l + factor)
        rgb_new = colorsys.hls_to_rgb(h, l, s)

        return f"#{int(rgb_new[0]*255):02x}{int(rgb_new[1]*255):02x}{int(rgb_new[2]*255):02x}"

    def _svg_to_string(self) -> str:
        """Convert SVG to formatted string"""
        rough_string = ET.tostring(self.svg_root, encoding='unicode')
        reparsed = minidom.parseString(rough_string)
        return reparsed.toprettyxml(indent="  ")


class PNGRenderer:
    """PNG rendering using external tools or libraries"""

    def __init__(self, theme: DraconTheme = None):
        self.theme = theme or DraconTheme()
        self.svg_renderer = SVGRenderer(theme)

    def render_schema(self, schema: DraconSchema, options: RenderOptions) -> bytes:
        """Render DRACON schema to PNG bytes"""
        # First render to SVG
        svg_content = self.svg_renderer.render_schema(schema, options)

        # Convert SVG to PNG (requires external library like cairosvg)
        try:
            import cairosvg
            png_bytes = cairosvg.svg2png(
                bytestring=svg_content.encode('utf-8'),
                output_width=options.width,
                output_height=options.height
            )
            return png_bytes

        except ImportError:
            logger.warning("cairosvg not available, PNG rendering disabled")
            # Return SVG as fallback
            return svg_content.encode('utf-8')


class DraconRenderer:
    """Main DRACON rendering engine with multi-format support"""

    def __init__(self, theme_name: str = "default"):
        self.theme = DraconTheme(theme_name)
        self.svg_renderer = SVGRenderer(self.theme)
        self.png_renderer = PNGRenderer(self.theme)

    def render(self, schema: DraconSchema, options: RenderOptions) -> Any:
        """Render schema in specified format"""
        if options.format.lower() == 'svg':
            return self.svg_renderer.render_schema(schema, options)
        elif options.format.lower() == 'png':
            return self.png_renderer.render_schema(schema, options)
        else:
            raise ValueError(f"Unsupported render format: {options.format}")

    def save_to_file(self, schema: DraconSchema, output_path: Path, options: RenderOptions):
        """Render and save schema to file"""
        output_path = Path(output_path)
        rendered_content = self.render(schema, options)

        if options.format.lower() == 'svg':
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(rendered_content)
        elif options.format.lower() == 'png':
            with open(output_path, 'wb') as f:
                f.write(rendered_content)

        logger.info(f"Rendered schema saved to {output_path}")


# Theme presets
THEMES = {
    'default': DraconTheme('default'),
    'dark': DraconTheme('dark'),
    'high_contrast': DraconTheme('high_contrast'),
    'corporate': DraconTheme('corporate')
}

# Initialize theme variations
THEMES['dark'].colors.update({
    'background': '#2d2d2d',
    'border': '#ffffff',
    'edge': '#cccccc'
})

THEMES['high_contrast'].colors.update({
    'title': '#000000',
    'action': '#ffffff', 
    'question': '#ffff00',
    'case': '#ff0000',
    'background': '#ffffff',
    'border': '#000000',
    'edge': '#000000'
})

```

### bot/features/dracon_generator.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 19,813 Ð±Ð°Ð¹Ñ‚

```python
"""
DRACON Code Generator - Automatic Python Code Generation

This module generates Python code from DRACON schemas with support for
Telegram bot handlers, state machines, and complete application frameworks.
"""

import ast
import inspect
from typing import Dict, List, Optional, Set, Any
from pathlib import Path
from jinja2 import Environment, BaseLoader, Template
from dataclasses import asdict
import logging
from datetime import datetime

from dracon_types import (
    DraconSchema, DraconNode, DraconEdge, NodeType, EdgeType,
    BotHandlerInfo, CodeGenerationResult
)

logger = logging.getLogger(__name__)


class DraconCodeGenerator:
    """Main code generator for DRACON schemas"""

    def __init__(self):
        self.analyzer = None

    def generate_telegram_bot(self, schema: DraconSchema) -> CodeGenerationResult:
        """Generate complete Telegram bot from DRACON schema"""
        try:
            # Analyze schema
            self.analyzer = DraconCodeAnalyzer(schema)
            analysis = self.analyzer.analyze()

            # Generate code files
            files = {}
            errors = []
            warnings = []

            # Main bot file
            bot_code = self._generate_bot_file(analysis)
            files[f"{analysis['bot_metadata']['bot_name'].lower()}.py"] = bot_code

            # Configuration file
            config_code = self._generate_config_file(analysis)
            files['config.py'] = config_code

            # Main entry point
            main_code = self._generate_main_file(analysis)
            files['main.py'] = main_code

            # Requirements file
            requirements_code = self._generate_requirements_file(analysis)
            files['requirements.txt'] = requirements_code

            success = len(errors) == 0
            return CodeGenerationResult(
                success=success,
                generated_code=bot_code,
                files=files,
                errors=errors,
                warnings=warnings
            )

        except Exception as e:
            logger.error(f"Code generation failed: {e}")
            return CodeGenerationResult(
                success=False,
                errors=[f"Code generation error: {str(e)}"]
            )

    def _generate_bot_file(self, analysis: Dict[str, Any]) -> str:
        """Generate main bot file"""
        bot_name = analysis['bot_metadata']['bot_class_name']
        metadata = analysis['schema_metadata']
        handlers = analysis['handlers']

        # Generate handler implementations
        handler_code = []
        for handler in handlers:
            impl = self._generate_handler_implementation(handler, analysis)
            handler_code.append(impl)

        bot_template = f""""""
{metadata['description']}

Generated from DRACON schema: {metadata['name']}
Author: {metadata['author']}
Version: {metadata['version']}
"""

import asyncio
import logging
from typing import Dict, Any, Optional
from datetime import datetime

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application, CommandHandler, CallbackQueryHandler, 
    MessageHandler, ContextTypes, filters
)

# Configure logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)


class {bot_name}:
    """{metadata['description']}"""

    def __init__(self, token: str):
        self.token = token
        self.application = None
        self.current_states = {{}}  # user_id -> current_node_id
        self.session_data = {{}}    # user_id -> session_data

    async def initialize(self):
        """Initialize the bot application"""
        self.application = Application.builder().token(self.token).build()

        # Register handlers
        {self._generate_handler_registrations(handlers)}

        logger.info("Bot initialized successfully")

    async def start(self):
        """Start the bot"""
        if not self.application:
            await self.initialize()

        logger.info("Starting bot...")
        await self.application.run_polling()

    async def stop(self):
        """Stop the bot"""
        if self.application:
            await self.application.stop()
            logger.info("Bot stopped")

    def get_user_state(self, user_id: int) -> Optional[str]:
        """Get current state for user"""
        return self.current_states.get(user_id)

    def set_user_state(self, user_id: int, node_id: str):
        """Set current state for user"""
        self.current_states[user_id] = node_id
        logger.debug(f"User {{user_id}} state changed to {{node_id}}")

    def get_session_data(self, user_id: int) -> Dict[str, Any]:
        """Get session data for user"""
        return self.session_data.get(user_id, {{}})

    def update_session_data(self, user_id: int, data: Dict[str, Any]):
        """Update session data for user"""
        if user_id not in self.session_data:
            self.session_data[user_id] = {{}}
        self.session_data[user_id].update(data)

{chr(10).join(handler_code)}


async def main():
    """Main entry point"""
    import os

    token = os.getenv('TELEGRAM_BOT_TOKEN')
    if not token:
        logger.error("TELEGRAM_BOT_TOKEN environment variable not set")
        return

    bot = {bot_name}(token)

    try:
        await bot.start()
    except KeyboardInterrupt:
        logger.info("Received interrupt signal")
    finally:
        await bot.stop()


if __name__ == '__main__':
    asyncio.run(main())
"""

        return bot_template

    def _generate_handler_registrations(self, handlers: List[BotHandlerInfo]) -> str:
        """Generate handler registration code"""
        registrations = []
        for handler in handlers:
            if handler.handler_type == "command":
                registrations.append(f"        self.application.add_handler(CommandHandler('{handler.command_name}', self.{handler.name}))")
            elif handler.handler_type == "callback":
                registrations.append(f"        self.application.add_handler(CallbackQueryHandler(self.{handler.name}, pattern=r'^{handler.callback_data}.*'))")
            elif handler.handler_type == "message":
                registrations.append(f"        self.application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.{handler.name}))")

        return "\n".join(registrations)

    def _generate_handler_implementation(self, handler: BotHandlerInfo, analysis: Dict[str, Any]) -> str:
        """Generate implementation for a specific handler"""
        # Find corresponding node
        node = None
        for n in self.analyzer.schema.nodes:
            if n.id == handler.dracon_node_id:
                node = n
                break

        if not node:
            return f"    # Handler for {handler.name} - node not found"

        # Find next nodes
        next_edges = [e for e in self.analyzer.schema.edges if e.from_node == node.id]
        next_node = next_edges[0].to_node if next_edges else None

        handler_template = f"""    async def {handler.name}(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """{handler.description}"""
        user_id = update.effective_user.id

        try:
            # Get current state and session data
            current_state = self.get_user_state(user_id)
            session_data = self.get_session_data(user_id)

            {self._generate_node_logic(node, next_node, next_edges)}

        except Exception as e:
            logger.error(f"Error in {handler.name}: {{e}}")
            await update.effective_message.reply_text(
                "An error occurred. Please try again later."
            )
"""

        return handler_template

    def _generate_node_logic(self, node: DraconNode, next_node: Optional[str], edges: List[DraconEdge]) -> str:
        """Generate logic for different node types"""
        text = node.properties.get('text', '')

        if node.node_type == NodeType.TITLE:
            logic = f"""# Title node - entry point
            await update.effective_message.reply_text(
                "{text}",
                parse_mode='HTML'
            )"""
            if next_node:
                logic += f"\n            self.set_user_state(user_id, '{next_node}')"

        elif node.node_type == NodeType.ACTION:
            logic = f"""# Action node - perform action
            logger.info(f"User {{user_id}} performed action: {text}")
            await update.effective_message.reply_text("Action completed: {text}")"""
            if next_node:
                logic += f"\n            self.set_user_state(user_id, '{next_node}')"

        elif node.node_type == NodeType.QUESTION:
            choices = []
            for edge in edges:
                choices.append(f"[InlineKeyboardButton('{edge.label or 'Option'}', callback_data='choice_{node.id}_{edge.to_node}')]")

            logic = f"""# Question node - present choice
            keyboard = [
                {(',\n                '.join(choices))}
            ]

            reply_markup = InlineKeyboardMarkup(keyboard)
            await update.effective_message.reply_text(
                "{text}",
                reply_markup=reply_markup
            )"""

        elif node.node_type == NodeType.END:
            logic = f"""# End node - cleanup
            if user_id in self.current_states:
                del self.current_states[user_id]
            if user_id in self.session_data:
                del self.session_data[user_id]

            await update.effective_message.reply_text("{text or 'Session completed!'}")"""

        else:
            logic = f"""# Default node logic
            await update.effective_message.reply_text("{text}")"""
            if next_node:
                logic += f"\n            self.set_user_state(user_id, '{next_node}')"

        return logic

    def _generate_config_file(self, analysis: Dict[str, Any]) -> str:
        """Generate configuration file"""
        bot_name = analysis['bot_metadata']['bot_name']

        return f""""""
Configuration module for {bot_name}
"""

import os
from typing import Dict, Any
from dataclasses import dataclass


@dataclass
class BotConfig:
    """Bot configuration settings"""
    token: str
    debug: bool = False
    log_level: str = "INFO"
    session_timeout: int = 3600  # 1 hour
    max_concurrent_users: int = 1000

    @classmethod
    def from_environment(cls) -> 'BotConfig':
        """Create config from environment variables"""
        return cls(
            token=os.getenv('TELEGRAM_BOT_TOKEN', ''),
            debug=os.getenv('DEBUG', 'false').lower() == 'true',
            log_level=os.getenv('LOG_LEVEL', 'INFO'),
            session_timeout=int(os.getenv('SESSION_TIMEOUT', '3600')),
            max_concurrent_users=int(os.getenv('MAX_CONCURRENT_USERS', '1000')),
        )


# Default configuration
config = BotConfig.from_environment()
"""

    def _generate_main_file(self, analysis: Dict[str, Any]) -> str:
        """Generate main entry point file"""
        bot_name = analysis['bot_metadata']['bot_name']
        bot_class = analysis['bot_metadata']['bot_class_name']
        bot_module = bot_name.lower()

        return f"""#!/usr/bin/env python3
"""
{bot_name} - Generated DRACON Telegram Bot

This bot was automatically generated from a DRACON schema.
Generated on: {datetime.now().isoformat()}
"""

import os
import sys
import asyncio
import logging
from pathlib import Path

# Add the current directory to Python path
sys.path.insert(0, str(Path(__file__).parent))

from {bot_module} import {bot_class}


def setup_logging():
    """Configure logging for the application"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('bot.log'),
            logging.StreamHandler(sys.stdout)
        ]
    )


async def main():
    """Main application entry point"""
    setup_logging()
    logger = logging.getLogger(__name__)

    # Get bot token from environment
    token = os.getenv('TELEGRAM_BOT_TOKEN')
    if not token:
        logger.error("TELEGRAM_BOT_TOKEN environment variable is required")
        logger.info("Set it using: export TELEGRAM_BOT_TOKEN='your-bot-token'")
        return 1

    # Create and start bot
    bot = {bot_class}(token)

    try:
        logger.info("Starting {bot_name}...")
        await bot.start()
    except KeyboardInterrupt:
        logger.info("Received interrupt signal, shutting down...")
    except Exception as e:
        logger.error(f"Unexpected error: {{e}}")
        return 1
    finally:
        await bot.stop()

    return 0


if __name__ == '__main__':
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
"""

    def _generate_requirements_file(self, analysis: Dict[str, Any]) -> str:
        """Generate requirements.txt file"""
        bot_name = analysis['bot_metadata']['bot_name']

        return f"""# Requirements for {bot_name}
# Generated from DRACON schema

# Core dependencies
python-telegram-bot>=22.0
asyncio
typing
dataclasses
pathlib
datetime
enum

# Development dependencies (optional)
pytest>=7.0
black>=22.0
flake8>=5.0
mypy>=1.0
"""


class DraconCodeAnalyzer:
    """Analyzer for DRACON schemas to extract code generation patterns"""

    def __init__(self, schema: DraconSchema):
        self.schema = schema
        self.handlers = []
        self.states = []
        self.transitions = []

    def analyze(self) -> Dict[str, Any]:
        """Analyze schema and extract code generation data"""
        # Find entry points
        entry_nodes = self._find_entry_nodes()

        # Analyze nodes for handler generation
        for node in self.schema.nodes:
            handler_info = self._analyze_node(node)
            if handler_info:
                self.handlers.append(handler_info)

        # Analyze workflow patterns
        workflow_patterns = self._analyze_workflow_patterns()

        # Extract bot metadata
        bot_metadata = self._extract_bot_metadata()

        return {
            'handlers': self.handlers,
            'entry_nodes': entry_nodes,
            'workflow_patterns': workflow_patterns,
            'bot_metadata': bot_metadata,
            'schema_metadata': asdict(self.schema.metadata)
        }

    def _find_entry_nodes(self) -> List[str]:
        """Find entry point nodes (nodes with no incoming edges)"""
        incoming_nodes = {edge.to_node for edge in self.schema.edges}
        all_nodes = {node.id for node in self.schema.nodes}
        return list(all_nodes - incoming_nodes)

    def _analyze_node(self, node: DraconNode) -> Optional[BotHandlerInfo]:
        """Analyze a node to determine handler requirements"""
        if node.node_type == NodeType.TITLE:
            return BotHandlerInfo(
                name=f"handle_{node.id}",
                handler_type="command",
                command_name="start",
                description=node.properties.get('text', 'Entry point'),
                dracon_node_id=node.id
            )

        elif node.node_type == NodeType.ACTION:
            # Check if this is a command handler
            text = node.properties.get('text', '')
            if text.startswith('/'):
                command_name = text[1:].split()[0]
                return BotHandlerInfo(
                    name=f"handle_{command_name}",
                    handler_type="command", 
                    command_name=command_name,
                    description=f"Handle {command_name} command",
                    dracon_node_id=node.id
                )
            else:
                return BotHandlerInfo(
                    name=f"action_{node.id}",
                    handler_type="message",
                    description=f"Handle action: {text[:50]}",
                    dracon_node_id=node.id
                )

        elif node.node_type == NodeType.QUESTION:
            return BotHandlerInfo(
                name=f"question_{node.id}",
                handler_type="callback",
                callback_data=f"q_{node.id}",
                description=f"Handle question: {node.properties.get('text', '')[:50]}",
                dracon_node_id=node.id
            )

        elif node.node_type == NodeType.CASE:
            return BotHandlerInfo(
                name=f"case_{node.id}",
                handler_type="callback",
                callback_data=f"c_{node.id}",
                description=f"Handle case logic",
                dracon_node_id=node.id
            )

        return None

    def _analyze_workflow_patterns(self) -> Dict[str, Any]:
        """Analyze workflow patterns for code generation"""
        patterns = {
            'has_state_machine': len(self.schema.edges) > 2,
            'has_conditional_logic': any(
                node.node_type in [NodeType.QUESTION, NodeType.CASE] 
                for node in self.schema.nodes
            ),
            'has_loops': any(
                edge.edge_type == EdgeType.LOOP_BACK 
                for edge in self.schema.edges
            ),
            'complexity_score': self._calculate_complexity()
        }
        return patterns

    def _calculate_complexity(self) -> int:
        """Calculate schema complexity score"""
        score = 0
        score += len(self.schema.nodes)
        score += len(self.schema.edges) * 0.5
        score += len(self.schema.macros) * 2

        # Add complexity for special node types
        for node in self.schema.nodes:
            if node.node_type in [NodeType.QUESTION, NodeType.CASE]:
                score += 2
            elif node.node_type == NodeType.LOOP_START:
                score += 3

        return int(score)

    def _extract_bot_metadata(self) -> Dict[str, Any]:
        """Extract bot-specific metadata"""
        return {
            'bot_name': self.schema.metadata.name.replace(' ', ''),
            'bot_class_name': self._to_class_name(self.schema.metadata.name),
            'description': self.schema.metadata.description,
            'version': self.schema.metadata.version
        }

    def _to_class_name(self, name: str) -> str:
        """Convert name to valid Python class name"""
        # Remove special characters and convert to PascalCase
        words = ''.join(c if c.isalnum() else ' ' for c in name).split()
        return ''.join(word.capitalize() for word in words if word) + 'Bot'


# Utility functions

def generate_bot_from_schema_file(schema_file: Path, output_dir: Path) -> CodeGenerationResult:
    """Generate bot code from schema file"""
    from dracon_parser import DraconParser

    # Parse schema
    parser = DraconParser()
    parse_result = parser.parse_file(schema_file)

    if not parse_result.success:
        return CodeGenerationResult(
            success=False,
            errors=parse_result.errors
        )

    # Generate code
    generator = DraconCodeGenerator()
    result = generator.generate_telegram_bot(parse_result.schema)

    if result.success:
        # Save files to output directory
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        for filename, content in result.files.items():
            file_path = output_dir / filename
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)

        logger.info(f"Generated bot files in {output_dir}")

    return result


def validate_generated_code(code: str) -> List[str]:
    """Validate generated Python code"""
    errors = []

    try:
        # Parse the code to check syntax
        ast.parse(code)
    except SyntaxError as e:
        errors.append(f"Syntax error: {e}")

    return errors

```

### bot/features/dracon_enhanced.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 13,851 Ð±Ð°Ð¹Ñ‚

```python
"""Enhanced DRACON-YAML System with Professional Components.

This module integrates Perplexity's enterprise-grade DRACON implementation
with our existing Telegram bot logic modeling system.

Features:
- Professional DRACON parser with DRAKON Hub compatibility
- Visual SVG/PNG diagram generation
- Enhanced code generation with Jinja2 templates
- Complete type system with validation
- Intelligent graph analysis using Claude CLI integration
- Visual logic modeling with closed graph topology
"""

import asyncio
import json
import os
import subprocess
import tempfile
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple, Union
import io

import structlog
import yaml

# Import enhanced DRACON components from Perplexity
from .dracon_types import (
    DraconSchema, DraconNode, DraconEdge, NodeType, EdgeType,
    Position, Size, SchemaMetadata, CanvasProperties, ValidationRules,
    ParseResult, DraconMetadata, VisualProperties, RenderOptions,
    CodeGenerationResult
)
from .dracon_parser import DraconParser
from .dracon_renderer import DraconRenderer
from .dracon_generator import DraconCodeGenerator

logger = structlog.get_logger()


class EnhancedDraconProcessor:
    """Enhanced DRACON processor combining our bot integration with Perplexity's professional components."""

    def __init__(self):
        """Initialize enhanced DRACON processor with Perplexity components."""
        self.parser = DraconParser()
        self.renderer = DraconRenderer()
        self.generator = DraconCodeGenerator()

    async def process_schema_file(self, file_path: Path) -> Dict[str, Any]:
        """Process a DRACON schema file with enhanced capabilities."""
        try:
            # Parse with professional parser
            parse_result = self.parser.parse_file(file_path)

            if not parse_result.success:
                return {
                    "success": False,
                    "errors": parse_result.errors,
                    "warnings": parse_result.warnings
                }

            schema = parse_result.schema

            # Generate analysis report
            analysis = await self._analyze_schema(schema)

            # Generate visual diagram
            svg_diagram = await self._generate_diagram(schema)

            # Generate bot components
            components = await self._generate_components(schema)

            return {
                "success": True,
                "schema": schema,
                "analysis": analysis,
                "svg_diagram": svg_diagram,
                "components": components,
                "metadata": {
                    "name": schema.metadata.name,
                    "version": schema.metadata.version,
                    "node_count": len(schema.nodes),
                    "edge_count": len(schema.edges),
                    "complexity": self._calculate_complexity(schema)
                }
            }

        except Exception as e:
            logger.error("Schema processing failed", error=str(e), file_path=str(file_path))
            return {
                "success": False,
                "errors": [f"Processing failed: {str(e)}"]
            }

    async def _analyze_schema(self, schema: DraconSchema) -> Dict[str, Any]:
        """Analyze schema using Claude CLI integration."""
        analysis_prompt = f"""
Analyze this DRACON schema for bot logic:

Schema: {schema.metadata.name}
Nodes: {len(schema.nodes)}
Edges: {len(schema.edges)}

Node details:
{self._format_nodes_for_analysis(schema.nodes)}

Edge details:
{self._format_edges_for_analysis(schema.edges)}

Provide analysis on:
1. Logic flow completeness
2. Potential deadlocks or infinite loops
3. Missing error handling paths
4. Optimization suggestions
5. Bot-specific recommendations

Format as JSON with fields: completeness, deadlocks, error_handling, optimizations, recommendations
"""

        try:
            # Use Claude CLI for intelligent analysis
            result = await self._call_claude_cli(analysis_prompt)
            if result and result.get('success'):
                try:
                    return json.loads(result['output'])
                except json.JSONDecodeError:
                    return {"analysis": result['output']}

            return {"analysis": "Analysis not available"}

        except Exception as e:
            logger.warning("Schema analysis failed", error=str(e))
            return {"analysis": f"Analysis failed: {str(e)}"}

    async def _generate_diagram(self, schema: DraconSchema) -> Optional[str]:
        """Generate SVG diagram using professional renderer."""
        try:
            options = RenderOptions(
                format="svg",
                theme="default",
                width=1200,
                height=800,
                show_grid=True,
                show_labels=True
            )

            svg_content = self.renderer.render(schema, options)
            return svg_content

        except Exception as e:
            logger.error("Diagram generation failed", error=str(e))
            return None

    async def _generate_components(self, schema: DraconSchema) -> Dict[str, Any]:
        """Generate bot components from schema."""
        try:
            # Generate complete bot code
            generation_result = self.generator.generate_telegram_bot(schema)

            if not generation_result.success:
                return {
                    "success": False,
                    "errors": generation_result.errors
                }

            # Extract components
            components = {
                "handlers": self._extract_handlers(schema),
                "commands": self._extract_commands(schema),
                "callbacks": self._extract_callbacks(schema),
                "messages": self._extract_messages(schema),
                "buttons": self._extract_buttons(schema),
                "generated_code": generation_result.generated_code,
                "files": generation_result.files
            }

            return {
                "success": True,
                "components": components
            }

        except Exception as e:
            logger.error("Component generation failed", error=str(e))
            return {
                "success": False,
                "errors": [f"Component generation failed: {str(e)}"]
            }

    def _extract_handlers(self, schema: DraconSchema) -> List[Dict[str, Any]]:
        """Extract handler information from schema."""
        handlers = []

        for node in schema.nodes:
            if node.node_type in [NodeType.ACTION, NodeType.QUESTION]:
                handlers.append({
                    "id": node.id,
                    "type": node.node_type.value,
                    "name": node.properties.get("text", f"Handler {node.id}"),
                    "description": node.properties.get("description", ""),
                    "position": [node.position.x, node.position.y]
                })

        return handlers

    def _extract_commands(self, schema: DraconSchema) -> List[Dict[str, Any]]:
        """Extract command information from schema."""
        commands = []

        for node in schema.nodes:
            if node.node_type == NodeType.TITLE:
                commands.append({
                    "id": node.id,
                    "command": node.properties.get("command", "start"),
                    "description": node.properties.get("text", "Start command"),
                    "handler": f"handle_{node.id}"
                })

        return commands

    def _extract_callbacks(self, schema: DraconSchema) -> List[Dict[str, Any]]:
        """Extract callback information from schema."""
        callbacks = []

        for edge in schema.edges:
            if edge.edge_type == EdgeType.TRUE or edge.edge_type == EdgeType.FALSE:
                if edge.condition:
                    callbacks.append({
                        "id": edge.id,
                        "callback_data": edge.condition,
                        "from_node": edge.from_node,
                        "to_node": edge.to_node,
                        "handler": f"callback_{edge.id}"
                    })

        return callbacks

    def _extract_messages(self, schema: DraconSchema) -> List[Dict[str, Any]]:
        """Extract message information from schema."""
        messages = []

        for node in schema.nodes:
            if node.properties.get("template"):
                messages.append({
                    "id": node.id,
                    "template": node.properties["template"],
                    "type": node.node_type.value,
                    "variables": self._extract_variables(node.properties["template"])
                })

        return messages

    def _extract_buttons(self, schema: DraconSchema) -> List[Dict[str, Any]]:
        """Extract button information from schema."""
        buttons = []

        for node in schema.nodes:
            if node.properties.get("text") and node.properties.get("callback_data"):
                buttons.append({
                    "id": node.id,
                    "text": node.properties["text"],
                    "callback_data": node.properties["callback_data"],
                    "type": "inline"
                })

        return buttons

    def _extract_variables(self, template: str) -> List[str]:
        """Extract variables from message template."""
        import re
        return re.findall(r'\{(\w+)\}', template)

    def _calculate_complexity(self, schema: DraconSchema) -> int:
        """Calculate schema complexity score."""
        base_score = len(schema.nodes) + len(schema.edges)

        # Add complexity for different node types
        for node in schema.nodes:
            if node.node_type == NodeType.QUESTION:
                base_score += 2  # Decisions add complexity
            elif node.node_type in [NodeType.LOOP_START, NodeType.LOOP_END]:
                base_score += 3  # Loops add more complexity

        return min(base_score, 100)  # Cap at 100

    def _format_nodes_for_analysis(self, nodes: List[DraconNode]) -> str:
        """Format nodes for Claude analysis."""
        formatted = []
        for node in nodes:
            formatted.append(f"- {node.id} ({node.node_type.value}): {node.properties.get('text', 'No description')}")
        return "\n".join(formatted)

    def _format_edges_for_analysis(self, edges: List[DraconEdge]) -> str:
        """Format edges for Claude analysis."""
        formatted = []
        for edge in edges:
            condition = f" [{edge.condition}]" if edge.condition else ""
            formatted.append(f"- {edge.from_node} -> {edge.to_node} ({edge.edge_type.value}){condition}")
        return "\n".join(formatted)

    async def _call_claude_cli(self, prompt: str) -> Optional[Dict[str, Any]]:
        """Call Claude CLI for analysis."""
        try:
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                f.write(prompt)
                temp_file = f.name

            # Call Claude CLI
            process = await asyncio.create_subprocess_exec(
                'claude', 'chat', '--no-markdown',
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )

            stdout, stderr = await process.communicate(input=prompt.encode())

            if process.returncode == 0:
                return {
                    "success": True,
                    "output": stdout.decode().strip()
                }
            else:
                logger.error("Claude CLI failed", stderr=stderr.decode())
                return {
                    "success": False,
                    "error": stderr.decode()
                }

        except Exception as e:
            logger.error("Claude CLI call failed", error=str(e))
            return None
        finally:
            # Clean up temp file
            try:
                os.unlink(temp_file)
            except:
                pass


async def create_example_schema() -> DraconSchema:
    """Create an example DRACON schema for demonstration."""
    metadata = SchemaMetadata(
        name="Enhanced Bot Example",
        version="1.0.0",
        description="Example bot with enhanced DRACON features",
        author="Enhanced DRACON System"
    )

    schema = DraconSchema(metadata=metadata)

    # Add start node
    start_node = DraconNode(
        id="start",
        node_type=NodeType.TITLE,
        position=Position(x=100, y=100),
        size=Size(width=120, height=60),
        properties={
            "text": "ðŸš€ Welcome to Enhanced Bot!",
            "command": "start"
        }
    )
    schema.add_node(start_node)

    # Add menu node
    menu_node = DraconNode(
        id="main_menu",
        node_type=NodeType.ACTION,
        position=Position(x=300, y=100),
        size=Size(width=140, height=80),
        properties={
            "text": "Main Menu",
            "template": "ðŸ  **Main Menu**\n\nChoose an option:"
        }
    )
    schema.add_node(menu_node)

    # Add end node
    end_node = DraconNode(
        id="end",
        node_type=NodeType.END,
        position=Position(x=500, y=100),
        size=Size(width=100, height=50),
        properties={
            "text": "End"
        }
    )
    schema.add_node(end_node)

    # Add edges
    start_edge = DraconEdge(
        id="start_to_menu",
        from_node="start",
        to_node="main_menu",
        edge_type=EdgeType.SEQUENCE
    )
    schema.add_edge(start_edge)

    menu_edge = DraconEdge(
        id="menu_to_end",
        from_node="main_menu",
        to_node="end",
        edge_type=EdgeType.SEQUENCE
    )
    schema.add_edge(menu_edge)

    return schema

```

### bot/features/dracon_types.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 7,992 Ð±Ð°Ð¹Ñ‚

```python
"""
DRACON Type Definitions and Data Structures

This module provides all the core type definitions and data structures
for the DRACON visual programming language implementation.
"""

from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, Set, Tuple, Union
from datetime import datetime
import uuid


class NodeType(Enum):
    """DRACON node types following DRAKON Hub format compatibility"""
    TITLE = "title"
    ACTION = "action" 
    QUESTION = "question"
    CASE = "case"
    SELECT = "select"
    LOOP_START = "loop_start"
    LOOP_END = "loop_end"
    ADDRESS = "address"
    END = "end"
    SHELF = "shelf"
    TIMER = "timer"
    PARALLEL_START = "parallel_start"
    PARALLEL_END = "parallel_end"


class EdgeType(Enum):
    """DRACON connection types"""
    SEQUENCE = "sequence"
    TRUE = "true"
    FALSE = "false"
    CASE_BRANCH = "case_branch"
    LOOP_BACK = "loop_back"


@dataclass
class Position:
    """2D position coordinates"""
    x: float
    y: float


@dataclass
class Size:
    """2D size dimensions"""
    width: float
    height: float


@dataclass
class DraconMetadata:
    """Metadata for DRACON schema elements"""
    is_macro: bool = False
    macro_definition: Optional[Dict[str, Any]] = None
    data_flow: List[str] = field(default_factory=list)
    complexity_score: int = 0


@dataclass
class VisualProperties:
    """Visual styling properties for DRACON elements"""
    color: str = "#ffffff"
    font_size: int = 12
    font_family: str = "Arial"
    border_width: int = 1
    border_color: str = "#000000"
    background_color: str = "#f0f0f0"


@dataclass
class DraconNode:
    """A single node in a DRACON schema"""
    id: str
    node_type: NodeType
    position: Position
    size: Size
    properties: Dict[str, Any] = field(default_factory=dict)
    dracon_metadata: DraconMetadata = field(default_factory=DraconMetadata)
    visual_properties: VisualProperties = field(default_factory=VisualProperties)

    def __post_init__(self):
        if not self.id:
            self.id = str(uuid.uuid4())


@dataclass
class ControlPoint:
    """Control point for edge routing"""
    x: float
    y: float


@dataclass
class EdgeMetadata:
    """Metadata for DRACON edges"""
    data_transfer: List[str] = field(default_factory=list)
    execution_weight: int = 1


@dataclass 
class DraconEdge:
    """A connection between DRACON nodes"""
    id: str
    from_node: str
    to_node: str
    edge_type: EdgeType
    condition: Optional[str] = None
    label: str = ""
    control_points: List[ControlPoint] = field(default_factory=list)
    edge_metadata: EdgeMetadata = field(default_factory=EdgeMetadata)

    def __post_init__(self):
        if not self.id:
            self.id = str(uuid.uuid4())


@dataclass
class MacroDefinition:
    """Definition of a reusable macro"""
    name: str
    parameters: List[str] = field(default_factory=list)
    definition: Optional['DraconSchema'] = None


@dataclass
class ValidationRules:
    """Validation rules for DRACON schema"""
    no_intersections: bool = True
    single_entry_exit: bool = True
    all_paths_covered: bool = True
    variable_scope_check: bool = True


@dataclass
class CanvasProperties:
    """Canvas properties for the schema"""
    width: int = 1200
    height: int = 800
    grid_size: int = 20
    theme: str = "default"
    zoom: float = 1.0


@dataclass
class SchemaMetadata:
    """Metadata for the entire schema"""
    name: str
    version: str = "1.0.0"
    description: str = ""
    author: str = ""
    created: datetime = field(default_factory=datetime.now)
    modified: datetime = field(default_factory=datetime.now)
    tags: List[str] = field(default_factory=list)
    dracon_version: str = "1.0"


@dataclass
class DraconSchema:
    """Complete DRACON schema representation"""
    metadata: SchemaMetadata
    canvas: CanvasProperties = field(default_factory=CanvasProperties)
    nodes: List[DraconNode] = field(default_factory=list)
    edges: List[DraconEdge] = field(default_factory=list)
    macros: List[MacroDefinition] = field(default_factory=list)
    validation_rules: ValidationRules = field(default_factory=ValidationRules)

    def add_node(self, node: DraconNode) -> None:
        """Add a node to the schema"""
        self.nodes.append(node)

    def add_edge(self, edge: DraconEdge) -> None:
        """Add an edge to the schema"""
        self.edges.append(edge)

    def get_node_by_id(self, node_id: str) -> Optional[DraconNode]:
        """Get a node by its ID"""
        return next((node for node in self.nodes if node.id == node_id), None)

    def get_edges_from_node(self, node_id: str) -> List[DraconEdge]:
        """Get all edges originating from a node"""
        return [edge for edge in self.edges if edge.from_node == node_id]

    def get_edges_to_node(self, node_id: str) -> List[DraconEdge]:
        """Get all edges pointing to a node"""
        return [edge for edge in self.edges if edge.to_node == node_id]


@dataclass
class ParseResult:
    """Result of parsing a DRACON schema"""
    success: bool
    schema: Optional[DraconSchema] = None
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)


@dataclass
class ValidationResult:
    """Result of validating a DRACON schema"""
    is_valid: bool
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    complexity_metrics: Dict[str, Any] = field(default_factory=dict)


@dataclass
class RenderOptions:
    """Options for rendering DRACON schemas"""
    format: str = "svg"  # svg, png, pdf
    theme: str = "default"
    width: int = 1200
    height: int = 800
    show_grid: bool = False
    show_labels: bool = True
    high_contrast: bool = False


@dataclass
class CodeGenerationResult:
    """Result of generating code from DRACON schema"""
    success: bool
    generated_code: str = ""
    files: Dict[str, str] = field(default_factory=dict)
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)


# Telegram Bot Integration Types

@dataclass
class BotHandlerInfo:
    """Information about a Telegram bot handler"""
    name: str
    handler_type: str  # command, callback, message
    command_name: Optional[str] = None
    callback_data: Optional[str] = None
    description: str = ""
    dracon_node_id: Optional[str] = None


@dataclass
class BotWorkflowState:
    """State information for bot workflow"""
    user_id: int
    current_node: str
    session_data: Dict[str, Any] = field(default_factory=dict)
    workflow_id: str = ""
    created_at: datetime = field(default_factory=datetime.now)


# File Management Types

class FileCategory(Enum):
    """File categories for DRACON storage"""
    REVERSE = "reverse"
    BUILD = "build"
    AUDIT = "audit"
    LIBRARY = "library"
    ACTIVE = "active"
    ARCHIVE = "archive"
    TEMP = "temp"
    EXPORT = "export"


@dataclass
class DraconFile:
    """File information for DRACON storage"""
    filename: str
    category: FileCategory
    schema: DraconSchema
    created_at: datetime = field(default_factory=datetime.now)
    modified_at: datetime = field(default_factory=datetime.now)
    version: str = "1.0.0"
    checksum: str = ""


# Constants
DEFAULT_COLORS = {
    "title": "#4a90e2",
    "action": "#7ed321", 
    "question": "#f5a623",
    "case": "#d0021b",
    "loop": "#9013fe",
    "address": "#50e3c2",
    "end": "#b8e986"
}

DRACON_ICONS = {
    NodeType.TITLE: "title_icon.svg",
    NodeType.ACTION: "action_icon.svg",
    NodeType.QUESTION: "question_icon.svg",
    NodeType.CASE: "case_icon.svg",
    NodeType.LOOP_START: "loop_start_icon.svg",
    NodeType.LOOP_END: "loop_end_icon.svg",
    NodeType.ADDRESS: "address_icon.svg",
    NodeType.END: "end_icon.svg"
}

# Validation constants
MAX_NODES_PER_SCHEMA = 1000
MAX_EDGES_PER_SCHEMA = 2000
MAX_MACRO_DEPTH = 10

```

### bot/features/quick_actions.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 11,295 Ð±Ð°Ð¹Ñ‚

```python
"""Quick Actions feature implementation.

Provides context-aware quick action suggestions for common development tasks.
"""

import logging
from dataclasses import dataclass
from typing import Any, Callable, Dict, List, Optional

from telegram import InlineKeyboardButton, InlineKeyboardMarkup

from src.storage.models import SessionModel

logger = logging.getLogger(__name__)


@dataclass
class QuickAction:
    """Represents a quick action suggestion."""

    id: str
    name: str
    description: str
    command: str
    icon: str
    category: str
    context_required: List[str]  # Required context keys
    priority: int = 0  # Higher = more important


class QuickActionManager:
    """Manages quick action suggestions based on context."""

    def __init__(self) -> None:
        """Initialize the quick action manager."""
        self.actions = self._create_default_actions()
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")

    def _create_default_actions(self) -> Dict[str, QuickAction]:
        """Create default quick actions."""
        return {
            "test": QuickAction(
                id="test",
                name="Run Tests",
                description="Run project tests",
                command="test",
                icon="ðŸ§ª",
                category="testing",
                context_required=["has_tests"],
                priority=10,
            ),
            "install": QuickAction(
                id="install",
                name="Install Dependencies",
                description="Install project dependencies",
                command="install",
                icon="ðŸ“¦",
                category="setup",
                context_required=["has_package_manager"],
                priority=9,
            ),
            "format": QuickAction(
                id="format",
                name="Format Code",
                description="Format code with project formatter",
                command="format",
                icon="ðŸŽ¨",
                category="quality",
                context_required=["has_formatter"],
                priority=7,
            ),
            "lint": QuickAction(
                id="lint",
                name="Lint Code",
                description="Check code quality",
                command="lint",
                icon="ðŸ”",
                category="quality",
                context_required=["has_linter"],
                priority=8,
            ),
            "security": QuickAction(
                id="security",
                name="Security Scan",
                description="Run security vulnerability scan",
                command="security",
                icon="ðŸ”’",
                category="security",
                context_required=["has_dependencies"],
                priority=6,
            ),
            "optimize": QuickAction(
                id="optimize",
                name="Optimize",
                description="Optimize code performance",
                command="optimize",
                icon="âš¡",
                category="performance",
                context_required=["has_code"],
                priority=5,
            ),
            "document": QuickAction(
                id="document",
                name="Generate Docs",
                description="Generate documentation",
                command="document",
                icon="ðŸ“",
                category="documentation",
                context_required=["has_code"],
                priority=4,
            ),
            "refactor": QuickAction(
                id="refactor",
                name="Refactor",
                description="Suggest code improvements",
                command="refactor",
                icon="ðŸ”§",
                category="quality",
                context_required=["has_code"],
                priority=3,
            ),
            # NEW FUNCTIONAL ACTIONS
            "ls": QuickAction(
                id="ls",
                name="Show Files",
                description="List files in current directory",
                command="ls -la",
                icon="ðŸ“‹",
                category="navigation",
                context_required=[],  # Always available
                priority=15,
            ),
            "pwd": QuickAction(
                id="pwd",
                name="Current Location",
                description="Show current directory path",
                command="pwd",
                icon="ðŸ ",
                category="navigation",
                context_required=[],
                priority=14,
            ),
            "git_status": QuickAction(
                id="git_status",
                name="Git Status",
                description="Show git repository status",
                command="git status",
                icon="ðŸ’¾",
                category="git",
                context_required=[],
                priority=13,
            ),
            "grep": QuickAction(
                id="grep",
                name="Search TODOs",
                description="Find TODO, FIXME, BUG comments",
                command="grep -r \"TODO\\|FIXME\\|BUG\" . --include=\"*.py\" --include=\"*.js\" --include=\"*.ts\" || echo 'No TODO/FIXME/BUG found'",
                icon="ðŸ”",
                category="search",
                context_required=[],
                priority=12,
            ),
            "find_files": QuickAction(
                id="find_files",
                name="Find Code Files",
                description="Find Python, JS, TS files",
                command="find . -type f -name \"*.py\" -o -name \"*.js\" -o -name \"*.ts\" | head -20",
                icon="ðŸ”",
                category="search",
                context_required=[],
                priority=11,
            ),
        }

    async def get_suggestions(
        self, session: SessionModel, limit: int = 6
    ) -> List[QuickAction]:
        """Get quick action suggestions based on session context.

        Args:
            session: Current session
            limit: Maximum number of suggestions

        Returns:
            List of suggested actions
        """
        try:
            # Analyze context
            context = await self._analyze_context(session)

            # Filter actions based on context
            available_actions = []
            for action in self.actions.values():
                if self._is_action_available(action, context):
                    available_actions.append(action)

            # Sort by priority and return top N
            available_actions.sort(key=lambda x: x.priority, reverse=True)
            return available_actions[:limit]

        except Exception as e:
            self.logger.error(f"Error getting suggestions: {e}")
            return []

    async def _analyze_context(self, session: SessionModel) -> Dict[str, Any]:
        """Analyze session context to determine available actions.

        Args:
            session: Current session

        Returns:
            Context dictionary
        """
        context = {
            "has_code": True,  # Default assumption
            "has_tests": False,
            "has_package_manager": False,
            "has_formatter": False,
            "has_linter": False,
            "has_dependencies": False,
        }

        # Analyze recent messages for context clues
        if session.context:
            recent_messages = session.context.get("recent_messages", [])
            for msg in recent_messages:
                content = msg.get("content", "").lower()

                # Check for test indicators
                if any(word in content for word in ["test", "pytest", "unittest"]):
                    context["has_tests"] = True

                # Check for package manager indicators
                if any(word in content for word in ["pip", "poetry", "npm", "yarn"]):
                    context["has_package_manager"] = True
                    context["has_dependencies"] = True

                # Check for formatter indicators
                if any(word in content for word in ["black", "prettier", "format"]):
                    context["has_formatter"] = True

                # Check for linter indicators
                if any(
                    word in content for word in ["flake8", "pylint", "eslint", "mypy"]
                ):
                    context["has_linter"] = True

        # File-based context analysis could be added here
        # For now, we'll use heuristics based on session history

        return context

    def _is_action_available(
        self, action: QuickAction, context: Dict[str, Any]
    ) -> bool:
        """Check if an action is available in the given context.

        Args:
            action: The action to check
            context: Current context

        Returns:
            True if action is available
        """
        # Check all required context keys
        for key in action.context_required:
            if not context.get(key, False):
                return False
        return True

    def create_inline_keyboard(
        self, actions: List[QuickAction], columns: int = 2, localization=None, user_lang=None
    ) -> InlineKeyboardMarkup:
        """Create inline keyboard for quick actions with localization support.

        Args:
            actions: List of actions to display
            columns: Number of columns in keyboard
            localization: Localization manager (optional)
            user_lang: User language code (optional)

        Returns:
            Inline keyboard markup
        """
        keyboard = []
        row = []

        for i, action in enumerate(actions):
            # Try to get localized action name, fallback to default
            if localization and user_lang:
                action_text = localization.get(f"quick_actions.{action.id}.name", language=user_lang)
                if not action_text:
                    action_text = f"{action.icon} {action.name}"
            else:
                action_text = f"{action.icon} {action.name}"
                
            button = InlineKeyboardButton(
                text=action_text,
                callback_data=f"quick_action:{action.id}",
            )
            row.append(button)

            # Add row when full or last item
            if len(row) >= columns or i == len(actions) - 1:
                keyboard.append(row)
                row = []

        return InlineKeyboardMarkup(keyboard)

    async def execute_action(
        self, action_id: str, session: SessionModel, callback: Optional[Callable] = None
    ) -> str:
        """Execute a quick action.

        Args:
            action_id: ID of action to execute
            session: Current session
            callback: Optional callback for command execution

        Returns:
            Command to execute
        """
        action = self.actions.get(action_id)
        if not action:
            raise ValueError(f"Unknown action: {action_id}")

        self.logger.info(
            f"Executing quick action: {action.name} for session {session.id}"
        )

        # Return the command - actual execution is handled by the bot
        return action.command

```

### bot/features/dracon_reverse_engineer.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 25,944 Ð±Ð°Ð¹Ñ‚

```python
"""DRACON Reverse Engineering: Convert Bot Code to DRACON Schemas.

This module analyzes existing Telegram bot code and converts it into
DRACON-YAML schemas for visualization and modernization.

Features:
- AST parsing of Python bot handlers
- Logic flow detection and mapping
- Intelligent code analysis with Claude
- Automatic DRACON schema generation
- Refactoring recommendations
"""

import ast
import inspect
import os
import re
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple, Union

import structlog
import yaml

from .dracon_yaml import DraconSchema, NodeType, EdgeType

logger = structlog.get_logger()


@dataclass
class HandlerInfo:
    """Information about a bot handler function."""
    name: str
    function_name: str
    file_path: str
    line_number: int
    handler_type: str  # 'command', 'callback', 'message'
    command_name: Optional[str] = None
    callback_data: Optional[str] = None
    docstring: Optional[str] = None
    calls_functions: Set[str] = field(default_factory=set)
    sends_messages: List[str] = field(default_factory=list)
    creates_buttons: List[Dict[str, str]] = field(default_factory=list)
    has_error_handling: bool = False
    complexity_score: int = 0


@dataclass
class LogicFlow:
    """Represents a logical flow between handlers."""
    from_handler: str
    to_handler: str
    trigger_type: str  # 'command', 'callback', 'condition'
    trigger_value: Optional[str] = None
    condition: Optional[str] = None


@dataclass
class BotArchitecture:
    """Complete bot architecture analysis."""
    handlers: List[HandlerInfo]
    flows: List[LogicFlow]
    entry_points: List[str]
    orphaned_handlers: List[str]
    complexity_metrics: Dict[str, Any]
    claude_analysis: Optional[str] = None


class DraconReverseEngineer:
    """Reverse engineer bot code into DRACON schemas."""

    def __init__(self, project_root: str, claude_integration=None):
        """Initialize reverse engineer."""
        self.project_root = Path(project_root)
        self.claude_integration = claude_integration
        self.logger = logger.bind(component="dracon_reverse")

    async def analyze_bot_architecture(self, focus_path: Optional[str] = None) -> BotArchitecture:
        """Analyze complete bot architecture and extract logical flows."""
        self.logger.info("Starting bot architecture analysis")

        # Determine analysis scope
        analysis_path = Path(focus_path) if focus_path else self.project_root / "src" / "bot"

        if not analysis_path.exists():
            raise ValueError(f"Analysis path does not exist: {analysis_path}")

        # Find and analyze all Python files
        handlers = await self._discover_handlers(analysis_path)
        flows = await self._analyze_logic_flows(handlers)

        # Analyze architecture patterns
        entry_points = self._find_entry_points(handlers)
        orphaned_handlers = self._find_orphaned_handlers(handlers, flows)
        complexity_metrics = self._calculate_complexity_metrics(handlers, flows)

        # Get Claude analysis if available
        claude_analysis = None
        if self.claude_integration:
            claude_analysis = await self._get_claude_architecture_analysis(handlers, flows)

        return BotArchitecture(
            handlers=handlers,
            flows=flows,
            entry_points=entry_points,
            orphaned_handlers=orphaned_handlers,
            complexity_metrics=complexity_metrics,
            claude_analysis=claude_analysis
        )

    async def _discover_handlers(self, analysis_path: Path) -> List[HandlerInfo]:
        """Discover all bot handlers in the codebase."""
        handlers = []

        for py_file in analysis_path.rglob("*.py"):
            if py_file.name.startswith("__"):
                continue

            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                # Parse AST
                tree = ast.parse(content)
                file_handlers = self._extract_handlers_from_ast(tree, py_file, content)
                handlers.extend(file_handlers)

            except Exception as e:
                self.logger.warning("Failed to parse file", file=str(py_file), error=str(e))

        self.logger.info("Discovered handlers", count=len(handlers))
        return handlers

    def _extract_handlers_from_ast(self, tree: ast.AST, file_path: Path, content: str) -> List[HandlerInfo]:
        """Extract handler information from AST."""
        handlers = []

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                handler_info = self._analyze_function_node(node, file_path, content)
                if handler_info:
                    handlers.append(handler_info)

        return handlers

    def _analyze_function_node(self, node: ast.FunctionDef, file_path: Path, content: str) -> Optional[HandlerInfo]:
        """Analyze a function node to determine if it's a handler."""
        func_name = node.name

        # Check if function looks like a handler
        handler_type = self._determine_handler_type(node, content)
        if not handler_type:
            return None

        # Extract handler information
        docstring = ast.get_docstring(node)
        command_name = self._extract_command_name(func_name, docstring)
        callback_data = self._extract_callback_data(node, content)

        # Analyze function body
        calls_functions = self._extract_function_calls(node)
        sends_messages = self._extract_message_sends(node)
        creates_buttons = self._extract_button_creation(node, content)
        has_error_handling = self._has_error_handling(node)
        complexity_score = self._calculate_function_complexity(node)

        return HandlerInfo(
            name=self._generate_handler_name(func_name, command_name, callback_data),
            function_name=func_name,
            file_path=str(file_path.relative_to(self.project_root)),
            line_number=node.lineno,
            handler_type=handler_type,
            command_name=command_name,
            callback_data=callback_data,
            docstring=docstring,
            calls_functions=calls_functions,
            sends_messages=sends_messages,
            creates_buttons=creates_buttons,
            has_error_handling=has_error_handling,
            complexity_score=complexity_score
        )

    def _determine_handler_type(self, node: ast.FunctionDef, content: str) -> Optional[str]:
        """Determine if function is a handler and what type."""
        func_name = node.name.lower()

        # Check function parameters for handler signature
        params = [arg.arg for arg in node.args.args]
        if not ('update' in params and 'context' in params):
            return None

        # Determine type based on name patterns
        if any(pattern in func_name for pattern in ['command', 'cmd', 'handler']):
            return 'command'
        elif any(pattern in func_name for pattern in ['callback', 'query', 'button']):
            return 'callback'
        elif any(pattern in func_name for pattern in ['message', 'text', 'handle']):
            return 'message'
        elif func_name.endswith('_handler') or func_name.endswith('_command'):
            return 'command'

        # Check for specific patterns in docstring or content
        function_content = content[node.lineno:node.end_lineno] if hasattr(node, 'end_lineno') else ""
        if 'CommandHandler' in function_content:
            return 'command'
        elif 'CallbackQueryHandler' in function_content:
            return 'callback'
        elif 'MessageHandler' in function_content:
            return 'message'

        return 'command'  # Default assumption

    def _extract_command_name(self, func_name: str, docstring: Optional[str]) -> Optional[str]:
        """Extract command name from function name or docstring."""
        # Try to extract from function name
        if func_name.endswith('_command'):
            return func_name[:-8]  # Remove '_command'
        elif func_name.endswith('_handler'):
            return func_name[:-8]  # Remove '_handler'

        # Try to extract from docstring
        if docstring:
            match = re.search(r'/(\w+)', docstring)
            if match:
                return match.group(1)

        # Generate from function name
        name = func_name.replace('_command', '').replace('_handler', '')
        return name if name else None

    def _extract_callback_data(self, node: ast.FunctionDef, content: str) -> Optional[str]:
        """Extract callback data pattern from function."""
        # Look for callback_data patterns in the function
        for child in ast.walk(node):
            if isinstance(child, ast.Str) and ':' in child.s:
                # Looks like callback data pattern
                return child.s
            elif isinstance(child, ast.Constant) and isinstance(child.value, str) and ':' in child.value:
                return child.value

        return None

    def _extract_function_calls(self, node: ast.FunctionDef) -> Set[str]:
        """Extract function calls made by this handler."""
        calls = set()

        for child in ast.walk(node):
            if isinstance(child, ast.Call):
                if isinstance(child.func, ast.Name):
                    calls.add(child.func.id)
                elif isinstance(child.func, ast.Attribute):
                    calls.add(child.func.attr)

        return calls

    def _extract_message_sends(self, node: ast.FunctionDef) -> List[str]:
        """Extract message sending patterns."""
        messages = []

        for child in ast.walk(node):
            if isinstance(child, ast.Call):
                if isinstance(child.func, ast.Attribute) and child.func.attr == 'reply_text':
                    # Try to extract message content
                    if child.args and isinstance(child.args[0], (ast.Str, ast.Constant)):
                        content = child.args[0].s if isinstance(child.args[0], ast.Str) else child.args[0].value
                        if isinstance(content, str):
                            messages.append(content[:100])  # Truncate for brevity

        return messages

    def _extract_button_creation(self, node: ast.FunctionDef, content: str) -> List[Dict[str, str]]:
        """Extract inline keyboard button creation."""
        buttons = []

        for child in ast.walk(node):
            if isinstance(child, ast.Call):
                if isinstance(child.func, ast.Name) and child.func.id == 'InlineKeyboardButton':
                    button_info = {}
                    if len(child.args) >= 2:
                        # Text and callback_data
                        if isinstance(child.args[0], (ast.Str, ast.Constant)):
                            text = child.args[0].s if isinstance(child.args[0], ast.Str) else child.args[0].value
                            button_info['text'] = text

                        # Check for callback_data in keyword arguments
                        for keyword in child.keywords:
                            if keyword.arg == 'callback_data':
                                if isinstance(keyword.value, (ast.Str, ast.Constant)):
                                    callback = keyword.value.s if isinstance(keyword.value, ast.Str) else keyword.value.value
                                    button_info['callback_data'] = callback

                    if button_info:
                        buttons.append(button_info)

        return buttons

    def _has_error_handling(self, node: ast.FunctionDef) -> bool:
        """Check if function has error handling."""
        for child in ast.walk(node):
            if isinstance(child, (ast.Try, ast.ExceptHandler)):
                return True
        return False

    def _calculate_function_complexity(self, node: ast.FunctionDef) -> int:
        """Calculate complexity score for function."""
        complexity = 1  # Base complexity

        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.For, ast.While, ast.Try)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1

        return complexity

    def _generate_handler_name(self, func_name: str, command_name: Optional[str], callback_data: Optional[str]) -> str:
        """Generate a descriptive name for the handler."""
        if command_name:
            return f"Command: /{command_name}"
        elif callback_data:
            return f"Callback: {callback_data}"
        else:
            return f"Handler: {func_name}"

    async def _analyze_logic_flows(self, handlers: List[HandlerInfo]) -> List[LogicFlow]:
        """Analyze logical flows between handlers."""
        flows = []

        # Create mapping of callback_data to handlers
        callback_map = {}
        for handler in handlers:
            if handler.callback_data:
                callback_map[handler.callback_data] = handler

        # Analyze each handler for flows to other handlers
        for handler in handlers:
            # Check buttons created by this handler
            for button in handler.creates_buttons:
                callback_data = button.get('callback_data')
                if callback_data and callback_data in callback_map:
                    target_handler = callback_map[callback_data]
                    flows.append(LogicFlow(
                        from_handler=handler.name,
                        to_handler=target_handler.name,
                        trigger_type='callback',
                        trigger_value=callback_data
                    ))

            # Check function calls that might lead to other handlers
            for func_call in handler.calls_functions:
                target_handler = next((h for h in handlers if h.function_name == func_call), None)
                if target_handler:
                    flows.append(LogicFlow(
                        from_handler=handler.name,
                        to_handler=target_handler.name,
                        trigger_type='function_call',
                        trigger_value=func_call
                    ))

        self.logger.info("Analyzed logic flows", count=len(flows))
        return flows

    def _find_entry_points(self, handlers: List[HandlerInfo]) -> List[str]:
        """Find entry point handlers (commands that start workflows)."""
        entry_points = []

        for handler in handlers:
            if handler.handler_type == 'command' and handler.command_name in ['start', 'help', 'new']:
                entry_points.append(handler.name)
            elif handler.handler_type == 'command':
                entry_points.append(handler.name)

        return entry_points

    def _find_orphaned_handlers(self, handlers: List[HandlerInfo], flows: List[LogicFlow]) -> List[str]:
        """Find handlers that are not reachable from any entry point."""
        reachable = set()
        targets = {flow.to_handler for flow in flows}

        # Find handlers that are referenced but might not be reachable
        all_handler_names = {h.name for h in handlers}
        orphaned = all_handler_names - targets

        return list(orphaned)

    def _calculate_complexity_metrics(self, handlers: List[HandlerInfo], flows: List[LogicFlow]) -> Dict[str, Any]:
        """Calculate various complexity metrics."""
        total_handlers = len(handlers)
        total_flows = len(flows)
        avg_complexity = sum(h.complexity_score for h in handlers) / total_handlers if total_handlers > 0 else 0

        handler_types = {}
        for handler in handlers:
            handler_types[handler.handler_type] = handler_types.get(handler.handler_type, 0) + 1

        return {
            'total_handlers': total_handlers,
            'total_flows': total_flows,
            'average_complexity': round(avg_complexity, 2),
            'handler_types': handler_types,
            'has_error_handling': sum(1 for h in handlers if h.has_error_handling),
            'complexity_distribution': {
                'simple': sum(1 for h in handlers if h.complexity_score <= 3),
                'medium': sum(1 for h in handlers if 3 < h.complexity_score <= 6),
                'complex': sum(1 for h in handlers if h.complexity_score > 6)
            }
        }

    async def _get_claude_architecture_analysis(self, handlers: List[HandlerInfo], flows: List[LogicFlow]) -> str:
        """Get Claude analysis of the bot architecture."""
        try:
            # Prepare analysis prompt
            analysis_text = self._generate_architecture_description(handlers, flows)

            prompt = f"""Analyze this Telegram bot architecture and provide recommendations:

{analysis_text}

Please provide:
1. Architecture quality assessment
2. Design pattern analysis
3. Potential issues and bottlenecks
4. Modernization recommendations
5. DRACON schema conversion suggestions
6. Refactoring priorities

Focus on logical flow, maintainability, and bot-specific best practices."""

            # Execute Claude analysis (assuming we have integration)
            if hasattr(self.claude_integration, 'send_message'):
                response = await self.claude_integration.send_message(prompt)
                return response
            else:
                return "Claude analysis not available"

        except Exception as e:
            self.logger.error("Claude architecture analysis failed", error=str(e))
            return f"Analysis failed: {str(e)}"

    def _generate_architecture_description(self, handlers: List[HandlerInfo], flows: List[LogicFlow]) -> str:
        """Generate human-readable architecture description."""
        description = f"BOT ARCHITECTURE ANALYSIS\n\n"

        description += f"HANDLERS ({len(handlers)}):\n"
        for handler in handlers:
            description += f"- {handler.name} ({handler.handler_type})\n"
            description += f"  File: {handler.file_path}:{handler.line_number}\n"
            description += f"  Complexity: {handler.complexity_score}\n"
            if handler.creates_buttons:
                description += f"  Buttons: {len(handler.creates_buttons)}\n"
            if handler.docstring:
                description += f"  Purpose: {handler.docstring[:100]}...\n"
            description += "\n"

        description += f"LOGICAL FLOWS ({len(flows)}):\n"
        for flow in flows:
            description += f"- {flow.from_handler} -> {flow.to_handler}\n"
            description += f"  Trigger: {flow.trigger_type}"
            if flow.trigger_value:
                description += f" ({flow.trigger_value})"
            description += "\n"

        return description

    async def generate_dracon_schema(self, architecture: BotArchitecture, schema_name: str = "Bot Architecture") -> str:
        """Generate DRACON schema from analyzed architecture."""
        self.logger.info("Generating DRACON schema from architecture")

        # Build nodes
        nodes = []
        node_id_map = {}

        # Add start node
        nodes.append({
            'id': 'start',
            'type': 'start',
            'name': 'Bot Start',
            'description': 'User interaction begins',
            'position': [0, 0]
        })

        # Add handler nodes
        for i, handler in enumerate(architecture.handlers):
            node_id = f"handler_{i}"
            node_id_map[handler.name] = node_id

            # Determine node type
            node_type = 'command' if handler.handler_type == 'command' else 'callback'
            if handler.handler_type == 'message':
                node_type = 'process'

            nodes.append({
                'id': node_id,
                'type': node_type,
                'name': handler.name,
                'description': handler.docstring or f"Handler: {handler.function_name}",
                'position': [100 + (i % 5) * 150, 100 + (i // 5) * 100],
                'properties': {
                    'function_name': handler.function_name,
                    'file_path': handler.file_path,
                    'complexity': handler.complexity_score,
                    'command_name': handler.command_name,
                    'callback_data': handler.callback_data
                }
            })

        # Add end node
        nodes.append({
            'id': 'end',
            'type': 'end',
            'name': 'Interaction Complete',
            'description': 'User interaction ends',
            'position': [500, 200]
        })

        # Build edges
        edges = []
        edge_counter = 0

        # Connect start to entry points
        for entry_point in architecture.entry_points:
            if entry_point in node_id_map:
                edges.append({
                    'id': f"edge_{edge_counter}",
                    'from_node': 'start',
                    'to_node': node_id_map[entry_point],
                    'type': 'sequence'
                })
                edge_counter += 1

        # Add flow edges
        for flow in architecture.flows:
            if flow.from_handler in node_id_map and flow.to_handler in node_id_map:
                edge_type = 'callback' if flow.trigger_type == 'callback' else 'sequence'

                edges.append({
                    'id': f"edge_{edge_counter}",
                    'from_node': node_id_map[flow.from_handler],
                    'to_node': node_id_map[flow.to_handler],
                    'type': edge_type,
                    'properties': {
                        'trigger_type': flow.trigger_type,
                        'trigger_value': flow.trigger_value
                    }
                })
                edge_counter += 1

        # Connect orphaned handlers to end (temporary solution)
        for handler in architecture.handlers:
            handler_id = node_id_map.get(handler.name)
            if handler_id and not any(edge['to_node'] == handler_id for edge in edges if edge['to_node'] != 'start'):
                edges.append({
                    'id': f"edge_{edge_counter}",
                    'from_node': handler_id,
                    'to_node': 'end',
                    'type': 'sequence'
                })
                edge_counter += 1

        # Build complete schema
        schema_data = {
            'version': '1.0',
            'name': schema_name,
            'description': f'Reverse-engineered DRACON schema from bot code ({len(architecture.handlers)} handlers)',
            'metadata': {
                'generated_from': 'reverse_engineering',
                'complexity_metrics': architecture.complexity_metrics,
                'analysis_timestamp': 'auto-generated'
            },
            'nodes': nodes,
            'edges': edges
        }

        # Convert to YAML
        yaml_content = yaml.dump(schema_data, default_flow_style=False, sort_keys=False, allow_unicode=True)

        self.logger.info("Generated DRACON schema",
                        nodes=len(nodes),
                        edges=len(edges))

        return yaml_content

    async def suggest_refactoring(self, architecture: BotArchitecture) -> Dict[str, Any]:
        """Suggest refactoring improvements based on analysis."""
        suggestions = {
            'complexity_issues': [],
            'flow_improvements': [],
            'modernization_opportunities': [],
            'architectural_patterns': []
        }

        # Analyze complexity issues
        for handler in architecture.handlers:
            if handler.complexity_score > 6:
                suggestions['complexity_issues'].append({
                    'handler': handler.name,
                    'issue': f"High complexity score: {handler.complexity_score}",
                    'recommendation': "Consider breaking into smaller functions"
                })

            if not handler.has_error_handling:
                suggestions['complexity_issues'].append({
                    'handler': handler.name,
                    'issue': "No error handling detected",
                    'recommendation': "Add try/except blocks for robustness"
                })

        # Analyze flow improvements
        if architecture.orphaned_handlers:
            suggestions['flow_improvements'].append({
                'issue': f"{len(architecture.orphaned_handlers)} orphaned handlers",
                'handlers': architecture.orphaned_handlers,
                'recommendation': "Connect orphaned handlers or remove if unused"
            })

        # Suggest modernization
        command_handlers = [h for h in architecture.handlers if h.handler_type == 'command']
        if len(command_handlers) > 10:
            suggestions['modernization_opportunities'].append({
                'opportunity': "Large number of command handlers",
                'recommendation': "Consider grouping related commands or implementing subcommands"
            })

        # Architectural patterns
        if len(architecture.flows) < len(architecture.handlers) * 0.5:
            suggestions['architectural_patterns'].append({
                'pattern': "Low interconnectivity",
                'recommendation': "Consider adding more interactive flows between handlers"
            })

        return suggestions


# Example usage functions
async def reverse_engineer_bot(project_root: str, claude_integration=None) -> Tuple[BotArchitecture, str]:
    """Reverse engineer a bot into DRACON schema."""
    engineer = DraconReverseEngineer(project_root, claude_integration)

    # Analyze architecture
    architecture = await engineer.analyze_bot_architecture()

    # Generate DRACON schema
    schema_yaml = await engineer.generate_dracon_schema(architecture)

    return architecture, schema_yaml

```

### bot/features/task_scheduler.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 19,661 Ð±Ð°Ð¹Ñ‚

```python
"""Task scheduler for automated Claude CLI execution."""

import asyncio
import structlog
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any

from ...claude.facade import ClaudeIntegration
from ...config.settings import Settings
from ...storage.models import ScheduledTaskModel
from ...storage.repositories.scheduled_task_repository import ScheduledTaskRepository
from .auto_responder import AutoResponder

logger = structlog.get_logger()


class TaskScheduler:
    """System for scheduling and automatically executing Claude CLI tasks."""

    def __init__(
        self,
        repository: ScheduledTaskRepository,
        claude_integration: ClaudeIntegration,
        settings: Settings
    ):
        """Initialize task scheduler."""
        self.repository = repository
        self.claude_integration = claude_integration
        self.settings = settings
        self.auto_responder = AutoResponder()
        self.is_running = False
        self.execution_lock = asyncio.Lock()
        self._execution_tasks: Dict[int, asyncio.Task] = {}

    async def add_scheduled_task(
        self,
        user_id: int,
        task_type: str,
        prompt: str,
        execution_time: Optional[datetime] = None,
        auto_execute: bool = True,
        auto_respond: bool = True,
        priority: int = 1,
        metadata: Optional[Dict[str, Any]] = None
    ) -> int:
        """Add a task to the execution queue."""
        task = ScheduledTaskModel(
            user_id=user_id,
            task_type=task_type,
            prompt=prompt,
            created_at=datetime.utcnow(),
            scheduled_for=execution_time,
            auto_execute=auto_execute,
            auto_respond=auto_respond,
            priority=priority,
            metadata=metadata or {}
        )

        task_id = await self.repository.create_task(task)
        logger.info(
            "Scheduled new task",
            task_id=task_id,
            user_id=user_id,
            task_type=task_type,
            scheduled_for=execution_time,
            auto_execute=auto_execute
        )
        return task_id

    async def get_pending_tasks(self, user_id: Optional[int] = None) -> List[ScheduledTaskModel]:
        """Get all pending tasks for a user or all users."""
        return await self.repository.get_pending_tasks(user_id, ready_for_execution=True)

    async def get_user_tasks(
        self,
        user_id: int,
        status: Optional[str] = None,
        limit: Optional[int] = None
    ) -> List[ScheduledTaskModel]:
        """Get tasks for a specific user."""
        return await self.repository.get_user_tasks(user_id, status, limit)

    async def cancel_task(self, task_id: int) -> bool:
        """Cancel a pending task."""
        # First try to cancel if it's currently executing
        if task_id in self._execution_tasks:
            self._execution_tasks[task_id].cancel()
            del self._execution_tasks[task_id]

        # Update status in database
        success = await self.repository.update_task_status(task_id, "cancelled")
        if success:
            logger.info("Cancelled task", task_id=task_id)
        return success

    async def delete_task(self, task_id: int) -> bool:
        """Delete a task completely."""
        # Cancel if running
        if task_id in self._execution_tasks:
            self._execution_tasks[task_id].cancel()
            del self._execution_tasks[task_id]

        success = await self.repository.delete_task(task_id)
        if success:
            logger.info("Deleted task", task_id=task_id)
        return success

    async def clear_user_tasks(self, user_id: int, status: Optional[str] = None) -> int:
        """Clear all tasks for a user."""
        # Cancel any running tasks for this user
        tasks_to_cancel = []
        for task_id, execution_task in self._execution_tasks.items():
            # We need a way to map task_id to user_id - let's get the task details
            task = await self.repository.get_task_by_id(task_id)
            if task and task.user_id == user_id:
                tasks_to_cancel.append(task_id)

        for task_id in tasks_to_cancel:
            self._execution_tasks[task_id].cancel()
            del self._execution_tasks[task_id]

        # Delete from database
        return await self.repository.delete_user_tasks(user_id, status)

    async def execute_task_queue(self, user_id: Optional[int] = None) -> Dict[str, Any]:
        """Execute all pending tasks for a user or all users."""
        async with self.execution_lock:
            pending_tasks = await self.get_pending_tasks(user_id)

            if not pending_tasks:
                logger.info("No pending tasks to execute", user_id=user_id)
                return {"executed": 0, "failed": 0, "skipped": 0}

            logger.info(f"Executing {len(pending_tasks)} pending tasks", user_id=user_id)

            results = {"executed": 0, "failed": 0, "skipped": 0}

            for task in pending_tasks:
                try:
                    # Skip if already running
                    if task.task_id in self._execution_tasks:
                        results["skipped"] += 1
                        continue

                    # Start execution in background
                    execution_task = asyncio.create_task(
                        self._execute_single_task(task)
                    )
                    self._execution_tasks[task.task_id] = execution_task

                    # For queue execution, we wait for each task to complete
                    success = await execution_task
                    if success:
                        results["executed"] += 1
                    else:
                        results["failed"] += 1

                    # Clean up the task reference
                    if task.task_id in self._execution_tasks:
                        del self._execution_tasks[task.task_id]

                except Exception as e:
                    logger.error(
                        "Error executing task",
                        task_id=task.task_id,
                        error=str(e),
                        exc_info=True
                    )
                    results["failed"] += 1

                    # Clean up on error
                    if task.task_id in self._execution_tasks:
                        del self._execution_tasks[task.task_id]

                    await self.repository.update_task_status(
                        task.task_id,
                        "failed",
                        error_message=f"Execution error: {str(e)}"
                    )

            logger.info("Task queue execution completed", results=results, user_id=user_id)
            return results

    async def _execute_single_task(self, task: ScheduledTaskModel) -> bool:
        """Execute a single task."""
        start_time = datetime.utcnow()

        try:
            # Mark task as running
            await self.repository.update_task_status(task.task_id, "running")

            logger.info(
                "Executing task",
                task_id=task.task_id,
                user_id=task.user_id,
                task_type=task.task_type
            )

            # Get working directory from metadata or use default
            working_directory = self.settings.approved_directory
            if task.metadata and "working_directory" in task.metadata:
                from pathlib import Path
                working_directory = Path(task.metadata["working_directory"])

            # Setup auto-responder if enabled
            original_responder = None
            if task.auto_respond:
                # This would integrate with Claude integration to auto-respond
                # For now, we'll pass it as a parameter
                pass

            # Execute the task through Claude integration
            response = await self.claude_integration.run_command(
                prompt=task.prompt,
                working_directory=working_directory,
                user_id=task.user_id,
                session_id=None,  # Use new session for scheduled tasks
                auto_respond=task.auto_respond
            )

            # Calculate execution duration
            duration_ms = int((datetime.utcnow() - start_time).total_seconds() * 1000)

            if response and response.content:
                # Mark as completed
                await self.repository.update_task_status(
                    task.task_id,
                    "completed",
                    result=response.content,
                    execution_duration_ms=duration_ms
                )

                logger.info(
                    "Task completed successfully",
                    task_id=task.task_id,
                    duration_ms=duration_ms
                )
                return True
            else:
                # No response received
                await self.repository.update_task_status(
                    task.task_id,
                    "failed",
                    error_message="No response received from Claude",
                    execution_duration_ms=duration_ms
                )
                logger.warning("Task failed - no response", task_id=task.task_id)
                return False

        except Exception as e:
            # Calculate duration even for failed tasks
            duration_ms = int((datetime.utcnow() - start_time).total_seconds() * 1000)

            await self.repository.update_task_status(
                task.task_id,
                "failed",
                error_message=str(e),
                execution_duration_ms=duration_ms
            )

            logger.error(
                "Task execution failed",
                task_id=task.task_id,
                error=str(e),
                duration_ms=duration_ms,
                exc_info=True
            )
            return False

    async def retry_failed_tasks(self, user_id: Optional[int] = None) -> Dict[str, Any]:
        """Retry failed tasks that haven't exceeded max retries."""
        failed_tasks = await self.repository.get_failed_tasks_for_retry()

        if user_id:
            failed_tasks = [task for task in failed_tasks if task.user_id == user_id]

        if not failed_tasks:
            logger.info("No failed tasks to retry", user_id=user_id)
            return {"retried": 0, "failed": 0, "skipped": 0}

        logger.info(f"Retrying {len(failed_tasks)} failed tasks", user_id=user_id)

        results = {"retried": 0, "failed": 0, "skipped": 0}

        for task in failed_tasks:
            if not task.can_retry():
                results["skipped"] += 1
                continue

            try:
                # Reset status to pending for retry
                await self.repository.update_task_status(task.task_id, "pending")

                # Execute the task
                success = await self._execute_single_task(task)
                if success:
                    results["retried"] += 1
                else:
                    results["failed"] += 1

            except Exception as e:
                logger.error(
                    "Error retrying task",
                    task_id=task.task_id,
                    error=str(e),
                    exc_info=True
                )
                results["failed"] += 1

        logger.info("Task retry completed", results=results, user_id=user_id)
        return results

    async def get_task_statistics(self, user_id: Optional[int] = None) -> Dict[str, Any]:
        """Get task execution statistics."""
        return await self.repository.get_task_statistics(user_id)

    async def cleanup_old_tasks(self, days_old: int = 30) -> int:
        """Clean up old completed/failed tasks."""
        return await self.repository.cleanup_old_tasks(days_old)

    def get_running_tasks(self) -> List[int]:
        """Get list of currently running task IDs."""
        return list(self._execution_tasks.keys())

    async def start_background_processor(self, check_interval: int = 60) -> None:
        """Start background task processor that checks for pending tasks periodically."""
        if self.is_running:
            logger.warning("Background processor already running")
            return

        self.is_running = True
        logger.info("Starting background task processor", check_interval=check_interval)

        try:
            while self.is_running:
                try:
                    # Execute any pending tasks
                    await self.execute_task_queue()

                    # Retry failed tasks (with backoff)
                    await self.retry_failed_tasks()

                    # Cleanup old tasks daily
                    if datetime.utcnow().hour == 2:  # 2 AM cleanup
                        await self.cleanup_old_tasks()

                except Exception as e:
                    logger.error(
                        "Error in background processor",
                        error=str(e),
                        exc_info=True
                    )

                # Wait for next check
                await asyncio.sleep(check_interval)

        except asyncio.CancelledError:
            logger.info("Background processor cancelled")
        finally:
            self.is_running = False

    def stop_background_processor(self) -> None:
        """Stop the background task processor."""
        logger.info("Stopping background task processor")
        self.is_running = False

        # Cancel all running tasks
        for task_id, execution_task in self._execution_tasks.items():
            execution_task.cancel()
            logger.info("Cancelled running task", task_id=task_id)

        self._execution_tasks.clear()

    # Predefined task templates
    @staticmethod
    def create_code_analysis_task(
        user_id: int,
        project_path: str,
        analysis_type: str = "full"
    ) -> Dict[str, Any]:
        """Create a code analysis task template."""
        prompts = {
            "full": """Ð’Ð¸ÐºÐ¾Ð½Ð°Ð¹Ñ‚Ðµ Ð¿Ð¾Ð²Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· ÐºÐ¾Ð´Ñƒ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ:

1. **Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ**: ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ñ‚Ð° Ð¾Ñ€Ð³Ð°Ð½Ñ–Ð·Ð°Ñ†Ñ–ÑŽ Ñ„Ð°Ð¹Ð»Ñ–Ð²
2. **Ð¯ÐºÑ–ÑÑ‚ÑŒ ÐºÐ¾Ð´Ñƒ**: ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ ÑÑ‚Ð¸Ð»ÑŒ, Ñ‡Ð¸Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ñ–ÑÑ‚ÑŒ Ñ‚Ð° Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ñ–ÑÑ‚ÑŒ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð°Ð¼
3. **ÐŸÐ¾Ñ‚ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸**: Ð—Ð½Ð°Ð¹Ð´Ñ–Ñ‚ÑŒ Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ñ– Ð±Ð°Ð³Ð¸, ÑƒÑ€Ð°Ð·Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ– Ð±ÐµÐ·Ð¿ÐµÐºÐ¸
4. **ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ**: Ð—Ð°Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–
5. **Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ—**: Ð”Ð°Ð¹Ñ‚Ðµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ– Ð¿Ð¾Ñ€Ð°Ð´Ð¸ Ñ‰Ð¾Ð´Ð¾ Ð¿Ð¾Ð»Ñ–Ð¿ÑˆÐµÐ½Ð½Ñ

Ð¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð·Ð²Ñ–Ñ‚ Ð· Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´Ð°Ð¼Ð¸ Ñ‚Ð° Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–ÑÐ¼Ð¸.""",

            "security": """ÐŸÑ€Ð¾Ð²ÐµÐ´Ñ–Ñ‚ÑŒ Ð°Ð½Ð°Ð»Ñ–Ð· Ð±ÐµÐ·Ð¿ÐµÐºÐ¸ ÐºÐ¾Ð´Ñƒ:

1. **Ð£Ñ€Ð°Ð·Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ–**: Ð—Ð½Ð°Ð¹Ð´Ñ–Ñ‚ÑŒ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ– Ð·Ð°Ð³Ñ€Ð¾Ð·Ð¸ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸
2. **ÐÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ**: ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸ Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ— Ñ‚Ð° Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ—
3. **Ð’Ð°Ð»Ñ–Ð´Ð°Ñ†Ñ–Ñ Ð´Ð°Ð½Ð¸Ñ…**: ÐžÑ†Ñ–Ð½Ñ–Ñ‚ÑŒ Ð²Ð°Ð»Ñ–Ð´Ð°Ñ†Ñ–ÑŽ Ð²Ñ…Ñ–Ð´Ð½Ð¸Ñ… Ð´Ð°Ð½Ð¸Ñ…
4. **Ð¡ÐµÐºÑ€ÐµÑ‚Ð¸**: ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ, Ñ‡Ð¸ Ð½ÐµÐ¼Ð°Ñ” Ð·Ð°Ñ…Ð°Ñ€Ð´ÐºÐ¾Ð´ÐµÐ½Ð¸Ñ… Ð¿Ð°Ñ€Ð¾Ð»Ñ–Ð²/ÐºÐ»ÑŽÑ‡Ñ–Ð²
5. **Ð—Ð²Ñ–Ñ‚**: Ð¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ Ð·Ð²Ñ–Ñ‚ Ð· Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–ÑÐ¼Ð¸ Ñ‰Ð¾Ð´Ð¾ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸""",

            "performance": """ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ ÐºÐ¾Ð´Ñƒ:

1. **Ð’ÑƒÐ·ÑŒÐºÑ– Ð¼Ñ–ÑÑ†Ñ**: Ð—Ð½Ð°Ð¹Ð´Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ñ–Ð»ÑŒÐ½Ñ– Ñ‡Ð°ÑÑ‚Ð¸Ð½Ð¸ ÐºÐ¾Ð´Ñƒ
2. **ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¸**: ÐžÑ†Ñ–Ð½Ñ–Ñ‚ÑŒ ÑÐºÐ»Ð°Ð´Ð½Ñ–ÑÑ‚ÑŒ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ–Ð²
3. **Ð‘Ð°Ð·Ð¸ Ð´Ð°Ð½Ð¸Ñ…**: ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ Ð·Ð°Ð¿Ð¸Ñ‚Ð¸ Ñ‚Ð° Ñ–Ð½Ð´ÐµÐºÑÐ¸
4. **ÐšÐµÑˆÑƒÐ²Ð°Ð½Ð½Ñ**: ÐžÑ†Ñ–Ð½Ñ–Ñ‚ÑŒ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ ÐºÐµÑˆÑƒ
5. **Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ—**: Ð—Ð°Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ– Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ—"""
        }

        return {
            "task_type": "code_analysis",
            "prompt": prompts.get(analysis_type, prompts["full"]),
            "metadata": {
                "working_directory": project_path,
                "analysis_type": analysis_type
            }
        }

    @staticmethod
    def create_documentation_task(user_id: int, doc_type: str = "api") -> Dict[str, Any]:
        """Create a documentation generation task template."""
        prompts = {
            "api": """Ð—Ð³ÐµÐ½ÐµÑ€ÑƒÐ¹Ñ‚Ðµ API Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–ÑŽ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ:

1. **Ð•Ð½Ð´Ð¿Ð¾Ñ–Ð½Ñ‚Ð¸**: ÐžÐ¿Ð¸ÑˆÑ–Ñ‚ÑŒ Ð²ÑÑ– API ÐµÐ½Ð´Ð¿Ð¾Ñ–Ð½Ñ‚Ð¸ Ð· Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸
2. **ÐœÐ¾Ð´ÐµÐ»Ñ– Ð´Ð°Ð½Ð¸Ñ…**: Ð—Ð°Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ÑƒÐ¹Ñ‚Ðµ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸ Ð´Ð°Ð½Ð¸Ñ…
3. **ÐÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ**: ÐžÐ¿Ð¸ÑˆÑ–Ñ‚ÑŒ Ð¼ÐµÑ‚Ð¾Ð´Ð¸ Ð°ÑƒÑ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ—
4. **ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸**: Ð”Ð¾Ð´Ð°Ð¹Ñ‚Ðµ Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´Ð¸ Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð² Ñ‚Ð° Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÐµÐ¹
5. **ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ¸**: ÐžÐ¿Ð¸ÑˆÑ–Ñ‚ÑŒ ÐºÐ¾Ð´Ð¸ Ð¿Ð¾Ð¼Ð¸Ð»Ð¾Ðº Ñ‚Ð° Ñ—Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ

Ð¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–ÑŽ Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ– Markdown.""",

            "readme": """ÐžÐ½Ð¾Ð²Ñ–Ñ‚ÑŒ Ð°Ð±Ð¾ ÑÑ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ README.md Ñ„Ð°Ð¹Ð»:

1. **ÐžÐ¿Ð¸Ñ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚Ñƒ**: ÐšÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾ Ð¾Ð¿Ð¸ÑˆÑ–Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð·Ð½Ð°Ñ‡ÐµÐ½Ð½Ñ
2. **Ð’ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ**: ÐŸÐ¾ÐºÑ€Ð¾ÐºÐ¾Ð²Ñ– Ñ–Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ñ–Ñ—
3. **Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ**: ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ
4. **ÐšÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ**: ÐÐ°Ð»Ð°ÑˆÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ñ‚Ð° Ð·Ð¼Ñ–Ð½Ð½Ñ– ÑÐµÑ€ÐµÐ´Ð¾Ð²Ð¸Ñ‰Ð°
5. **ÐšÐ¾Ð½Ñ‚Ñ€Ð¸Ð±ÑƒÑ†Ñ–Ñ**: ÐŸÑ€Ð°Ð²Ð¸Ð»Ð° Ð´Ð»Ñ Ñ€Ð¾Ð·Ñ€Ð¾Ð±Ð½Ð¸ÐºÑ–Ð²

Ð—Ñ€Ð¾Ð±Ñ–Ñ‚ÑŒ README Ð·Ñ€Ð¾Ð·ÑƒÐ¼Ñ–Ð»Ð¸Ð¼ Ñ‚Ð° ÐºÐ¾Ñ€Ð¸ÑÐ½Ð¸Ð¼.""",

            "changelog": """Ð—Ð³ÐµÐ½ÐµÑ€ÑƒÐ¹Ñ‚Ðµ CHANGELOG.md:

1. **ÐžÑÑ‚Ð°Ð½Ð½Ñ– Ð·Ð¼Ñ–Ð½Ð¸**: ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ git Ñ–ÑÑ‚Ð¾Ñ€Ñ–ÑŽ
2. **ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ**: Ð Ð¾Ð·Ð´Ñ–Ð»Ñ–Ñ‚ÑŒ Ð½Ð° Added, Changed, Fixed, Removed
3. **Ð’ÐµÑ€ÑÑ–Ñ—**: ÐžÑ€Ð³Ð°Ð½Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ð·Ð° Ð²ÐµÑ€ÑÑ–ÑÐ¼Ð¸
4. **Ð”Ð°Ñ‚Ð¸**: Ð”Ð¾Ð´Ð°Ð¹Ñ‚Ðµ Ð´Ð°Ñ‚Ð¸ Ñ€ÐµÐ»Ñ–Ð·Ñ–Ð²
5. **Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚**: Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚ Keep a Changelog"""
        }

        return {
            "task_type": "documentation",
            "prompt": prompts.get(doc_type, prompts["readme"]),
            "metadata": {"doc_type": doc_type}
        }

    @staticmethod
    def create_refactoring_task(
        user_id: int,
        target_files: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Create a code refactoring task template."""
        files_prompt = ""
        if target_files:
            files_prompt = f"\nÐ¦Ñ–Ð»ÑŒÐ¾Ð²Ñ– Ñ„Ð°Ð¹Ð»Ð¸: {', '.join(target_files)}"

        prompt = f"""Ð’Ð¸ÐºÐ¾Ð½Ð°Ð¹Ñ‚Ðµ Ñ€ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³ ÐºÐ¾Ð´Ñƒ:{files_prompt}

1. **ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸**: ÐŸÐ¾Ð»Ñ–Ð¿ÑˆÑ–Ñ‚ÑŒ Ð¾Ñ€Ð³Ð°Ð½Ñ–Ð·Ð°Ñ†Ñ–ÑŽ ÐºÐ¾Ð´Ñƒ
2. **Ð’Ð¸Ð´Ð°Ð»ÐµÐ½Ð½Ñ Ð´ÑƒÐ±Ð»ÑŽÐ²Ð°Ð½Ð½Ñ**: Ð£ÑÑƒÐ½ÑŒÑ‚Ðµ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑŽÐ²Ð°Ð½Ñ– Ñ‡Ð°ÑÑ‚Ð¸Ð½Ð¸
3. **ÐŸÐ¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ Ñ‡Ð¸Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ñ–**: Ð—Ñ€Ð¾Ð±Ñ–Ñ‚ÑŒ ÐºÐ¾Ð´ Ð±Ñ–Ð»ÑŒÑˆ Ð·Ñ€Ð¾Ð·ÑƒÐ¼Ñ–Ð»Ð¸Ð¼
4. **Ð’Ð¸Ð´Ñ–Ð»ÐµÐ½Ð½Ñ Ñ„ÑƒÐ½ÐºÑ†Ñ–Ð¹**: Ð Ð¾Ð·Ð±Ð¸Ð¹Ñ‚Ðµ Ð²ÐµÐ»Ð¸ÐºÑ– Ñ„ÑƒÐ½ÐºÑ†Ñ–Ñ— Ð½Ð° Ð¼ÐµÐ½ÑˆÑ–
5. **Ð¢Ð¸Ð¿Ñ–Ð·Ð°Ñ†Ñ–Ñ**: Ð”Ð¾Ð´Ð°Ð¹Ñ‚Ðµ/Ð¿Ð¾Ð»Ñ–Ð¿ÑˆÑ–Ñ‚ÑŒ Ñ‚Ð¸Ð¿Ð¸ Ð´Ð°Ð½Ð¸Ñ…
6. **Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ**: Ð”Ð¾Ð´Ð°Ð¹Ñ‚Ðµ ÐºÐ¾Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ñ– Ð´Ð¾ ÑÐºÐ»Ð°Ð´Ð½Ð¸Ñ… Ñ‡Ð°ÑÑ‚Ð¸Ð½

Ð—Ð±ÐµÑ€ÐµÐ¶Ñ–Ñ‚ÑŒ Ñ„ÑƒÐ½ÐºÑ†Ñ–Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ–ÑÑ‚ÑŒ, Ð¿Ð¾Ð»Ñ–Ð¿ÑˆÐ¸Ð²ÑˆÐ¸ ÑÐºÑ–ÑÑ‚ÑŒ ÐºÐ¾Ð´Ñƒ."""

        return {
            "task_type": "refactoring",
            "prompt": prompt,
            "metadata": {"target_files": target_files or []}
        }

```

### bot/features/dnd_prompt_manager.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 18,746 Ð±Ð°Ð¹Ñ‚

```python
"""
DND Prompt Manager - Ð£Ð¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°Ð¼Ð¸ Ð´Ð»Ñ Do Not Disturb Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ
Ð”Ð¾Ð·Ð²Ð¾Ð»ÑÑ” Ð´Ð¾Ð´Ð°Ð²Ð°Ñ‚Ð¸, Ñ€ÐµÐ´Ð°Ð³ÑƒÐ²Ð°Ñ‚Ð¸ Ñ‚Ð° Ð·Ð±ÐµÑ€Ñ–Ð³Ð°Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¸ Ñƒ markdown Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ–
"""

import asyncio
import json
import os
from datetime import datetime, time
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
import structlog

logger = structlog.get_logger()

@dataclass
class DNDPrompt:
    """Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° DND Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ"""
    id: str
    title: str
    description: str
    prompt_content: str
    tags: List[str]
    priority: int  # 1-10, Ð´Ðµ 10 - Ð½Ð°Ð¹Ð²Ð¸Ñ‰Ð¸Ð¹
    created_at: str
    updated_at: str
    enabled: bool = True
    category: str = "general"
    estimated_duration: int = 30  # Ñ…Ð²Ð¸Ð»Ð¸Ð½Ð¸
    required_tools: List[str] = None
    
    def __post_init__(self):
        if self.required_tools is None:
            self.required_tools = []

class DNDPromptManager:
    """ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ DND Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°Ð¼Ð¸"""
    
    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.prompts_dir = data_dir / "dnd_prompts"
        self.prompts_dir.mkdir(exist_ok=True)
        
        self.config_file = self.prompts_dir / "config.json"
        self.prompts: Dict[str, DNDPrompt] = {}
        
        # Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ð¸Ñ‚Ð¸ Ñ–ÑÐ½ÑƒÑŽÑ‡Ñ– Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¸
        asyncio.create_task(self.load_prompts())
    
    async def load_prompts(self) -> Dict[str, DNDPrompt]:
        """Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ð¸Ñ‚Ð¸ Ð²ÑÑ– Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¸ Ð· Ñ„Ð°Ð¹Ð»Ñ–Ð²"""
        try:
            # Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ð¸Ñ‚Ð¸ ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–ÑŽ
            config = {}
            if self.config_file.exists():
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
            
            # Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ð¸Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¸ Ð· markdown Ñ„Ð°Ð¹Ð»Ñ–Ð²
            self.prompts = {}
            
            for md_file in self.prompts_dir.glob("*.md"):
                if md_file.name == "README.md":
                    continue
                    
                prompt = await self._load_prompt_from_markdown(md_file)
                if prompt:
                    self.prompts[prompt.id] = prompt
            
            logger.info(f"Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð¾ {len(self.prompts)} DND Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²")
            return self.prompts
            
        except Exception as e:
            logger.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²: {e}")
            return {}
    
    async def _load_prompt_from_markdown(self, file_path: Path) -> Optional[DNDPrompt]:
        """Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ð¸Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð· markdown Ñ„Ð°Ð¹Ð»Ñƒ"""
        try:
            content = file_path.read_text(encoding='utf-8')
            
            # ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð¸Ñ… Ð· YAML frontmatter
            if content.startswith('---'):
                parts = content.split('---', 2)
                if len(parts) >= 3:
                    import yaml
                    metadata = yaml.safe_load(parts[1])
                    prompt_content = parts[2].strip()
                    
                    return DNDPrompt(
                        id=metadata.get('id', file_path.stem),
                        title=metadata.get('title', file_path.stem),
                        description=metadata.get('description', ''),
                        prompt_content=prompt_content,
                        tags=metadata.get('tags', []),
                        priority=metadata.get('priority', 5),
                        created_at=metadata.get('created_at', datetime.now().isoformat()),
                        updated_at=metadata.get('updated_at', datetime.now().isoformat()),
                        enabled=metadata.get('enabled', True),
                        category=metadata.get('category', 'general'),
                        estimated_duration=metadata.get('estimated_duration', 30),
                        required_tools=metadata.get('required_tools', [])
                    )
            
            # Ð¯ÐºÑ‰Ð¾ Ð½ÐµÐ¼Ð°Ñ” frontmatter, ÑÑ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð±Ð°Ð·Ð¾Ð²Ð¸Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
            return DNDPrompt(
                id=file_path.stem,
                title=file_path.stem.replace('_', ' ').title(),
                description=f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Ð· Ñ„Ð°Ð¹Ð»Ñƒ {file_path.name}",
                prompt_content=content,
                tags=[],
                priority=5,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat()
            )
            
        except Exception as e:
            logger.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ Ð· {file_path}: {e}")
            return None
    
    async def add_prompt(self, prompt: DNDPrompt) -> bool:
        """Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ð¸Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚"""
        try:
            # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ ÑƒÐ½Ñ–ÐºÐ°Ð»ÑŒÐ½Ñ–ÑÑ‚ÑŒ ID
            if prompt.id in self.prompts:
                logger.warning(f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Ð· ID '{prompt.id}' Ð²Ð¶Ðµ Ñ–ÑÐ½ÑƒÑ”")
                return False
            
            # Ð—Ð±ÐµÑ€ÐµÐ³Ñ‚Ð¸ Ð² Ð¿Ð°Ð¼'ÑÑ‚Ñ–
            self.prompts[prompt.id] = prompt
            
            # Ð—Ð±ÐµÑ€ÐµÐ³Ñ‚Ð¸ Ð² Ñ„Ð°Ð¹Ð»
            await self._save_prompt_to_markdown(prompt)
            
            logger.info(f"Ð”Ð¾Ð´Ð°Ð½Ð¾ Ð½Ð¾Ð²Ð¸Ð¹ DND Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚: {prompt.title}")
            return True
            
        except Exception as e:
            logger.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð´Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ: {e}")
            return False
    
    async def _save_prompt_to_markdown(self, prompt: DNDPrompt) -> None:
        """Ð—Ð±ÐµÑ€ÐµÐ³Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ñƒ markdown Ñ„Ð°Ð¹Ð»"""
        file_path = self.prompts_dir / f"{prompt.id}.md"
        
        # Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ YAML frontmatter
        metadata = {
            'id': prompt.id,
            'title': prompt.title,
            'description': prompt.description,
            'tags': prompt.tags,
            'priority': prompt.priority,
            'created_at': prompt.created_at,
            'updated_at': prompt.updated_at,
            'enabled': prompt.enabled,
            'category': prompt.category,
            'estimated_duration': prompt.estimated_duration,
            'required_tools': prompt.required_tools
        }
        
        import yaml
        frontmatter = yaml.dump(metadata, allow_unicode=True, default_flow_style=False)
        
        content = f"---\n{frontmatter}---\n\n{prompt.prompt_content}"
        
        file_path.write_text(content, encoding='utf-8')
    
    async def update_prompt(self, prompt_id: str, updates: Dict[str, Any]) -> bool:
        """ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸ Ñ–ÑÐ½ÑƒÑŽÑ‡Ð¸Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚"""
        try:
            if prompt_id not in self.prompts:
                logger.warning(f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Ð· ID '{prompt_id}' Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾")
                return False
            
            # ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
            prompt = self.prompts[prompt_id]
            for key, value in updates.items():
                if hasattr(prompt, key):
                    setattr(prompt, key, value)
            
            prompt.updated_at = datetime.now().isoformat()
            
            # Ð—Ð±ÐµÑ€ÐµÐ³Ñ‚Ð¸ Ð·Ð¼Ñ–Ð½Ð¸
            await self._save_prompt_to_markdown(prompt)
            
            logger.info(f"ÐžÐ½Ð¾Ð²Ð»ÐµÐ½Ð¾ DND Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚: {prompt.title}")
            return True
            
        except Exception as e:
            logger.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ: {e}")
            return False
    
    async def delete_prompt(self, prompt_id: str) -> bool:
        """Ð’Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚"""
        try:
            if prompt_id not in self.prompts:
                logger.warning(f"ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Ð· ID '{prompt_id}' Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾")
                return False
            
            # Ð’Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸ Ð· Ð¿Ð°Ð¼'ÑÑ‚Ñ–
            del self.prompts[prompt_id]
            
            # Ð’Ð¸Ð´Ð°Ð»Ð¸Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»
            file_path = self.prompts_dir / f"{prompt_id}.md"
            if file_path.exists():
                file_path.unlink()
            
            logger.info(f"Ð’Ð¸Ð´Ð°Ð»ÐµÐ½Ð¾ DND Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚: {prompt_id}")
            return True
            
        except Exception as e:
            logger.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð²Ð¸Ð´Ð°Ð»ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ: {e}")
            return False
    
    async def get_prompt(self, prompt_id: str) -> Optional[DNDPrompt]:
        """ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð·Ð° ID"""
        return self.prompts.get(prompt_id)
    
    async def list_prompts(self, category: Optional[str] = None, 
                          enabled_only: bool = True) -> List[DNDPrompt]:
        """ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²"""
        prompts = list(self.prompts.values())
        
        if enabled_only:
            prompts = [p for p in prompts if p.enabled]
        
        if category:
            prompts = [p for p in prompts if p.category == category]
        
        # Ð¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð° Ð¿Ñ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð¾Ð¼
        return sorted(prompts, key=lambda p: (-p.priority, p.title))
    
    async def get_prompts_for_execution(self, max_duration: int = 120) -> List[DNDPrompt]:
        """ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¸ Ð´Ð»Ñ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð² DND Ð¿ÐµÑ€Ñ–Ð¾Ð´"""
        suitable_prompts = []
        
        for prompt in self.prompts.values():
            if (prompt.enabled and 
                prompt.estimated_duration <= max_duration):
                suitable_prompts.append(prompt)
        
        # Ð¡Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð° Ð¿Ñ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð¾Ð¼
        return sorted(suitable_prompts, key=lambda p: -p.priority)
    
    async def create_sample_prompts(self) -> None:
        """Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²"""
        sample_prompts = [
            DNDPrompt(
                id="code_review_daily",
                title="Ð©Ð¾Ð´ÐµÐ½Ð½Ðµ Ñ€ÐµÐ²ÑŽ ÐºÐ¾Ð´Ñƒ",
                description="ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ð·Ð¼Ñ–Ð½ Ð² ÐºÐ¾Ð´Ñ– Ð·Ð° Ð´ÐµÐ½ÑŒ",
                prompt_content="""Ð’Ð¸ÐºÐ¾Ð½Ð°Ð¹ ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ðµ Ñ€ÐµÐ²ÑŽ ÐºÐ¾Ð´Ñƒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ:

1. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ð¾ÑÑ‚Ð°Ð½Ð½Ñ– Ð·Ð¼Ñ–Ð½Ð¸ Ð² git Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ñ—
2. ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ ÐºÐ¾Ð´ Ð½Ð° Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð½Ñ–ÑÑ‚ÑŒ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð°Ð¼
3. Ð—Ð½Ð°Ð¹Ð´Ð¸ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ñ–Ð¹Ð½Ñ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸
4. Ð—Ð°Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÐ¹ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸
5. Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸ Ð·Ð²Ñ–Ñ‚ Ð· Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–ÑÐ¼Ð¸

Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ¹ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸:
- `git log --oneline --since="1 day ago"`
- `git diff HEAD~1..HEAD`
- ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ñ„Ð°Ð¹Ð»Ð¸ Ñ‡ÐµÑ€ÐµÐ· Read tool
- Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸ markdown Ð·Ð²Ñ–Ñ‚ Ð· Ð²Ð¸ÑÐ½Ð¾Ð²ÐºÐ°Ð¼Ð¸""",
                tags=["code-review", "git", "analysis"],
                priority=8,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                category="code-quality",
                estimated_duration=45,
                required_tools=["Read", "Bash", "Write"]
            ),
            
            DNDPrompt(
                id="security_audit",
                title="ÐÑƒÐ´Ð¸Ñ‚ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸",
                description="ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸ Ð½Ð° Ð²Ñ€Ð°Ð·Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ–",
                prompt_content="""ÐŸÑ€Ð¾Ð²ÐµÐ´Ð¸ Ð°ÑƒÐ´Ð¸Ñ‚ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñƒ:

1. Ð¡ÐºÐ°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ÑÑ‚ÐµÐ¹ Ð½Ð° Ð²Ñ–Ð´Ð¾Ð¼Ñ– Ð²Ñ€Ð°Ð·Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ–
2. ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ð¹Ð½Ð¸Ñ… Ñ„Ð°Ð¹Ð»Ñ–Ð²
3. ÐÐ½Ð°Ð»Ñ–Ð· authentication Ñ‚Ð° authorization Ð»Ð¾Ð³Ñ–ÐºÐ¸
4. ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° input validation
5. ÐžÐ³Ð»ÑÐ´ Ð»Ð¾Ð³ÑƒÐ²Ð°Ð½Ð½Ñ Ñ‚Ð° Ð¼Ð¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ñƒ

Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð·Ð²Ñ–Ñ‚ Ð·:
- Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¸Ð¼Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°Ð¼Ð¸
- Ð Ñ–Ð²Ð½ÐµÐ¼ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¾ÑÑ‚Ñ–
- ÐŸÐ»Ð°Ð½Ð¾Ð¼ ÑƒÑÑƒÐ½ÐµÐ½Ð½Ñ
- Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–ÑÐ¼Ð¸ Ð´Ð»Ñ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ""",
                tags=["security", "audit", "vulnerabilities"],
                priority=9,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                category="security",
                estimated_duration=60,
                required_tools=["Read", "Bash", "Grep", "Write"]
            ),
            
            DNDPrompt(
                id="documentation_update",
                title="ÐžÐ½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—",
                description="ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ README Ñ‚Ð° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—",
                prompt_content="""ÐžÐ½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð½Ð¾Ñ— Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—:

1. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ ÑÑ‚Ð°Ð½ ÐºÐ¾Ð´Ñƒ
2. ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ–ÑÑ‚ÑŒ README.md
3. ÐžÐ½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ API Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—
4. ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´Ð¸ ÐºÐ¾Ð´Ñƒ Ð² Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—
5. Ð”Ð¾Ð´Ð°Ð¹ Ð½Ð¾Ð²Ñ– Ñ„ÑƒÐ½ÐºÑ†Ñ–Ñ— Ð² Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–ÑŽ

Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚:
- ÐžÐ½Ð¾Ð²Ð»ÐµÐ½Ð¸Ð¹ README.md
- ÐÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ API
- ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ
- Changelog Ð· Ð¾ÑÑ‚Ð°Ð½Ð½Ñ–Ð¼Ð¸ Ð·Ð¼Ñ–Ð½Ð°Ð¼Ð¸""",
                tags=["documentation", "readme", "api"],
                priority=6,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                category="documentation",
                estimated_duration=30,
                required_tools=["Read", "Write", "Edit"]
            ),
            
            DNDPrompt(
                id="performance_analysis",
                title="ÐÐ½Ð°Ð»Ñ–Ð· Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–",
                description="ÐŸÐ¾ÑˆÑƒÐº bottlenecks Ñ‚Ð° Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ",
                prompt_content="""ÐÐ½Ð°Ð»Ñ–Ð· Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸:

1. ÐŸÑ€Ð¾Ñ„Ñ–Ð»ÑŽÐ²Ð°Ð½Ð½Ñ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¸Ñ… Ñ‡Ð°ÑÑ‚Ð¸Ð½ ÐºÐ¾Ð´Ñƒ
2. ÐÐ½Ð°Ð»Ñ–Ð· database queries
3. ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° memory usage
4. ÐžÐ¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ–Ð²
5. Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ— Ð· Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ

Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸ Ð·Ð²Ñ–Ñ‚ Ð·:
- Ð’Ð¸ÑÐ²Ð»ÐµÐ½Ð¸Ð¼Ð¸ bottlenecks
- ÐœÐµÑ‚Ñ€Ð¸ÐºÐ°Ð¼Ð¸ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–
- ÐŸÐ»Ð°Ð½Ð¾Ð¼ Ð¾Ð¿Ñ‚Ð¸Ð¼Ñ–Ð·Ð°Ñ†Ñ–Ñ—
- ÐžÑ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð¸Ð¼Ð¸ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½ÑÐ¼Ð¸""",
                tags=["performance", "optimization", "profiling"],
                priority=7,
                created_at=datetime.now().isoformat(),
                updated_at=datetime.now().isoformat(),
                category="optimization",
                estimated_duration=40,
                required_tools=["Read", "Bash", "Write"]
            )
        ]
        
        for prompt in sample_prompts:
            await self.add_prompt(prompt)
    
    async def export_prompts(self, file_path: Path) -> bool:
        """Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ð²ÑÑ– Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¸ Ð² JSON"""
        try:
            export_data = {
                'exported_at': datetime.now().isoformat(),
                'prompts': [asdict(prompt) for prompt in self.prompts.values()]
            }
            
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Ð•ÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¾Ð²Ð°Ð½Ð¾ {len(self.prompts)} Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð² Ð² {file_path}")
            return True
            
        except Exception as e:
            logger.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° ÐµÐºÑÐ¿Ð¾Ñ€Ñ‚Ñƒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²: {e}")
            return False
    
    async def import_prompts(self, file_path: Path) -> int:
        """Ð†Ð¼Ð¿Ð¾Ñ€Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¸ Ð· JSON"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            imported_count = 0
            for prompt_data in data.get('prompts', []):
                prompt = DNDPrompt(**prompt_data)
                if await self.add_prompt(prompt):
                    imported_count += 1
            
            logger.info(f"Ð†Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¾Ð²Ð°Ð½Ð¾ {imported_count} Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð² Ð· {file_path}")
            return imported_count
            
        except Exception as e:
            logger.error(f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ñ–Ð¼Ð¿Ð¾Ñ€Ñ‚Ñƒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²: {e}")
            return 0

async def create_default_readme(prompts_dir: Path) -> None:
    """Ð¡Ñ‚Ð²Ð¾Ñ€Ð¸Ñ‚Ð¸ README Ð´Ð»Ñ Ð¿Ð°Ð¿ÐºÐ¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²"""
    readme_content = """# DND Prompts - ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚Ð¸ Ð´Ð»Ñ Do Not Disturb Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ

Ð¦Ñ Ð¿Ð°Ð¿ÐºÐ° Ð¼Ñ–ÑÑ‚Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¸, ÑÐºÑ– Ð²Ð¸ÐºÐ¾Ð½ÑƒÑŽÑ‚ÑŒÑÑ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð¿Ñ–Ð´ Ñ‡Ð°Ñ DND Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ (23:00-08:00).

## Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ñ„Ð°Ð¹Ð»Ñ–Ð²

ÐšÐ¾Ð¶ÐµÐ½ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð·Ð±ÐµÑ€Ñ–Ð³Ð°Ñ”Ñ‚ÑŒÑÑ Ñƒ Ð¾ÐºÑ€ÐµÐ¼Ð¾Ð¼Ñƒ `.md` Ñ„Ð°Ð¹Ð»Ñ– Ð· YAML frontmatter:

```yaml
---
id: unique_prompt_id
title: ÐÐ°Ð·Ð²Ð° Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñƒ
description: ÐžÐ¿Ð¸Ñ Ñ‚Ð¾Ð³Ð¾, Ñ‰Ð¾ Ñ€Ð¾Ð±Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚
tags: [tag1, tag2, tag3]
priority: 8  # 1-10, Ð´Ðµ 10 - Ð½Ð°Ð¹Ð²Ð¸Ñ‰Ð¸Ð¹ Ð¿Ñ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚
created_at: 2025-01-15T10:30:00
updated_at: 2025-01-15T10:30:00
enabled: true
category: code-quality
estimated_duration: 45  # Ñ…Ð²Ð¸Ð»Ð¸Ð½Ð¸
required_tools: [Read, Write, Bash]
---

Ð¢ÑƒÑ‚ Ð¹Ð´Ðµ ÑÐ°Ð¼ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ñƒ markdown Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ–...
```

## ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ñ— Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²

- **code-quality**: Ð ÐµÐ²ÑŽ ÐºÐ¾Ð´Ñƒ, Ñ€ÐµÑ„Ð°ÐºÑ‚Ð¾Ñ€Ð¸Ð½Ð³
- **security**: ÐÑƒÐ´Ð¸Ñ‚ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸, ÑÐºÐ°Ð½ÑƒÐ²Ð°Ð½Ð½Ñ Ð²Ñ€Ð°Ð·Ð»Ð¸Ð²Ð¾ÑÑ‚ÐµÐ¹  
- **documentation**: ÐžÐ½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ñ–Ñ—
- **optimization**: ÐÐ½Ð°Ð»Ñ–Ð· Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ–
- **testing**: ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð¾Ð²Ð°Ð½Ðµ Ñ‚ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ
- **maintenance**: Ð¢ÐµÑ…Ð½Ñ–Ñ‡Ð½Ðµ Ð¾Ð±ÑÐ»ÑƒÐ³Ð¾Ð²ÑƒÐ²Ð°Ð½Ð½Ñ

## Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ

ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚Ð¸ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð²Ð¸ÐºÐ¾Ð½ÑƒÑŽÑ‚ÑŒÑÑ ÑÐ¸ÑÑ‚ÐµÐ¼Ð¾ÑŽ scheduled prompts Ð¿Ñ–Ð´ Ñ‡Ð°Ñ DND Ð¿ÐµÑ€Ñ–Ð¾Ð´Ñƒ.
ÐŸÑ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð²Ð¸Ð·Ð½Ð°Ñ‡Ð°Ñ”Ñ‚ÑŒÑÑ Ð¿Ð¾Ð»ÐµÐ¼ `priority` (Ð²Ð¸Ñ‰Ñ– Ñ†Ð¸Ñ„Ñ€Ð¸ = Ð²Ð¸Ñ‰Ð¸Ð¹ Ð¿Ñ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚).

## Ð”Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ Ð½Ð¾Ð²Ð¸Ñ… Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ–Ð²

1. Ð¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ Ð½Ð¾Ð²Ð¸Ð¹ `.md` Ñ„Ð°Ð¹Ð» Ð· ÑƒÐ½Ñ–ÐºÐ°Ð»ÑŒÐ½Ð¸Ð¼ Ñ–Ð¼'ÑÐ¼
2. Ð”Ð¾Ð´Ð°Ð¹Ñ‚Ðµ YAML frontmatter Ð· Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð¸Ð¼Ð¸
3. ÐžÐ¿Ð¸ÑˆÑ–Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ñƒ markdown Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ–
4. Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð¿Ñ–Ð´Ñ…Ð¾Ð¿Ð¸Ñ‚ÑŒ Ð½Ð¾Ð²Ð¸Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚

## ÐŸÑ€Ð¸ÐºÐ»Ð°Ð´Ð¸

Ð”Ð¸Ð²Ñ–Ñ‚ÑŒÑÑ Ñ–ÑÐ½ÑƒÑŽÑ‡Ñ– Ñ„Ð°Ð¹Ð»Ð¸ `.md` Ð² Ñ†Ñ–Ð¹ Ð¿Ð°Ð¿Ñ†Ñ– Ð´Ð»Ñ Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´Ñ–Ð² ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸ Ñ‚Ð° Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ.
"""
    
    readme_path = prompts_dir / "README.md"
    readme_path.write_text(readme_content, encoding='utf-8')

```

### bot/features/dracon_yaml.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 27,494 Ð±Ð°Ð¹Ñ‚

```python
"""DRACON-YAML System for Telegram Bot Logic Modeling.

This module implements DRACON (Ð”Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ñ‹Ðµ Ð ÑƒÑÑÐºÐ¸Ðµ ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñ‹, ÐšÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÐžÐ±ÐµÑÐ¿ÐµÑ‡Ð¸Ð²Ð°ÑŽÑ‚ ÐÐ°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚ÑŒ)
language for modeling bot process logic using "silhouette" schemas (closed graphs) stored in YAML.

Features:
- YAML-based DRACON schema definition and validation
- Intelligent graph analysis using Claude CLI integration
- Automatic component generation (buttons, commands, messages, handlers)
- Graph closure verification and logical integrity checks
- Visual logic modeling with closed graph topology
"""

import asyncio
import json
import os
import subprocess
import tempfile
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple, Union

import structlog
import yaml
from pydantic import BaseModel, Field, validator

logger = structlog.get_logger()


class NodeType(str, Enum):
    """DRACON node types."""
    START = "start"
    END = "end"
    ACTION = "action"
    CONDITION = "condition"
    PROCESS = "process"
    HANDLER = "handler"
    COMMAND = "command"
    CALLBACK = "callback"
    MESSAGE = "message"
    BUTTON = "button"


class EdgeType(str, Enum):
    """DRACON edge types."""
    SEQUENCE = "sequence"
    CONDITION_TRUE = "true"
    CONDITION_FALSE = "false"
    CALLBACK = "callback"
    ERROR = "error"
    TIMEOUT = "timeout"


@dataclass
class DraconNode:
    """DRACON graph node."""
    id: str
    type: NodeType
    name: str
    description: Optional[str] = None
    properties: Dict[str, Any] = field(default_factory=dict)
    position: Optional[Tuple[int, int]] = None


@dataclass
class DraconEdge:
    """DRACON graph edge."""
    id: str
    from_node: str
    to_node: str
    type: EdgeType
    condition: Optional[str] = None
    properties: Dict[str, Any] = field(default_factory=dict)


class DraconSchema(BaseModel):
    """DRACON schema validation model."""

    class Config:
        extra = "forbid"

    version: str = Field(default="1.0")
    name: str = Field(..., description="Schema name")
    description: Optional[str] = Field(None, description="Schema description")
    metadata: Dict[str, Any] = Field(default_factory=dict)

    nodes: List[Dict[str, Any]] = Field(..., description="Graph nodes")
    edges: List[Dict[str, Any]] = Field(..., description="Graph edges")

    @validator('nodes')
    def validate_nodes(cls, v):
        """Validate nodes structure."""
        if not v:
            raise ValueError("At least one node is required")

        node_ids = set()
        has_start = False
        has_end = False

        for node in v:
            if 'id' not in node:
                raise ValueError("Node must have 'id' field")
            if 'type' not in node:
                raise ValueError("Node must have 'type' field")
            if 'name' not in node:
                raise ValueError("Node must have 'name' field")

            node_id = node['id']
            if node_id in node_ids:
                raise ValueError(f"Duplicate node ID: {node_id}")
            node_ids.add(node_id)

            node_type = node['type']
            if node_type not in [t.value for t in NodeType]:
                raise ValueError(f"Invalid node type: {node_type}")

            if node_type == NodeType.START:
                has_start = True
            elif node_type == NodeType.END:
                has_end = True

        if not has_start:
            raise ValueError("Graph must have at least one START node")
        if not has_end:
            raise ValueError("Graph must have at least one END node")

        return v

    @validator('edges')
    def validate_edges(cls, v, values):
        """Validate edges structure and references."""
        if 'nodes' not in values:
            return v

        node_ids = {node['id'] for node in values['nodes']}
        edge_ids = set()

        for edge in v:
            if 'id' not in edge:
                raise ValueError("Edge must have 'id' field")
            if 'from_node' not in edge:
                raise ValueError("Edge must have 'from_node' field")
            if 'to_node' not in edge:
                raise ValueError("Edge must have 'to_node' field")
            if 'type' not in edge:
                raise ValueError("Edge must have 'type' field")

            edge_id = edge['id']
            if edge_id in edge_ids:
                raise ValueError(f"Duplicate edge ID: {edge_id}")
            edge_ids.add(edge_id)

            from_node = edge['from_node']
            to_node = edge['to_node']

            if from_node not in node_ids:
                raise ValueError(f"Edge references unknown from_node: {from_node}")
            if to_node not in node_ids:
                raise ValueError(f"Edge references unknown to_node: {to_node}")

            edge_type = edge['type']
            if edge_type not in [t.value for t in EdgeType]:
                raise ValueError(f"Invalid edge type: {edge_type}")

        return v


@dataclass
class GraphAnalysisResult:
    """Result of DRACON graph analysis."""
    is_valid: bool
    is_closed: bool
    is_reachable: bool
    issues: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    suggestions: List[str] = field(default_factory=list)
    claude_analysis: Optional[str] = None
    components: Dict[str, List[str]] = field(default_factory=dict)


@dataclass
class ComponentSpec:
    """Generated component specification."""
    type: str
    name: str
    code: str
    properties: Dict[str, Any] = field(default_factory=dict)
    dependencies: List[str] = field(default_factory=list)


class DraconYamlProcessor:
    """DRACON-YAML processor for bot logic modeling."""

    def __init__(self, claude_cli_path: str = "claude"):
        """Initialize processor."""
        self.claude_cli_path = claude_cli_path
        self.logger = logger.bind(component="dracon_yaml")

    def load_schema(self, yaml_content: str) -> DraconSchema:
        """Load and validate DRACON schema from YAML."""
        try:
            data = yaml.safe_load(yaml_content)
            schema = DraconSchema(**data)
            self.logger.info("DRACON schema loaded", name=schema.name)
            return schema
        except yaml.YAMLError as e:
            raise ValueError(f"Invalid YAML format: {e}")
        except Exception as e:
            raise ValueError(f"Schema validation failed: {e}")

    def parse_graph(self, schema: DraconSchema) -> Tuple[List[DraconNode], List[DraconEdge]]:
        """Parse schema into graph structures."""
        nodes = []
        edges = []

        for node_data in schema.nodes:
            node = DraconNode(
                id=node_data['id'],
                type=NodeType(node_data['type']),
                name=node_data['name'],
                description=node_data.get('description'),
                properties=node_data.get('properties', {}),
                position=tuple(node_data['position']) if 'position' in node_data else None
            )
            nodes.append(node)

        for edge_data in schema.edges:
            edge = DraconEdge(
                id=edge_data['id'],
                from_node=edge_data['from_node'],
                to_node=edge_data['to_node'],
                type=EdgeType(edge_data['type']),
                condition=edge_data.get('condition'),
                properties=edge_data.get('properties', {})
            )
            edges.append(edge)

        return nodes, edges

    def verify_graph_closure(self, nodes: List[DraconNode], edges: List[DraconEdge]) -> Tuple[bool, List[str]]:
        """Verify that graph forms a closed silhouette (no intersecting lines)."""
        issues = []

        # Build adjacency graph
        node_map = {node.id: node for node in nodes}
        adjacency = {node.id: [] for node in nodes}

        for edge in edges:
            adjacency[edge.from_node].append(edge.to_node)

        # Check for unreachable nodes
        start_nodes = [node for node in nodes if node.type == NodeType.START]
        if not start_nodes:
            issues.append("No START node found")
            return False, issues

        visited = set()
        queue = [start_nodes[0].id]

        while queue:
            current = queue.pop(0)
            if current in visited:
                continue
            visited.add(current)
            queue.extend(adjacency[current])

        unreachable = set(node_map.keys()) - visited
        if unreachable:
            issues.append(f"Unreachable nodes: {', '.join(unreachable)}")

        # Check for cycles (should be controlled cycles only)
        def has_uncontrolled_cycles():
            color = {node.id: 'white' for node in nodes}

            def dfs(node_id):
                if color[node_id] == 'gray':
                    return True  # Back edge found (cycle)
                if color[node_id] == 'black':
                    return False

                color[node_id] = 'gray'
                for neighbor in adjacency[node_id]:
                    if dfs(neighbor):
                        return True
                color[node_id] = 'black'
                return False

            for node in nodes:
                if color[node.id] == 'white':
                    if dfs(node.id):
                        return True
            return False

        # Check for proper termination
        end_nodes = [node for node in nodes if node.type == NodeType.END]
        if not end_nodes:
            issues.append("No END node found")

        is_closed = len(issues) == 0 and not has_uncontrolled_cycles()

        return is_closed, issues

    def check_reachability(self, nodes: List[DraconNode], edges: List[DraconEdge]) -> Tuple[bool, List[str]]:
        """Check if all END nodes are reachable from START nodes."""
        issues = []

        # Build graph
        node_map = {node.id: node for node in nodes}
        adjacency = {node.id: [] for node in nodes}

        for edge in edges:
            adjacency[edge.from_node].append(edge.to_node)

        start_nodes = [node for node in nodes if node.type == NodeType.START]
        end_nodes = [node for node in nodes if node.type == NodeType.END]

        if not start_nodes:
            issues.append("No START nodes found")
            return False, issues

        if not end_nodes:
            issues.append("No END nodes found")
            return False, issues

        # Check reachability from each START to each END
        def can_reach(start_id: str, end_id: str) -> bool:
            visited = set()
            queue = [start_id]

            while queue:
                current = queue.pop(0)
                if current == end_id:
                    return True
                if current in visited:
                    continue
                visited.add(current)
                queue.extend(adjacency[current])

            return False

        for start_node in start_nodes:
            reachable_ends = []
            for end_node in end_nodes:
                if can_reach(start_node.id, end_node.id):
                    reachable_ends.append(end_node.id)

            if not reachable_ends:
                issues.append(f"START node '{start_node.id}' cannot reach any END node")

        for end_node in end_nodes:
            reachable_from = []
            for start_node in start_nodes:
                if can_reach(start_node.id, end_node.id):
                    reachable_from.append(start_node.id)

            if not reachable_from:
                issues.append(f"END node '{end_node.id}' is not reachable from any START node")

        is_reachable = len(issues) == 0
        return is_reachable, issues

    async def analyze_with_claude(self, schema: DraconSchema, nodes: List[DraconNode], edges: List[DraconEdge]) -> str:
        """Analyze graph logic using Claude CLI."""
        try:
            # Prepare analysis prompt
            graph_description = self._generate_graph_description(schema, nodes, edges)

            prompt = f"""Analyze this DRACON bot logic graph for potential issues:

GRAPH: {schema.name}
{graph_description}

Please analyze for:
1. Logical flow consistency
2. Missing error handling paths
3. Potential infinite loops or deadlocks
4. Incomplete user interaction flows
5. Security considerations
6. Performance bottlenecks
7. Bot-specific patterns and best practices

Provide specific recommendations for improvement."""

            # Execute Claude analysis
            result = await self._execute_claude_analysis(prompt)
            return result

        except Exception as e:
            self.logger.error("Claude analysis failed", error=str(e))
            return f"Analysis failed: {str(e)}"

    def _generate_graph_description(self, schema: DraconSchema, nodes: List[DraconNode], edges: List[DraconEdge]) -> str:
        """Generate human-readable graph description."""
        description = f"Description: {schema.description}\n\n"

        description += "NODES:\n"
        for node in nodes:
            description += f"- {node.id} ({node.type.value}): {node.name}"
            if node.description:
                description += f" - {node.description}"
            if node.properties:
                description += f" [Properties: {node.properties}]"
            description += "\n"

        description += "\nEDGES (FLOW):\n"
        for edge in edges:
            description += f"- {edge.from_node} -> {edge.to_node} ({edge.type.value})"
            if edge.condition:
                description += f" [Condition: {edge.condition}]"
            if edge.properties:
                description += f" [Properties: {edge.properties}]"
            description += "\n"

        return description

    async def _execute_claude_analysis(self, prompt: str) -> str:
        """Execute Claude CLI analysis."""
        try:
            # Create temporary file for prompt
            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                f.write(prompt)
                prompt_file = f.name

            try:
                # Execute Claude CLI
                cmd = [self.claude_cli_path, 'chat', '--no-markdown']

                # Use subprocess with input
                process = await asyncio.create_subprocess_exec(
                    *cmd,
                    stdin=asyncio.subprocess.PIPE,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )

                stdout, stderr = await process.communicate(input=prompt.encode())

                if process.returncode == 0:
                    return stdout.decode().strip()
                else:
                    error_msg = stderr.decode().strip()
                    self.logger.error("Claude CLI error", error=error_msg)
                    return f"Claude analysis error: {error_msg}"

            finally:
                # Clean up temp file
                os.unlink(prompt_file)

        except Exception as e:
            self.logger.error("Failed to execute Claude analysis", error=str(e))
            return f"Execution failed: {str(e)}"

    async def analyze_graph(self, yaml_content: str) -> GraphAnalysisResult:
        """Perform comprehensive graph analysis."""
        try:
            # Load and parse schema
            schema = self.load_schema(yaml_content)
            nodes, edges = self.parse_graph(schema)

            # Perform validation checks
            is_closed, closure_issues = self.verify_graph_closure(nodes, edges)
            is_reachable, reachability_issues = self.check_reachability(nodes, edges)

            issues = closure_issues + reachability_issues
            warnings = []
            suggestions = []

            # Add warnings for complex patterns
            if len(nodes) > 20:
                warnings.append("Large graph detected - consider breaking into smaller subgraphs")

            condition_nodes = [n for n in nodes if n.type == NodeType.CONDITION]
            if len(condition_nodes) > 5:
                warnings.append("Many condition nodes - ensure decision logic is clear")

            # Generate suggestions
            if not any(n.type == NodeType.HANDLER for n in nodes):
                suggestions.append("Consider adding error handler nodes for robustness")

            start_nodes = [n for n in nodes if n.type == NodeType.START]
            if len(start_nodes) > 1:
                suggestions.append("Multiple START nodes - ensure proper initialization")

            # Perform Claude analysis
            claude_analysis = await self.analyze_with_claude(schema, nodes, edges)

            # Identify potential components
            components = self._identify_components(nodes, edges)

            is_valid = is_closed and is_reachable and len(issues) == 0

            return GraphAnalysisResult(
                is_valid=is_valid,
                is_closed=is_closed,
                is_reachable=is_reachable,
                issues=issues,
                warnings=warnings,
                suggestions=suggestions,
                claude_analysis=claude_analysis,
                components=components
            )

        except Exception as e:
            self.logger.error("Graph analysis failed", error=str(e))
            return GraphAnalysisResult(
                is_valid=False,
                is_closed=False,
                is_reachable=False,
                issues=[f"Analysis failed: {str(e)}"]
            )

    def _identify_components(self, nodes: List[DraconNode], edges: List[DraconEdge]) -> Dict[str, List[str]]:
        """Identify potential bot components from graph."""
        components = {
            'commands': [],
            'handlers': [],
            'buttons': [],
            'messages': [],
            'callbacks': []
        }

        for node in nodes:
            if node.type == NodeType.COMMAND:
                components['commands'].append(node.id)
            elif node.type == NodeType.HANDLER:
                components['handlers'].append(node.id)
            elif node.type == NodeType.BUTTON:
                components['buttons'].append(node.id)
            elif node.type == NodeType.MESSAGE:
                components['messages'].append(node.id)
            elif node.type == NodeType.CALLBACK:
                components['callbacks'].append(node.id)

        return components

    async def generate_components(self, yaml_content: str, target_dir: str = "generated") -> List[ComponentSpec]:
        """Generate bot components from DRACON schema."""
        try:
            schema = self.load_schema(yaml_content)
            nodes, edges = self.parse_graph(schema)

            components = []

            # Generate command handlers
            command_nodes = [n for n in nodes if n.type == NodeType.COMMAND]
            for node in command_nodes:
                spec = await self._generate_command_handler(node, edges, schema)
                components.append(spec)

            # Generate callback handlers
            callback_nodes = [n for n in nodes if n.type == NodeType.CALLBACK]
            for node in callback_nodes:
                spec = await self._generate_callback_handler(node, edges, schema)
                components.append(spec)

            # Generate message templates
            message_nodes = [n for n in nodes if n.type == NodeType.MESSAGE]
            for node in message_nodes:
                spec = await self._generate_message_template(node, schema)
                components.append(spec)

            # Generate button configurations
            button_nodes = [n for n in nodes if n.type == NodeType.BUTTON]
            for node in button_nodes:
                spec = await self._generate_button_config(node, edges, schema)
                components.append(spec)

            self.logger.info("Generated components", count=len(components))
            return components

        except Exception as e:
            self.logger.error("Component generation failed", error=str(e))
            return []

    async def _generate_command_handler(self, node: DraconNode, edges: List[DraconEdge], schema: DraconSchema) -> ComponentSpec:
        """Generate command handler code."""
        command_name = node.properties.get('command', node.id.lower())

        code = f'''async def {node.id}_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Generated handler for {node.name}."""
    try:
        user_id = update.effective_user.id
        logger.info("Command {command_name} invoked", user_id=user_id)

        # TODO: Implement {node.name} logic
        message = "{node.description or f'Executing {node.name}'}"

        await update.message.reply_text(message)

    except Exception as e:
        logger.error("Command {command_name} failed", error=str(e))
        await update.message.reply_text("âŒ Command failed")
'''

        return ComponentSpec(
            type="command_handler",
            name=f"{node.id}_command",
            code=code,
            properties={
                'command': command_name,
                'description': node.description,
                'node_id': node.id
            }
        )

    async def _generate_callback_handler(self, node: DraconNode, edges: List[DraconEdge], schema: DraconSchema) -> ComponentSpec:
        """Generate callback handler code."""
        callback_data = node.properties.get('callback_data', node.id)

        code = f'''async def handle_{node.id}_callback(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """Generated callback handler for {node.name}."""
    query = update.callback_query
    await query.answer()

    try:
        user_id = update.effective_user.id
        logger.info("Callback {callback_data} triggered", user_id=user_id)

        # TODO: Implement {node.name} callback logic

        await query.edit_message_text("{node.description or f'Processing {node.name}'}")

    except Exception as e:
        logger.error("Callback {callback_data} failed", error=str(e))
        await query.edit_message_text("âŒ Action failed")
'''

        return ComponentSpec(
            type="callback_handler",
            name=f"handle_{node.id}_callback",
            code=code,
            properties={
                'callback_data': callback_data,
                'description': node.description,
                'node_id': node.id
            }
        )

    async def _generate_message_template(self, node: DraconNode, schema: DraconSchema) -> ComponentSpec:
        """Generate message template."""
        template = node.properties.get('template', node.description or node.name)

        code = f'''# Message template for {node.name}
MESSAGE_TEMPLATE = """{template}"""

def get_{node.id}_message(**kwargs) -> str:
    """Get formatted message for {node.name}."""
    return MESSAGE_TEMPLATE.format(**kwargs)
'''

        return ComponentSpec(
            type="message_template",
            name=f"get_{node.id}_message",
            code=code,
            properties={
                'template': template,
                'node_id': node.id
            }
        )

    async def _generate_button_config(self, node: DraconNode, edges: List[DraconEdge], schema: DraconSchema) -> ComponentSpec:
        """Generate button configuration."""
        button_text = node.properties.get('text', node.name)
        callback_data = node.properties.get('callback_data', node.id)

        # Find outgoing edges to determine button behavior
        outgoing_edges = [e for e in edges if e.from_node == node.id]

        code = f'''# Button configuration for {node.name}
BUTTON_CONFIG = {{
    "text": "{button_text}",
    "callback_data": "{callback_data}",
    "description": "{node.description or ''}",
    "node_id": "{node.id}"
}}

def create_{node.id}_button() -> InlineKeyboardButton:
    """Create {node.name} button."""
    return InlineKeyboardButton(
        BUTTON_CONFIG["text"],
        callback_data=BUTTON_CONFIG["callback_data"]
    )
'''

        return ComponentSpec(
            type="button_config",
            name=f"create_{node.id}_button",
            code=code,
            properties={
                'text': button_text,
                'callback_data': callback_data,
                'node_id': node.id,
                'outgoing_edges': len(outgoing_edges)
            }
        )


# Example DRACON schema for bot menu system
EXAMPLE_MENU_SCHEMA = """
version: "1.0"
name: "Bot Main Menu Flow"
description: "Main menu navigation flow for Telegram bot"
metadata:
  author: "DRACON Generator"
  created: "2024-01-01"

nodes:
  - id: "start"
    type: "start"
    name: "Bot Start"
    description: "User starts interaction with bot"
    position: [0, 0]

  - id: "main_menu"
    type: "message"
    name: "Main Menu"
    description: "Display main menu with options"
    position: [100, 0]
    properties:
      template: "ðŸ  **Main Menu**\\n\\nChoose an action:"

  - id: "help_button"
    type: "button"
    name: "Help Button"
    description: "Get help information"
    position: [200, -50]
    properties:
      text: "â“ Help"
      callback_data: "help"

  - id: "settings_button"
    type: "button"
    name: "Settings Button"
    description: "Open settings"
    position: [200, 50]
    properties:
      text: "âš™ï¸ Settings"
      callback_data: "settings"

  - id: "help_handler"
    type: "callback"
    name: "Help Handler"
    description: "Process help request"
    position: [300, -50]
    properties:
      callback_data: "help"

  - id: "settings_handler"
    type: "callback"
    name: "Settings Handler"
    description: "Process settings request"
    position: [300, 50]
    properties:
      callback_data: "settings"

  - id: "help_message"
    type: "message"
    name: "Help Message"
    description: "Display help information"
    position: [400, -50]
    properties:
      template: "â“ **Help**\\n\\nAvailable commands:\\n/start - Start bot\\n/help - Show help"

  - id: "settings_message"
    type: "message"
    name: "Settings Message"
    description: "Display settings"
    position: [400, 50]
    properties:
      template: "âš™ï¸ **Settings**\\n\\nLanguage: English\\nNotifications: On"

  - id: "end"
    type: "end"
    name: "End"
    description: "User interaction complete"
    position: [500, 0]

edges:
  - id: "start_to_menu"
    from_node: "start"
    to_node: "main_menu"
    type: "sequence"

  - id: "menu_to_help_btn"
    from_node: "main_menu"
    to_node: "help_button"
    type: "sequence"

  - id: "menu_to_settings_btn"
    from_node: "main_menu"
    to_node: "settings_button"
    type: "sequence"

  - id: "help_btn_to_handler"
    from_node: "help_button"
    to_node: "help_handler"
    type: "callback"

  - id: "settings_btn_to_handler"
    from_node: "settings_button"
    to_node: "settings_handler"
    type: "callback"

  - id: "help_handler_to_message"
    from_node: "help_handler"
    to_node: "help_message"
    type: "sequence"

  - id: "settings_handler_to_message"
    from_node: "settings_handler"
    to_node: "settings_message"
    type: "sequence"

  - id: "help_to_end"
    from_node: "help_message"
    to_node: "end"
    type: "sequence"

  - id: "settings_to_end"
    from_node: "settings_message"
    to_node: "end"
    type: "sequence"
"""

```

### bot/features/dracon_parser.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 21,499 Ð±Ð°Ð¹Ñ‚

```python
"""
DRACON Language Parser with AST Generation

This module provides complete DRACON language parsing with Abstract Syntax Tree
generation, supporting all DRAKON Hub format features and DRACON language constructs.
"""

import ast
import re
import yaml
from typing import Any, Dict, List, Optional, Set, Tuple
from pathlib import Path
import json
import logging
from dataclasses import asdict

from dracon_types import (
    DraconSchema, DraconNode, DraconEdge, NodeType, EdgeType,
    Position, Size, SchemaMetadata, CanvasProperties, ValidationRules,
    ParseResult, DraconMetadata, VisualProperties, MacroDefinition
)

logger = logging.getLogger(__name__)


class DraconParsingError(Exception):
    """Custom exception for DRACON parsing errors"""
    pass


class DraconLexer:
    """Lexical analyzer for DRACON constructs"""

    # DRACON keywords and patterns
    KEYWORDS = {
        'title', 'action', 'question', 'case', 'select',
        'loop_start', 'loop_end', 'address', 'end', 'shelf',
        'timer', 'parallel_start', 'parallel_end', 'macro'
    }

    # Regular expressions for DRACON tokens
    PATTERNS = {
        'node_id': r'\b[a-zA-Z_][a-zA-Z0-9_]*\b',
        'position': r'\((\d+),\s*(\d+)\)',
        'size': r'\[(\d+)x(\d+)\]',
        'condition': r'\{([^}]+)\}',
        'label': r'"([^"]*)"',
        'color': r'#[0-9a-fA-F]{6}',
        'connection': r'->|-->|=>|==>'
    }

    def __init__(self):
        self.compiled_patterns = {
            name: re.compile(pattern) 
            for name, pattern in self.PATTERNS.items()
        }

    def tokenize(self, text: str) -> List[Dict[str, Any]]:
        """Tokenize DRACON text input"""
        tokens = []
        lines = text.split('\n')

        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            if not line or line.startswith('#'):  # Skip comments
                continue

            # Extract tokens from line
            line_tokens = self._extract_line_tokens(line, line_num)
            tokens.extend(line_tokens)

        return tokens

    def _extract_line_tokens(self, line: str, line_num: int) -> List[Dict[str, Any]]:
        """Extract tokens from a single line"""
        tokens = []
        pos = 0

        while pos < len(line):
            # Skip whitespace
            while pos < len(line) and line[pos].isspace():
                pos += 1

            if pos >= len(line):
                break

            # Try to match patterns
            token_found = False

            for pattern_name, compiled_pattern in self.compiled_patterns.items():
                match = compiled_pattern.match(line, pos)
                if match:
                    tokens.append({
                        'type': pattern_name,
                        'value': match.group(0),
                        'groups': match.groups(),
                        'line': line_num,
                        'position': pos
                    })
                    pos = match.end()
                    token_found = True
                    break

            if not token_found:
                # Handle individual characters or unknown tokens
                tokens.append({
                    'type': 'unknown',
                    'value': line[pos],
                    'line': line_num,
                    'position': pos
                })
                pos += 1

        return tokens


class DraconYAMLParser:
    """Parser for DRACON-YAML format"""

    def __init__(self):
        self.lexer = DraconLexer()
        self.current_schema = None

    def parse_yaml_file(self, file_path: Path) -> ParseResult:
        """Parse a DRACON YAML file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                yaml_content = yaml.safe_load(f)

            return self.parse_yaml_dict(yaml_content)

        except Exception as e:
            logger.error(f"Failed to parse YAML file {file_path}: {e}")
            return ParseResult(
                success=False,
                errors=[f"YAML parsing error: {str(e)}"]
            )

    def parse_yaml_dict(self, yaml_data: Dict[str, Any]) -> ParseResult:
        """Parse DRACON schema from YAML dictionary"""
        errors = []
        warnings = []

        try:
            # Parse metadata
            metadata = self._parse_metadata(yaml_data.get('metadata', {}))

            # Parse canvas properties
            canvas = self._parse_canvas(yaml_data.get('canvas', {}))

            # Parse validation rules
            validation_rules = self._parse_validation_rules(
                yaml_data.get('validation_rules', {})
            )

            # Create schema
            schema = DraconSchema(
                metadata=metadata,
                canvas=canvas,
                validation_rules=validation_rules
            )

            # Parse nodes
            nodes_data = yaml_data.get('nodes', [])
            for node_data in nodes_data:
                node, node_errors = self._parse_node(node_data)
                if node:
                    schema.add_node(node)
                errors.extend(node_errors)

            # Parse edges
            edges_data = yaml_data.get('edges', [])
            for edge_data in edges_data:
                edge, edge_errors = self._parse_edge(edge_data)
                if edge:
                    schema.add_edge(edge)
                errors.extend(edge_errors)

            # Parse macros
            macros_data = yaml_data.get('macros', [])
            for macro_data in macros_data:
                macro, macro_errors = self._parse_macro(macro_data)
                if macro:
                    schema.macros.append(macro)
                errors.extend(macro_errors)

            success = len(errors) == 0
            return ParseResult(
                success=success,
                schema=schema if success else None,
                errors=errors,
                warnings=warnings
            )

        except Exception as e:
            logger.error(f"Schema parsing error: {e}")
            return ParseResult(
                success=False,
                errors=[f"Schema parsing error: {str(e)}"]
            )

    def _parse_metadata(self, metadata_data: Dict[str, Any]) -> SchemaMetadata:
        """Parse schema metadata"""
        from datetime import datetime

        return SchemaMetadata(
            name=metadata_data.get('name', 'Unnamed Schema'),
            version=metadata_data.get('version', '1.0.0'),
            description=metadata_data.get('description', ''),
            author=metadata_data.get('author', ''),
            created=self._parse_datetime(metadata_data.get('created')),
            modified=self._parse_datetime(metadata_data.get('modified')),
            tags=metadata_data.get('tags', []),
            dracon_version=metadata_data.get('dracon_version', '1.0')
        )

    def _parse_datetime(self, dt_str: Optional[str]) -> datetime:
        """Parse datetime string"""
        from datetime import datetime

        if not dt_str:
            return datetime.now()

        try:
            return datetime.fromisoformat(dt_str.replace('Z', '+00:00'))
        except:
            return datetime.now()

    def _parse_canvas(self, canvas_data: Dict[str, Any]) -> CanvasProperties:
        """Parse canvas properties"""
        return CanvasProperties(
            width=canvas_data.get('width', 1200),
            height=canvas_data.get('height', 800),
            grid_size=canvas_data.get('grid_size', 20),
            theme=canvas_data.get('theme', 'default'),
            zoom=canvas_data.get('zoom', 1.0)
        )

    def _parse_validation_rules(self, rules_data: Dict[str, Any]) -> ValidationRules:
        """Parse validation rules"""
        return ValidationRules(
            no_intersections=rules_data.get('no_intersections', True),
            single_entry_exit=rules_data.get('single_entry_exit', True),
            all_paths_covered=rules_data.get('all_paths_covered', True),
            variable_scope_check=rules_data.get('variable_scope_check', True)
        )

    def _parse_node(self, node_data: Dict[str, Any]) -> Tuple[Optional[DraconNode], List[str]]:
        """Parse a DRACON node"""
        errors = []

        try:
            # Required fields
            node_id = node_data.get('id')
            node_type_str = node_data.get('type')
            position_data = node_data.get('position', {})
            size_data = node_data.get('size', {})

            if not node_id:
                errors.append("Node missing required 'id' field")
                return None, errors

            if not node_type_str:
                errors.append(f"Node {node_id} missing required 'type' field")
                return None, errors

            # Parse node type
            try:
                node_type = NodeType(node_type_str)
            except ValueError:
                errors.append(f"Invalid node type '{node_type_str}' for node {node_id}")
                return None, errors

            # Parse position and size
            position = Position(
                x=position_data.get('x', 0),
                y=position_data.get('y', 0)
            )

            size = Size(
                width=size_data.get('width', 100),
                height=size_data.get('height', 50)
            )

            # Parse properties
            properties = node_data.get('properties', {})

            # Parse DRACON metadata
            metadata_data = node_data.get('dracon_metadata', {})
            dracon_metadata = DraconMetadata(
                is_macro=metadata_data.get('is_macro', False),
                macro_definition=metadata_data.get('macro_definition'),
                data_flow=metadata_data.get('data_flow', []),
                complexity_score=metadata_data.get('complexity_score', 0)
            )

            # Parse visual properties
            visual_data = node_data.get('visual_properties', {})
            visual_properties = VisualProperties(
                color=visual_data.get('color', '#ffffff'),
                font_size=visual_data.get('font_size', 12),
                font_family=visual_data.get('font_family', 'Arial'),
                border_width=visual_data.get('border_width', 1),
                border_color=visual_data.get('border_color', '#000000'),
                background_color=visual_data.get('background_color', '#f0f0f0')
            )

            node = DraconNode(
                id=node_id,
                node_type=node_type,
                position=position,
                size=size,
                properties=properties,
                dracon_metadata=dracon_metadata,
                visual_properties=visual_properties
            )

            return node, errors

        except Exception as e:
            errors.append(f"Error parsing node: {str(e)}")
            return None, errors

    def _parse_edge(self, edge_data: Dict[str, Any]) -> Tuple[Optional[DraconEdge], List[str]]:
        """Parse a DRACON edge"""
        errors = []

        try:
            # Required fields
            edge_id = edge_data.get('id')
            from_node = edge_data.get('from_node')
            to_node = edge_data.get('to_node')
            edge_type_str = edge_data.get('type')

            if not edge_id:
                errors.append("Edge missing required 'id' field")
                return None, errors

            if not from_node:
                errors.append(f"Edge {edge_id} missing required 'from_node' field")
                return None, errors

            if not to_node:
                errors.append(f"Edge {edge_id} missing required 'to_node' field")
                return None, errors

            if not edge_type_str:
                errors.append(f"Edge {edge_id} missing required 'type' field")
                return None, errors

            # Parse edge type
            try:
                edge_type = EdgeType(edge_type_str)
            except ValueError:
                errors.append(f"Invalid edge type '{edge_type_str}' for edge {edge_id}")
                return None, errors

            # Optional fields
            condition = edge_data.get('condition')
            label = edge_data.get('label', '')

            # Parse control points
            control_points = []
            for cp_data in edge_data.get('control_points', []):
                control_points.append(ControlPoint(
                    x=cp_data.get('x', 0),
                    y=cp_data.get('y', 0)
                ))

            # Parse edge metadata
            from dracon_types import EdgeMetadata, ControlPoint
            metadata_data = edge_data.get('dracon_metadata', {})
            edge_metadata = EdgeMetadata(
                data_transfer=metadata_data.get('data_transfer', []),
                execution_weight=metadata_data.get('execution_weight', 1)
            )

            edge = DraconEdge(
                id=edge_id,
                from_node=from_node,
                to_node=to_node,
                edge_type=edge_type,
                condition=condition,
                label=label,
                control_points=control_points,
                edge_metadata=edge_metadata
            )

            return edge, errors

        except Exception as e:
            errors.append(f"Error parsing edge: {str(e)}")
            return None, errors

    def _parse_macro(self, macro_data: Dict[str, Any]) -> Tuple[Optional[MacroDefinition], List[str]]:
        """Parse a macro definition"""
        errors = []

        try:
            name = macro_data.get('name')
            if not name:
                errors.append("Macro missing required 'name' field")
                return None, errors

            parameters = macro_data.get('parameters', [])
            definition_data = macro_data.get('definition')

            # Parse nested definition if present
            definition = None
            if definition_data:
                result = self.parse_yaml_dict(definition_data)
                if result.success:
                    definition = result.schema
                else:
                    errors.extend(result.errors)

            macro = MacroDefinition(
                name=name,
                parameters=parameters,
                definition=definition
            )

            return macro, errors

        except Exception as e:
            errors.append(f"Error parsing macro: {str(e)}")
            return None, errors


class DraconHubImporter:
    """Importer for DRAKON Hub JSON format"""

    def parse_drakon_hub_file(self, file_path: Path) -> ParseResult:
        """Parse DRAKON Hub JSON file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                hub_data = json.load(f)

            return self._convert_hub_to_dracon(hub_data)

        except Exception as e:
            logger.error(f"Failed to parse DRAKON Hub file {file_path}: {e}")
            return ParseResult(
                success=False,
                errors=[f"DRAKON Hub parsing error: {str(e)}"]
            )

    def _convert_hub_to_dracon(self, hub_data: Dict[str, Any]) -> ParseResult:
        """Convert DRAKON Hub format to DRACON schema"""
        # Implementation for converting DRAKON Hub JSON format
        # This would handle the specific format used by DRAKON Hub

        errors = []
        warnings = []

        try:
            # Extract metadata from hub format
            metadata = SchemaMetadata(
                name=hub_data.get('name', 'Imported Schema'),
                description=hub_data.get('description', ''),
                author=hub_data.get('author', ''),
                dracon_version='1.0'
            )

            # Create schema
            schema = DraconSchema(metadata=metadata)

            # Convert nodes (specific to DRAKON Hub format)
            nodes = hub_data.get('nodes', [])
            for hub_node in nodes:
                dracon_node = self._convert_hub_node(hub_node)
                if dracon_node:
                    schema.add_node(dracon_node)

            # Convert edges
            edges = hub_data.get('edges', [])
            for hub_edge in edges:
                dracon_edge = self._convert_hub_edge(hub_edge)
                if dracon_edge:
                    schema.add_edge(dracon_edge)

            return ParseResult(
                success=True,
                schema=schema,
                errors=errors,
                warnings=warnings
            )

        except Exception as e:
            return ParseResult(
                success=False,
                errors=[f"DRAKON Hub conversion error: {str(e)}"]
            )

    def _convert_hub_node(self, hub_node: Dict[str, Any]) -> Optional[DraconNode]:
        """Convert DRAKON Hub node to DRACON node"""
        # Specific conversion logic for DRAKON Hub node format
        try:
            node_type_map = {
                'action': NodeType.ACTION,
                'question': NodeType.QUESTION,
                'case': NodeType.CASE,
                'title': NodeType.TITLE,
                'end': NodeType.END,
                # Add more mappings as needed
            }

            hub_type = hub_node.get('type', 'action')
            node_type = node_type_map.get(hub_type, NodeType.ACTION)

            return DraconNode(
                id=hub_node.get('id', ''),
                node_type=node_type,
                position=Position(
                    x=hub_node.get('x', 0),
                    y=hub_node.get('y', 0)
                ),
                size=Size(
                    width=hub_node.get('width', 100),
                    height=hub_node.get('height', 50)
                ),
                properties={
                    'text': hub_node.get('text', ''),
                    'icon': hub_node.get('icon', ''),
                }
            )

        except Exception as e:
            logger.error(f"Error converting hub node: {e}")
            return None

    def _convert_hub_edge(self, hub_edge: Dict[str, Any]) -> Optional[DraconEdge]:
        """Convert DRAKON Hub edge to DRACON edge"""
        try:
            edge_type_map = {
                'sequence': EdgeType.SEQUENCE,
                'true': EdgeType.TRUE,
                'false': EdgeType.FALSE,
                'case': EdgeType.CASE_BRANCH,
            }

            hub_type = hub_edge.get('type', 'sequence')
            edge_type = edge_type_map.get(hub_type, EdgeType.SEQUENCE)

            return DraconEdge(
                id=hub_edge.get('id', ''),
                from_node=hub_edge.get('from', ''),
                to_node=hub_edge.get('to', ''),
                edge_type=edge_type,
                label=hub_edge.get('label', ''),
                condition=hub_edge.get('condition')
            )

        except Exception as e:
            logger.error(f"Error converting hub edge: {e}")
            return None


class DraconParser:
    """Main DRACON parser with multiple format support"""

    def __init__(self):
        self.yaml_parser = DraconYAMLParser()
        self.hub_importer = DraconHubImporter()

    def parse_file(self, file_path: Path) -> ParseResult:
        """Parse DRACON file based on extension"""
        file_path = Path(file_path)

        if file_path.suffix.lower() in ['.yaml', '.yml']:
            return self.yaml_parser.parse_yaml_file(file_path)
        elif file_path.suffix.lower() == '.json':
            return self.hub_importer.parse_drakon_hub_file(file_path)
        else:
            return ParseResult(
                success=False,
                errors=[f"Unsupported file format: {file_path.suffix}"]
            )

    def parse_yaml_string(self, yaml_string: str) -> ParseResult:
        """Parse DRACON schema from YAML string"""
        try:
            yaml_data = yaml.safe_load(yaml_string)
            return self.yaml_parser.parse_yaml_dict(yaml_data)
        except Exception as e:
            return ParseResult(
                success=False,
                errors=[f"YAML string parsing error: {str(e)}"]
            )

    def parse_json_string(self, json_string: str) -> ParseResult:
        """Parse DRAKON Hub schema from JSON string"""
        try:
            hub_data = json.loads(json_string)
            return self.hub_importer._convert_hub_to_dracon(hub_data)
        except Exception as e:
            return ParseResult(
                success=False,
                errors=[f"JSON string parsing error: {str(e)}"]
            )


# Utility functions for schema manipulation

def schema_to_dict(schema: DraconSchema) -> Dict[str, Any]:
    """Convert DRACON schema to dictionary representation"""
    return asdict(schema)


def dict_to_schema(schema_dict: Dict[str, Any]) -> DraconSchema:
    """Convert dictionary to DRACON schema"""
    # This would need proper deserialization logic
    pass


def validate_schema_references(schema: DraconSchema) -> List[str]:
    """Validate that all node references in edges exist"""
    errors = []
    node_ids = {node.id for node in schema.nodes}

    for edge in schema.edges:
        if edge.from_node not in node_ids:
            errors.append(f"Edge {edge.id} references non-existent from_node: {edge.from_node}")

        if edge.to_node not in node_ids:
            errors.append(f"Edge {edge.id} references non-existent to_node: {edge.to_node}")

    return errors

```

### bot/features/conversation_mode.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 13,576 Ð±Ð°Ð¹Ñ‚

```python
"""Enhanced conversation features.

This module implements the Conversation Enhancement feature from TODO-7, providing:

Features:
- Context preservation across conversation turns
- Intelligent follow-up suggestions based on tools used and content
- Code execution tracking and analysis
- Interactive conversation controls with inline keyboards
- Smart suggestion prioritization

Core Components:
- ConversationContext: Tracks conversation state and metadata
- ConversationEnhancer: Main class for generating suggestions and formatting responses

The implementation analyzes Claude's responses to generate contextually relevant
follow-up suggestions, making it easier for users to continue productive conversations
with actionable next steps.

Usage:
    enhancer = ConversationEnhancer()
    enhancer.update_context(user_id, claude_response)
    suggestions = enhancer.generate_follow_up_suggestions(response, context)
    keyboard = enhancer.create_follow_up_keyboard(suggestions)
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional

import structlog
from telegram import InlineKeyboardButton, InlineKeyboardMarkup

from ...claude.integration import ClaudeResponse

logger = structlog.get_logger()


@dataclass
class ConversationContext:
    """Context information for a conversation."""

    user_id: int
    session_id: Optional[str] = None
    project_path: Optional[str] = None
    last_tools_used: List[str] = field(default_factory=list)
    last_response_content: str = ""
    conversation_turn: int = 0
    has_errors: bool = False
    active_files: List[str] = field(default_factory=list)
    todo_count: int = 0

    def update_from_response(self, response: ClaudeResponse) -> None:
        """Update context from Claude response."""
        self.session_id = response.session_id
        self.last_response_content = response.content.lower()
        self.conversation_turn += 1
        self.has_errors = response.is_error or "error" in self.last_response_content

        # Extract tools used
        self.last_tools_used = [tool.get("name", "") for tool in response.tools_used]

        # Update active files if file tools were used
        if any(tool in self.last_tools_used for tool in ["Edit", "Write", "Read"]):
            # In a real implementation, we'd parse the tool outputs to get file names
            # For now, we'll track that file operations occurred
            pass

        # Count TODOs/FIXMEs in response
        todo_keywords = ["todo", "fixme", "note", "hack", "bug"]
        self.todo_count = sum(
            1 for keyword in todo_keywords if keyword in self.last_response_content
        )


class ConversationEnhancer:
    """Enhance conversation experience."""

    def __init__(self) -> None:
        """Initialize conversation enhancer."""
        self.conversation_contexts: Dict[int, ConversationContext] = {}

    def get_or_create_context(self, user_id: int) -> ConversationContext:
        """Get or create conversation context for user."""
        if user_id not in self.conversation_contexts:
            self.conversation_contexts[user_id] = ConversationContext(user_id=user_id)

        return self.conversation_contexts[user_id]

    def update_context(self, user_id: int, response: ClaudeResponse) -> None:
        """Update conversation context with response."""
        context = self.get_or_create_context(user_id)
        context.update_from_response(response)

        logger.debug(
            "Updated conversation context",
            user_id=user_id,
            session_id=context.session_id,
            turn=context.conversation_turn,
            tools_used=context.last_tools_used,
        )

    def generate_follow_up_suggestions(
        self, response: ClaudeResponse, context: ConversationContext
    ) -> List[str]:
        """Generate relevant follow-up suggestions."""
        suggestions = []

        # Based on tools used
        tools_used = [tool.get("name", "") for tool in response.tools_used]

        if "Write" in tools_used or "MultiEdit" in tools_used:
            suggestions.extend(
                [
                    "Add tests for the new code",
                    "Create documentation for this",
                    "Review the implementation",
                ]
            )

        if "Edit" in tools_used:
            suggestions.extend(
                [
                    "Review the changes made",
                    "Run tests to verify changes",
                    "Check for any side effects",
                ]
            )

        if "Read" in tools_used:
            suggestions.extend(
                [
                    "Explain how this code works",
                    "Suggest improvements",
                    "Add error handling",
                ]
            )

        if "Bash" in tools_used:
            suggestions.extend(
                [
                    "Explain the command output",
                    "Run additional related commands",
                    "Check for any issues",
                ]
            )

        if "Glob" in tools_used or "Grep" in tools_used:
            suggestions.extend(
                [
                    "Analyze the search results",
                    "Look into specific files found",
                    "Create a summary of findings",
                ]
            )

        # Based on response content analysis
        content_lower = response.content.lower()

        if "error" in content_lower or "failed" in content_lower:
            suggestions.extend(
                [
                    "Help me debug this error",
                    "Suggest alternative approaches",
                    "Check the logs for more details",
                ]
            )

        if "todo" in content_lower or "fixme" in content_lower:
            suggestions.extend(
                [
                    "Complete the TODO items",
                    "Prioritize the tasks",
                    "Create an action plan",
                ]
            )

        if "test" in content_lower and (
            "fail" in content_lower or "error" in content_lower
        ):
            suggestions.extend(
                [
                    "Fix the failing tests",
                    "Update test expectations",
                    "Add more test coverage",
                ]
            )

        if "install" in content_lower or "dependency" in content_lower:
            suggestions.extend(
                [
                    "Verify the installation",
                    "Check for version conflicts",
                    "Update package documentation",
                ]
            )

        if "git" in content_lower:
            suggestions.extend(
                [
                    "Review the git status",
                    "Check commit history",
                    "Create a commit with changes",
                ]
            )

        # Based on conversation context
        if context.conversation_turn > 1:
            suggestions.append("Continue with the next step")

        if context.has_errors:
            suggestions.extend(
                ["Investigate the error further", "Try a different approach"]
            )

        if context.todo_count > 0:
            suggestions.append("Address the TODO items")

        # General suggestions based on development patterns
        if any(keyword in content_lower for keyword in ["function", "class", "method"]):
            suggestions.extend(
                ["Add unit tests", "Improve documentation", "Add type hints"]
            )

        if "performance" in content_lower or "optimize" in content_lower:
            suggestions.extend(
                [
                    "Profile the performance",
                    "Benchmark the changes",
                    "Monitor resource usage",
                ]
            )

        # Remove duplicates and limit to most relevant
        unique_suggestions = list(dict.fromkeys(suggestions))

        # Prioritize based on tools used and content
        prioritized = []

        # High priority: error handling and fixes
        for suggestion in unique_suggestions:
            if any(
                keyword in suggestion.lower() for keyword in ["error", "debug", "fix"]
            ):
                prioritized.append(suggestion)

        # Medium priority: development workflow
        for suggestion in unique_suggestions:
            if suggestion not in prioritized and any(
                keyword in suggestion.lower()
                for keyword in ["test", "review", "verify"]
            ):
                prioritized.append(suggestion)

        # Lower priority: enhancements
        for suggestion in unique_suggestions:
            if suggestion not in prioritized:
                prioritized.append(suggestion)

        # Return top 3-4 most relevant suggestions
        return prioritized[:4]

    def create_follow_up_keyboard(self, suggestions: List[str]) -> InlineKeyboardMarkup:
        """Create keyboard with follow-up suggestions."""
        if not suggestions:
            return InlineKeyboardMarkup([])

        keyboard = []

        # Add suggestion buttons (max 4, in rows of 1 for better mobile experience)
        for suggestion in suggestions[:4]:
            # Create a shorter hash for callback data
            suggestion_hash = str(hash(suggestion) % 1000000)
            keyboard.append(
                [
                    InlineKeyboardButton(
                        f"ðŸ’¡ {suggestion}", callback_data=f"followup:{suggestion_hash}"
                    )
                ]
            )

        # Add control buttons
        keyboard.append(
            [
                InlineKeyboardButton(
                    "âœ… Continue Coding", callback_data="conversation:continue"
                ),
                InlineKeyboardButton(
                    "ðŸ›‘ End Session", callback_data="conversation:end"
                ),
            ]
        )

        return InlineKeyboardMarkup(keyboard)

    def should_show_suggestions(self, response: ClaudeResponse) -> bool:
        """Determine if follow-up suggestions should be shown."""
        # Don't show suggestions for errors
        if response.is_error:
            return False

        # Show suggestions if tools were used
        if response.tools_used:
            return True

        # Show suggestions for longer responses (likely more substantial)
        if len(response.content) > 200:
            return True

        # Show suggestions if response contains actionable content
        actionable_keywords = [
            "todo",
            "fixme",
            "next",
            "consider",
            "you can",
            "you could",
            "try",
            "test",
            "check",
            "verify",
            "review",
        ]

        content_lower = response.content.lower()
        return any(keyword in content_lower for keyword in actionable_keywords)

    def format_response_with_suggestions(
        self,
        response: ClaudeResponse,
        context: ConversationContext,
        max_content_length: int = 3000,
    ) -> tuple[str, Optional[InlineKeyboardMarkup]]:
        """Format response with follow-up suggestions."""
        # Truncate content if too long for Telegram
        content = response.content
        if len(content) > max_content_length:
            content = content[:max_content_length] + "\n\n... _(response truncated)_"

        # Add session info if this is a new session
        if context.conversation_turn == 1 and response.session_id:
            session_info = f"\n\nðŸ†” **Session:** `{response.session_id[:8]}...`"
            content += session_info

        # Add cost info if significant
        if response.cost > 0.01:
            cost_info = f"\n\nðŸ’° **Cost:** ${response.cost:.4f}"
            content += cost_info

        # Generate follow-up suggestions
        keyboard = None
        if self.should_show_suggestions(response):
            suggestions = self.generate_follow_up_suggestions(response, context)
            if suggestions:
                keyboard = self.create_follow_up_keyboard(suggestions)
                logger.debug(
                    "Generated follow-up suggestions",
                    user_id=context.user_id,
                    suggestions=suggestions,
                )

        return content, keyboard

    def clear_context(self, user_id: int) -> None:
        """Clear conversation context for user."""
        if user_id in self.conversation_contexts:
            del self.conversation_contexts[user_id]
            logger.debug("Cleared conversation context", user_id=user_id)

    def get_context(self, user_id: int) -> Optional[ConversationContext]:
        """Get conversation context for user."""
        return self.conversation_contexts.get(user_id)

    def get_context_summary(self, user_id: int) -> Optional[Dict]:
        """Get summary of conversation context."""
        context = self.conversation_contexts.get(user_id)
        if not context:
            return None

        return {
            "session_id": context.session_id,
            "project_path": context.project_path,
            "conversation_turn": context.conversation_turn,
            "last_tools_used": context.last_tools_used,
            "has_errors": context.has_errors,
            "todo_count": context.todo_count,
            "active_files_count": len(context.active_files),
        }

```

### bot/features/file_handler.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 16,716 Ð±Ð°Ð¹Ñ‚

```python
"""
Advanced file handling

Features:
- Multiple file processing
- Zip archive extraction
- Code analysis
- Diff generation
"""

import shutil
import tarfile
import uuid
import zipfile
from collections import defaultdict
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List

from telegram import Document

from src.config import Settings
from src.security.validators import SecurityValidator


@dataclass
class ProcessedFile:
    """Processed file result"""

    type: str
    prompt: str
    metadata: Dict[str, any]


@dataclass
class CodebaseAnalysis:
    """Codebase analysis result"""

    languages: Dict[str, int]
    frameworks: List[str]
    entry_points: List[str]
    todo_count: int
    test_coverage: bool
    file_stats: Dict[str, int]


class FileHandler:
    """Handle various file operations"""

    def __init__(self, config: Settings, security: SecurityValidator):
        self.config = config
        self.security = security
        self.temp_dir = Path("/tmp/claude_bot_files")
        self.temp_dir.mkdir(exist_ok=True)

        # Supported code extensions
        self.code_extensions = {
            ".py",
            ".js",
            ".ts",
            ".jsx",
            ".tsx",
            ".java",
            ".cpp",
            ".c",
            ".h",
            ".go",
            ".rs",
            ".rb",
            ".php",
            ".swift",
            ".kt",
            ".scala",
            ".r",
            ".jl",
            ".lua",
            ".pl",
            ".sh",
            ".bash",
            ".zsh",
            ".fish",
            ".ps1",
            ".sql",
            ".html",
            ".css",
            ".scss",
            ".sass",
            ".less",
            ".vue",
            ".yaml",
            ".yml",
            ".json",
            ".xml",
            ".toml",
            ".ini",
            ".cfg",
            ".dockerfile",
            ".makefile",
            ".cmake",
            ".gradle",
            ".maven",
        }

        # Language mapping
        self.language_map = {
            ".py": "Python",
            ".js": "JavaScript",
            ".ts": "TypeScript",
            ".java": "Java",
            ".cpp": "C++",
            ".c": "C",
            ".go": "Go",
            ".rs": "Rust",
            ".rb": "Ruby",
            ".php": "PHP",
            ".swift": "Swift",
            ".kt": "Kotlin",
            ".scala": "Scala",
            ".r": "R",
            ".jl": "Julia",
            ".lua": "Lua",
            ".pl": "Perl",
            ".sh": "Shell",
            ".sql": "SQL",
            ".html": "HTML",
            ".css": "CSS",
            ".vue": "Vue",
            ".yaml": "YAML",
            ".json": "JSON",
            ".xml": "XML",
        }

    async def handle_document_upload(
        self, document: Document, user_id: int, context: str = ""
    ) -> ProcessedFile:
        """Process uploaded document"""

        # Download file
        file_path = await self._download_file(document)

        try:
            # Detect file type
            file_type = self._detect_file_type(file_path)

            # Process based on type
            if file_type == "archive":
                return await self._process_archive(file_path, context)
            elif file_type == "code":
                return await self._process_code_file(file_path, context)
            elif file_type == "text":
                return await self._process_text_file(file_path, context)
            else:
                raise ValueError(f"Unsupported file type: {file_type}")

        finally:
            # Cleanup
            file_path.unlink(missing_ok=True)

    async def _download_file(self, document: Document) -> Path:
        """Download file from Telegram"""
        # Get file
        file = await document.get_file()

        # Create temp file path
        file_name = document.file_name or f"file_{uuid.uuid4()}"
        file_path = self.temp_dir / file_name

        # Download to path
        await file.download_to_drive(str(file_path))

        return file_path

    def _detect_file_type(self, file_path: Path) -> str:
        """Detect file type based on extension and content"""
        ext = file_path.suffix.lower()

        # Check if archive
        if ext in {".zip", ".tar", ".gz", ".bz2", ".xz", ".7z"}:
            return "archive"

        # Check if code
        if ext in self.code_extensions:
            return "code"

        # Check if text
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                f.read(1024)  # Try reading first 1KB
            return "text"
        except (UnicodeDecodeError, IOError):
            return "binary"

    async def _process_archive(self, archive_path: Path, context: str) -> ProcessedFile:
        """Extract and analyze archive contents"""

        # Create extraction directory
        extract_dir = self.temp_dir / f"extract_{uuid.uuid4()}"
        extract_dir.mkdir()

        try:
            # Extract based on type
            if archive_path.suffix == ".zip":
                with zipfile.ZipFile(archive_path) as zf:
                    # Security check - prevent zip bombs
                    total_size = sum(f.file_size for f in zf.filelist)
                    if total_size > 100 * 1024 * 1024:  # 100MB limit
                        raise ValueError("Archive too large")

                    # Extract with security checks
                    for file_info in zf.filelist:
                        # Prevent path traversal
                        file_path = Path(file_info.filename)
                        if file_path.is_absolute() or ".." in file_path.parts:
                            continue

                        # Extract file
                        target_path = extract_dir / file_path
                        target_path.parent.mkdir(parents=True, exist_ok=True)

                        with (
                            zf.open(file_info) as source,
                            open(target_path, "wb") as target,
                        ):
                            shutil.copyfileobj(source, target)

            elif archive_path.suffix in {".tar", ".gz", ".bz2", ".xz"}:
                with tarfile.open(archive_path) as tf:
                    # Security checks
                    total_size = sum(member.size for member in tf.getmembers())
                    if total_size > 100 * 1024 * 1024:  # 100MB limit
                        raise ValueError("Archive too large")

                    # Extract with security checks
                    for member in tf.getmembers():
                        # Prevent path traversal
                        if member.name.startswith("/") or ".." in member.name:
                            continue

                        tf.extract(member, extract_dir)

            # Analyze contents
            file_tree = self._build_file_tree(extract_dir)
            code_files = self._find_code_files(extract_dir)

            # Create analysis prompt
            prompt = f"{context}\n\nProject structure:\n{file_tree}\n\n"

            # Add key files
            for file_path in code_files[:5]:  # Limit to 5 files
                content = file_path.read_text(encoding="utf-8", errors="ignore")
                prompt += f"\nFile: {file_path.relative_to(extract_dir)}\n```\n{content[:1000]}...\n```\n"

            return ProcessedFile(
                type="archive",
                prompt=prompt,
                metadata={
                    "file_count": len(list(extract_dir.rglob("*"))),
                    "code_files": len(code_files),
                },
            )

        finally:
            # Cleanup
            shutil.rmtree(extract_dir, ignore_errors=True)

    async def _process_code_file(self, file_path: Path, context: str) -> ProcessedFile:
        """Process single code file"""
        content = file_path.read_text(encoding="utf-8", errors="ignore")

        # Detect language
        language = self._detect_language(file_path.suffix)

        # Create prompt
        prompt = f"{context}\n\nFile: {file_path.name}\nLanguage: {language}\n\n```{language.lower()}\n{content}\n```"

        return ProcessedFile(
            type="code",
            prompt=prompt,
            metadata={
                "language": language,
                "lines": len(content.splitlines()),
                "size": file_path.stat().st_size,
            },
        )

    async def _process_text_file(self, file_path: Path, context: str) -> ProcessedFile:
        """Process text file"""
        content = file_path.read_text(encoding="utf-8", errors="ignore")

        # Create prompt
        prompt = f"{context}\n\nFile: {file_path.name}\n\n{content}"

        return ProcessedFile(
            type="text",
            prompt=prompt,
            metadata={
                "lines": len(content.splitlines()),
                "size": file_path.stat().st_size,
            },
        )

    def _build_file_tree(self, directory: Path, prefix: str = "") -> str:
        """Build visual file tree"""
        items = sorted(directory.iterdir(), key=lambda x: (x.is_file(), x.name))
        tree_lines = []

        for i, item in enumerate(items):
            is_last = i == len(items) - 1
            current_prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "

            if item.is_dir():
                tree_lines.append(f"{prefix}{current_prefix}{item.name}/")
                # Recursive call with updated prefix
                sub_prefix = prefix + ("    " if is_last else "â”‚   ")
                tree_lines.append(self._build_file_tree(item, sub_prefix))
            else:
                size = item.stat().st_size
                tree_lines.append(
                    f"{prefix}{current_prefix}{item.name} ({self._format_size(size)})"
                )

        return "\n".join(filter(None, tree_lines))

    def _format_size(self, size: int) -> str:
        """Format file size for display"""
        for unit in ["B", "KB", "MB", "GB"]:
            if size < 1024.0:
                return f"{size:.1f}{unit}"
            size /= 1024.0
        return f"{size:.1f}TB"

    def _find_code_files(self, directory: Path) -> List[Path]:
        """Find all code files in directory"""
        code_files = []

        for file_path in directory.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in self.code_extensions:
                # Skip common non-code directories
                if any(
                    part in file_path.parts
                    for part in ["node_modules", "__pycache__", ".git", "dist", "build"]
                ):
                    continue
                code_files.append(file_path)

        # Sort by importance (main files first, then by name)
        def sort_key(path: Path) -> tuple:
            name = path.name.lower()
            # Prioritize main/index files
            if name in [
                "main.py",
                "index.js",
                "app.py",
                "server.py",
                "main.go",
                "main.rs",
            ]:
                return (0, name)
            elif name.startswith("index."):
                return (1, name)
            elif name.startswith("main."):
                return (2, name)
            else:
                return (3, name)

        code_files.sort(key=sort_key)
        return code_files

    def _detect_language(self, extension: str) -> str:
        """Detect programming language from extension"""
        return self.language_map.get(extension.lower(), "text")

    async def analyze_codebase(self, directory: Path) -> CodebaseAnalysis:
        """Analyze entire codebase"""

        analysis = CodebaseAnalysis(
            languages={},
            frameworks=[],
            entry_points=[],
            todo_count=0,
            test_coverage=False,
            file_stats={},
        )

        # Language detection
        language_stats = defaultdict(int)
        file_extensions = defaultdict(int)

        for file_path in directory.rglob("*"):
            if file_path.is_file():
                ext = file_path.suffix.lower()
                file_extensions[ext] += 1

                language = self._detect_language(ext)
                if language and language != "text":
                    language_stats[language] += 1

        analysis.languages = dict(language_stats)
        analysis.file_stats = dict(file_extensions)

        # Find entry points
        analysis.entry_points = self._find_entry_points(directory)

        # Detect frameworks
        analysis.frameworks = self._detect_frameworks(directory)

        # Find TODOs and FIXMEs
        analysis.todo_count = await self._find_todos(directory)

        # Check for tests
        test_files = self._find_test_files(directory)
        analysis.test_coverage = len(test_files) > 0

        return analysis

    def _find_entry_points(self, directory: Path) -> List[str]:
        """Find likely entry points in the codebase"""
        entry_points = []

        # Common entry point patterns
        patterns = [
            "main.py",
            "app.py",
            "server.py",
            "__main__.py",
            "index.js",
            "app.js",
            "server.js",
            "main.js",
            "main.go",
            "main.rs",
            "main.cpp",
            "main.c",
            "Main.java",
            "App.java",
            "index.php",
            "index.html",
        ]

        for pattern in patterns:
            for file_path in directory.rglob(pattern):
                if file_path.is_file():
                    entry_points.append(str(file_path.relative_to(directory)))

        return entry_points

    def _detect_frameworks(self, directory: Path) -> List[str]:
        """Detect frameworks and libraries used"""
        frameworks = []

        # Framework indicators
        indicators = {
            "package.json": ["React", "Vue", "Angular", "Express", "Next.js"],
            "requirements.txt": ["Django", "Flask", "FastAPI", "PyTorch", "TensorFlow"],
            "Cargo.toml": ["Tokio", "Actix", "Rocket"],
            "go.mod": ["Gin", "Echo", "Fiber"],
            "pom.xml": ["Spring", "Maven"],
            "build.gradle": ["Spring", "Gradle"],
            "composer.json": ["Laravel", "Symfony"],
            "Gemfile": ["Rails", "Sinatra"],
        }

        for indicator_file, possible_frameworks in indicators.items():
            file_path = directory / indicator_file
            if file_path.exists():
                content = file_path.read_text(encoding="utf-8", errors="ignore").lower()
                for framework in possible_frameworks:
                    if framework.lower() in content:
                        frameworks.append(framework)

        # Check for specific framework files
        if (directory / "manage.py").exists():
            frameworks.append("Django")
        if (directory / "artisan").exists():
            frameworks.append("Laravel")
        if (directory / "next.config.js").exists():
            frameworks.append("Next.js")

        return list(set(frameworks))  # Remove duplicates

    async def _find_todos(self, directory: Path) -> int:
        """Count TODO and FIXME comments"""
        todo_count = 0

        for file_path in directory.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in self.code_extensions:
                try:
                    content = file_path.read_text(encoding="utf-8", errors="ignore")
                    # Count TODOs and FIXMEs
                    todo_count += content.upper().count("TODO")
                    todo_count += content.upper().count("FIXME")
                except Exception:
                    continue

        return todo_count

    def _find_test_files(self, directory: Path) -> List[Path]:
        """Find test files in the codebase"""
        test_files = []

        # Common test patterns
        test_patterns = [
            "test_*.py",
            "*_test.py",
            "*_test.go",
            "*.test.js",
            "*.spec.js",
            "*.test.ts",
            "*.spec.ts",
        ]

        for pattern in test_patterns:
            test_files.extend(directory.rglob(pattern))

        # Check test directories
        for test_dir_name in ["test", "tests", "__tests__", "spec"]:
            test_dir = directory / test_dir_name
            if test_dir.exists() and test_dir.is_dir():
                test_files.extend(test_dir.rglob("*"))

        return [f for f in test_files if f.is_file()]

```

### bot/features/git_integration.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 12,632 Ð±Ð°Ð¹Ñ‚

```python
"""Git integration for safe repository operations."""

import asyncio
import logging
import re
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Set, Tuple

from src.config.settings import Settings
from src.exceptions import SecurityError

logger = logging.getLogger(__name__)


class GitError(Exception):
    """Git operation error."""

    pass


@dataclass
class GitStatus:
    """Git repository status."""

    branch: str
    modified: List[str]
    added: List[str]
    deleted: List[str]
    untracked: List[str]
    ahead: int
    behind: int

    @property
    def is_clean(self) -> bool:
        """Check if working directory is clean."""
        return not any([self.modified, self.added, self.deleted, self.untracked])


@dataclass
class CommitInfo:
    """Git commit information."""

    hash: str
    author: str
    date: datetime
    message: str
    files_changed: int
    insertions: int
    deletions: int


class GitIntegration:
    """Safe git integration for repositories."""

    # Safe git commands allowed
    SAFE_COMMANDS: Set[str] = {
        "status",
        "log",
        "diff",
        "branch",
        "remote",
        "show",
        "ls-files",
        "ls-tree",
        "rev-parse",
        "rev-list",
        "describe",
    }

    # Dangerous patterns to block
    DANGEROUS_PATTERNS = [
        r"--exec",
        r"--upload-pack",
        r"--receive-pack",
        r"-c\s*core\.gitProxy",
        r"-c\s*core\.sshCommand",
    ]

    def __init__(self, settings: Settings):
        """Initialize git integration.

        Args:
            settings: Application settings
        """
        self.settings = settings
        self.approved_dir = Path(settings.approved_directory)

    async def execute_git_command(
        self, command: List[str], cwd: Path
    ) -> Tuple[str, str]:
        """Execute safe git command.

        Args:
            command: Git command parts
            cwd: Working directory

        Returns:
            Tuple of (stdout, stderr)

        Raises:
            SecurityError: If command is unsafe
            GitError: If git command fails
        """
        # Validate command safety
        if not command or command[0] != "git":
            raise SecurityError("Only git commands allowed")

        if len(command) < 2 or command[1] not in self.SAFE_COMMANDS:
            raise SecurityError(f"Unsafe git command: {command[1]}")

        # Check for dangerous patterns
        cmd_str = " ".join(command)
        for pattern in self.DANGEROUS_PATTERNS:
            if re.search(pattern, cmd_str, re.IGNORECASE):
                raise SecurityError(f"Dangerous pattern detected: {pattern}")

        # Validate working directory
        try:
            cwd = cwd.resolve()
            if not cwd.is_relative_to(self.approved_dir):
                raise SecurityError("Repository outside approved directory")
        except Exception:
            raise SecurityError("Invalid repository path")

        # Execute command
        try:
            process = await asyncio.create_subprocess_exec(
                *command,
                cwd=cwd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )

            stdout, stderr = await process.communicate()

            if process.returncode != 0:
                raise GitError(f"Git command failed: {stderr.decode()}")

            return stdout.decode(), stderr.decode()

        except asyncio.TimeoutError:
            raise GitError("Git command timed out")
        except Exception as e:
            logger.error(f"Git command error: {e}")
            raise GitError(f"Failed to execute git command: {e}")

    async def get_status(self, repo_path: Path) -> GitStatus:
        """Get repository status.

        Args:
            repo_path: Repository path

        Returns:
            Git status information
        """
        # Get branch and tracking info
        branch_out, _ = await self.execute_git_command(
            ["git", "branch", "--show-current"], repo_path
        )
        branch = branch_out.strip() or "HEAD"

        # Get file status
        status_out, _ = await self.execute_git_command(
            ["git", "status", "--porcelain=v1"], repo_path
        )

        modified = []
        added = []
        deleted = []
        untracked = []

        for line in status_out.strip().split("\n"):
            if not line:
                continue

            status = line[:2]
            filename = line[3:]

            if status == "??":
                untracked.append(filename)
            elif "M" in status:
                modified.append(filename)
            elif "A" in status:
                added.append(filename)
            elif "D" in status:
                deleted.append(filename)

        # Get ahead/behind counts
        ahead = behind = 0
        try:
            # Try to get upstream tracking info
            rev_out, _ = await self.execute_git_command(
                ["git", "rev-list", "--count", "--left-right", "HEAD...@{upstream}"],
                repo_path,
            )
            if rev_out.strip():
                parts = rev_out.strip().split("\t")
                if len(parts) == 2:
                    ahead = int(parts[0])
                    behind = int(parts[1])
        except GitError:
            # No upstream configured
            pass

        return GitStatus(
            branch=branch,
            modified=modified,
            added=added,
            deleted=deleted,
            untracked=untracked,
            ahead=ahead,
            behind=behind,
        )

    async def get_diff(
        self, repo_path: Path, staged: bool = False, file_path: Optional[str] = None
    ) -> str:
        """Get repository diff.

        Args:
            repo_path: Repository path
            staged: Show staged changes
            file_path: Specific file to diff

        Returns:
            Formatted diff output
        """
        command = ["git", "diff"]

        if staged:
            command.append("--staged")

        # Add formatting options
        command.extend(["--no-color", "--minimal"])

        if file_path:
            # Validate file path
            file_path_obj = (repo_path / file_path).resolve()
            if not file_path_obj.is_relative_to(repo_path):
                raise SecurityError("File path outside repository")
            command.append(file_path)

        diff_out, _ = await self.execute_git_command(command, repo_path)

        if not diff_out.strip():
            return "No changes to show"

        # Format diff with indicators
        lines = []
        for line in diff_out.split("\n"):
            if line.startswith("+") and not line.startswith("+++"):
                lines.append(f"âž• {line[1:]}")
            elif line.startswith("-") and not line.startswith("---"):
                lines.append(f"âž– {line[1:]}")
            elif line.startswith("@@"):
                lines.append(f"ðŸ“ {line}")
            else:
                lines.append(line)

        return "\n".join(lines)

    async def get_file_history(
        self, repo_path: Path, file_path: str, limit: int = 10
    ) -> List[CommitInfo]:
        """Get file commit history.

        Args:
            repo_path: Repository path
            file_path: File to get history for
            limit: Maximum commits to return

        Returns:
            List of commit information
        """
        # Validate file path
        file_path_obj = (repo_path / file_path).resolve()
        if not file_path_obj.is_relative_to(repo_path):
            raise SecurityError("File path outside repository")

        # Get commit log with stats
        log_out, _ = await self.execute_git_command(
            [
                "git",
                "log",
                f"--max-count={limit}",
                "--pretty=format:%H|%an|%aI|%s",
                "--numstat",
                "--",
                file_path,
            ],
            repo_path,
        )

        commits = []
        current_commit = None

        for line in log_out.strip().split("\n"):
            if not line:
                continue

            if "|" in line and len(line.split("|")) == 4:
                # Commit info line
                parts = line.split("|")

                if current_commit:
                    commits.append(current_commit)

                current_commit = CommitInfo(
                    hash=parts[0][:8],  # Short hash
                    author=parts[1],
                    date=datetime.fromisoformat(parts[2].replace("Z", "+00:00")),
                    message=parts[3],
                    files_changed=0,
                    insertions=0,
                    deletions=0,
                )
            elif current_commit and "\t" in line:
                # Numstat line
                parts = line.split("\t")
                if len(parts) == 3:
                    try:
                        insertions = int(parts[0]) if parts[0] != "-" else 0
                        deletions = int(parts[1]) if parts[1] != "-" else 0
                        current_commit.insertions += insertions
                        current_commit.deletions += deletions
                        current_commit.files_changed += 1
                    except ValueError:
                        pass

        if current_commit:
            commits.append(current_commit)

        return commits

    def format_status(self, status: GitStatus) -> str:
        """Format git status for display.

        Args:
            status: Git status object

        Returns:
            Formatted status string
        """
        lines = [f"ðŸŒ¿ Branch: {status.branch}"]

        # Add tracking info
        if status.ahead or status.behind:
            tracking = []
            if status.ahead:
                tracking.append(f"â†‘{status.ahead}")
            if status.behind:
                tracking.append(f"â†“{status.behind}")
            lines.append(f"ðŸ“Š Tracking: {' '.join(tracking)}")

        if status.is_clean:
            lines.append("âœ… Working tree clean")
        else:
            if status.modified:
                lines.append(f"ðŸ“ Modified: {len(status.modified)} files")
                for f in status.modified[:5]:  # Show first 5
                    lines.append(f"  â€¢ {f}")
                if len(status.modified) > 5:
                    lines.append(f"  ... and {len(status.modified) - 5} more")

            if status.added:
                lines.append(f"âž• Added: {len(status.added)} files")
                for f in status.added[:5]:
                    lines.append(f"  â€¢ {f}")
                if len(status.added) > 5:
                    lines.append(f"  ... and {len(status.added) - 5} more")

            if status.deleted:
                lines.append(f"âž– Deleted: {len(status.deleted)} files")
                for f in status.deleted[:5]:
                    lines.append(f"  â€¢ {f}")
                if len(status.deleted) > 5:
                    lines.append(f"  ... and {len(status.deleted) - 5} more")

            if status.untracked:
                lines.append(f"â“ Untracked: {len(status.untracked)} files")
                for f in status.untracked[:5]:
                    lines.append(f"  â€¢ {f}")
                if len(status.untracked) > 5:
                    lines.append(f"  ... and {len(status.untracked) - 5} more")

        return "\n".join(lines)

    def format_history(self, commits: List[CommitInfo]) -> str:
        """Format commit history for display.

        Args:
            commits: List of commits

        Returns:
            Formatted history string
        """
        if not commits:
            return "No commit history found"

        lines = ["ðŸ“œ Commit History:"]

        for commit in commits:
            lines.append(
                f"\nðŸ”¹ {commit.hash} - {commit.date.strftime('%Y-%m-%d %H:%M')}"
            )
            lines.append(f"   ðŸ‘¤ {commit.author}")
            lines.append(f"   ðŸ’¬ {commit.message}")

            if commit.files_changed:
                stats = []
                if commit.insertions:
                    stats.append(f"+{commit.insertions}")
                if commit.deletions:
                    stats.append(f"-{commit.deletions}")
                lines.append(
                    f"   ðŸ“Š {commit.files_changed} files changed, {' '.join(stats)}"
                )

        return "\n".join(lines)

```

### bot/features/demo_dracon_system.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 7,547 Ð±Ð°Ð¹Ñ‚

```python
#!/usr/bin/env python3
"""
DRACON System Demonstration

This script demonstrates the complete DRACON subsystem for Telegram bot development:
1. Parse a DRACON-YAML schema
2. Validate the schema  
3. Render visual diagram
4. Generate Python bot code
5. Analyze the existing bot code for reverse engineering
"""

import sys
from pathlib import Path
import logging

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def demonstrate_dracon_system():
    """Demonstrate the complete DRACON system functionality"""

    print("=" * 80)
    print("DRACON TELEGRAM BOT SUBSYSTEM DEMONSTRATION")
    print("=" * 80)
    print()

    # Step 1: Parse DRACON Schema
    print("ðŸ” Step 1: Parsing DRACON-YAML Schema")
    print("-" * 50)

    try:
        from dracon_parser import DraconParser
        from dracon_types import RenderOptions

        schema_file = Path("simple_bot_schema.yaml")
        if not schema_file.exists():
            print(f"âŒ Schema file {schema_file} not found")
            return

        parser = DraconParser()
        parse_result = parser.parse_file(schema_file)

        if parse_result.success:
            print(f"âœ… Successfully parsed schema: {parse_result.schema.metadata.name}")
            print(f"   - Nodes: {len(parse_result.schema.nodes)}")
            print(f"   - Edges: {len(parse_result.schema.edges)}")
            print(f"   - Author: {parse_result.schema.metadata.author}")
            print(f"   - Version: {parse_result.schema.metadata.version}")

            schema = parse_result.schema
        else:
            print(f"âŒ Schema parsing failed:")
            for error in parse_result.errors:
                print(f"   - {error}")
            return

    except Exception as e:
        print(f"âŒ Error parsing schema: {e}")
        return

    print()

    # Step 2: Validate Schema
    print("âœ… Step 2: Schema Validation")
    print("-" * 50)

    try:
        # Basic validation (could be enhanced with dracon_validator.py)
        validation_errors = []

        # Check for orphaned nodes
        node_ids = {node.id for node in schema.nodes}
        for edge in schema.edges:
            if edge.from_node not in node_ids:
                validation_errors.append(f"Edge references non-existent from_node: {edge.from_node}")
            if edge.to_node not in node_ids:
                validation_errors.append(f"Edge references non-existent to_node: {edge.to_node}")

        if validation_errors:
            print("âš ï¸  Validation warnings:")
            for error in validation_errors:
                print(f"   - {error}")
        else:
            print("âœ… Schema validation passed")

    except Exception as e:
        print(f"âŒ Error validating schema: {e}")

    print()

    # Step 3: Render Visual Diagram
    print("ðŸŽ¨ Step 3: Rendering Visual Diagram")
    print("-" * 50)

    try:
        from dracon_renderer import DraconRenderer

        renderer = DraconRenderer("default")
        render_options = RenderOptions(
            format="svg",
            width=800,
            height=600,
            show_grid=True,
            show_labels=True
        )

        svg_content = renderer.render(schema, render_options)

        # Save SVG file
        svg_path = Path("simple_bot_diagram.svg")
        with open(svg_path, 'w', encoding='utf-8') as f:
            f.write(svg_content)

        print(f"âœ… Visual diagram rendered and saved to {svg_path}")
        print(f"   - Format: SVG")
        print(f"   - Size: {render_options.width}x{render_options.height}")
        print(f"   - Features: Grid, Labels, Professional styling")

    except Exception as e:
        print(f"âŒ Error rendering diagram: {e}")

    print()

    # Step 4: Generate Bot Code
    print("ðŸ¤– Step 4: Generating Telegram Bot Code")
    print("-" * 50)

    try:
        from dracon_generator import DraconCodeGenerator

        generator = DraconCodeGenerator()
        generation_result = generator.generate_telegram_bot(schema)

        if generation_result.success:
            print("âœ… Bot code generated successfully")
            print(f"   - Generated files: {len(generation_result.files)}")

            # Save generated files
            output_dir = Path("generated_bot")
            output_dir.mkdir(exist_ok=True)

            for filename, content in generation_result.files.items():
                file_path = output_dir / filename
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"   - {filename} ({len(content)} chars)")

            print(f"   ðŸ“ All files saved to: {output_dir}/")

        else:
            print("âŒ Code generation failed:")
            for error in generation_result.errors:
                print(f"   - {error}")

    except Exception as e:
        print(f"âŒ Error generating code: {e}")

    print()

    # Step 5: Demonstrate Integration with Existing Bot
    print("ðŸ”„ Step 5: Integration with Existing Bot Code")
    print("-" * 50)

    try:
        print("âœ… DRACON system can integrate with existing bot:")
        print("   - Reverse engineering: Extract DRACON schemas from existing code")
        print("   - Forward compatibility: Generate code that works with current bot")
        print("   - Telegram integration: /dracon, /schema, /generate commands")
        print("   - File management: Organized drn/ directory structure")
        print("   - Version control: Schema evolution and versioning")

    except Exception as e:
        print(f"âŒ Error in integration demo: {e}")

    print()

    # Step 6: Summary
    print("ðŸ“Š Step 6: System Capabilities Summary")
    print("-" * 50)

    capabilities = [
        "âœ… Complete DRACON language parser and validator",
        "âœ… Professional visual schema renderer (SVG/PNG)",
        "âœ… Bidirectional conversion: code â†” DRACON â†” YAML", 
        "âœ… Real-time schema validation with DRACON rules",
        "âœ… Automatic Python code generation from schemas",
        "âœ… Telegram bot handler generation",
        "âœ… State machine implementation",
        "âœ… File management with categorized storage",
        "âœ… Multiple export formats supported",
        "âœ… Template-based code generation",
        "âœ… Hierarchical layout algorithms",
        "âœ… Professional diagram theming",
        "âœ… Comprehensive error handling",
        "âœ… Type hints and documentation generation",
        "âœ… Extensible architecture for future features"
    ]

    for capability in capabilities:
        print(f"   {capability}")

    print()
    print("=" * 80)
    print("DRACON SYSTEM DEMONSTRATION COMPLETE")
    print("=" * 80)
    print()
    print("ðŸ“ Generated Files:")
    print("   - simple_bot_diagram.svg (Visual diagram)")
    print("   - generated_bot/ (Complete bot implementation)")
    print("     â””â”€â”€ simple_telegram_bot.py")
    print("     â””â”€â”€ config.py") 
    print("     â””â”€â”€ main.py")
    print("     â””â”€â”€ requirements.txt")
    print()
    print("ðŸš€ Next Steps:")
    print("   1. Set TELEGRAM_BOT_TOKEN environment variable")
    print("   2. Install requirements: pip install -r generated_bot/requirements.txt")
    print("   3. Run bot: python generated_bot/main.py")
    print("   4. Integrate with existing project using the drn/ folder structure")
    print()


if __name__ == "__main__":
    demonstrate_dracon_system()

```

### bot/features/intelligent_auditor.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 22,636 Ð±Ð°Ð¹Ñ‚

```python
#!/usr/bin/env python3
"""
Intelligent Telegram Bot Auditor - Ð¿Ð¾Ñ”Ð´Ð½ÑƒÑ” ÑÑ‚Ð°Ñ‚Ð¸Ñ‡Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ð· Claude CLI Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚Ð¾Ð¼
Ð’Ð¸ÑÐ²Ð»ÑÑ” ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð½Ñ–, Ð»Ð¾Ð³Ñ–Ñ‡Ð½Ñ– Ñ‚Ð° Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð½Ñ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ Ð² Telegram Ð±Ð¾Ñ‚Ð°Ñ…
"""

import ast
import json
import os
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, List, Set, Tuple, Union, Optional
from dataclasses import dataclass, asdict
from collections import defaultdict
import structlog

logger = structlog.get_logger(__name__)

@dataclass
class AuditIssue:
    category: str
    severity: str  # CRITICAL, HIGH, MEDIUM, LOW
    file_path: str
    line_number: int
    description: str
    code_snippet: str = ""
    fix_suggestion: str = ""
    claude_analysis: str = ""  # Ð”Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ð²Ñ–Ð´ Claude
    group: str = ""  # Ð“Ñ€ÑƒÐ¿Ð° Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ð´Ð»Ñ batch fixing

@dataclass
class AuditResult:
    total_issues: int
    critical_count: int
    high_count: int
    medium_count: int
    low_count: int
    issues: List[AuditIssue]
    claude_summary: str = ""
    recommendations: List[str] = None

    def __post_init__(self):
        if self.recommendations is None:
            self.recommendations = []

class IntelligentTelegramBotAuditor:
    """Ð Ð¾Ð·ÑƒÐ¼Ð½Ð¸Ð¹ Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€ Ð´Ð»Ñ Telegram Ð±Ð¾Ñ‚Ñ–Ð² Ð· Claude CLI Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ”ÑŽ"""

    def __init__(self, project_root: str, claude_integration=None):
        self.project_root = Path(project_root)
        self.claude_integration = claude_integration
        self.issues: List[AuditIssue] = []

        # Ð”Ð°Ð½Ñ– Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ
        self.translation_keys: Dict[str, Set[str]] = {}
        self.callback_handlers: Set[str] = set()
        self.button_callbacks: Set[str] = set()
        self.used_translation_keys: Set[str] = set()
        self.command_handlers: Set[str] = set()

        # ÐšÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ
        self.analysis_config = {
            "enable_claude_analysis": True,
            "claude_analysis_threshold": "HIGH",  # ÐœÑ–Ð½Ñ–Ð¼Ð°Ð»ÑŒÐ½Ð° ÑÐµÑ€Ð¹Ð¾Ð·Ð½Ñ–ÑÑ‚ÑŒ Ð´Ð»Ñ Claude Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ
            "group_similar_issues": True,
            "max_claude_calls": 10  # ÐžÐ±Ð¼ÐµÐ¶ÐµÐ½Ð½Ñ Ð²Ð¸ÐºÐ»Ð¸ÐºÑ–Ð² Claude
        }

    async def run_audit(self, focus_area: Optional[str] = None) -> AuditResult:
        """Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ð¿Ð¾Ð²Ð½Ð¸Ð¹ Ð°ÑƒÐ´Ð¸Ñ‚ Ð· Claude Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ñ–Ñ”ÑŽ"""
        logger.info("Starting intelligent bot audit", project_root=str(self.project_root), focus_area=focus_area)

        # 1. Ð¡Ñ‚Ð°Ñ‚Ð¸Ñ‡Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· (Ð½Ð° Ð±Ð°Ð·Ñ– Ñ–ÑÐ½ÑƒÑŽÑ‡Ð¾Ð³Ð¾ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð°)
        await self._run_static_analysis(focus_area)

        # 2. Ð“Ñ€ÑƒÐ¿ÑƒÐ²Ð°Ð½Ð½Ñ ÑÑ…Ð¾Ð¶Ð¸Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼
        if self.analysis_config["group_similar_issues"]:
            self._group_similar_issues()

        # 3. Claude Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð·
        if self.analysis_config["enable_claude_analysis"] and self.claude_integration:
            await self._run_claude_analysis()

        # 4. Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ð¹
        recommendations = await self._generate_recommendations()

        # 5. ÐŸÑ–Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñƒ
        result = self._prepare_audit_result(recommendations)

        logger.info("Audit completed",
                   total_issues=result.total_issues,
                   critical=result.critical_count,
                   high=result.high_count)

        return result

    async def _run_static_analysis(self, focus_area: Optional[str] = None):
        """Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ ÑÑ‚Ð°Ñ‚Ð¸Ñ‡Ð½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· ÐºÐ¾Ð´Ñƒ"""
        logger.info("Running static analysis")

        # Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ð¸Ñ‚Ð¸ Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´Ð¸
        self._load_translation_keys()

        # Ð—Ð½Ð°Ð¹Ñ‚Ð¸ Ð²ÑÑ– Python Ñ„Ð°Ð¹Ð»Ð¸
        python_files = list(self.project_root.rglob("*.py"))

        for file_path in python_files:
            if self._should_skip_file(file_path):
                continue

            try:
                await self._analyze_python_file(file_path, focus_area)
            except Exception as e:
                self.issues.append(AuditIssue(
                    category="PARSING_ERROR",
                    severity="HIGH",
                    file_path=str(file_path),
                    line_number=0,
                    description=f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ñƒ Ñ„Ð°Ð¹Ð»Ñƒ: {e}",
                    group="parsing_errors"
                ))

        # Ð¡Ð¿ÐµÑ†Ñ–Ð°Ð»ÑŒÐ½Ñ– Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸
        self._audit_callback_coverage()
        self._audit_translation_coverage()
        self._audit_architecture_issues()

    def _should_skip_file(self, file_path: Path) -> bool:
        """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ñ‡Ð¸ Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ð¾ Ð¿Ñ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»"""
        skip_patterns = ["venv", "__pycache__", ".git", "node_modules", ".pytest_cache"]
        return any(pattern in str(file_path) for pattern in skip_patterns)

    async def _analyze_python_file(self, file_path: Path, focus_area: Optional[str] = None):
        """ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ²Ð°Ñ‚Ð¸ Ð¾Ð´Ð¸Ð½ Python Ñ„Ð°Ð¹Ð»"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')

            tree = ast.parse(content)

            # Ð Ñ–Ð·Ð½Ñ– Ñ‚Ð¸Ð¿Ð¸ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ Ð·Ð°Ð»ÐµÐ¶Ð½Ð¾ Ð²Ñ–Ð´ focus_area
            if not focus_area or focus_area == "callbacks":
                self._check_callback_handlers(tree, file_path, lines)
                self._check_button_callback_consistency(tree, file_path, lines)

            if not focus_area or focus_area == "localization":
                self._check_translation_usage(tree, file_path, lines)
                self._check_hardcoded_strings(file_path, lines)

            if not focus_area or focus_area == "security":
                self._check_security_issues(tree, file_path, lines)

            if not focus_area or focus_area == "architecture":
                self._check_architecture_patterns(tree, file_path, lines)

        except Exception as e:
            logger.error("Failed to analyze file", file_path=str(file_path), error=str(e))

    def _check_callback_handlers(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ callback handlers (Ñ€Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ð° Ð²ÐµÑ€ÑÑ–Ñ)"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if node.name.endswith('_callback') or 'callback' in node.name:
                    self.callback_handlers.add(node.name)

                    # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ñ‡Ð¸ Ñ” await query.answer()
                    has_answer = False
                    for subnode in ast.walk(node):
                        if (isinstance(subnode, ast.Call) and
                            isinstance(subnode.func, ast.Attribute) and
                            subnode.func.attr == 'answer'):
                            has_answer = True
                            break

                    if not has_answer:
                        self.issues.append(AuditIssue(
                            category="CALLBACK_NO_ANSWER",
                            severity="MEDIUM",
                            file_path=str(file_path),
                            line_number=getattr(node, 'lineno', 0),
                            description=f"Callback {node.name} Ð½Ðµ Ð²Ð¸ÐºÐ»Ð¸ÐºÐ°Ñ” query.answer()",
                            code_snippet=lines[getattr(node, 'lineno', 1) - 1] if lines else "",
                            fix_suggestion="Ð”Ð¾Ð´Ð°Ñ‚Ð¸ await query.answer() Ð½Ð° Ð¿Ð¾Ñ‡Ð°Ñ‚Ð¾Ðº callback Ñ„ÑƒÐ½ÐºÑ†Ñ–Ñ—",
                            group="callback_missing_answer"
                        ))

    def _check_security_issues(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ Ð±ÐµÐ·Ð¿ÐµÐºÐ¸"""
        for node in ast.walk(tree):
            # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ SQL injection Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾ÑÑ‚Ñ–
            if isinstance(node, ast.Call):
                if (isinstance(node.func, ast.Attribute) and
                    node.func.attr in ['execute', 'query']):

                    # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ñ‡Ð¸ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ñ‚ÑŒÑÑ string formatting Ð² SQL
                    for arg in node.args:
                        if isinstance(arg, ast.BinOp) and isinstance(arg.op, ast.Mod):
                            self.issues.append(AuditIssue(
                                category="SQL_INJECTION_RISK",
                                severity="CRITICAL",
                                file_path=str(file_path),
                                line_number=getattr(node, 'lineno', 0),
                                description="ÐœÐ¾Ð¶Ð»Ð¸Ð²Ð¸Ð¹ SQL injection Ñ‡ÐµÑ€ÐµÐ· string formatting",
                                code_snippet=lines[getattr(node, 'lineno', 1) - 1] if lines else "",
                                fix_suggestion="Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ parameterized queries",
                                group="security_sql"
                            ))

    def _check_architecture_patterns(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð½Ñ– Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð¸"""
        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð²ÐµÐ»Ð¸ÐºÑ– Ñ„ÑƒÐ½ÐºÑ†Ñ–Ñ—
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                func_lines = getattr(node, 'end_lineno', 0) - getattr(node, 'lineno', 0)
                if func_lines > 50:
                    self.issues.append(AuditIssue(
                        category="LARGE_FUNCTION",
                        severity="MEDIUM",
                        file_path=str(file_path),
                        line_number=getattr(node, 'lineno', 0),
                        description=f"Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ {node.name} Ð·Ð°Ð½Ð°Ð´Ñ‚Ð¾ Ð²ÐµÐ»Ð¸ÐºÐ° ({func_lines} Ñ€ÑÐ´ÐºÑ–Ð²)",
                        fix_suggestion="Ð Ð¾Ð·Ð±Ð¸Ñ‚Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ñ–ÑŽ Ð½Ð° Ð¼ÐµÐ½ÑˆÑ– Ñ‡Ð°ÑÑ‚Ð¸Ð½Ð¸",
                        group="architecture_large_functions"
                    ))

    def _group_similar_issues(self):
        """Ð“Ñ€ÑƒÐ¿ÑƒÐ²Ð°Ñ‚Ð¸ ÑÑ…Ð¾Ð¶Ñ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ Ð´Ð»Ñ batch Ð²Ð¸Ñ€Ñ–ÑˆÐµÐ½Ð½Ñ"""
        groups = defaultdict(list)

        for issue in self.issues:
            if issue.group:
                groups[issue.group].append(issue)

        # ÐžÐ½Ð¾Ð²Ð¸Ñ‚Ð¸ Ð¾Ð¿Ð¸ÑÐ¸ Ð´Ð»Ñ Ð³Ñ€ÑƒÐ¿
        for group_name, group_issues in groups.items():
            if len(group_issues) > 1:
                for issue in group_issues:
                    issue.description = f"[Ð“Ð Ð£ÐŸÐ: {len(group_issues)} ÑÑ…Ð¾Ð¶Ð¸Ñ…] {issue.description}"

    async def _run_claude_analysis(self):
        """Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ñ–Ð½Ñ‚ÐµÐ»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ñ‡ÐµÑ€ÐµÐ· Claude CLI"""
        if not self.claude_integration:
            logger.warning("Claude integration not available for intelligent analysis")
            return

        # Ð’Ð¸Ð±Ñ€Ð°Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ Ð´Ð»Ñ Claude Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ
        high_priority_issues = [
            issue for issue in self.issues
            if issue.severity in ["CRITICAL", "HIGH"]
        ][:self.analysis_config["max_claude_calls"]]

        logger.info("Running Claude analysis", issues_count=len(high_priority_issues))

        for issue in high_priority_issues:
            try:
                claude_analysis = await self._get_claude_analysis_for_issue(issue)
                issue.claude_analysis = claude_analysis
            except Exception as e:
                logger.error("Claude analysis failed for issue",
                           issue_description=issue.description, error=str(e))

    async def _get_claude_analysis_for_issue(self, issue: AuditIssue) -> str:
        """ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Claude Ð°Ð½Ð°Ð»Ñ–Ð· Ð´Ð»Ñ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¾Ñ— Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸"""
        prompt = self._build_claude_prompt_for_issue(issue)

        try:
            response = await self.claude_integration.run_command(
                prompt=prompt,
                working_directory=self.project_root,
                user_id=0  # System user for audit
            )

            if response and response.content:
                return response.content.strip()
            else:
                return "Claude Ð°Ð½Ð°Ð»Ñ–Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹"

        except Exception as e:
            logger.error("Failed to get Claude analysis", error=str(e))
            return f"ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Claude Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ: {str(e)}"

    def _build_claude_prompt_for_issue(self, issue: AuditIssue) -> str:
        """ÐŸÐ¾Ð±ÑƒÐ´ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Claude Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸"""

        # Ð§Ð¸Ñ‚Ð°Ñ”Ð¼Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð½Ð°Ð²ÐºÐ¾Ð»Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸
        context_lines = self._get_file_context(issue.file_path, issue.line_number)

        prompt = f"""
**ÐÐ£Ð”Ð˜Ð¢ TELEGRAM Ð‘ÐžÐ¢Ð - Ð†ÐÐ¢Ð•Ð›Ð•ÐšÐ¢Ð£ÐÐ›Ð¬ÐÐ˜Ð™ ÐÐÐÐ›Ð†Ð— ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ˜**

**Ð¢Ð¸Ð¿ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸:** {issue.category}
**Ð¡ÐµÑ€Ð¹Ð¾Ð·Ð½Ñ–ÑÑ‚ÑŒ:** {issue.severity}
**ÐžÐ¿Ð¸Ñ:** {issue.description}
**Ð¤Ð°Ð¹Ð»:** {issue.file_path}:{issue.line_number}

**ÐšÐ¾Ð´ Ð½Ð°Ð²ÐºÐ¾Ð»Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸:**
```python
{context_lines}
```

**ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð° Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ:** {issue.fix_suggestion}

**Ð—ÐÐ’Ð”ÐÐÐÐ¯:**
1. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñƒ Ð· Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð·Ð¾Ñ€Ñƒ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸ Telegram Ð±Ð¾Ñ‚Ñ–Ð²
2. ÐžÑ†Ñ–Ð½Ñ–Ñ‚ÑŒ Ð¿Ð¾Ñ‚ÐµÐ½Ñ†Ñ–Ð¹Ð½Ð¸Ð¹ Ð²Ð¿Ð»Ð¸Ð² Ð½Ð° ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ñ–Ð²
3. Ð—Ð°Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÐ¹Ñ‚Ðµ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ðµ Ñ€Ñ–ÑˆÐµÐ½Ð½Ñ Ð· ÐºÐ¾Ð´Ð¾Ð¼
4. Ð’Ð¸Ð·Ð½Ð°Ñ‡Ñ‚Ðµ Ñ‡Ð¸ Ð¼Ð¾Ð¶Ðµ Ñ†Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ð¿Ñ€Ð¸Ð·Ð²ÐµÑÑ‚Ð¸ Ð´Ð¾ Ñ–Ð½ÑˆÐ¸Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼
5. ÐžÑ†Ñ–Ð½Ñ–Ñ‚Ðµ Ð¿Ñ€Ñ–Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ Ð²Ð¸Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ñ (1-10)

**ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢ ÐŸÐ ÐžÐ•ÐšÐ¢Ð£:**
- Ð¦Ðµ Claude Code Telegram Bot Ð· Ð»Ð¾ÐºÐ°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ”ÑŽ
- Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ñ‚ÑŒÑÑ python-telegram-bot Ð±Ñ–Ð±Ð»Ñ–Ð¾Ñ‚ÐµÐºÐ°
- Ð„ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° callback handlers Ñ‚Ð° inline keyboards
- ÐŸÑ–Ð´Ñ‚Ñ€Ð¸Ð¼ÑƒÑ”Ñ‚ÑŒÑÑ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ° Ñ‚Ð° Ð°Ð½Ð³Ð»Ñ–Ð¹ÑÑŒÐºÐ° Ð¼Ð¾Ð²Ð¸

Ð”Ð°Ð¹Ñ‚Ðµ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ñ– Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ñ– Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ—.
"""
        return prompt

    def _get_file_context(self, file_path: str, line_number: int, context_size: int = 10) -> str:
        """ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð½Ð°Ð²ÐºÐ¾Ð»Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ð¾Ñ— Ð»Ñ–Ð½Ñ–Ñ—"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            start = max(0, line_number - context_size - 1)
            end = min(len(lines), line_number + context_size)

            context_lines = []
            for i in range(start, end):
                prefix = ">>> " if i == line_number - 1 else "    "
                context_lines.append(f"{prefix}{i+1:3d}: {lines[i].rstrip()}")

            return "\n".join(context_lines)

        except Exception as e:
            return f"ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: {e}"

    async def _generate_recommendations(self) -> List[str]:
        """Ð—Ð³ÐµÐ½ÐµÑ€ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð°Ð³Ð°Ð»ÑŒÐ½Ñ– Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ— Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¸Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼"""
        recommendations = []

        # ÐÐ½Ð°Ð»Ñ–Ð· Ð¿Ð°Ñ‚ÐµÑ€Ð½Ñ–Ð² Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼
        category_counts = defaultdict(int)
        severity_counts = defaultdict(int)

        for issue in self.issues:
            category_counts[issue.category] += 1
            severity_counts[issue.severity] += 1

        # Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ— Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¸Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼
        if severity_counts["CRITICAL"] > 0:
            recommendations.append(f"ðŸš¨ ÐÐ•Ð“ÐÐ™ÐÐž Ð²Ð¸Ð¿Ñ€Ð°Ð²Ð¸Ñ‚Ð¸ {severity_counts['CRITICAL']} ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¸Ñ… Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼")

        # Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ— Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ñ–Ð¹
        if category_counts["CALLBACK_ERROR"] > 3:
            recommendations.append("ðŸ”˜ ÐŸÑ€Ð¾Ð²ÐµÑÑ‚Ð¸ Ñ€ÐµÐ²Ñ–Ð·Ñ–ÑŽ Ð²ÑÑ–Ñ… callback handlers - Ð±Ð°Ð³Ð°Ñ‚Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼")

        if category_counts["HARDCODED_UKRAINIAN"] > 5:
            recommendations.append("ðŸŒ Ð—Ð°Ð²ÐµÑ€ÑˆÐ¸Ñ‚Ð¸ Ð¼Ñ–Ð³Ñ€Ð°Ñ†Ñ–ÑŽ Ð½Ð° Ð»Ð¾ÐºÐ°Ð»Ñ–Ð·Ð°Ñ†Ñ–ÑŽ - Ð·Ð°Ð±Ð°Ð³Ð°Ñ‚Ð¾ hardcoded Ñ‚ÐµÐºÑÑ‚Ñƒ")

        # Ð—Ð°Ð³Ð°Ð»ÑŒÐ½Ñ– Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ—
        if len(self.issues) > 20:
            recommendations.append("ðŸ“Š Ð Ð¾Ð·Ð³Ð»ÑÐ½ÑƒÑ‚Ð¸ Ð²Ð¿Ñ€Ð¾Ð²Ð°Ð´Ð¶ÐµÐ½Ð½Ñ CI/CD Ð· Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¸Ð¼Ð¸ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ°Ð¼Ð¸")

        return recommendations

    def _prepare_audit_result(self, recommendations: List[str]) -> AuditResult:
        """ÐŸÑ–Ð´Ð³Ð¾Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ñ„Ñ–Ð½Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð°ÑƒÐ´Ð¸Ñ‚Ñƒ"""
        severity_counts = defaultdict(int)

        for issue in self.issues:
            severity_counts[issue.severity] += 1

        return AuditResult(
            total_issues=len(self.issues),
            critical_count=severity_counts["CRITICAL"],
            high_count=severity_counts["HIGH"],
            medium_count=severity_counts["MEDIUM"],
            low_count=severity_counts["LOW"],
            issues=sorted(self.issues, key=lambda x: (x.severity, x.category)),
            recommendations=recommendations
        )

    def _load_translation_keys(self):
        """Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ð¸Ñ‚Ð¸ ÐºÐ»ÑŽÑ‡Ñ– Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´Ñ–Ð² (ÑÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð° Ð²ÐµÑ€ÑÑ–Ñ Ð· original script)"""
        translation_dir = self.project_root / "src" / "localization" / "translations"

        if not translation_dir.exists():
            return

        for lang_file in translation_dir.glob("*.json"):
            try:
                with open(lang_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                lang_code = lang_file.stem
                self.translation_keys[lang_code] = set()
                self._extract_translation_keys(data, "", self.translation_keys[lang_code])

            except Exception as e:
                logger.error("Failed to load translations", file=str(lang_file), error=str(e))

    def _extract_translation_keys(self, data: Union[dict, str], prefix: str, keys_set: Set[str]):
        """Ð ÐµÐºÑƒÑ€ÑÐ¸Ð²Ð½Ð¾ Ð²Ð¸Ñ‚ÑÐ³Ð½ÑƒÑ‚Ð¸ ÐºÐ»ÑŽÑ‡Ñ– Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´Ñ–Ð²"""
        if isinstance(data, dict):
            for key, value in data.items():
                if key.startswith("_"):
                    continue
                new_prefix = f"{prefix}.{key}" if prefix else key
                self._extract_translation_keys(value, new_prefix, keys_set)
        else:
            keys_set.add(prefix)

    def _audit_callback_coverage(self):
        """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð¿Ð¾ÐºÑ€Ð¸Ñ‚Ñ‚Ñ callback handlers"""
        # Ð¡Ð¿Ñ€Ð¾Ñ‰ÐµÐ½Ð° Ð²ÐµÑ€ÑÑ–Ñ - Ñ‚ÑƒÑ‚ Ð¼Ð¾Ð¶Ð½Ð° Ð´Ð¾Ð´Ð°Ñ‚Ð¸ Ð±Ñ–Ð»ÑŒÑˆ ÑÐºÐ»Ð°Ð´Ð½Ñƒ Ð»Ð¾Ð³Ñ–ÐºÑƒ
        pass

    def _audit_translation_coverage(self):
        """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð¿Ð¾ÐºÑ€Ð¸Ñ‚Ñ‚Ñ Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´Ñ–Ð²"""
        if 'uk' in self.translation_keys and 'en' in self.translation_keys:
            uk_keys = self.translation_keys['uk']
            en_keys = self.translation_keys['en']

            # Ð—Ð½Ð°Ð¹Ñ‚Ð¸ Ð½ÐµÑÐ¿Ñ–Ð²Ð¿Ð°Ð´Ñ–Ð½Ð½Ñ
            missing_in_en = uk_keys - en_keys
            missing_in_uk = en_keys - uk_keys

            for key in missing_in_en:
                self.issues.append(AuditIssue(
                    category="MISSING_TRANSLATION",
                    severity="MEDIUM",
                    file_path="src/localization/translations/en.json",
                    line_number=0,
                    description=f"Ð’Ñ–Ð´ÑÑƒÑ‚Ð½Ñ–Ð¹ Ð°Ð½Ð³Ð»Ñ–Ð¹ÑÑŒÐºÐ¸Ð¹ Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´: {key}",
                    fix_suggestion=f"Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´ Ð´Ð»Ñ ÐºÐ»ÑŽÑ‡Ð° '{key}'",
                    group="missing_translations_en"
                ))

    def _audit_architecture_issues(self):
        """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð½Ñ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸"""
        # Ð¢ÑƒÑ‚ Ð¼Ð¾Ð¶Ð½Ð° Ð´Ð¾Ð´Ð°Ñ‚Ð¸ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸ ÑÐ¿ÐµÑ†Ð¸Ñ„Ñ–Ñ‡Ð½Ñ– Ð´Ð»Ñ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸ Ð±Ð¾Ñ‚Ñ–Ð²
        pass

    def _check_translation_usage(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ Ð¿ÐµÑ€ÐµÐºÐ»Ð°Ð´Ñ–Ð² (ÑÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð¾)"""
        pass

    def _check_hardcoded_strings(self, file_path: Path, lines: List[str]):
        """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ hardcoded Ñ€ÑÐ´ÐºÐ¸ (ÑÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð¾)"""
        pass

    def _check_button_callback_consistency(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ consistency ÐºÐ½Ð¾Ð¿Ð¾Ðº Ñ‚Ð° callbacks (ÑÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð¾)"""
        pass

def format_audit_report(result: AuditResult) -> str:
    """Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ð·Ð²Ñ–Ñ‚ Ð°ÑƒÐ´Ð¸Ñ‚Ñƒ Ð´Ð»Ñ Telegram"""

    if result.total_issues == 0:
        return "ðŸŽ‰ **PERFECT CODE!** ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼ Ð½Ðµ Ð·Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð² ÐºÐ¾Ð´Ñ– Ð±Ð¾Ñ‚Ð°."

    report = []
    report.append(f"ðŸ” **Ð†ÐÐ¢Ð•Ð›Ð•ÐšÐ¢Ð£ÐÐ›Ð¬ÐÐ˜Ð™ ÐÐ£Ð”Ð˜Ð¢ Ð‘ÐžÐ¢Ð**")
    report.append(f"ðŸ“Š **Ð—Ð°Ð³Ð°Ð»Ð¾Ð¼ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼:** {result.total_issues}")
    report.append("")

    # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° ÑÐµÑ€Ð¹Ð¾Ð·Ð½Ð¾ÑÑ‚Ñ–
    report.append("**Ð Ð¾Ð·Ð¿Ð¾Ð´Ñ–Ð» Ð·Ð° ÑÐµÑ€Ð¹Ð¾Ð·Ð½Ñ–ÑÑ‚ÑŽ:**")
    if result.critical_count > 0:
        report.append(f"ðŸ”´ CRITICAL: {result.critical_count}")
    if result.high_count > 0:
        report.append(f"ðŸŸ  HIGH: {result.high_count}")
    if result.medium_count > 0:
        report.append(f"ðŸŸ¡ MEDIUM: {result.medium_count}")
    if result.low_count > 0:
        report.append(f"ðŸŸ¢ LOW: {result.low_count}")
    report.append("")

    # Ð¢Ð¾Ð¿ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ñ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸
    critical_issues = [i for i in result.issues if i.severity == "CRITICAL"][:5]
    if critical_issues:
        report.append("ðŸš¨ **ÐšÐ Ð˜Ð¢Ð˜Ð§ÐÐ† ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ˜:**")
        for i, issue in enumerate(critical_issues, 1):
            report.append(f"{i}. {issue.description}")
            report.append(f"   ðŸ“ `{issue.file_path}:{issue.line_number}`")
            if issue.claude_analysis:
                report.append(f"   ðŸ¤– Claude: {issue.claude_analysis[:100]}...")
        report.append("")

    # Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ñ–Ñ—
    if result.recommendations:
        report.append("ðŸ’¡ **Ð Ð•ÐšÐžÐœÐ•ÐÐ”ÐÐ¦Ð†Ð‡:**")
        for rec in result.recommendations:
            report.append(f"â€¢ {rec}")
        report.append("")

    # Claude Ð·Ð°Ð³Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð·
    if result.claude_summary:
        report.append(f"ðŸ§  **CLAUDE ÐÐÐÐ›Ð†Ð—:**\n{result.claude_summary[:500]}...")

    return "\n".join(report)

```

### bot/features/image_processor.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 14,442 Ð±Ð°Ð¹Ñ‚

```python
"""Image processing logic for Claude Code Telegram Bot.

Features:
- Image validation and preprocessing
- Format conversion and optimization  
- Metadata extraction
- Base64 encoding for Claude CLI
- Temporary file management
"""

import asyncio
import base64
import hashlib
import mimetypes
import tempfile
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import structlog
from telegram import PhotoSize
from PIL import Image, ExifTags
import aiofiles

from ...config.settings import Settings
from ...exceptions import SecurityError
from ...security.validators import SecurityValidator

logger = structlog.get_logger(__name__)

@dataclass
class ProcessedImage:
    """Processed image data with metadata."""

    filename: str
    file_path: Path
    file_size: int
    format: str
    dimensions: Tuple[int, int]
    base64_data: Optional[str] = None
    caption: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    temp_file: bool = True

    def __post_init__(self):
        """Initialize after creation."""
        self.file_hash = self._calculate_hash()

    def _calculate_hash(self) -> str:
        """Calculate SHA-256 hash of file."""
        hash_obj = hashlib.sha256()
        try:
            with open(self.file_path, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_obj.update(chunk)
            return hash_obj.hexdigest()
        except Exception:
            return ""

    async def get_base64_data(self) -> str:
        """Get base64 encoded image data."""
        if not self.base64_data:
            async with aiofiles.open(self.file_path, 'rb') as f:
                image_data = await f.read()
                self.base64_data = base64.b64encode(image_data).decode('utf-8')
        return self.base64_data

    async def cleanup(self) -> None:
        """Clean up temporary files."""
        if self.temp_file and self.file_path.exists():
            try:
                self.file_path.unlink()
                logger.debug("Cleaned up temp image file", path=str(self.file_path))
            except Exception as e:
                logger.warning("Failed to cleanup temp file", error=str(e))

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for storage."""
        return {
            "filename": self.filename,
            "file_size": self.file_size,
            "format": self.format,
            "dimensions": self.dimensions,
            "caption": self.caption,
            "metadata": self.metadata,
            "file_hash": self.file_hash
        }


class ImageProcessor:
    """Process and validate images for Claude CLI integration."""

    def __init__(self, settings: Settings, security_validator: SecurityValidator):
        """Initialize image processor."""
        self.settings = settings
        self.security_validator = security_validator
        self.temp_dir = Path(settings.image_temp_directory)
        self.temp_dir.mkdir(parents=True, exist_ok=True)

        # Supported image formats
        self.supported_formats = {
            'PNG': '.png',
            'JPEG': '.jpg', 
            'GIF': '.gif',
            'WEBP': '.webp',
            'BMP': '.bmp',
            'TIFF': '.tiff'
        }

        # MIME type mapping
        self.mime_mapping = {
            'image/png': 'PNG',
            'image/jpeg': 'JPEG',
            'image/jpg': 'JPEG',
            'image/gif': 'GIF',
            'image/webp': 'WEBP',
            'image/bmp': 'BMP',
            'image/tiff': 'TIFF',
            'image/tif': 'TIFF'
        }

    async def process_telegram_photo(
        self, 
        photo: PhotoSize, 
        caption: Optional[str] = None,
        user_id: Optional[int] = None
    ) -> ProcessedImage:
        """Process image from Telegram PhotoSize."""
        logger.info("Processing Telegram photo", 
                   file_id=photo.file_id, 
                   size=photo.file_size,
                   user_id=user_id)

        # Download image from Telegram
        file = await photo.get_file()
        temp_path = self.temp_dir / f"tg_{photo.file_id}_{photo.file_unique_id}.jpg"

        try:
            await file.download_to_drive(str(temp_path))

            # Process the downloaded image
            return await self.process_image_file(
                temp_path,
                caption=caption,
                original_filename=f"telegram_photo_{photo.file_unique_id}.jpg"
            )

        except Exception as e:
            # Clean up temp file if processing failed
            if temp_path.exists():
                temp_path.unlink(missing_ok=True)
            raise

    async def process_image_file(
        self, 
        file_path: Path, 
        caption: Optional[str] = None,
        original_filename: Optional[str] = None
    ) -> ProcessedImage:
        """Process image file from path."""
        if not file_path.exists():
            raise FileNotFoundError(f"Image file not found: {file_path}")

        logger.info("Processing image file", path=str(file_path))

        # Validate file security
        await self._validate_image_security(file_path)

        # Get image info
        img_info = await self._extract_image_info(file_path)

        # Validate image properties
        await self._validate_image_properties(img_info)

        # Optimize image if needed
        optimized_path = await self._optimize_image(file_path, img_info)

        return ProcessedImage(
            filename=original_filename or file_path.name,
            file_path=optimized_path,
            file_size=optimized_path.stat().st_size,
            format=img_info['format'],
            dimensions=img_info['dimensions'],
            caption=caption,
            metadata=img_info['metadata'],
            temp_file=True
        )

    async def _validate_image_security(self, file_path: Path) -> None:
        """Validate image for security issues."""
        # Check file size
        file_size = file_path.stat().st_size
        if file_size > self.settings.image_max_file_size:
            raise SecurityError(
                f"Image file too large: {file_size / (1024*1024):.1f}MB "
                f"(max: {self.settings.image_max_file_size / (1024*1024):.1f}MB)"
            )

        # Check MIME type
        mime_type, _ = mimetypes.guess_type(str(file_path))
        if mime_type not in self.mime_mapping:
            raise SecurityError(f"Unsupported image format: {mime_type}")

        # Use existing filename validation from SecurityValidator
        is_valid, error = self.security_validator.validate_filename(file_path.name)
        if not is_valid:
            raise SecurityError(f"Security validation failed: {error}")

    async def _extract_image_info(self, file_path: Path) -> Dict[str, Any]:
        """Extract image information and metadata."""
        def _extract_sync():
            with Image.open(file_path) as img:
                # Basic info
                info = {
                    'format': img.format,
                    'mode': img.mode,
                    'dimensions': img.size,
                    'metadata': {}
                }

                # Extract EXIF data
                if hasattr(img, '_getexif'):
                    exif = img._getexif()
                    if exif:
                        exif_dict = {}
                        for tag, value in exif.items():
                            tag_name = ExifTags.TAGS.get(tag, str(tag))
                            exif_dict[tag_name] = str(value) if not isinstance(value, (int, float, str)) else value
                        info['metadata']['exif'] = exif_dict

                # Get color info
                if hasattr(img, 'getcolors'):
                    try:
                        colors = img.getcolors(maxcolors=256*256*256)
                        if colors:
                            info['metadata']['color_count'] = len(colors)
                            info['metadata']['dominant_color'] = colors[0][1] if colors else None
                    except Exception:
                        pass

                return info

        return await asyncio.to_thread(_extract_sync)

    async def _validate_image_properties(self, img_info: Dict[str, Any]) -> None:
        """Validate image properties."""
        dimensions = img_info['dimensions']
        width, height = dimensions

        # Check dimensions
        if width > self.settings.image_max_width or height > self.settings.image_max_height:
            raise SecurityError(
                f"Image dimensions too large: {width}x{height} "
                f"(max: {self.settings.image_max_width}x{self.settings.image_max_height})"
            )

        # Check minimum dimensions
        if width < self.settings.image_min_width or height < self.settings.image_min_height:
            raise SecurityError(
                f"Image dimensions too small: {width}x{height} "
                f"(min: {self.settings.image_min_width}x{self.settings.image_min_height})"
            )

        # Validate format
        if img_info['format'] not in self.supported_formats:
            raise SecurityError(f"Unsupported image format: {img_info['format']}")

    async def _optimize_image(self, file_path: Path, img_info: Dict[str, Any]) -> Path:
        """Optimize image for Claude CLI processing."""
        def _optimize_sync():
            with Image.open(file_path) as img:
                # Convert to RGB if needed (for JPEG compatibility)
                if img.mode not in ('RGB', 'RGBA'):
                    if img.mode == 'P' and 'transparency' in img.info:
                        img = img.convert('RGBA')
                    else:
                        img = img.convert('RGB')

                # Resize if too large
                width, height = img.size
                max_size = (self.settings.image_optimization_max_width, 
                           self.settings.image_optimization_max_height)

                if width > max_size[0] or height > max_size[1]:
                    img.thumbnail(max_size, Image.Resampling.LANCZOS)
                    logger.info("Resized image for optimization", 
                               original_size=f"{width}x{height}",
                               new_size=f"{img.width}x{img.height}")

                # Save optimized version
                optimized_path = self.temp_dir / f"opt_{file_path.stem}.jpg"

                # Save with optimization
                save_kwargs = {
                    'format': 'JPEG',
                    'quality': self.settings.image_optimization_quality,
                    'optimize': True
                }

                # Handle transparency for RGBA images
                if img.mode == 'RGBA':
                    # Create white background for JPEG
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    background.paste(img, mask=img.split()[-1] if len(img.split()) == 4 else None)
                    img = background

                img.save(optimized_path, **save_kwargs)
                return optimized_path

        return await asyncio.to_thread(_optimize_sync)

    async def batch_process_images(
        self, 
        image_files: List[Path],
        captions: Optional[List[str]] = None
    ) -> List[ProcessedImage]:
        """Process multiple images in batch."""
        if len(image_files) > self.settings.image_max_batch_size:
            raise SecurityError(
                f"Too many images in batch: {len(image_files)} "
                f"(max: {self.settings.image_max_batch_size})"
            )

        results = []
        captions = captions or [None] * len(image_files)

        # Process images concurrently
        tasks = []
        for i, (image_file, caption) in enumerate(zip(image_files, captions)):
            task = asyncio.create_task(
                self.process_image_file(image_file, caption=caption),
                name=f"process_image_{i}"
            )
            tasks.append(task)

        # Wait for all processing to complete
        try:
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # Check for exceptions
            processed_images = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"Failed to process image {i}", error=str(result))
                    raise result
                processed_images.append(result)

            return processed_images

        except Exception as e:
            # Clean up any successfully processed images
            for result in results:
                if isinstance(result, ProcessedImage):
                    await result.cleanup()
            raise

    async def create_image_summary(self, images: List[ProcessedImage]) -> Dict[str, Any]:
        """Create summary of processed images."""
        if not images:
            return {}

        total_size = sum(img.file_size for img in images)
        formats = list(set(img.format for img in images))
        dimensions = [img.dimensions for img in images]

        return {
            'count': len(images),
            'total_size': total_size,
            'total_size_mb': round(total_size / (1024 * 1024), 2),
            'formats': formats,
            'dimensions': dimensions,
            'has_captions': sum(1 for img in images if img.caption),
            'average_size': total_size // len(images) if images else 0
        }

    async def cleanup_temp_files(self, max_age_hours: int = 24) -> int:
        """Clean up old temporary files."""
        import time

        if not self.temp_dir.exists():
            return 0

        cutoff_time = time.time() - (max_age_hours * 3600)
        cleaned_count = 0

        for file_path in self.temp_dir.iterdir():
            if file_path.is_file() and file_path.stat().st_mtime < cutoff_time:
                try:
                    file_path.unlink()
                    cleaned_count += 1
                except Exception as e:
                    logger.warning("Failed to cleanup old temp file", 
                                 path=str(file_path), error=str(e))

        if cleaned_count > 0:
            logger.info(f"Cleaned up {cleaned_count} old temp files")

        return cleaned_count

```

### bot/features/availability_monitor.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 31,161 Ð±Ð°Ð¹Ñ‚

```python
"""Claude CLI availability monitoring feature."""

import asyncio
import json
import re
import time
from datetime import datetime, time as dt_time
from pathlib import Path
from typing import Optional, Dict, Any, Tuple
from zoneinfo import ZoneInfo

import structlog
from telegram import Bot
from telegram.error import RetryAfter, TimedOut, NetworkError
from telegram.ext import Application

from src.config.settings import Settings

# Add retry support
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

logger = structlog.get_logger(__name__)


class ClaudeAvailabilityMonitor:
    """Monitors Claude CLI availability and sends notifications."""

    def __init__(self, application: Application, settings: Settings):
        """Initialize the availability monitor."""
        self.application = application
        self.settings = settings
        self.bot: Bot = application.bot
        self.last_state: Optional[bool] = None
        self.ok_counter = 0
        self.pending_notification: Optional[Dict[str, Any]] = None

        # Additional tracking fields
        self.last_limit_warning: Optional[datetime] = None
        self.consecutive_limit_hits = 0

        # Ensure state files exist
        self._init_state_files()

    def _get_localized_text(self, key: str, **kwargs) -> str:
        """Get localized text using Ukrainian as default language for notifications."""
        try:
            localization = self.application.bot_data.get("localization")
            if localization:
                result = localization.get(key, language="uk", **kwargs)
                # Safe fallback if key is missing
                return result or f"[{key}]"
            else:
                # Fallback if localization not available
                return f"[{key}]"
        except Exception as e:
            logger.warning(f"Failed to get localized text for {key}: {e}")
            return f"[{key}]"

    def _init_state_files(self):
        """Initialize state files if they don't exist."""
        data_dir = Path("./data")
        data_dir.mkdir(exist_ok=True)
        
        self.state_file = data_dir / ".claude_last_cmd.json"
        self.transitions_log = data_dir / "transitions.jsonl"
        
        if not self.state_file.exists():
            self.state_file.write_text(json.dumps({"available": False, "last_check": None}))
        if not self.transitions_log.exists():
            self.transitions_log.touch()

    def parse_limit_message(self, output: str) -> Optional[datetime]:
        """Parse limit message from Claude CLI output and extract reset time.
        
        Args:
            output: Combined stdout/stderr output from Claude CLI
            
        Returns:
            datetime in UTC if reset time found, None otherwise
            
        Examples:
            "5-hour limit reached âˆ™ resets 2pm" -> datetime for 2pm today in Europe/Kyiv -> UTC
            "limit reached âˆ™ resets 11:30am" -> datetime for 11:30am today in Europe/Kyiv -> UTC
            "limit reached âˆ™ resets 14:00" -> datetime for 14:00 today in Europe/Kyiv -> UTC
        """
        # Regex pattern to match various time formats after "resets"
        pattern = r"resets\s+(\d{1,2}(?::\d{2})?\s*(?:am|pm)?)"
        
        match = re.search(pattern, output, re.IGNORECASE)
        if not match:
            return None
            
        time_str = match.group(1).strip().lower()
        
        try:
            # Parse different time formats
            if 'am' in time_str or 'pm' in time_str:
                # Handle 12-hour format: "2pm", "11:30am", "2:00 pm"
                time_str = time_str.replace(' ', '')  # Remove spaces
                if ':' in time_str:
                    # "11:30am" format
                    time_obj = datetime.strptime(time_str, "%I:%M%p").time()
                else:
                    # "2pm" format  
                    time_obj = datetime.strptime(time_str, "%I%p").time()
            else:
                # Handle 24-hour format: "14:00", "2" (assume 24-hour if no am/pm)
                if ':' in time_str:
                    # "14:00" format
                    time_obj = datetime.strptime(time_str, "%H:%M").time()
                else:
                    # Single digit like "2" - assume 24-hour format
                    time_obj = datetime.strptime(time_str, "%H").time()
            
            # Create datetime for today in Europe/Kyiv timezone
            kyiv_tz = ZoneInfo("Europe/Kyiv")
            today = datetime.now(kyiv_tz).date()
            reset_time_kyiv = datetime.combine(today, time_obj, tzinfo=kyiv_tz)
            
            # If the time is in the past today, assume it means tomorrow
            if reset_time_kyiv <= datetime.now(kyiv_tz):
                reset_time_kyiv = reset_time_kyiv.replace(day=reset_time_kyiv.day + 1)
            
            # Convert to UTC
            reset_time_utc = reset_time_kyiv.astimezone(ZoneInfo("UTC"))
            
            logger.debug(f"Parsed reset time: {time_str} -> {reset_time_utc.isoformat()}")
            return reset_time_utc
            
        except ValueError as e:
            logger.warning(f"Failed to parse time '{time_str}': {e}")
            return None

    def _classify_limit_type(self, output: str, reset_time: datetime) -> str:
        """Classify the type of limit hit based on output content and reset time patterns."""
        output_lower = output.lower()
        
        # Check for hourly limits (resets within 2 hours)
        now_utc = datetime.now(ZoneInfo("UTC"))
        time_until_reset = reset_time - now_utc
        hours_until_reset = time_until_reset.total_seconds() / 3600
        
        if "5-hour" in output_lower or "5 hour" in output_lower:
            return "5_hour_limit"
        elif hours_until_reset <= 2:
            return "hourly_limit" 
        elif "daily" in output_lower or hours_until_reset > 12:
            return "daily_limit"
        else:
            return "request_limit"

    async def check_availability_with_details(self) -> Tuple[bool, dict]:
        """Ð Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ð° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð· Ð´ÐµÑ‚Ð°Ð»ÑÐ¼Ð¸ Ð¿Ñ€Ð¾ Ð¿Ñ€Ð¸Ñ‡Ð¸Ð½Ñƒ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ– Ð·Ð³Ñ–Ð´Ð½Ð¾ Ð· Ð¿Ð»Ð°Ð½Ð¾Ð¼."""
        is_available, reason, reset_time = await self.health_check()

        details = {
            "available": is_available,
            "reason": reason,
            "reset_time": reset_time,
            "last_check": datetime.now(ZoneInfo("UTC")),
            "status_text": "available" if is_available else reason or "unknown"
        }

        # Ð”Ð¾Ð´Ð°Ñ‚Ð¸ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÑ– Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ð´Ð»Ñ Ñ€Ñ–Ð·Ð½Ð¸Ñ… ÑÑ‚Ð°Ñ‚ÑƒÑÑ–Ð²
        if is_available:
            details["status_message"] = "ðŸŸ¢ Claude Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹"
        elif reason == "limit" or reason == "5_hour_limit" or reason == "hourly_limit":
            details["status_message"] = "â³ Claude Ñ‚Ð¸Ð¼Ñ‡Ð°ÑÐ¾Ð²Ð¾ Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð¸Ð¹ (rate limit)"
        elif reason == "auth":
            details["status_message"] = "ðŸ”‘ ÐŸÐ¾Ñ‚Ñ€Ñ–Ð±Ð½Ð° Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð° Ð°Ð²Ñ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ñ–Ñ Claude"
        elif reason == "error":
            details["status_message"] = "ðŸŒ ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ Ð· Ð¼ÐµÑ€ÐµÐ¶ÐµÑŽ"
        else:
            details["status_message"] = "ðŸ”´ Claude Ð·Ð°Ñ€Ð°Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹"

        # Ð”Ð¾Ð´Ð°Ñ‚Ð¸ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð· Ñ‡Ð°ÑÑƒ Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ
        if reset_time and not is_available:
            kyiv_time = reset_time.astimezone(ZoneInfo("Europe/Kyiv"))
            details["estimated_recovery"] = f"ÐžÑ‡Ñ–ÐºÑƒÑ”Ñ‚ÑŒÑÑ Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ñ‡ÐµÑ€ÐµÐ·: {kyiv_time.strftime('%H:%M')}"

        return is_available, details

    async def is_claude_available_cached(self) -> Tuple[bool, dict]:
        """ÐšÐµÑˆÐ¾Ð²Ð°Ð½Ð° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ–."""
        now = time.time()

        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸, Ñ‡Ð¸ Ñ” ÐºÐµÑˆ Ñ– Ñ‡Ð¸ Ð½Ðµ Ð·Ð°ÑÑ‚Ð°Ñ€Ñ–Ð² Ð²Ñ–Ð½ (30 ÑÐµÐºÑƒÐ½Ð´)
        if (hasattr(self, '_last_cache_time') and
            hasattr(self, '_cached_result') and
            now - self._last_cache_time < 30):
            return self._cached_result

        # Ð’Ð¸ÐºÐ¾Ð½Ð°Ñ‚Ð¸ Ð½Ð¾Ð²Ñƒ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÑƒ
        result = await self.check_availability_with_details()

        # Ð—Ð±ÐµÑ€ÐµÐ³Ñ‚Ð¸ Ð² ÐºÐµÑˆ
        self._last_cache_time = now
        self._cached_result = result

        return result

    async def health_check(self) -> Tuple[bool, Optional[str], Optional[datetime]]:
        """Perform health check by running `claude auth status`.
        
        Returns:
            Tuple of (is_available, reason, reset_time):
            - is_available: True if Claude CLI is working
            - reason: None if available, "limit" if rate limited, "auth" for authentication issues, "error" for other issues
            - reset_time: UTC datetime when limit resets, None if not applicable
        
        âš ï¸ For Claude CLI to work inside the container:
        - Authentication must be done on the host and the ~/.claude directory must be mounted
          to /home/claudebot/.claude in the container.
        - The target project directory must be mounted to /app/target_project.
        - See README.md for instructions.
        """
        try:
            # Use shell with explicit PATH environment
            import os
            env = os.environ.copy()
            env['PATH'] = f"/home/claudebot/.local/bin:{env.get('PATH', '')}"
            
            proc = await asyncio.create_subprocess_shell(
                "claude auth status",
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                env=env,
            )
            
            # Use async timeout
            stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=10)
            
            if proc.returncode == 0:
                logger.debug("Claude CLI check: available and authenticated")
                return True, None, None
            
            # Decode output for analysis
            stdout_text = stdout.decode('utf-8', errors='ignore') if stdout else ""
            stderr_text = stderr.decode('utf-8', errors='ignore') if stderr else ""
            combined_output = f"{stdout_text}\n{stderr_text}"
            
            # Debug logging for diagnosis
            logger.debug(f"Claude CLI exit code: {proc.returncode}")
            logger.debug(f"Claude CLI stdout: {stdout_text}")
            logger.debug(f"Claude CLI stderr: {stderr_text}")
            
            # Check for authentication errors first
            auth_errors = [
                "authentication_error",
                "OAuth token has expired",
                "Please run /login",
                "Invalid authentication",
                "Please obtain a new token"
            ]
            
            if any(auth_error in combined_output for auth_error in auth_errors):
                logger.debug("Claude CLI check: authentication error detected")
                return False, "auth", None
            
            # Check if this is a limit-related error and classify the type
            reset_time = self.parse_limit_message(combined_output)
            if reset_time:
                # Classify limit type based on output patterns and timing
                limit_type = self._classify_limit_type(combined_output, reset_time)
                logger.debug(f"Claude CLI {limit_type} reached, resets at: {reset_time.isoformat()}")
                return False, limit_type, reset_time
            
            # Other error
            logger.debug(f"Claude CLI check: unavailable (exit_code={proc.returncode})")
            return False, "error", None
            
        except (asyncio.TimeoutError, FileNotFoundError) as e:
            logger.warning(f"Claude CLI unavailable (timeout/not found): {e}")
            return False, "error", None
        except Exception as e:
            logger.warning(f"Claude CLI unavailable (general error): {e}")
            logger.debug(f"Exception details: {type(e).__name__}: {str(e)}")
            return False, "error", None

    async def _save_state(self, available: bool, reason: Optional[str] = None, reset_expected: Optional[datetime] = None):
        """Save current state to file asynchronously."""
        state = {
            "available": available,
            "last_check": datetime.now(ZoneInfo("Europe/Kyiv")).isoformat()
        }
        
        # Add reason and reset_expected for limited state
        if not available and reason:
            state["reason"] = reason
            if reset_expected and reason == "limit":
                state["reset_expected"] = reset_expected.isoformat()
        
        # Use aiofiles for async file writing
        import aiofiles
        async with aiofiles.open(self.state_file, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(state, ensure_ascii=False, indent=2))

    async def _log_transition(self, from_state: str, to_state: str, 
                            duration: Optional[float] = None, 
                            reset_expected: Optional[datetime] = None,
                            reset_actual: Optional[datetime] = None):
        """Log state transition to transitions.jsonl asynchronously."""
        record = {
            "timestamp": datetime.now(ZoneInfo("UTC")).isoformat(),
            "from": from_state,
            "to": to_state,
            "duration_unavailable": duration,
            "platform": self._get_platform()
        }
        
        # Add reset times for limit-related transitions
        if reset_expected:
            record["reset_expected"] = reset_expected.isoformat()
        if reset_actual:
            record["reset_actual"] = reset_actual.isoformat()
        
        # Use aiofiles for async file writing
        import aiofiles
        async with aiofiles.open(self.transitions_log, "a", encoding="utf-8") as f:
            await f.write(json.dumps(record, ensure_ascii=False) + "\n")

    def _get_platform(self) -> str:
        """Get platform information."""
        import platform
        return f"{platform.system()} {platform.machine()}"

    def _is_dnd_time(self) -> bool:
        """Check if current time is within DND window (23:00â€“08:00 Europe/Kyiv)."""
        now = datetime.now(ZoneInfo("Europe/Kyiv")).time()
        dnd_start = self.settings.claude_availability.dnd_start
        dnd_end = self.settings.claude_availability.dnd_end

        if dnd_start > dnd_end:  # e.g., 23:00â€“08:00
            return now >= dnd_start or now < dnd_end
        else:
            return dnd_start <= now < dnd_end

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type((RetryAfter, TimedOut, NetworkError)),
        reraise=True
    )
    async def _send_notification(self, message: str):
        """Send notification to all subscribed chats with retry logic."""
        chat_ids = self.settings.claude_availability.notify_chat_ids
        if not chat_ids:
            logger.warning("No chats configured for Claude CLI availability notifications")
            return

        for chat_id in chat_ids:
            try:
                await self.bot.send_message(chat_id=chat_id, text=message, parse_mode=None)
                logger.info(f"Availability notification sent to chat {chat_id}")
            except Exception as e:
                logger.error(f"Failed to send message to {chat_id}: {e}")
                raise  # Retry only for specific error types

    async def _build_availability_message(self, downtime_duration: Optional[float] = None, 
                                        reset_expected: Optional[datetime] = None, 
                                        reset_actual: Optional[datetime] = None) -> str:
        """Build availability message in the specified format."""
        now = datetime.now(ZoneInfo("Europe/Kyiv"))
        platform = self._get_platform()
        duration_str = ""
        if downtime_duration:
            hours, remainder = divmod(downtime_duration, 3600)
            minutes, seconds = divmod(remainder, 60)
            duration_text = self._get_localized_text("availability.downtime_duration", 
                                                   hours=int(hours), minutes=int(minutes))
            duration_str = f" {duration_text}"

        # Get localized message template
        message = self._get_localized_text("availability.cli_available", 
                                         timestamp=now.strftime('%Y-%m-%d %H:%M:%S'),
                                         platform=platform,
                                         duration=duration_str)
        
        # Add reset time information if available
        if reset_expected and reset_actual:
            kyiv_tz = ZoneInfo("Europe/Kyiv")
            expected_local = reset_expected.astimezone(kyiv_tz)
            actual_local = reset_actual.astimezone(kyiv_tz)
            
            message += (
                f"\nðŸ“… Ð¤Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ð¸Ð¹ Ñ‡Ð°Ñ Ð²Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ: {actual_local.strftime('%H:%M')}"
                f"\nâ³ ÐžÑ‡Ñ–ÐºÑƒÐ²Ð°Ð½Ð¸Ð¹ Ð±ÑƒÐ²: {expected_local.strftime('%H:%M')}"
            )
        
        return message

    async def _build_limit_message(self, reset_expected: Optional[datetime] = None) -> str:
        """Build limit reached message for Telegram."""
        now = datetime.now(ZoneInfo("Europe/Kyiv"))
        
        message = self._get_localized_text("availability.cli_unavailable", 
                                         timestamp=now.strftime('%Y-%m-%d %H:%M:%S'))
        
        if reset_expected:
            kyiv_tz = ZoneInfo("Europe/Kyiv")
            reset_local = reset_expected.astimezone(kyiv_tz)
            reset_text = self._get_localized_text("availability.reset_time_expected", 
                                                time=reset_local.strftime('%H:%M'))
            message += reset_text
        
        return message

    async def _build_auth_message(self) -> str:
        """Build authentication error message for Telegram."""
        now = datetime.now(ZoneInfo("Europe/Kyiv"))
        platform = self._get_platform()
        
        message = (
            f"ðŸ”´ **Claude CLI Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹ (Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ° Ð°Ð²Ñ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ—)**\n"
            f"ðŸ“… `{now.strftime('%Y-%m-%d %H:%M:%S')}`\n"
            f"ðŸ–¥ï¸ `{platform}`\n"
            f"âš ï¸ Ð¢Ð¾ÐºÐµÐ½ Ð°Ð²Ñ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ— Ð·Ð°ÐºÑ–Ð½Ñ‡Ð¸Ð²ÑÑ Ð°Ð±Ð¾ Ð½ÐµÐ²Ð°Ð»Ñ–Ð´Ð½Ð¸Ð¹\n"
            f"ðŸ”§ ÐŸÐ¾Ñ‚Ñ€Ñ–Ð±Ð½Ð¾ Ð¾Ð½Ð¾Ð²Ð¸Ñ‚Ð¸ Ð°Ð²Ñ‚ÐµÐ½Ñ‚Ð¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–ÑŽ Claude CLI"
        )
        
        return message

    async def _check_scheduled_prompts(self, context):
        """Check and trigger scheduled prompts if conditions are met."""
        try:
            # Import here to avoid circular imports
            from src.bot.features.scheduled_prompts import ScheduledPromptsManager

            # Check if we have a scheduled prompts manager
            if not hasattr(self, '_prompts_manager'):
                self._prompts_manager = ScheduledPromptsManager(self.application, self.settings)

            # Trigger prompt check
            await self._prompts_manager.check_and_execute_prompts(context)

        except Exception as e:
            logger.error(f"Error checking scheduled prompts: {e}")

    async def _execute_scheduled_tasks(self, context):
        """Execute scheduled tasks when Claude becomes available."""
        try:
            # Get task scheduler from bot context
            task_scheduler = self.application.bot_data.get("task_scheduler")
            if not task_scheduler:
                logger.debug("Task scheduler not available")
                return

            logger.info("Claude available - checking for scheduled tasks to execute")

            # Execute all pending tasks
            results = await task_scheduler.execute_task_queue()

            if results["executed"] > 0 or results["failed"] > 0:
                logger.info(
                    "Executed scheduled tasks",
                    executed=results["executed"],
                    failed=results["failed"],
                    skipped=results["skipped"]
                )

                # Send notification about task execution if configured
                if self.settings.claude_availability.notify_chat_ids:
                    await self._send_task_execution_notification(results)

        except Exception as e:
            logger.error(f"Error executing scheduled tasks: {e}", exc_info=True)

    async def _send_task_execution_notification(self, results: dict):
        """Send notification about automated task execution."""
        try:
            now = datetime.now(ZoneInfo("Europe/Kyiv"))

            message = (
                f"ðŸ¤– **ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ðµ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ Ð·Ð°Ð²Ð´Ð°Ð½ÑŒ**\n"
                f"ðŸ“… `{now.strftime('%Y-%m-%d %H:%M:%S')}`\n\n"
                f"âœ… Ð’Ð¸ÐºÐ¾Ð½Ð°Ð½Ð¾: {results['executed']}\n"
                f"âŒ ÐŸÐ¾Ð¼Ð¸Ð»Ð¾Ðº: {results['failed']}\n"
                f"â­ï¸ ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾: {results['skipped']}\n\n"
                f"_Ð’ÑÑ– Ð·Ð°Ð¿Ð»Ð°Ð½Ð¾Ð²Ð°Ð½Ñ– Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð¾Ð±Ñ€Ð¾Ð±Ð»ÐµÐ½Ñ– Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾_"
            )

            # Send to notification chats during DND only (don't spam during day)
            if self._is_dnd_time():
                await self._send_notification(message)
            else:
                logger.debug("Task execution notification skipped - not DND time")

        except Exception as e:
            logger.error(f"Error sending task execution notification: {e}")

    async def _handle_greeting_check(self) -> bool:
        """Send greeting to Claude to test availability and auto-respond."""
        try:
            # Get Claude integration
            claude_integration = self.application.bot_data.get("claude_integration")
            if not claude_integration:
                logger.debug("Claude integration not available for greeting check")
                return False

            # Send simple greeting that should get auto-response
            greeting_prompt = "ÐŸÑ€Ð¸Ð²Ñ–Ñ‚! Ð¦Ðµ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ–. Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ 'Ñ‚Ð°Ðº' Ð½Ð° Ð²ÑÑ– ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ– Ð·Ð°Ð¿Ð¸Ñ‚Ð¸."

            # Get settings for working directory
            working_directory = self.settings.approved_directory

            logger.debug("Sending greeting to Claude CLI")

            # Execute greeting with auto-respond enabled
            response = await claude_integration.run_command(
                prompt=greeting_prompt,
                working_directory=working_directory,
                user_id=0,  # System user ID for automated checks
                session_id=None,  # Use new session
                auto_respond=True  # Enable auto-responses
            )

            if response and response.content:
                logger.info("Claude greeting check successful", response_length=len(response.content))
                return True
            else:
                logger.warning("Claude greeting check failed - no response")
                return False

        except Exception as e:
            logger.error(f"Error in greeting check: {e}")
            return False

    async def monitor_task(self, context):
        """Main monitoring task that runs periodically."""
        if not self.settings.claude_availability.enabled:
            return  # Feature disabled

        # Get current health status
        current_available, current_reason, current_reset_time = await self.health_check()
        current_time = time.time()
        
        # Check for scheduled prompts and tasks during DND when Claude is available
        if current_available and self._is_dnd_time():
            await self._check_scheduled_prompts(context)
            await self._execute_scheduled_tasks(context)

        # Load previous state
        try:
            # Use aiofiles for async file reading
            import aiofiles
            async with aiofiles.open(self.state_file, 'r', encoding='utf-8') as f:
                content = await f.read()
                last_state_data = json.loads(content)
                
            last_available = last_state_data.get("available", False)
            last_reason = last_state_data.get("reason")
            last_reset_expected_str = last_state_data.get("reset_expected")
            last_reset_expected = datetime.fromisoformat(last_reset_expected_str) if last_reset_expected_str else None
            last_check_str = last_state_data.get("last_check")
            last_check = datetime.fromisoformat(last_check_str) if last_check_str else None
        except (json.JSONDecodeError, FileNotFoundError, Exception) as e:
            logger.error(f"Error reading state: {e}")
            last_available = False
            last_reason = None
            last_reset_expected = None
            last_check = None

        # Debounce logic: need N consecutive OK checks for availability
        if current_available:
            self.ok_counter += 1
        else:
            self.ok_counter = 0

        debounce_threshold = self.settings.claude_availability.debounce_ok_count
        confirmed_available = self.ok_counter >= debounce_threshold

        # Determine current state string for logging
        if confirmed_available:
            current_state = "available"
        elif current_reason == "limit":
            current_state = "limited"
        elif current_reason == "auth":
            current_state = "auth_error"
        else:
            current_state = "unavailable"

        # Determine previous state string for logging
        if last_available:
            last_state = "available"
        elif last_reason == "limit":
            last_state = "limited"
        elif last_reason == "auth":
            last_state = "auth_error"
        else:
            last_state = "unavailable"

        # Check if state changed
        state_changed = (confirmed_available != last_available) or (current_reason != last_reason)

        if state_changed:
            downtime_duration = None
            reset_actual = None
            
            # Calculate downtime duration if recovering from unavailable/limited
            if last_check and not last_available and confirmed_available:
                downtime_duration = (datetime.now(ZoneInfo("Europe/Kyiv")) - last_check).total_seconds()
                if last_state == "limited":
                    reset_actual = datetime.now(ZoneInfo("UTC"))

            # Log the transition
            await self._log_transition(
                from_state=last_state,
                to_state=current_state,
                duration=downtime_duration,
                reset_expected=last_reset_expected if last_state == "limited" and current_state == "available" else current_reset_time,
                reset_actual=reset_actual
            )

            # Save new state
            await self._save_state(confirmed_available, current_reason, current_reset_time)

            # Handle notifications and task execution
            if confirmed_available and not last_available:
                # Became available from limited/unavailable
                message = await self._build_availability_message(
                    downtime_duration=downtime_duration,
                    reset_expected=last_reset_expected,
                    reset_actual=reset_actual
                )

                # Execute scheduled tasks immediately when Claude becomes available
                logger.info("Claude became available - executing scheduled tasks")
                await self._execute_scheduled_tasks(context)

                # Send greeting to test and warm up Claude
                greeting_success = await self._handle_greeting_check()
                if greeting_success:
                    logger.info("Claude greeting check successful - system ready for automation")

                if self._is_dnd_time():
                    # Save for sending in the morning
                    self.pending_notification = {
                        "message": message,
                        "prepared_at": current_time
                    }
                    logger.info(f"Transition from {last_state} to available during DND - notification deferred.")
                else:
                    await self._send_notification(message)
                    self.pending_notification = None

            elif not confirmed_available and last_available and current_reason == "limit":
                # Became limited from available
                message = await self._build_limit_message(current_reset_time)
                
                if not self._is_dnd_time():
                    await self._send_notification(message)
                # Note: We don't defer limit notifications during DND as they are important

            elif not confirmed_available and last_available and current_reason == "auth":
                # Became auth error from available
                message = await self._build_auth_message()
                
                if not self._is_dnd_time():
                    await self._send_notification(message)
                # Note: We don't defer auth error notifications during DND as they are important

            self.last_state = confirmed_available

        # If there's a pending notification and we're no longer in DND - send it
        if self.pending_notification and not self._is_dnd_time():
            await self._send_notification(self.pending_notification["message"])
            logger.info("Deferred availability notification sent.")
            self.pending_notification = None

        # Always update the last check time
        await self._save_state(confirmed_available, current_reason, current_reset_time)


async def setup_availability_monitor(application: Application, settings: Settings):
    """Set up Claude CLI availability monitoring."""
    if not settings.claude_availability.enabled:
        logger.info("Claude CLI availability monitoring disabled in settings.")
        return

    monitor = ClaudeAvailabilityMonitor(application, settings)

    # Check if job_queue is available
    if application.job_queue is None:
        logger.warning("JobQueue not available - availability monitoring will not run periodic checks")
        logger.warning("To enable periodic monitoring, install python-telegram-bot[job-queue]")
        return

    # Add periodic task
    application.job_queue.run_repeating(
        monitor.monitor_task,
        interval=settings.claude_availability.check_interval_seconds,
        first=10,  # First check after 10 seconds
        name="claude_availability_monitor"
    )

    logger.info(
        f"âœ… Claude CLI monitoring enabled. Interval: {settings.claude_availability.check_interval_seconds}s. "
        f"Notification chats: {settings.claude_availability.notify_chat_ids}"
    )

```

### bot/middleware/__init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 272 Ð±Ð°Ð¹Ñ‚

```python
"""Bot middleware for authentication, rate limiting, and security."""

from .auth import auth_middleware
from .rate_limit import rate_limit_middleware
from .security import security_middleware

__all__ = ["auth_middleware", "rate_limit_middleware", "security_middleware"]

```

### bot/middleware/auth.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 5,480 Ð±Ð°Ð¹Ñ‚

```python
"""Telegram bot authentication middleware."""

from datetime import datetime
from typing import Any, Callable, Dict

import structlog

logger = structlog.get_logger()


async def auth_middleware(handler: Callable, event: Any, data: Dict[str, Any]) -> Any:
    """Check authentication before processing messages.

    This middleware:
    1. Checks if user is authenticated
    2. Attempts authentication if not authenticated
    3. Updates session activity
    4. Logs authentication events
    """
    # Extract user information
    user_id = event.effective_user.id if event.effective_user else None
    username = (
        getattr(event.effective_user, "username", None)
        if event.effective_user
        else None
    )

    if not user_id:
        logger.warning("No user information in update")
        return

    # Get dependencies from context
    auth_manager = data.get("auth_manager")
    audit_logger = data.get("audit_logger")

    if not auth_manager:
        logger.error("Authentication manager not available in middleware context")
        if event.effective_message:
            await event.effective_message.reply_text(
                "ðŸ”’ Authentication system unavailable. Please try again later."
            )
        return

    # Check if user is already authenticated
    if auth_manager.is_authenticated(user_id):
        # Update session activity
        if auth_manager.refresh_session(user_id):
            session = auth_manager.get_session(user_id)
            logger.debug(
                "Session refreshed",
                user_id=user_id,
                username=username,
                auth_provider=session.auth_provider if session else None,
            )

        # Continue to handler
        return await handler(event, data)

    # User not authenticated - attempt authentication
    logger.info(
        "Attempting authentication for user", user_id=user_id, username=username
    )

    # Try to authenticate (providers will check whitelist and tokens)
    authentication_successful = await auth_manager.authenticate_user(user_id)

    # Log authentication attempt
    if audit_logger:
        await audit_logger.log_auth_attempt(
            user_id=user_id,
            success=authentication_successful,
            method="automatic",
            reason="message_received",
        )

    if authentication_successful:
        session = auth_manager.get_session(user_id)
        logger.info(
            "User authenticated successfully",
            user_id=user_id,
            username=username,
            auth_provider=session.auth_provider if session else None,
        )

        # Log authentication success (welcome message handled by /start command)
        logger.info(
            "New user session started",
            user_id=user_id,
            username=username,
            session_time=datetime.utcnow().isoformat()
        )

        # Continue to handler
        return await handler(event, data)

    else:
        # Authentication failed
        logger.warning("Authentication failed", user_id=user_id, username=username)

        if event.effective_message:
            await event.effective_message.reply_text(
                "ðŸ”’ **Authentication Required**\n\n"
                "You are not authorized to use this bot.\n"
                "Please contact the administrator for access.\n\n"
                f"Your Telegram ID: `{user_id}`\n"
                "Share this ID with the administrator to request access."
            )
        return  # Stop processing


async def require_auth(handler: Callable, event: Any, data: Dict[str, Any]) -> Any:
    """Decorator-style middleware that requires authentication.

    This is a stricter version that only allows authenticated users.
    """
    user_id = event.effective_user.id if event.effective_user else None
    auth_manager = data.get("auth_manager")

    if not auth_manager or not auth_manager.is_authenticated(user_id):
        if event.effective_message:
            await event.effective_message.reply_text(
                "ðŸ”’ Authentication required to use this command."
            )
        return

    return await handler(event, data)


async def admin_required(handler: Callable, event: Any, data: Dict[str, Any]) -> Any:
    """Middleware that requires admin privileges.

    Note: This is a placeholder - admin privileges would need to be
    implemented in the authentication system.
    """
    user_id = event.effective_user.id if event.effective_user else None
    auth_manager = data.get("auth_manager")

    if not auth_manager or not auth_manager.is_authenticated(user_id):
        if event.effective_message:
            await event.effective_message.reply_text("ðŸ”’ Authentication required.")
        return

    session = auth_manager.get_session(user_id)
    if not session or not session.user_info:
        if event.effective_message:
            await event.effective_message.reply_text(
                "ðŸ”’ Session information unavailable."
            )
        return

    # Check for admin permissions (placeholder logic)
    permissions = session.user_info.get("permissions", [])
    if "admin" not in permissions:
        if event.effective_message:
            await event.effective_message.reply_text(
                "ðŸ”’ **Admin Access Required**\n\n"
                "This command requires administrator privileges."
            )
        return

    return await handler(event, data)

```

### bot/middleware/rate_limit.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 7,561 Ð±Ð°Ð¹Ñ‚

```python
"""Rate limiting middleware for Telegram bot."""

from typing import Any, Callable, Dict

import structlog

logger = structlog.get_logger()


async def rate_limit_middleware(
    handler: Callable, event: Any, data: Dict[str, Any]
) -> Any:
    """Check rate limits before processing messages.

    This middleware:
    1. Checks request rate limits
    2. Estimates and checks cost limits
    3. Logs rate limit violations
    4. Provides helpful error messages
    """
    user_id = event.effective_user.id if event.effective_user else None
    username = (
        getattr(event.effective_user, "username", None)
        if event.effective_user
        else None
    )

    if not user_id:
        logger.warning("No user information in update")
        return await handler(event, data)

    # Get dependencies from context
    rate_limiter = data.get("rate_limiter")
    audit_logger = data.get("audit_logger")

    if not rate_limiter:
        logger.error("Rate limiter not available in middleware context")
        # Don't block on missing rate limiter - this could be a config issue
        return await handler(event, data)

    # Estimate cost based on message content and type
    estimated_cost = estimate_message_cost(event)

    # Check rate limits
    allowed, message = await rate_limiter.check_rate_limit(
        user_id=user_id, cost=estimated_cost, tokens=1  # One token per message
    )

    if not allowed:
        logger.warning(
            "Rate limit exceeded",
            user_id=user_id,
            username=username,
            estimated_cost=estimated_cost,
            message=message,
        )

        # Log rate limit violation
        if audit_logger:
            await audit_logger.log_rate_limit_exceeded(
                user_id=user_id,
                limit_type="combined",
                current_usage=0,  # Would need to extract from rate_limiter
                limit_value=0,  # Would need to extract from rate_limiter
            )

        # Send user-friendly rate limit message
        if event.effective_message:
            await event.effective_message.reply_text(f"â±ï¸ {message}")
        return  # Stop processing

    # Rate limit check passed
    logger.debug(
        "Rate limit check passed",
        user_id=user_id,
        username=username,
        estimated_cost=estimated_cost,
    )

    # Continue to handler
    return await handler(event, data)


def estimate_message_cost(event: Any) -> float:
    """Estimate the cost of processing a message.

    This is a simple heuristic - in practice, you'd want more
    sophisticated cost estimation based on:
    - Message type (text, file, command)
    - Content complexity
    - Expected Claude usage
    """
    message = event.effective_message
    message_text = message.text if message else ""

    # Base cost for any message
    base_cost = 0.01

    # Additional cost based on message length (handle None case)
    length_cost = len(message_text or "") * 0.0001

    # Higher cost for certain types of messages
    if (message and message.document) or (message and message.photo):
        # File uploads cost more
        return base_cost + length_cost + 0.05

    if message_text.startswith("/"):
        # Commands cost more
        return base_cost + length_cost + 0.02

    # Check for complex operations keywords
    complex_keywords = [
        "analyze",
        "generate",
        "create",
        "build",
        "compile",
        "test",
        "debug",
        "refactor",
        "optimize",
        "explain",
    ]

    if any(keyword in message_text.lower() for keyword in complex_keywords):
        return base_cost + length_cost + 0.03

    return base_cost + length_cost


async def cost_tracking_middleware(
    handler: Callable, event: Any, data: Dict[str, Any]
) -> Any:
    """Track actual costs after processing.

    This middleware runs after the main handler to track
    actual costs incurred during processing.
    """
    user_id = event.from_user.id
    rate_limiter = data.get("rate_limiter")

    # Store start time for duration tracking
    import time

    start_time = time.time()

    try:
        # Execute the handler
        result = await handler(event, data)

        # Calculate processing time
        processing_time = time.time() - start_time

        # Get actual cost from context if available
        actual_cost = data.get("actual_cost", 0.0)

        if actual_cost > 0 and rate_limiter:
            # Update cost tracking with actual cost
            # Note: This would require extending the rate limiter
            # to support post-processing cost updates
            logger.debug(
                "Actual cost tracked",
                user_id=user_id,
                actual_cost=actual_cost,
                processing_time=processing_time,
            )

        return result

    except Exception as e:
        # Log error but don't update costs for failed operations
        processing_time = time.time() - start_time
        logger.error(
            "Handler execution failed",
            user_id=user_id,
            processing_time=processing_time,
            error=str(e),
        )
        raise


async def burst_protection_middleware(
    handler: Callable, event: Any, data: Dict[str, Any]
) -> Any:
    """Additional burst protection for high-frequency requests.

    This middleware provides an additional layer of protection
    against burst attacks that might bypass normal rate limiting.
    """
    user_id = event.from_user.id

    # Get or create burst tracker
    burst_tracker = data.setdefault("burst_tracker", {})
    user_burst_data = burst_tracker.setdefault(
        user_id, {"recent_requests": [], "warnings_sent": 0}
    )

    import time

    current_time = time.time()

    # Clean old requests (older than 10 seconds)
    user_burst_data["recent_requests"] = [
        req_time
        for req_time in user_burst_data["recent_requests"]
        if current_time - req_time < 10
    ]

    # Add current request
    user_burst_data["recent_requests"].append(current_time)

    # Check for burst (more than 5 requests in 10 seconds)
    if len(user_burst_data["recent_requests"]) > 5:
        user_burst_data["warnings_sent"] += 1

        logger.warning(
            "Burst protection triggered",
            user_id=user_id,
            requests_in_window=len(user_burst_data["recent_requests"]),
            warnings_sent=user_burst_data["warnings_sent"],
        )

        # Progressive response based on warning count
        if user_burst_data["warnings_sent"] == 1:
            if event.effective_message:
                await event.effective_message.reply_text(
                    "âš ï¸ **Slow down!**\n\n"
                    "You're sending requests too quickly. "
                    "Please wait a moment between messages."
                )
        elif user_burst_data["warnings_sent"] <= 3:
            if event.effective_message:
                await event.effective_message.reply_text(
                    "ðŸ›‘ **Rate limit warning**\n\n"
                    "Please reduce your request frequency to avoid being temporarily blocked."
                )
        else:
            if event.effective_message:
                await event.effective_message.reply_text(
                    "ðŸš« **Temporarily blocked**\n\n"
                    "Too many rapid requests. Please wait 30 seconds before trying again."
                )
            return  # Block this request

    return await handler(event, data)

```

### bot/middleware/security.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 14,748 Ð±Ð°Ð¹Ñ‚

```python
"""Security middleware for input validation and threat detection."""

from typing import Any, Callable, Dict

import structlog

logger = structlog.get_logger()


async def security_middleware(
    handler: Callable, event: Any, data: Dict[str, Any]
) -> Any:
    """Validate inputs and detect security threats.

    This middleware:
    1. Validates message content for dangerous patterns
    2. Sanitizes file uploads
    3. Detects potential attacks
    4. Logs security violations
    """
    user_id = event.effective_user.id if event.effective_user else None
    username = (
        getattr(event.effective_user, "username", None)
        if event.effective_user
        else None
    )

    if not user_id:
        logger.warning("No user information in update")
        return await handler(event, data)

    # Get dependencies from context
    security_validator = data.get("security_validator")
    audit_logger = data.get("audit_logger")

    if not security_validator:
        logger.error("Security validator not available in middleware context")
        # Continue without validation (log error but don't block)
        return await handler(event, data)

    # Validate text content if present
    message = event.effective_message
    if message and message.text:
        # Check if this is an image processing context (more lenient validation)
        is_image_context = await is_image_processing_context(event, data)

        is_safe, violation_type = await validate_message_content(
            message.text, security_validator, user_id, audit_logger, is_image_context
        )
        if not is_safe:
            await message.reply_text(
                f"ðŸ›¡ï¸ **Security Alert**\n\n"
                f"Your message contains potentially dangerous content and has been blocked.\n"
                f"Violation: {violation_type}\n\n"
                "If you believe this is an error, please contact the administrator."
            )
            return  # Block processing

    # Validate file uploads if present
    if message and message.document:
        is_safe, error_message = await validate_file_upload(
            message.document, security_validator, user_id, audit_logger
        )
        if not is_safe:
            await message.reply_text(
                f"ðŸ›¡ï¸ **File Upload Blocked**\n\n"
                f"{error_message}\n\n"
                "Please ensure your file meets security requirements."
            )
            return  # Block processing

    # Log successful security validation
    logger.debug(
        "Security validation passed",
        user_id=user_id,
        username=username,
        has_text=bool(message and message.text),
        has_document=bool(message and message.document),
    )

    # Continue to handler
    return await handler(event, data)


async def is_image_processing_context(event: Any, data: Dict[str, Any]) -> bool:
    """Check if current context is image processing (allows more lenient validation)."""
    try:
        # Check if user has active image session
        if hasattr(event, 'effective_user') and event.effective_user:
            user_id = event.effective_user.id
            # Check if bot_data contains information about image sessions
            bot_data = data.get('bot_data', {})
            if isinstance(bot_data, dict):
                # Look for image command handler or active image sessions
                image_handler = bot_data.get('image_command_handler')
                if image_handler and hasattr(image_handler, 'active_sessions'):
                    return user_id in image_handler.active_sessions

        # Check for context clues in the update
        message = event.effective_message if hasattr(event, 'effective_message') else None
        if message:
            # Check if this is during an image processing workflow
            if hasattr(message, 'reply_to_message') and message.reply_to_message:
                prev_text = getattr(message.reply_to_message, 'text', '')
                if any(keyword in prev_text.lower() for keyword in ['Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð½Ñ', 'image', 'Ð³Ð¾Ñ‚Ð¾Ð²Ð¾', 'done', 'Ð¿Ñ€Ð¾Ñ†ÐµÑ']):
                    return True

            # Check user data for awaiting_images flag
            user_data = data.get('user_data', {})
            if isinstance(user_data, dict) and user_data.get('awaiting_images'):
                return True

    except Exception as e:
        logger.debug("Error checking image processing context", error=str(e))

    return False


async def validate_message_content(
    text: str, security_validator: Any, user_id: int, audit_logger: Any, is_image_context: bool = False
) -> tuple[bool, str]:
    """Validate message text content for security threats."""

    # Check for command injection patterns
    dangerous_patterns = [
        r";\s*rm\s+",
        r";\s*del\s+",
        r";\s*format\s+",
        r"`[^`]*`",
        r"\$\([^)]*\)",
        r"&&\s*rm\s+",
        r"\|\s*mail\s+",
        r">\s*/dev/",
        r"curl\s+.*\|\s*sh",
        r"wget\s+.*\|\s*sh",
        r"exec\s*\(",
        r"eval\s*\(",
    ]

    import re

    for pattern in dangerous_patterns:
        if re.search(pattern, text, re.IGNORECASE):
            if audit_logger:
                await audit_logger.log_security_violation(
                    user_id=user_id,
                    violation_type="command_injection_attempt",
                    details=f"Dangerous pattern detected: {pattern}",
                    severity="high",
                    attempted_action="message_send",
                )

            logger.warning(
                "Command injection attempt detected",
                user_id=user_id,
                pattern=pattern,
                text_preview=text[:100],
            )
            return False, "Command injection attempt"

    # Check for path traversal attempts
    path_traversal_patterns = [
        r"\.\./.*",
        r"~\/.*",
        r"\/etc\/.*",
        r"\/var\/.*",
        r"\/usr\/.*",
        r"\/sys\/.*",
        r"\/proc\/.*",
    ]

    for pattern in path_traversal_patterns:
        if re.search(pattern, text):
            if audit_logger:
                await audit_logger.log_security_violation(
                    user_id=user_id,
                    violation_type="path_traversal_attempt",
                    details=f"Path traversal pattern detected: {pattern}",
                    severity="high",
                    attempted_action="message_send",
                )

            logger.warning(
                "Path traversal attempt detected",
                user_id=user_id,
                pattern=pattern,
                text_preview=text[:100],
            )
            return False, "Path traversal attempt"

    # Check for suspicious URLs or domains
    suspicious_patterns = [
        r"https?://[^/]*\.ru/",
        r"https?://[^/]*\.tk/",
        r"https?://[^/]*\.ml/",
        r"https?://bit\.ly/",
        r"https?://tinyurl\.com/",
        r"javascript:",
        r"data:text/html",
    ]

    for pattern in suspicious_patterns:
        if re.search(pattern, text, re.IGNORECASE):
            if audit_logger:
                await audit_logger.log_security_violation(
                    user_id=user_id,
                    violation_type="suspicious_url",
                    details=f"Suspicious URL pattern detected: {pattern}",
                    severity="medium",
                    attempted_action="message_send",
                )

            logger.warning("Suspicious URL detected", user_id=user_id, pattern=pattern)
            return False, "Suspicious URL detected"

    # Sanitize content using security validator
    if is_image_context:
        # In image processing context, use more lenient sanitization
        sanitized = security_validator.sanitize_command_input_lenient(text)
    else:
        sanitized = security_validator.sanitize_command_input(text)

    # Adjust threshold based on context
    threshold = 0.7 if is_image_context else 0.5  # Allow more removal in image context

    if len(sanitized) < len(text) * threshold:  # More than threshold removed
        if audit_logger:
            await audit_logger.log_security_violation(
                user_id=user_id,
                violation_type="excessive_sanitization",
                details=f"More than {int(threshold*100)}% of content was dangerous (image_context: {is_image_context})",
                severity="medium",
                attempted_action="message_send",
            )

        logger.warning(
            "Excessive content sanitization required",
            user_id=user_id,
            original_length=len(text),
            sanitized_length=len(sanitized),
            is_image_context=is_image_context,
        )
        return False, "Content contains too many dangerous characters"

    return True, ""


async def validate_file_upload(
    document: Any, security_validator: Any, user_id: int, audit_logger: Any
) -> tuple[bool, str]:
    """Validate file uploads for security."""

    filename = getattr(document, "file_name", "unknown")
    file_size = getattr(document, "file_size", 0)
    mime_type = getattr(document, "mime_type", "unknown")

    # Validate filename
    is_valid, error_message = security_validator.validate_filename(filename)
    if not is_valid:
        if audit_logger:
            await audit_logger.log_security_violation(
                user_id=user_id,
                violation_type="dangerous_filename",
                details=f"Filename validation failed: {error_message}",
                severity="medium",
                attempted_action="file_upload",
            )

        logger.warning(
            "Dangerous filename detected",
            user_id=user_id,
            filename=filename,
            error=error_message,
        )
        return False, error_message

    # Check file size limits
    max_file_size = 10 * 1024 * 1024  # 10MB
    if file_size > max_file_size:
        if audit_logger:
            await audit_logger.log_security_violation(
                user_id=user_id,
                violation_type="file_too_large",
                details=f"File size {file_size} exceeds limit {max_file_size}",
                severity="low",
                attempted_action="file_upload",
            )

        return False, f"File too large. Maximum size: {max_file_size // (1024*1024)}MB"

    # Check MIME type
    dangerous_mime_types = [
        "application/x-executable",
        "application/x-msdownload",
        "application/x-msdos-program",
        "application/x-dosexec",
        "application/x-winexe",
        "application/x-sh",
        "application/x-shellscript",
    ]

    if mime_type in dangerous_mime_types:
        if audit_logger:
            await audit_logger.log_security_violation(
                user_id=user_id,
                violation_type="dangerous_mime_type",
                details=f"Dangerous MIME type: {mime_type}",
                severity="high",
                attempted_action="file_upload",
            )

        logger.warning(
            "Dangerous MIME type detected",
            user_id=user_id,
            filename=filename,
            mime_type=mime_type,
        )
        return False, f"File type not allowed: {mime_type}"

    # Log successful file validation
    if audit_logger:
        await audit_logger.log_file_access(
            user_id=user_id,
            file_path=filename,
            action="upload_validated",
            success=True,
            file_size=file_size,
        )

    logger.info(
        "File upload validated",
        user_id=user_id,
        filename=filename,
        file_size=file_size,
        mime_type=mime_type,
    )

    return True, ""


async def threat_detection_middleware(
    handler: Callable, event: Any, data: Dict[str, Any]
) -> Any:
    """Advanced threat detection middleware.

    This middleware looks for patterns that might indicate
    sophisticated attacks or reconnaissance attempts.
    """
    user_id = event.effective_user.id if event.effective_user else None
    if not user_id:
        return await handler(event, data)

    audit_logger = data.get("audit_logger")

    # Track user behavior patterns
    user_behavior = data.setdefault("user_behavior", {})
    user_data = user_behavior.setdefault(
        user_id,
        {
            "message_count": 0,
            "failed_commands": 0,
            "path_requests": 0,
            "file_requests": 0,
            "first_seen": None,
        },
    )

    import time

    current_time = time.time()

    if user_data["first_seen"] is None:
        user_data["first_seen"] = current_time

    user_data["message_count"] += 1

    # Check for reconnaissance patterns
    message = event.effective_message
    text = message.text if message else ""

    # Suspicious commands that might indicate reconnaissance
    recon_patterns = [
        r"ls\s+/",
        r"find\s+/",
        r"locate\s+",
        r"which\s+",
        r"whereis\s+",
        r"ps\s+",
        r"netstat\s+",
        r"lsof\s+",
        r"env\s*$",
        r"printenv\s*$",
        r"whoami\s*$",
        r"id\s*$",
        r"uname\s+",
        r"cat\s+/etc/",
        r"cat\s+/proc/",
    ]

    import re

    recon_attempts = sum(
        1 for pattern in recon_patterns if re.search(pattern, text, re.IGNORECASE)
    )

    if recon_attempts > 0:
        user_data["recon_attempts"] = (
            user_data.get("recon_attempts", 0) + recon_attempts
        )

        # Alert if too many reconnaissance attempts
        if user_data["recon_attempts"] > 5:
            if audit_logger:
                await audit_logger.log_security_violation(
                    user_id=user_id,
                    violation_type="reconnaissance_attempt",
                    details=f"Multiple reconnaissance patterns detected: {user_data['recon_attempts']}",
                    severity="high",
                    attempted_action="reconnaissance",
                )

            logger.warning(
                "Reconnaissance attempt pattern detected",
                user_id=user_id,
                total_attempts=user_data["recon_attempts"],
                current_message=text[:100],
            )

            if event.effective_message:
                await event.effective_message.reply_text(
                    "ðŸ” **Suspicious Activity Detected**\n\n"
                    "Multiple reconnaissance-style commands detected. "
                    "This activity has been logged.\n\n"
                    "If you have legitimate needs, please contact the administrator."
                )

    return await handler(event, data)

```

### bot/middleware/claude_availability.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 4,869 Ð±Ð°Ð¹Ñ‚

```python
"""Claude availability middleware for intercepting requests."""

import structlog
from typing import Optional, Callable, Any
from telegram import Update
from telegram.ext import ContextTypes

from ...config.settings import Settings

logger = structlog.get_logger(__name__)


class ClaudeAvailabilityMiddleware:
    """Middleware Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚Ñ– Ð¿ÐµÑ€ÐµÐ´ Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ð¼Ð¸ Ð·Ð³Ñ–Ð´Ð½Ð¾ Ð· Ð¿Ð»Ð°Ð½Ð¾Ð¼."""

    def __init__(self, settings: Settings):
        """Initialize the middleware."""
        self.settings = settings
        self.enabled = settings.claude_availability.enabled

    def is_claude_request(self, update: Update) -> bool:
        """ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸, Ñ‡Ð¸ Ñ” Ñ†Ðµ Ð·Ð°Ð¿Ð¸Ñ‚ Ð´Ð¾ Claude."""
        if not update or not update.message:
            return False

        # ÐŸÑ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¸ (Ð¿Ð¾Ñ‡Ð¸Ð½Ð°ÑŽÑ‚ÑŒÑÑ Ð· /)
        if update.message.text and update.message.text.startswith('/'):
            return False

        # ÐŸÑ€Ð¾Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ callback queries
        if update.callback_query:
            return False

        # Ð¢ÐµÐºÑÑ‚Ð¾Ð²Ñ– Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ Ñ‚Ð° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¸ Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð±ÑƒÑ‚Ð¸ Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ð¼Ð¸ Ð´Ð¾ Claude
        return bool(update.message.text or update.message.document)

    async def handle_unavailable(self, update: Update, context: ContextTypes.DEFAULT_TYPE,
                                details: dict) -> bool:
        """ÐžÐ±Ñ€Ð¾Ð±Ð¸Ñ‚Ð¸ ÑÐ¸Ñ‚ÑƒÐ°Ñ†Ñ–ÑŽ ÐºÐ¾Ð»Ð¸ Claude Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹."""
        try:
            # ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ Ð»Ð¾ÐºÐ°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ‚ÐµÐºÑÑ‚
            status_message = details.get("status_message", "ðŸ”´ Claude Ð·Ð°Ñ€Ð°Ð· Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹")

            # ÐŸÐ¾Ð±ÑƒÐ´ÑƒÐ²Ð°Ñ‚Ð¸ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ
            message_parts = [status_message]

            if "estimated_recovery" in details:
                message_parts.append(f"\nâ³ {details['estimated_recovery']}")

            message_parts.append("\n\nðŸ’¡ Ð¯ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÑŽ Ð² Ð³Ñ€ÑƒÐ¿Ñƒ, ÐºÐ¾Ð»Ð¸ Claude ÑÑ‚Ð°Ð½Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹")
            message_parts.append("ðŸ“‹ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð¹Ñ‚Ðµ /claude_status Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸")

            full_message = "".join(message_parts)

            # ÐÐ°Ð´Ñ–ÑÐ»Ð°Ñ‚Ð¸ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ñƒ
            await update.message.reply_text(full_message, parse_mode=None)

            logger.info("Claude unavailable - user notified",
                       user_id=update.effective_user.id,
                       reason=details.get("reason"))

            return True  # Ð—Ð°Ð¿Ð¸Ñ‚ Ð¾Ð±Ñ€Ð¾Ð±Ð»ÐµÐ½Ð¾

        except Exception as e:
            logger.error(f"Error handling unavailable Claude: {e}")
            return False

    async def __call__(self, handler: Callable, update: Update,
                      context: ContextTypes.DEFAULT_TYPE) -> Any:
        """Middleware entry point."""
        if not self.enabled:
            return await handler(update, context)

        # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸, Ñ‡Ð¸ Ñ†Ðµ Ð·Ð°Ð¿Ð¸Ñ‚ Ð´Ð¾ Claude
        if not self.is_claude_request(update):
            return await handler(update, context)

        # ÐžÑ‚Ñ€Ð¸Ð¼Ð°Ñ‚Ð¸ availability monitor
        availability_monitor = context.bot_data.get("claude_availability_monitor")
        if not availability_monitor:
            # Ð¯ÐºÑ‰Ð¾ Ð½ÐµÐ¼Ð°Ñ” Ð¼Ð¾Ð½Ñ–Ñ‚Ð¾Ñ€Ð°, Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾
            return await handler(update, context)

        try:
            # ÐŸÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ–ÑÑ‚ÑŒ Ð· ÐºÐµÑˆÐµÐ¼
            is_available, details = await availability_monitor.is_claude_available_cached()

            if not is_available:
                # Claude Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹ - Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð¸Ñ‚Ð¸ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð°
                handled = await self.handle_unavailable(update, context, details)
                if handled:
                    return None  # Ð—Ð°Ð¿Ð¸Ñ‚ Ð¾Ð±Ñ€Ð¾Ð±Ð»ÐµÐ½Ð¾, Ð½Ðµ Ð¿ÐµÑ€ÐµÐ´Ð°Ð²Ð°Ñ‚Ð¸ Ð´Ð°Ð»Ñ–

            # Claude Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹ Ð°Ð±Ð¾ Ð½Ðµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€Ð¸Ñ‚Ð¸ - Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸
            return await handler(update, context)

        except Exception as e:
            logger.error(f"Error in Claude availability middleware: {e}")
            # ÐŸÑ€Ð¸ Ð¿Ð¾Ð¼Ð¸Ð»Ñ†Ñ– Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸ Ð½Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾
            return await handler(update, context)


async def claude_availability_middleware(handler: Callable, update: Update,
                                       context: ContextTypes.DEFAULT_TYPE) -> Any:
    """Ð¤ÑƒÐ½ÐºÑ†Ñ–Ñ middleware Ð´Ð»Ñ Ñ€ÐµÑ”ÑÑ‚Ñ€Ð°Ñ†Ñ–Ñ— Ð² ÑÐ¸ÑÑ‚ÐµÐ¼Ñ–."""
    settings: Settings = context.bot_data.get("settings")
    if not settings:
        return await handler(update, context)

    middleware = ClaudeAvailabilityMiddleware(settings)
    return await middleware(handler, update, context)

```

### bot/utils/__init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 29 Ð±Ð°Ð¹Ñ‚

```python
"""Bot utilities package."""

```

### bot/utils/error_handler.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 2,079 Ð±Ð°Ð¹Ñ‚

```python
"""
Error handling utilities.
New: Resolves all silent failures with user guidance.
"""

import structlog
from telegram import Update
from telegram.ext import ContextTypes
from src.localization.util import t

logger = structlog.get_logger(__name__)

async def safe_user_error(update: Update, context: ContextTypes.DEFAULT_TYPE, key: str, exception: Exception = None):
    """Handle errors with localized, helpful messages."""
    try:
        user_id = update.effective_user.id if update.effective_user else None
        error_msg = await t(context, user_id, key) if user_id else "âŒ Ð’Ð¸Ð½Ð¸ÐºÐ»Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ."
        
        if exception:
            guidance_key = f"{key}_guidance"
            try:
                guidance = await t(context, user_id, guidance_key) if user_id else ""
                if guidance and guidance != guidance_key:  # Check if translation exists
                    error_msg += f"\n\n{guidance}"
            except:
                pass  # No guidance available
            
            if user_id:
                logger.error("User error", error=str(exception), user_id=user_id)
        
        if update.callback_query:
            await update.callback_query.edit_message_text(error_msg)
        elif update.message:
            await update.message.reply_text(error_msg)
    except Exception as e:
        # Fallback
        fallback = "âŒ Ð’Ð¸Ð½Ð¸ÐºÐ»Ð° Ð¿Ð¾Ð¼Ð¸Ð»ÐºÐ°. Ð¡Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ–Ð·Ð½Ñ–ÑˆÐµ."
        try:
            if update.callback_query:
                await update.callback_query.edit_message_text(fallback)
            elif update.message:
                await update.message.reply_text(fallback)
        except:
            pass  # Ultimate fallback - do nothing
        logger.error("Fallback error handling failed", error=str(e))

async def safe_critical_error(update: Update, context: ContextTypes.DEFAULT_TYPE, key: str, exception: Exception = None):
    """Handle critical errors that block functionality."""
    await safe_user_error(update, context, key, exception)

```

### bot/utils/formatting.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 25,721 Ð±Ð°Ð¹Ñ‚

```python
"""Format bot responses for optimal display."""

import re
from dataclasses import dataclass
from typing import Any, List, Optional

from telegram import InlineKeyboardButton, InlineKeyboardMarkup

from ...config.settings import Settings


@dataclass
class FormattedMessage:
    """Represents a formatted message for Telegram."""

    text: str
    parse_mode: Optional[str] = None
    reply_markup: Optional[InlineKeyboardMarkup] = None

    def __len__(self) -> int:
        """Return length of message text."""
        return len(self.text)


class ResponseFormatter:
    """Format Claude responses for Telegram display."""

    def __init__(self, settings: Settings):
        """Initialize formatter with settings."""
        self.settings = settings
        self.max_message_length = 4000  # Telegram limit is 4096, leave some buffer
        self.max_code_block_length = 3000  # Max length for code blocks

    def format_claude_response(
        self, text: str, context: Optional[dict] = None
    ) -> List[FormattedMessage]:
        """Enhanced formatting with context awareness and semantic chunking."""
        # Clean and prepare text
        text = self._clean_text(text)

        # Check if we need semantic chunking (for complex content)
        if self._should_use_semantic_chunking(text):
            # Use enhanced semantic chunking for complex content
            chunks = self._semantic_chunk(text, context)
            messages = []
            for chunk in chunks:
                formatted = self._format_chunk(chunk)
                messages.extend(formatted)
        else:
            # Use original simple formatting for basic content
            text = self._format_code_blocks(text)
            messages = self._split_message(text)

        # Add context-aware quick actions to the last message
        if messages and self.settings.enable_quick_actions:
            messages[-1].reply_markup = self._get_contextual_keyboard(context)

        return messages if messages else [FormattedMessage("_(No content to display)_")]

    def _should_use_semantic_chunking(self, text: str) -> bool:
        """Determine if semantic chunking is needed."""
        # Use semantic chunking for complex content with multiple code blocks,
        # file operations, or very long text
        code_block_count = text.count("```")
        has_file_operations = any(
            indicator in text
            for indicator in [
                "Creating file",
                "Editing file",
                "Reading file",
                "Writing to",
                "Modified file",
                "Deleted file",
                "File created",
                "File updated",
            ]
        )
        is_very_long = len(text) > self.max_message_length * 2

        return code_block_count > 2 or has_file_operations or is_very_long

    def format_error_message(
        self, error: str, error_type: str = "Error"
    ) -> FormattedMessage:
        """Format error message with appropriate styling."""
        icon = {
            "Error": "âŒ",
            "Warning": "âš ï¸",
            "Info": "â„¹ï¸",
            "Security": "ðŸ›¡ï¸",
            "Rate Limit": "â±ï¸",
        }.get(error_type, "âŒ")

        text = f"{icon} **{error_type}**\n\n{error}"

        return FormattedMessage(text, parse_mode=None)

    def format_success_message(
        self, message: str, title: str = "Success"
    ) -> FormattedMessage:
        """Format success message with appropriate styling."""
        text = f"âœ… **{title}**\n\n{message}"
        return FormattedMessage(text, parse_mode=None)

    def format_info_message(
        self, message: str, title: str = "Info"
    ) -> FormattedMessage:
        """Format info message with appropriate styling."""
        text = f"â„¹ï¸ **{title}**\n\n{message}"
        return FormattedMessage(text, parse_mode=None)

    def format_code_output(
        self, output: str, language: str = "", title: str = "Output"
    ) -> List[FormattedMessage]:
        """Format code output with syntax highlighting."""
        if not output.strip():
            return [FormattedMessage(f"ðŸ“„ **{title}**\n\n_(empty output)_")]

        # Add language hint if provided
        code_block = (
            f"```{language}\n{output}\n```" if language else f"```\n{output}\n```"
        )

        # Check if the code block is too long
        if len(code_block) > self.max_code_block_length:
            # Truncate and add notice
            truncated = output[: self.max_code_block_length - 100]
            code_block = f"```{language}\n{truncated}\n... (output truncated)\n```"

        text = f"ðŸ“„ **{title}**\n\n{code_block}"

        return self._split_message(text)

    def format_file_list(
        self, files: List[str], directory: str = ""
    ) -> FormattedMessage:
        """Format file listing with appropriate icons."""
        if not files:
            text = f"ðŸ“‚ **{directory}**\n\n_(empty directory)_"
        else:
            file_lines = []
            for file in files[:50]:  # Limit to 50 items
                if file.endswith("/"):
                    file_lines.append(f"ðŸ“ {file}")
                else:
                    file_lines.append(f"ðŸ“„ {file}")

            file_text = "\n".join(file_lines)
            if len(files) > 50:
                file_text += f"\n\n_... and {len(files) - 50} more items_"

            text = f"ðŸ“‚ **{directory}**\n\n{file_text}"

        return FormattedMessage(text, parse_mode=None)

    def format_progress_message(
        self, message: str, percentage: Optional[float] = None
    ) -> FormattedMessage:
        """Format progress message with optional progress bar."""
        if percentage is not None:
            # Create simple progress bar
            filled = int(percentage / 10)
            empty = 10 - filled
            progress_bar = "â–“" * filled + "â–‘" * empty
            text = f"ðŸ”„ **{message}**\n\n{progress_bar} {percentage:.0f}%"
        else:
            text = f"ðŸ”„ **{message}**"

        return FormattedMessage(text, parse_mode=None)

    def _semantic_chunk(self, text: str, context: Optional[dict]) -> List[dict]:
        """Split text into semantic chunks based on content type."""
        chunks = []

        # Identify different content sections
        sections = self._identify_sections(text)

        for section in sections:
            if section["type"] == "code_block":
                chunks.extend(self._chunk_code_block(section))
            elif section["type"] == "explanation":
                chunks.extend(self._chunk_explanation(section))
            elif section["type"] == "file_operations":
                chunks.append(self._format_file_operations_section(section))
            elif section["type"] == "mixed":
                chunks.extend(self._chunk_mixed_content(section))
            else:
                # Default text chunking
                chunks.extend(self._chunk_text(section))

        return chunks

    def _identify_sections(self, text: str) -> List[dict]:
        """Identify different content types in the text."""
        sections = []
        lines = text.split("\n")
        current_section = {"type": "text", "content": "", "start_line": 0}
        in_code_block = False
        code_start = 0

        for i, line in enumerate(lines):
            # Check for code block markers
            if line.strip().startswith("```"):
                if not in_code_block:
                    # Start of code block
                    if current_section["content"].strip():
                        sections.append(current_section)
                    in_code_block = True
                    code_start = i
                    current_section = {
                        "type": "code_block",
                        "content": line + "\n",
                        "start_line": i,
                    }
                else:
                    # End of code block
                    current_section["content"] += line + "\n"
                    sections.append(current_section)
                    in_code_block = False
                    current_section = {
                        "type": "text",
                        "content": "",
                        "start_line": i + 1,
                    }
            elif in_code_block:
                current_section["content"] += line + "\n"
            else:
                # Check for file operation patterns
                if self._is_file_operation_line(line):
                    if current_section["type"] != "file_operations":
                        if current_section["content"].strip():
                            sections.append(current_section)
                        current_section = {
                            "type": "file_operations",
                            "content": line + "\n",
                            "start_line": i,
                        }
                    else:
                        current_section["content"] += line + "\n"
                else:
                    # Regular text
                    if current_section["type"] != "text":
                        if current_section["content"].strip():
                            sections.append(current_section)
                        current_section = {
                            "type": "text",
                            "content": line + "\n",
                            "start_line": i,
                        }
                    else:
                        current_section["content"] += line + "\n"

        # Add the last section
        if current_section["content"].strip():
            sections.append(current_section)

        return sections

    def _is_file_operation_line(self, line: str) -> bool:
        """Check if a line indicates file operations."""
        file_indicators = [
            "Creating file",
            "Editing file",
            "Reading file",
            "Writing to",
            "Modified file",
            "Deleted file",
            "File created",
            "File updated",
        ]
        return any(indicator in line for indicator in file_indicators)

    def _chunk_code_block(self, section: dict) -> List[dict]:
        """Handle code block chunking."""
        content = section["content"]
        if len(content) <= self.max_code_block_length:
            return [{"type": "code_block", "content": content, "format": "single"}]

        # Split large code blocks
        chunks = []
        lines = content.split("\n")
        current_chunk = lines[0] + "\n"  # Start with the ``` line

        for line in lines[1:-1]:  # Skip first and last ``` lines
            if len(current_chunk + line + "\n```\n") > self.max_code_block_length:
                current_chunk += "```"
                chunks.append(
                    {"type": "code_block", "content": current_chunk, "format": "split"}
                )
                current_chunk = "```\n" + line + "\n"
            else:
                current_chunk += line + "\n"

        current_chunk += lines[-1]  # Add the closing ```
        chunks.append(
            {"type": "code_block", "content": current_chunk, "format": "split"}
        )

        return chunks

    def _chunk_explanation(self, section: dict) -> List[dict]:
        """Handle explanation text chunking."""
        content = section["content"]
        if len(content) <= self.max_message_length:
            return [{"type": "explanation", "content": content}]

        # Split by paragraphs first
        paragraphs = content.split("\n\n")
        chunks = []
        current_chunk = ""

        for paragraph in paragraphs:
            if len(current_chunk + paragraph + "\n\n") > self.max_message_length:
                if current_chunk:
                    chunks.append(
                        {"type": "explanation", "content": current_chunk.strip()}
                    )
                current_chunk = paragraph + "\n\n"
            else:
                current_chunk += paragraph + "\n\n"

        if current_chunk:
            chunks.append({"type": "explanation", "content": current_chunk.strip()})

        return chunks

    def _chunk_mixed_content(self, section: dict) -> List[dict]:
        """Handle mixed content sections."""
        # For now, treat as regular text
        return self._chunk_text(section)

    def _chunk_text(self, section: dict) -> List[dict]:
        """Handle regular text chunking."""
        content = section["content"]
        if len(content) <= self.max_message_length:
            return [{"type": "text", "content": content}]

        # Split at natural break points
        chunks = []
        current_chunk = ""

        sentences = content.split(". ")
        for sentence in sentences:
            test_chunk = current_chunk + sentence + ". "
            if len(test_chunk) > self.max_message_length:
                if current_chunk:
                    chunks.append({"type": "text", "content": current_chunk.strip()})
                current_chunk = sentence + ". "
            else:
                current_chunk = test_chunk

        if current_chunk:
            chunks.append({"type": "text", "content": current_chunk.strip()})

        return chunks

    def _format_file_operations_section(self, section: dict) -> dict:
        """Format file operations section."""
        return {"type": "file_operations", "content": section["content"]}

    def _format_chunk(self, chunk: dict) -> List[FormattedMessage]:
        """Format individual chunks into FormattedMessage objects."""
        chunk_type = chunk["type"]
        content = chunk["content"]

        if chunk_type == "code_block":
            # Format code blocks with proper styling
            if chunk.get("format") == "split":
                title = (
                    "ðŸ“„ **Code (continued)**"
                    if "continued" in content
                    else "ðŸ“„ **Code**"
                )
            else:
                title = "ðŸ“„ **Code**"

            text = f"{title}\n\n{content}"

        elif chunk_type == "file_operations":
            # Format file operations with icons
            text = f"ðŸ“ **File Operations**\n\n{content}"

        elif chunk_type == "explanation":
            # Regular explanation text
            text = content

        else:
            # Default text formatting
            text = content

        # Split if still too long
        return self._split_message(text)

    def _get_contextual_keyboard(
        self, context: Optional[dict]
    ) -> Optional[InlineKeyboardMarkup]:
        """Get context-aware quick action keyboard."""
        if not context:
            return self._get_quick_actions_keyboard()

        buttons = []

        # Add context-specific buttons
        if context.get("has_code"):
            buttons.append(
                [InlineKeyboardButton("ðŸ’¾ Save Code", callback_data="save_code")]
            )

        if context.get("has_file_operations"):
            buttons.append(
                [InlineKeyboardButton("ðŸ“ Show Files", callback_data="show_files")]
            )

        if context.get("has_errors"):
            buttons.append([InlineKeyboardButton("ðŸ”§ Debug", callback_data="debug")])

        # Add default actions
        default_buttons = [
            [InlineKeyboardButton("ðŸ”„ Continue", callback_data="continue")],
            [InlineKeyboardButton("ðŸ’¡ Explain", callback_data="explain")],
        ]
        buttons.extend(default_buttons)

        return InlineKeyboardMarkup(buttons) if buttons else None

    def _clean_text(self, text: str) -> str:
        """Clean text for Telegram display."""
        # Remove excessive whitespace
        text = re.sub(r"\n{3,}", "\n\n", text)

        # Escape special Markdown characters (but preserve intentional formatting)
        # Be careful not to escape characters inside code blocks
        text = self._escape_markdown_outside_code(text)

        return text.strip()

    def _escape_markdown_outside_code(self, text: str) -> str:
        """Escape Markdown characters outside of code blocks."""
        # More robust markdown escaping
        parts = []
        in_code_block = False
        
        lines = text.split("\n")
        for line in lines:
            if line.strip().startswith("```"):
                in_code_block = not in_code_block
                parts.append(line)
            elif in_code_block:
                # Inside code block - don't escape anything
                parts.append(line)
            else:
                # Outside code blocks - escape problematic characters more carefully
                # Split by backticks to handle inline code
                line_parts = []
                segments = line.split("`")
                
                for i, segment in enumerate(segments):
                    if i % 2 == 0:  # Outside inline code
                        # Escape only truly problematic characters for Telegram
                        segment = (segment
                                  .replace("\\", "\\\\")  # Escape backslashes first
                                  .replace("[", r"\[")    # Escape square brackets
                                  .replace("]", r"\]")
                                  )
                        # Don't escape * and _ as they're commonly used intentionally
                    line_parts.append(segment)
                
                # Rejoin with backticks
                processed_line = "`".join(line_parts)
                parts.append(processed_line)

        return "\n".join(parts)

    def _format_code_blocks(self, text: str) -> str:
        """Ensure code blocks are properly formatted for Telegram."""
        # Handle triple backticks with language specification
        pattern = r"```(\w+)?\n(.*?)```"

        def replace_code_block(match):
            lang = match.group(1) or ""
            code = match.group(2)

            # Telegram doesn't support language hints, but we can add them as comments
            if lang and lang.lower() not in ["text", "plain"]:
                # Add language as a comment at the top
                code = f"# {lang}\n{code}"

            # Ensure code block doesn't exceed length limits
            if len(code) > self.max_code_block_length:
                code = code[: self.max_code_block_length - 50] + "\n... (truncated)"

            return f"```\n{code}\n```"

        return re.sub(pattern, replace_code_block, text, flags=re.DOTALL)

    def _split_message(self, text: str) -> List[FormattedMessage]:
        """Split long messages while preserving formatting."""
        if len(text) <= self.max_message_length:
            return [FormattedMessage(text)]

        messages = []
        current_lines = []
        current_length = 0
        in_code_block = False

        lines = text.split("\n")

        for line in lines:
            line_length = len(line) + 1  # +1 for newline

            # Check for code block markers
            if line.strip() == "```":
                in_code_block = not in_code_block

            # If this is a very long line that exceeds limit by itself, split it
            if line_length > self.max_message_length:
                # Split the line into chunks
                chunks = []
                for i in range(0, len(line), self.max_message_length - 100):
                    chunks.append(line[i : i + self.max_message_length - 100])

                for chunk in chunks:
                    chunk_length = len(chunk) + 1

                    if (
                        current_length + chunk_length > self.max_message_length
                        and current_lines
                    ):
                        # Save current message
                        if in_code_block:
                            current_lines.append("```")
                        messages.append(FormattedMessage("\n".join(current_lines)))

                        # Start new message
                        current_lines = []
                        current_length = 0
                        if in_code_block:
                            current_lines.append("```")
                            current_length = 4

                    current_lines.append(chunk)
                    current_length += chunk_length
                continue

            # Check if adding this line would exceed the limit
            if current_length + line_length > self.max_message_length and current_lines:
                # Close code block if we're in one
                if in_code_block:
                    current_lines.append("```")

                # Save current message
                messages.append(FormattedMessage("\n".join(current_lines)))

                # Start new message
                current_lines = []
                current_length = 0

                # Reopen code block if needed
                if in_code_block:
                    current_lines.append("```")
                    current_length = 4  # Length of '```\n'

            current_lines.append(line)
            current_length += line_length

        # Add remaining content
        if current_lines:
            # Close code block if needed
            if in_code_block:
                current_lines.append("```")
            messages.append(FormattedMessage("\n".join(current_lines)))

        return messages

    def _get_quick_actions_keyboard(self) -> InlineKeyboardMarkup:
        """Get quick actions inline keyboard."""
        keyboard = [
            [
                InlineKeyboardButton("ðŸ§ª Test", callback_data="quick:test"),
                InlineKeyboardButton("ðŸ“¦ Install", callback_data="quick:install"),
                InlineKeyboardButton("ðŸŽ¨ Format", callback_data="quick:format"),
            ],
            [
                InlineKeyboardButton("ðŸ” Find TODOs", callback_data="quick:find_todos"),
                InlineKeyboardButton("ðŸ”¨ Build", callback_data="quick:build"),
                InlineKeyboardButton("ðŸ“Š Git Status", callback_data="quick:git_status"),
            ],
        ]

        return InlineKeyboardMarkup(keyboard)

    def create_confirmation_keyboard(
        self, confirm_data: str, cancel_data: str = "confirm:no"
    ) -> InlineKeyboardMarkup:
        """Create a confirmation keyboard."""
        keyboard = [
            [
                InlineKeyboardButton("âœ… Yes", callback_data=confirm_data),
                InlineKeyboardButton("âŒ No", callback_data=cancel_data),
            ]
        ]
        return InlineKeyboardMarkup(keyboard)

    def create_navigation_keyboard(self, options: List[tuple]) -> InlineKeyboardMarkup:
        """Create navigation keyboard from options list.

        Args:
            options: List of (text, callback_data) tuples
        """
        keyboard = []
        current_row = []

        for text, callback_data in options:
            current_row.append(InlineKeyboardButton(text, callback_data=callback_data))

            # Create rows of 2 buttons
            if len(current_row) == 2:
                keyboard.append(current_row)
                current_row = []

        # Add remaining button if any
        if current_row:
            keyboard.append(current_row)

        return InlineKeyboardMarkup(keyboard)


class ProgressIndicator:
    """Helper for creating progress indicators."""

    @staticmethod
    def create_bar(
        percentage: float,
        length: int = 10,
        filled_char: str = "â–“",
        empty_char: str = "â–‘",
    ) -> str:
        """Create a progress bar."""
        filled = int((percentage / 100) * length)
        empty = length - filled
        return filled_char * filled + empty_char * empty

    @staticmethod
    def create_spinner(step: int) -> str:
        """Create a spinning indicator."""
        spinners = ["â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "]
        return spinners[step % len(spinners)]

    @staticmethod
    def create_dots(step: int) -> str:
        """Create a dots indicator."""
        dots = ["", ".", "..", "..."]
        return dots[step % len(dots)]


class CodeHighlighter:
    """Simple code highlighting for common languages."""

    # Language file extensions mapping
    LANGUAGE_EXTENSIONS = {
        ".py": "python",
        ".js": "javascript",
        ".ts": "typescript",
        ".jsx": "javascript",
        ".tsx": "typescript",
        ".java": "java",
        ".cpp": "cpp",
        ".c": "c",
        ".cs": "csharp",
        ".go": "go",
        ".rs": "rust",
        ".rb": "ruby",
        ".php": "php",
        ".swift": "swift",
        ".kt": "kotlin",
        ".scala": "scala",
        ".sh": "bash",
        ".bash": "bash",
        ".zsh": "bash",
        ".sql": "sql",
        ".json": "json",
        ".xml": "xml",
        ".html": "html",
        ".css": "css",
        ".scss": "scss",
        ".yaml": "yaml",
        ".yml": "yaml",
        ".toml": "toml",
        ".md": "markdown",
    }

    @classmethod
    def detect_language(cls, filename: str) -> str:
        """Detect programming language from filename."""
        from pathlib import Path

        ext = Path(filename).suffix.lower()
        return cls.LANGUAGE_EXTENSIONS.get(ext, "")

    @classmethod
    def format_code(cls, code: str, language: str = "", filename: str = "") -> str:
        """Format code with language detection."""
        if not language and filename:
            language = cls.detect_language(filename)

        if language:
            return f"```{language}\n{code}\n```"
        else:
            return f"```\n{code}\n```"

```

### security/rate_limiter.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 10,493 Ð±Ð°Ð¹Ñ‚

```python
"""Rate limiting implementation with multiple strategies.

Features:
- Token bucket algorithm
- Cost-based limiting
- Per-user tracking
- Burst handling
"""

import asyncio
from collections import defaultdict
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, Optional, Tuple

import structlog

from ..config.settings import Settings

logger = structlog.get_logger()


@dataclass
class RateLimitBucket:
    """Token bucket for rate limiting."""

    capacity: int
    tokens: float
    last_update: datetime
    refill_rate: float = 1.0  # tokens per second

    def consume(self, tokens: int = 1) -> bool:
        """Try to consume tokens from bucket."""
        self._refill()
        if self.tokens >= tokens:
            self.tokens -= tokens
            return True
        return False

    def _refill(self) -> None:
        """Refill tokens based on time passed."""
        now = datetime.utcnow()
        elapsed = (now - self.last_update).total_seconds()
        self.tokens = min(self.capacity, self.tokens + (elapsed * self.refill_rate))
        self.last_update = now

    def get_wait_time(self, tokens: int = 1) -> float:
        """Get time to wait before tokens are available."""
        self._refill()
        if self.tokens >= tokens:
            return 0.0

        tokens_needed = tokens - self.tokens
        return tokens_needed / self.refill_rate

    def get_status(self) -> Dict[str, float]:
        """Get current bucket status."""
        self._refill()
        return {
            "capacity": self.capacity,
            "tokens": self.tokens,
            "utilization": (self.capacity - self.tokens) / self.capacity,
            "refill_rate": self.refill_rate,
        }


class RateLimiter:
    """Main rate limiting system with request and cost-based limits."""

    def __init__(self, config: Settings):
        self.config = config
        self.request_buckets: Dict[int, RateLimitBucket] = {}
        self.cost_tracker: Dict[int, float] = defaultdict(float)
        self.cost_reset_time: Dict[int, datetime] = {}
        self.locks: Dict[int, asyncio.Lock] = defaultdict(asyncio.Lock)

        # Calculate refill rate from config
        self.refill_rate = (
            self.config.rate_limit_requests / self.config.rate_limit_window
        )

        logger.info(
            "Rate limiter initialized",
            requests_per_window=self.config.rate_limit_requests,
            window_seconds=self.config.rate_limit_window,
            burst_capacity=self.config.rate_limit_burst,
            max_cost_per_user=self.config.claude_max_cost_per_user,
            refill_rate=self.refill_rate,
        )

    async def check_rate_limit(
        self, user_id: int, cost: float = 1.0, tokens: int = 1
    ) -> Tuple[bool, Optional[str]]:
        """Check if request is allowed under rate limits."""
        async with self.locks[user_id]:
            # Check request rate limit
            rate_allowed, rate_message = self._check_request_rate(user_id, tokens)
            if not rate_allowed:
                logger.warning(
                    "Request rate limit exceeded",
                    user_id=user_id,
                    tokens_requested=tokens,
                )
                return False, rate_message

            # Check cost limit
            cost_allowed, cost_message = self._check_cost_limit(user_id, cost)
            if not cost_allowed:
                logger.warning(
                    "Cost limit exceeded",
                    user_id=user_id,
                    cost_requested=cost,
                    current_usage=self.cost_tracker[user_id],
                )
                return False, cost_message

            # If both checks pass, consume resources
            self._consume_request_tokens(user_id, tokens)
            self._track_cost(user_id, cost)

            logger.debug(
                "Rate limit check passed", user_id=user_id, cost=cost, tokens=tokens
            )
            return True, None

    def _check_request_rate(
        self, user_id: int, tokens: int
    ) -> Tuple[bool, Optional[str]]:
        """Check request rate limit."""
        bucket = self._get_or_create_bucket(user_id)

        if bucket.consume(tokens):
            return True, None

        wait_time = bucket.get_wait_time(tokens)
        status = bucket.get_status()

        message = (
            f"Rate limit exceeded. Please wait {wait_time:.1f} seconds "
            f"before making more requests. "
            f"Bucket: {status['tokens']:.1f}/{status['capacity']} tokens available."
        )
        return False, message

    def _check_cost_limit(
        self, user_id: int, cost: float
    ) -> Tuple[bool, Optional[str]]:
        """Check cost-based limit."""
        # Reset cost tracker if enough time has passed
        self._maybe_reset_cost_tracker(user_id)

        current_cost = self.cost_tracker[user_id]
        if current_cost + cost > self.config.claude_max_cost_per_user:
            remaining = max(0, self.config.claude_max_cost_per_user - current_cost)
            message = (
                f"Cost limit exceeded. Remaining budget: ${remaining:.2f}. "
                f"Current usage: ${current_cost:.2f}/"
                f"${self.config.claude_max_cost_per_user:.2f}"
            )
            return False, message

        return True, None

    def _consume_request_tokens(self, user_id: int, tokens: int) -> None:
        """Consume tokens from request bucket."""
        bucket = self._get_or_create_bucket(user_id)
        bucket.consume(tokens)

    def _track_cost(self, user_id: int, cost: float) -> None:
        """Track cost usage for user."""
        self.cost_tracker[user_id] += cost

        logger.debug(
            "Cost tracked",
            user_id=user_id,
            cost=cost,
            total_usage=self.cost_tracker[user_id],
        )

    def _get_or_create_bucket(self, user_id: int) -> RateLimitBucket:
        """Get or create rate limit bucket for user."""
        if user_id not in self.request_buckets:
            self.request_buckets[user_id] = RateLimitBucket(
                capacity=self.config.rate_limit_burst,
                tokens=self.config.rate_limit_burst,
                last_update=datetime.utcnow(),
                refill_rate=self.refill_rate,
            )
            logger.debug("Created rate limit bucket", user_id=user_id)

        return self.request_buckets[user_id]

    def _maybe_reset_cost_tracker(self, user_id: int) -> None:
        """Reset cost tracker if reset period has passed."""
        now = datetime.utcnow()
        last_reset = self.cost_reset_time.get(user_id, now - timedelta(days=1))

        # Reset daily (configurable)
        reset_interval = timedelta(hours=24)
        if now - last_reset >= reset_interval:
            old_cost = self.cost_tracker[user_id]
            self.cost_tracker[user_id] = 0
            self.cost_reset_time[user_id] = now

            if old_cost > 0:
                logger.info(
                    "Cost tracker reset",
                    user_id=user_id,
                    old_cost=old_cost,
                    reset_time=now.isoformat(),
                )

    async def reset_user_limits(self, user_id: int) -> None:
        """Reset all limits for a user (admin function)."""
        async with self.locks[user_id]:
            # Reset cost tracking
            old_cost = self.cost_tracker[user_id]
            self.cost_tracker[user_id] = 0
            self.cost_reset_time[user_id] = datetime.utcnow()

            # Reset request bucket
            if user_id in self.request_buckets:
                self.request_buckets[user_id].tokens = self.request_buckets[
                    user_id
                ].capacity
                self.request_buckets[user_id].last_update = datetime.utcnow()

            logger.info("User limits reset", user_id=user_id, old_cost=old_cost)

    def get_user_status(self, user_id: int) -> Dict[str, Any]:
        """Get current rate limit status for user."""
        # Get request bucket status
        bucket = self._get_or_create_bucket(user_id)
        bucket_status = bucket.get_status()

        # Get cost status
        self._maybe_reset_cost_tracker(user_id)
        current_cost = self.cost_tracker[user_id]
        cost_remaining = max(0, self.config.claude_max_cost_per_user - current_cost)

        return {
            "request_bucket": bucket_status,
            "cost_usage": {
                "current": current_cost,
                "limit": self.config.claude_max_cost_per_user,
                "remaining": cost_remaining,
                "utilization": current_cost / self.config.claude_max_cost_per_user,
            },
            "last_reset": self.cost_reset_time.get(
                user_id, datetime.utcnow()
            ).isoformat(),
        }

    def get_global_status(self) -> Dict[str, Any]:
        """Get global rate limiter statistics."""
        return {
            "active_users": len(self.request_buckets),
            "total_cost_tracked": sum(self.cost_tracker.values()),
            "config": {
                "requests_per_window": self.config.rate_limit_requests,
                "window_seconds": self.config.rate_limit_window,
                "burst_capacity": self.config.rate_limit_burst,
                "max_cost_per_user": self.config.claude_max_cost_per_user,
                "refill_rate": self.refill_rate,
            },
        }

    async def cleanup_inactive_users(
        self, inactive_threshold: timedelta = timedelta(hours=24)
    ) -> int:
        """Clean up rate limit data for inactive users."""
        now = datetime.utcnow()
        inactive_users = []

        # Find users with old buckets
        for user_id, bucket in self.request_buckets.items():
            if now - bucket.last_update > inactive_threshold:
                inactive_users.append(user_id)

        # Clean up data
        for user_id in inactive_users:
            self.request_buckets.pop(user_id, None)
            self.cost_tracker.pop(user_id, None)
            self.cost_reset_time.pop(user_id, None)
            self.locks.pop(user_id, None)

        if inactive_users:
            logger.info(
                "Cleaned up inactive users",
                count=len(inactive_users),
                threshold_hours=inactive_threshold.total_seconds() / 3600,
            )

        return len(inactive_users)

```

### security/__init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 1,056 Ð±Ð°Ð¹Ñ‚

```python
"""Security framework for Claude Code Telegram Bot.

This module provides comprehensive security features including:
- Multi-layer authentication (whitelist and token-based)
- Rate limiting with token bucket algorithm
- Path traversal and injection prevention
- Input validation and sanitization
- Security audit logging

Key Components:
- AuthenticationManager: Main authentication system
- RateLimiter: Request and cost-based rate limiting
- SecurityValidator: Input validation and path security
- AuditLogger: Security event logging
"""

from .audit import AuditEvent, AuditLogger
from .auth import (
    AuthenticationManager,
    AuthProvider,
    TokenAuthProvider,
    UserSession,
    WhitelistAuthProvider,
)
from .rate_limiter import RateLimitBucket, RateLimiter
from .validators import SecurityValidator

__all__ = [
    "AuthProvider",
    "WhitelistAuthProvider",
    "TokenAuthProvider",
    "AuthenticationManager",
    "UserSession",
    "RateLimiter",
    "RateLimitBucket",
    "SecurityValidator",
    "AuditLogger",
    "AuditEvent",
]

```

### security/auth.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 11,347 Ð±Ð°Ð¹Ñ‚

```python
"""Authentication system supporting multiple methods.

Features:
- Telegram ID whitelist
- Token-based authentication
- Session management
- Audit logging
"""

import hashlib
import secrets
from abc import ABC, abstractmethod
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import structlog

from src.exceptions import SecurityError

# from src.exceptions import AuthenticationError  # Future use

logger = structlog.get_logger()


@dataclass
class UserSession:
    """User session data."""

    user_id: int
    auth_provider: str
    created_at: datetime
    last_activity: datetime
    user_info: Optional[Dict[str, Any]] = None
    session_timeout: timedelta = timedelta(hours=24)

    def __post_init__(self) -> None:
        if self.last_activity is None:
            self.last_activity = self.created_at

    def is_expired(self) -> bool:
        """Check if session has expired."""
        return datetime.utcnow() - self.last_activity > self.session_timeout

    def refresh(self) -> None:
        """Refresh session activity."""
        self.last_activity = datetime.utcnow()


class AuthProvider(ABC):
    """Base authentication provider."""

    @abstractmethod
    async def authenticate(self, user_id: int, credentials: Dict[str, Any]) -> bool:
        """Verify user credentials."""
        pass

    @abstractmethod
    async def get_user_info(self, user_id: int) -> Optional[Dict[str, Any]]:
        """Get user information."""
        pass


class WhitelistAuthProvider(AuthProvider):
    """Whitelist-based authentication."""

    def __init__(self, allowed_users: List[int], allow_all_dev: bool = False):
        self.allowed_users = set(allowed_users)
        self.allow_all_dev = allow_all_dev
        logger.info(
            "Whitelist auth provider initialized",
            allowed_users=len(self.allowed_users),
            allow_all_dev=allow_all_dev,
        )

    async def authenticate(self, user_id: int, credentials: Dict[str, Any]) -> bool:
        """Authenticate user against whitelist."""
        is_allowed = self.allow_all_dev or user_id in self.allowed_users
        logger.info(
            "Whitelist authentication attempt", user_id=user_id, success=is_allowed
        )
        return is_allowed

    async def get_user_info(self, user_id: int) -> Optional[Dict[str, Any]]:
        """Get user information if whitelisted."""
        if self.allow_all_dev or user_id in self.allowed_users:
            return {
                "user_id": user_id,
                "auth_type": "whitelist" + ("_dev" if self.allow_all_dev else ""),
                "permissions": ["basic"],
            }
        return None


class TokenStorage(ABC):
    """Abstract token storage interface."""

    @abstractmethod
    async def store_token(
        self, user_id: int, token_hash: str, expires_at: datetime
    ) -> None:
        """Store token hash for user."""
        pass

    @abstractmethod
    async def get_user_token(self, user_id: int) -> Optional[Dict[str, Any]]:
        """Get token data for user."""
        pass

    @abstractmethod
    async def revoke_token(self, user_id: int) -> None:
        """Revoke token for user."""
        pass


class InMemoryTokenStorage(TokenStorage):
    """In-memory token storage for development/testing."""

    def __init__(self) -> None:
        self._tokens: Dict[int, Dict[str, Any]] = {}

    async def store_token(
        self, user_id: int, token_hash: str, expires_at: datetime
    ) -> None:
        """Store token hash in memory."""
        self._tokens[user_id] = {
            "hash": token_hash,
            "expires_at": expires_at,
            "created_at": datetime.utcnow(),
        }

    async def get_user_token(self, user_id: int) -> Optional[Dict[str, Any]]:
        """Get token data from memory."""
        token_data = self._tokens.get(user_id)
        if token_data and token_data["expires_at"] > datetime.utcnow():
            return token_data
        elif token_data:
            # Token expired, remove it
            del self._tokens[user_id]
        return None

    async def revoke_token(self, user_id: int) -> None:
        """Remove token from memory."""
        self._tokens.pop(user_id, None)


class TokenAuthProvider(AuthProvider):
    """Token-based authentication."""

    def __init__(
        self,
        secret: str,
        storage: TokenStorage,
        token_lifetime: timedelta = timedelta(days=30),
    ):
        self.secret = secret
        self.storage = storage
        self.token_lifetime = token_lifetime
        logger.info("Token auth provider initialized")

    async def authenticate(self, user_id: int, credentials: Dict[str, Any]) -> bool:
        """Authenticate using token."""
        token = credentials.get("token")
        if not token:
            logger.warning(
                "Token authentication failed: no token provided", user_id=user_id
            )
            return False

        stored_token = await self.storage.get_user_token(user_id)
        if not stored_token:
            logger.warning(
                "Token authentication failed: no stored token", user_id=user_id
            )
            return False

        is_valid = self._verify_token(token, stored_token["hash"])
        logger.info("Token authentication attempt", user_id=user_id, success=is_valid)
        return is_valid

    async def generate_token(self, user_id: int) -> str:
        """Generate new authentication token."""
        token = secrets.token_urlsafe(32)
        hashed = self._hash_token(token)
        expires_at = datetime.utcnow() + self.token_lifetime

        await self.storage.store_token(user_id, hashed, expires_at)

        logger.info(
            "Token generated", user_id=user_id, expires_at=expires_at.isoformat()
        )
        return token

    async def revoke_token(self, user_id: int) -> None:
        """Revoke user's token."""
        await self.storage.revoke_token(user_id)
        logger.info("Token revoked", user_id=user_id)

    async def get_user_info(self, user_id: int) -> Optional[Dict[str, Any]]:
        """Get user information if token is valid."""
        token_data = await self.storage.get_user_token(user_id)
        if token_data:
            return {
                "user_id": user_id,
                "auth_type": "token",
                "permissions": ["basic", "advanced"],
                "token_created": token_data["created_at"].isoformat(),
                "token_expires": token_data["expires_at"].isoformat(),
            }
        return None

    def _hash_token(self, token: str) -> str:
        """Hash token for secure storage."""
        return hashlib.sha256(f"{token}{self.secret}".encode()).hexdigest()

    def _verify_token(self, token: str, stored_hash: str) -> bool:
        """Verify token against stored hash."""
        return self._hash_token(token) == stored_hash


class AuthenticationManager:
    """Main authentication manager supporting multiple providers."""

    def __init__(self, providers: List[AuthProvider]):
        if not providers:
            raise SecurityError("At least one authentication provider is required")

        self.providers = providers
        self.sessions: Dict[int, UserSession] = {}
        logger.info("Authentication manager initialized", providers=len(self.providers))

    async def authenticate_user(
        self, user_id: int, credentials: Optional[Dict[str, Any]] = None
    ) -> bool:
        """Try authentication with all providers."""
        credentials = credentials or {}

        # Clean expired sessions first
        self._cleanup_expired_sessions()

        # Try each provider
        for provider in self.providers:
            try:
                if await provider.authenticate(user_id, credentials):
                    await self._create_session(user_id, provider)
                    logger.info(
                        "User authenticated successfully",
                        user_id=user_id,
                        provider=provider.__class__.__name__,
                    )
                    return True
            except Exception as e:
                logger.error(
                    "Authentication provider error",
                    user_id=user_id,
                    provider=provider.__class__.__name__,
                    error=str(e),
                )

        logger.warning("Authentication failed for user", user_id=user_id)
        return False

    async def _create_session(self, user_id: int, provider: AuthProvider) -> None:
        """Create authenticated session."""
        user_info = await provider.get_user_info(user_id)
        self.sessions[user_id] = UserSession(
            user_id=user_id,
            auth_provider=provider.__class__.__name__,
            created_at=datetime.utcnow(),
            last_activity=datetime.utcnow(),
            user_info=user_info,
        )

        logger.info(
            "Session created", user_id=user_id, provider=provider.__class__.__name__
        )

    def is_authenticated(self, user_id: int) -> bool:
        """Check if user has active session."""
        session = self.sessions.get(user_id)
        if session and not session.is_expired():
            return True
        elif session:
            # Remove expired session
            del self.sessions[user_id]
            logger.info("Expired session removed", user_id=user_id)
        return False

    def get_session(self, user_id: int) -> Optional[UserSession]:
        """Get user session if valid."""
        if self.is_authenticated(user_id):
            return self.sessions[user_id]
        return None

    def refresh_session(self, user_id: int) -> bool:
        """Refresh user session activity."""
        session = self.get_session(user_id)
        if session:
            session.refresh()
            return True
        return False

    def end_session(self, user_id: int) -> None:
        """End user session."""
        if user_id in self.sessions:
            del self.sessions[user_id]
            logger.info("Session ended", user_id=user_id)

    def _cleanup_expired_sessions(self) -> None:
        """Remove expired sessions."""
        expired_sessions = [
            user_id
            for user_id, session in self.sessions.items()
            if session.is_expired()
        ]

        for user_id in expired_sessions:
            del self.sessions[user_id]

        if expired_sessions:
            logger.info("Expired sessions cleaned up", count=len(expired_sessions))

    def get_active_sessions_count(self) -> int:
        """Get count of active sessions."""
        self._cleanup_expired_sessions()
        return len(self.sessions)

    def get_session_info(self, user_id: int) -> Optional[Dict[str, Any]]:
        """Get session information for user."""
        session = self.get_session(user_id)
        if session:
            return {
                "user_id": session.user_id,
                "auth_provider": session.auth_provider,
                "created_at": session.created_at.isoformat(),
                "last_activity": session.last_activity.isoformat(),
                "is_expired": session.is_expired(),
                "user_info": session.user_info,
            }
        return None

```

### security/validators.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 15,861 Ð±Ð°Ð¹Ñ‚

```python
"""Input validation and security checks.

Features:
- Path traversal prevention
- Command injection prevention
- File type validation
- Input sanitization
"""

import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import structlog

# from src.exceptions import SecurityError  # Future use

logger = structlog.get_logger()


class SecurityValidator:
    """Security validation for user inputs."""

    # Dangerous patterns for path traversal and injection
    # Note: Split into different categories for different validation contexts
    DANGEROUS_PATH_PATTERNS = [
        r"\.\.",  # Parent directory
        r"~",  # Home directory expansion
        r"\x00",  # Null byte
    ]
    
    DANGEROUS_COMMAND_PATTERNS = [
        r"\$\{",  # Variable expansion ${...}
        r"\$\(",  # Command substitution $(...)
        r"\$[A-Za-z_]",  # Environment variable expansion $VAR
        r"`",  # Command substitution with backticks
        r";\s*(?:rm|del|format|sudo|curl|wget)",  # Command chaining with dangerous commands
        r"&&\s*(?:rm|del|format|sudo|curl|wget)",  # AND chaining with dangerous commands
        r"\|\|",  # OR chaining
        r">\s*/dev/",  # Dangerous output redirection
        r"<\s*/dev/",  # Dangerous input redirection
        r"\|\s*(?:sh|bash|cmd|powershell)",  # Piping to shells
        r"#.*(?:rm|del|format|sudo)",  # Comments with dangerous commands
    ]
    
    # Keep original for backward compatibility - now combines both
    DANGEROUS_PATTERNS = DANGEROUS_PATH_PATTERNS + DANGEROUS_COMMAND_PATTERNS

    # Allowed file extensions for uploads
    ALLOWED_EXTENSIONS = {
        ".py",
        ".js",
        ".ts",
        ".jsx",
        ".tsx",
        ".java",
        ".cpp",
        ".c",
        ".h",
        ".hpp",
        ".cs",
        ".go",
        ".rs",
        ".rb",
        ".php",
        ".swift",
        ".kt",
        ".md",
        ".txt",
        ".json",
        ".yml",
        ".yaml",
        ".toml",
        ".xml",
        ".html",
        ".css",
        ".scss",
        ".less",
        ".sql",
        ".sh",
        ".bash",
        ".zsh",
        ".fish",
        ".ps1",
        ".bat",
        ".cmd",
        ".r",
        ".scala",
        ".clj",
        ".hs",
        ".elm",
        ".vue",
        ".svelte",
        ".lock",
        # Image formats for image processing
        ".jpg",
        ".jpeg",
        ".png",
        ".gif",
        ".webp",
        ".bmp",
        ".tiff",
        ".tif",
    }

    # Forbidden filenames and patterns
    FORBIDDEN_FILENAMES = {
        ".env",
        ".env.local",
        ".env.production",
        ".env.development",
        ".ssh",
        ".aws",
        ".docker",
        "id_rsa",
        "id_dsa",
        "id_ecdsa",
        "shadow",
        "passwd",
        "hosts",
        "sudoers",
        ".bash_history",
        ".zsh_history",
        ".mysql_history",
        ".psql_history",
    }

    # Dangerous file patterns
    DANGEROUS_FILE_PATTERNS = [
        r".*\.key$",  # Key files
        r".*\.pem$",  # Certificate files
        r".*\.p12$",  # Certificate files
        r".*\.pfx$",  # Certificate files
        r".*\.crt$",  # Certificate files
        r".*\.cer$",  # Certificate files
        r".*_rsa$",  # SSH keys
        r".*_dsa$",  # SSH keys
        r".*_ecdsa$",  # SSH keys
        r".*\.exe$",  # Executables
        r".*\.dll$",  # Windows libraries
        r".*\.so$",  # Shared objects
        r".*\.dylib$",  # macOS libraries
        r".*\.bat$",  # Batch files
        r".*\.cmd$",  # Command files
        r".*\.msi$",  # Installers
        r".*\.rar$",  # Archives (potentially dangerous)
    ]

    def __init__(self, approved_directory: Path, flexible_mode: bool = False):
        """Initialize validator with approved directory.
        
        Args:
            approved_directory: Base directory for file operations
            flexible_mode: If True, allows operations in subdirectories of approved_directory
                          If False, strict mode - only exact approved_directory
        """
        self.approved_directory = approved_directory.resolve()
        self.flexible_mode = flexible_mode
        logger.info(
            "Security validator initialized",
            approved_directory=str(self.approved_directory),
            flexible_mode=flexible_mode,
        )

    def validate_path(
        self, user_path: str, current_dir: Optional[Path] = None
    ) -> Tuple[bool, Optional[Path], Optional[str]]:
        """Validate and resolve user-provided path.

        Returns:
            Tuple of (is_valid, resolved_path, error_message)
        """
        try:
            # Basic input validation
            if not user_path or not user_path.strip():
                return False, None, "Empty path not allowed"

            user_path = user_path.strip()

            # Check for dangerous path patterns (more restrictive for paths)
            for pattern in self.DANGEROUS_PATH_PATTERNS:
                if re.search(pattern, user_path, re.IGNORECASE):
                    logger.warning(
                        "Dangerous pattern detected in path",
                        path=user_path,
                        pattern=pattern,
                    )
                    return (
                        False,
                        None,
                        f"Invalid path: contains forbidden pattern '{pattern}'",
                    )

            # Handle path resolution
            current_dir = current_dir or self.approved_directory

            if user_path.startswith("/"):
                # Absolute path - use as-is
                target = Path(user_path)
            else:
                # Relative path
                target = current_dir / user_path

            # Resolve path and check boundaries
            target = target.resolve()

            # Ensure target is within approved directory
            if not self._is_within_directory(target, self.approved_directory):
                if self.flexible_mode:
                    # In flexible mode, check if we're still within a reasonable subdirectory
                    try:
                        # Allow current working directory if it's a subdirectory of approved_directory
                        if current_dir and self._is_within_directory(current_dir, self.approved_directory):
                            # If target is in current_dir and current_dir is safe, allow it
                            if self._is_within_directory(target, current_dir):
                                logger.debug(
                                    "Path allowed in flexible mode",
                                    requested_path=user_path,
                                    resolved_path=str(target),
                                    current_dir=str(current_dir),
                                )
                                return True, target, None
                    except Exception:
                        pass
                
                logger.warning(
                    "Path traversal attempt detected",
                    requested_path=user_path,
                    resolved_path=str(target),
                    approved_directory=str(self.approved_directory),
                    flexible_mode=self.flexible_mode,
                )
                return False, None, "Access denied: path outside approved directory"

            logger.debug(
                "Path validation successful",
                original_path=user_path,
                resolved_path=str(target),
            )
            return True, target, None

        except Exception as e:
            logger.error("Path validation error", path=user_path, error=str(e))
            return False, None, f"Invalid path: {str(e)}"

    def _is_within_directory(self, path: Path, directory: Path) -> bool:
        """Check if path is within directory."""
        try:
            path.relative_to(directory)
            return True
        except ValueError:
            return False

    def validate_filename(self, filename: str) -> Tuple[bool, Optional[str]]:
        """Validate uploaded filename.

        Returns:
            Tuple of (is_valid, error_message)
        """
        # Basic checks
        if not filename or not filename.strip():
            return False, "Empty filename not allowed"

        filename = filename.strip()

        # Check for path separators in filename
        if "/" in filename or "\\" in filename:
            logger.warning("Path separator in filename", filename=filename)
            return False, "Invalid filename: contains path separators"

        # Check for forbidden patterns in filenames (use path patterns, not command patterns)
        for pattern in self.DANGEROUS_PATH_PATTERNS:
            if re.search(pattern, filename, re.IGNORECASE):
                logger.warning(
                    "Dangerous pattern in filename", filename=filename, pattern=pattern
                )
                return False, "Invalid filename: contains forbidden pattern"

        # Check for forbidden filenames
        if filename.lower() in {name.lower() for name in self.FORBIDDEN_FILENAMES}:
            logger.warning("Forbidden filename", filename=filename)
            return False, f"Forbidden filename: {filename}"

        # Check for dangerous file patterns
        for pattern in self.DANGEROUS_FILE_PATTERNS:
            if re.match(pattern, filename, re.IGNORECASE):
                logger.warning(
                    "Dangerous file pattern", filename=filename, pattern=pattern
                )
                return False, f"File type not allowed: {filename}"

        # Check extension
        path_obj = Path(filename)
        ext = path_obj.suffix.lower()

        if ext and ext not in self.ALLOWED_EXTENSIONS:
            logger.warning(
                "File extension not allowed", filename=filename, extension=ext
            )
            return False, f"File type not allowed: {ext}"

        # Check for hidden files (starting with .)
        if filename.startswith(".") and filename not in {".gitignore", ".gitkeep"}:
            logger.warning("Hidden file upload attempt", filename=filename)
            return False, "Hidden files not allowed"

        # Check filename length
        if len(filename) > 255:
            return False, "Filename too long (max 255 characters)"

        logger.debug("Filename validation successful", filename=filename)
        return True, None

    def sanitize_command_input(self, text: str) -> str:
        """Sanitize text input for commands.

        This removes potentially dangerous characters but preserves
        the structure needed for legitimate commands.
        """
        if not text:
            return ""

        # Remove dangerous characters but preserve basic ones
        # Note: This is very restrictive - adjust based on actual needs
        sanitized = re.sub(r"[`$;|&<>#\x00-\x1f\x7f]", "", text)

        # Limit length to prevent buffer overflow attacks
        max_length = 1000
        if len(sanitized) > max_length:
            sanitized = sanitized[:max_length]
            logger.warning(
                "Command input truncated",
                original_length=len(text),
                truncated_length=len(sanitized),
            )

        # Remove excessive whitespace
        sanitized = " ".join(sanitized.split())

        if sanitized != text:
            logger.debug(
                "Command input sanitized",
                original=text[:100],  # Log first 100 chars
                sanitized=sanitized[:100],
            )

        return sanitized

    def sanitize_command_input_lenient(self, text: str) -> str:
        """Sanitize text input for commands with lenient rules for image processing context.

        This allows Markdown characters like # while still blocking dangerous patterns.
        """
        if not text:
            return ""

        # Remove dangerous characters but allow Markdown formatting
        # Allow # for headers, * for emphasis, etc.
        sanitized = re.sub(r"[`$;|&<>\x00-\x1f\x7f]", "", text)

        # Limit length to prevent buffer overflow attacks
        max_length = 5000  # Higher limit for image context with detailed prompts
        if len(sanitized) > max_length:
            sanitized = sanitized[:max_length]
            logger.warning(
                "Command input truncated (lenient)",
                original_length=len(text),
                truncated_length=len(sanitized),
            )

        # Keep original whitespace structure for formatted text
        # Only collapse excessive runs of whitespace
        sanitized = re.sub(r'\s{3,}', '  ', sanitized)

        if sanitized != text:
            logger.debug(
                "Command input sanitized (lenient)",
                original=text[:100],  # Log first 100 chars
                sanitized=sanitized[:100],
            )

        return sanitized

    def validate_command_args(
        self, args: List[str]
    ) -> Tuple[bool, List[str], Optional[str]]:
        """Validate and sanitize command arguments.

        Returns:
            Tuple of (is_valid, sanitized_args, error_message)
        """
        if not args:
            return True, [], None

        sanitized_args = []

        for arg in args:
            # Check for dangerous command patterns in arguments
            for pattern in self.DANGEROUS_COMMAND_PATTERNS:
                if re.search(pattern, arg, re.IGNORECASE):
                    logger.warning(
                        "Dangerous pattern in command arg", arg=arg, pattern=pattern
                    )
                    return False, [], "Invalid argument: contains forbidden pattern"

            # Sanitize argument
            sanitized = self.sanitize_command_input(arg)
            if not sanitized and arg:  # If original had content but sanitized is empty
                logger.warning("Command argument completely sanitized", original=arg)
                return (
                    False,
                    [],
                    f"Invalid argument: '{arg}' contains only forbidden characters",
                )

            sanitized_args.append(sanitized)

        return True, sanitized_args, None

    def is_safe_directory_name(self, dirname: str) -> bool:
        """Check if directory name is safe for creation."""
        if not dirname or not dirname.strip():
            return False

        dirname = dirname.strip()

        # Check for dangerous patterns in directory names (use path patterns)
        for pattern in self.DANGEROUS_PATH_PATTERNS:
            if re.search(pattern, dirname, re.IGNORECASE):
                return False

        # Check for path separators
        if "/" in dirname or "\\" in dirname:
            return False

        # Check for forbidden names
        if dirname.lower() in {name.lower() for name in self.FORBIDDEN_FILENAMES}:
            return False

        # Check for hidden directories
        if dirname.startswith("."):
            return False

        # Check length
        if len(dirname) > 100:
            return False

        return True

    def get_security_summary(self) -> Dict[str, Any]:
        """Get summary of security validation rules."""
        return {
            "approved_directory": str(self.approved_directory),
            "allowed_extensions": sorted(list(self.ALLOWED_EXTENSIONS)),
            "forbidden_filenames": sorted(list(self.FORBIDDEN_FILENAMES)),
            "dangerous_patterns_count": len(self.DANGEROUS_PATTERNS),
            "dangerous_file_patterns_count": len(self.DANGEROUS_FILE_PATTERNS),
            "max_filename_length": 255,
            "max_command_length": 1000,
        }

```

### security/audit.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 14,504 Ð±Ð°Ð¹Ñ‚

```python
"""Security audit logging.

Features:
- All authentication attempts
- Command execution
- File access
- Security violations
"""

import json
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import structlog

# from src.exceptions import SecurityError  # Future use

logger = structlog.get_logger()


@dataclass
class AuditEvent:
    """Security audit event."""

    timestamp: datetime
    user_id: int
    event_type: str
    success: bool
    details: Dict[str, Any]
    ip_address: Optional[str] = None
    session_id: Optional[str] = None
    risk_level: str = "low"  # low, medium, high, critical

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for storage/logging."""
        data = asdict(self)
        data["timestamp"] = self.timestamp.isoformat()
        return data

    def to_json(self) -> str:
        """Convert to JSON string."""
        return json.dumps(self.to_dict(), default=str)


class AuditStorage:
    """Abstract interface for audit event storage."""

    async def store_event(self, event: AuditEvent) -> None:
        """Store audit event."""
        raise NotImplementedError

    async def get_events(
        self,
        user_id: Optional[int] = None,
        event_type: Optional[str] = None,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None,
        limit: int = 100,
    ) -> List[AuditEvent]:
        """Retrieve audit events with filters."""
        raise NotImplementedError

    async def get_security_violations(
        self, user_id: Optional[int] = None, limit: int = 100
    ) -> List[AuditEvent]:
        """Get security violations."""
        raise NotImplementedError


class InMemoryAuditStorage(AuditStorage):
    """In-memory audit storage for development/testing."""

    def __init__(self, max_events: int = 10000):
        self.events: List[AuditEvent] = []
        self.max_events = max_events

    async def store_event(self, event: AuditEvent) -> None:
        """Store event in memory."""
        self.events.append(event)

        # Trim old events if we exceed limit
        if len(self.events) > self.max_events:
            self.events = self.events[-self.max_events :]

        # Log high-risk events immediately
        if event.risk_level in ["high", "critical"]:
            logger.warning(
                "High-risk security event",
                event_type=event.event_type,
                user_id=event.user_id,
                risk_level=event.risk_level,
                details=event.details,
            )

    async def get_events(
        self,
        user_id: Optional[int] = None,
        event_type: Optional[str] = None,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None,
        limit: int = 100,
    ) -> List[AuditEvent]:
        """Get filtered events."""
        filtered_events = self.events

        # Apply filters
        if user_id is not None:
            filtered_events = [e for e in filtered_events if e.user_id == user_id]

        if event_type is not None:
            filtered_events = [e for e in filtered_events if e.event_type == event_type]

        if start_time is not None:
            filtered_events = [e for e in filtered_events if e.timestamp >= start_time]

        if end_time is not None:
            filtered_events = [e for e in filtered_events if e.timestamp <= end_time]

        # Sort by timestamp (newest first) and limit
        filtered_events.sort(key=lambda e: e.timestamp, reverse=True)
        return filtered_events[:limit]

    async def get_security_violations(
        self, user_id: Optional[int] = None, limit: int = 100
    ) -> List[AuditEvent]:
        """Get security violations."""
        return await self.get_events(
            user_id=user_id, event_type="security_violation", limit=limit
        )


class AuditLogger:
    """Security audit logger."""

    def __init__(self, storage: AuditStorage):
        self.storage = storage
        logger.info("Audit logger initialized")

    async def log_auth_attempt(
        self,
        user_id: int,
        success: bool,
        method: str,
        reason: Optional[str] = None,
        ip_address: Optional[str] = None,
    ) -> None:
        """Log authentication attempt."""
        risk_level = "medium" if not success else "low"

        event = AuditEvent(
            timestamp=datetime.utcnow(),
            user_id=user_id,
            event_type="auth_attempt",
            success=success,
            details={"method": method, "reason": reason},
            ip_address=ip_address,
            risk_level=risk_level,
        )

        await self.storage.store_event(event)

        logger.info(
            "Authentication attempt logged",
            user_id=user_id,
            method=method,
            success=success,
            reason=reason,
        )

    async def log_session_event(
        self,
        user_id: int,
        action: str,
        success: bool = True,
        details: Optional[Dict[str, Any]] = None,
    ) -> None:
        """Log session-related events."""
        event = AuditEvent(
            timestamp=datetime.utcnow(),
            user_id=user_id,
            event_type="session",
            success=success,
            details={"action": action, **(details or {})},
            risk_level="low",
        )

        await self.storage.store_event(event)

    async def log_command(
        self,
        user_id: int,
        command: str,
        args: List[str],
        success: bool,
        working_directory: Optional[str] = None,
        execution_time: Optional[float] = None,
        exit_code: Optional[int] = None,
    ) -> None:
        """Log command execution."""
        # Determine risk level based on command
        risk_level = self._assess_command_risk(command, args)

        event = AuditEvent(
            timestamp=datetime.utcnow(),
            user_id=user_id,
            event_type="command",
            success=success,
            details={
                "command": command,
                "args": args[:10],  # Limit args for storage
                "working_directory": working_directory,
                "execution_time": execution_time,
                "exit_code": exit_code,
            },
            risk_level=risk_level,
        )

        await self.storage.store_event(event)

        logger.info(
            "Command execution logged",
            user_id=user_id,
            command=command,
            success=success,
            risk_level=risk_level,
        )

    async def log_file_access(
        self,
        user_id: int,
        file_path: str,
        action: str,  # read, write, delete, create
        success: bool,
        file_size: Optional[int] = None,
    ) -> None:
        """Log file access."""
        # Assess risk based on file path and action
        risk_level = self._assess_file_access_risk(file_path, action)

        event = AuditEvent(
            timestamp=datetime.utcnow(),
            user_id=user_id,
            event_type="file_access",
            success=success,
            details={"file_path": file_path, "action": action, "file_size": file_size},
            risk_level=risk_level,
        )

        await self.storage.store_event(event)

    async def log_security_violation(
        self,
        user_id: int,
        violation_type: str,
        details: str,
        severity: str = "medium",
        attempted_action: Optional[str] = None,
    ) -> None:
        """Log security violation."""
        # Map severity to risk level
        risk_mapping = {"low": "medium", "medium": "high", "high": "critical"}
        risk_level = risk_mapping.get(severity, "high")

        event = AuditEvent(
            timestamp=datetime.utcnow(),
            user_id=user_id,
            event_type="security_violation",
            success=False,  # Security violations are always failures
            details={
                "violation_type": violation_type,
                "details": details,
                "severity": severity,
                "attempted_action": attempted_action,
            },
            risk_level=risk_level,
        )

        await self.storage.store_event(event)

        logger.warning(
            "Security violation logged",
            user_id=user_id,
            violation_type=violation_type,
            severity=severity,
            details=details,
        )

    async def log_rate_limit_exceeded(
        self,
        user_id: int,
        limit_type: str,  # request, cost
        current_usage: float,
        limit_value: float,
    ) -> None:
        """Log rate limit exceeded."""
        event = AuditEvent(
            timestamp=datetime.utcnow(),
            user_id=user_id,
            event_type="rate_limit_exceeded",
            success=False,
            details={
                "limit_type": limit_type,
                "current_usage": current_usage,
                "limit_value": limit_value,
                "utilization": current_usage / limit_value if limit_value > 0 else 0,
            },
            risk_level="low",
        )

        await self.storage.store_event(event)

    def _assess_command_risk(self, command: str, args: List[str]) -> str:
        """Assess risk level of command execution."""
        high_risk_commands = {
            "rm",
            "del",
            "delete",
            "format",
            "fdisk",
            "dd",
            "chmod",
            "chown",
            "sudo",
            "su",
            "passwd",
            "curl",
            "wget",
            "ssh",
            "scp",
            "rsync",
        }

        medium_risk_commands = {
            "git",
            "npm",
            "pip",
            "docker",
            "kubectl",
            "make",
            "cmake",
            "gcc",
            "python",
            "node",
        }

        command_lower = command.lower()

        if any(risky in command_lower for risky in high_risk_commands):
            return "high"
        elif any(risky in command_lower for risky in medium_risk_commands):
            return "medium"
        else:
            return "low"

    def _assess_file_access_risk(self, file_path: str, action: str) -> str:
        """Assess risk level of file access."""
        sensitive_paths = [
            "/etc/",
            "/var/",
            "/usr/",
            "/sys/",
            "/proc/",
            "/.env",
            "/.ssh/",
            "/.aws/",
            "/secrets/",
            "config",
            "password",
            "key",
            "token",
        ]

        risky_actions = {"delete", "write"}

        path_lower = file_path.lower()

        # High risk: sensitive paths with write/delete
        if action in risky_actions and any(
            sensitive in path_lower for sensitive in sensitive_paths
        ):
            return "high"

        # Medium risk: any sensitive path access or risky actions
        if (
            any(sensitive in path_lower for sensitive in sensitive_paths)
            or action in risky_actions
        ):
            return "medium"

        return "low"

    async def get_user_activity_summary(
        self, user_id: int, hours: int = 24
    ) -> Dict[str, Any]:
        """Get activity summary for user."""
        start_time = datetime.utcnow() - timedelta(hours=hours)
        events = await self.storage.get_events(
            user_id=user_id, start_time=start_time, limit=1000
        )

        # Aggregate statistics
        summary: Dict[str, Any] = {
            "user_id": user_id,
            "period_hours": hours,
            "total_events": len(events),
            "event_types": {},
            "risk_levels": {},
            "success_rate": 0,
            "security_violations": 0,
            "last_activity": None,
        }

        if events:
            summary["last_activity"] = events[0].timestamp.isoformat()

            successful_events = 0
            for event in events:
                # Count by type
                event_type = event.event_type
                summary["event_types"][event_type] = (
                    summary["event_types"].get(event_type, 0) + 1
                )

                # Count by risk level
                risk_level = event.risk_level
                summary["risk_levels"][risk_level] = (
                    summary["risk_levels"].get(risk_level, 0) + 1
                )

                # Count successes
                if event.success:
                    successful_events += 1

                # Count security violations
                if event.event_type == "security_violation":
                    summary["security_violations"] += 1

            summary["success_rate"] = successful_events / len(events)

        return summary

    async def get_security_dashboard(self) -> Dict[str, Any]:
        """Get security dashboard data."""
        # Get recent events (last 24 hours)
        start_time = datetime.utcnow() - timedelta(hours=24)
        recent_events = await self.storage.get_events(start_time=start_time, limit=1000)

        # Get security violations
        violations = await self.storage.get_security_violations(limit=100)

        dashboard: Dict[str, Any] = {
            "period": "24_hours",
            "total_events": len(recent_events),
            "security_violations": len(violations),
            "active_users": len(set(e.user_id for e in recent_events)),
            "risk_distribution": {},
            "top_violation_types": {},
            "authentication_failures": 0,
        }

        # Analyze events
        for event in recent_events:
            # Risk distribution
            risk = event.risk_level
            dashboard["risk_distribution"][risk] = (
                dashboard["risk_distribution"].get(risk, 0) + 1
            )

            # Authentication failures
            if event.event_type == "auth_attempt" and not event.success:
                dashboard["authentication_failures"] += 1

        # Analyze violations
        for violation in violations:
            violation_type = violation.details.get("violation_type", "unknown")
            dashboard["top_violation_types"][violation_type] = (
                dashboard["top_violation_types"].get(violation_type, 0) + 1
            )

        return dashboard

```

### storage/__init__.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 0 Ð±Ð°Ð¹Ñ‚

```python


```

### storage/session_storage.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 10,156 Ð±Ð°Ð¹Ñ‚

```python
"""Persistent session storage implementation.

Replaces the in-memory session storage with SQLite persistence.
"""

from datetime import datetime
from pathlib import Path
from typing import List, Optional

import structlog

from ..claude.session import ClaudeSession, SessionStorage
from .database import DatabaseManager
from .models import SessionModel, UserModel

logger = structlog.get_logger()


class SQLiteSessionStorage(SessionStorage):
    """SQLite-based session storage."""

    def __init__(self, db_manager: DatabaseManager):
        """Initialize with database manager."""
        self.db_manager = db_manager

    async def _ensure_user_exists(
        self, user_id: int, username: Optional[str] = None
    ) -> None:
        """Ensure user exists in database before creating session."""
        async with self.db_manager.get_connection() as conn:
            # Check if user exists
            cursor = await conn.execute(
                "SELECT user_id FROM users WHERE user_id = ?", (user_id,)
            )
            user_exists = await cursor.fetchone()

            if not user_exists:
                # Create user record
                now = datetime.utcnow()
                await conn.execute(
                    """
                    INSERT INTO users (user_id, telegram_username, first_seen, last_active, is_allowed)
                    VALUES (?, ?, ?, ?, ?)
                    """,
                    (
                        user_id,
                        username,
                        now,
                        now,
                        True,
                    ),  # Allow user by default for now
                )
                await conn.commit()

                logger.info(
                    "Created user record for session",
                    user_id=user_id,
                    username=username,
                )

    async def save_session(self, session: ClaudeSession) -> None:
        """Save session to database."""
        # Ensure user exists before creating session
        await self._ensure_user_exists(session.user_id)

        session_model = SessionModel(
            session_id=session.session_id,
            user_id=session.user_id,
            project_path=str(session.project_path),
            created_at=session.created_at,
            last_used=session.last_used,
            total_cost=session.total_cost,
            total_turns=session.total_turns,
            message_count=session.message_count,
        )

        async with self.db_manager.get_connection() as conn:
            # Try to update first
            cursor = await conn.execute(
                """
                UPDATE sessions 
                SET last_used = ?, total_cost = ?, total_turns = ?, message_count = ?
                WHERE session_id = ?
            """,
                (
                    session_model.last_used,
                    session_model.total_cost,
                    session_model.total_turns,
                    session_model.message_count,
                    session_model.session_id,
                ),
            )

            # If no rows were updated, insert new record
            if cursor.rowcount == 0:
                await conn.execute(
                    """
                    INSERT INTO sessions 
                    (session_id, user_id, project_path, created_at, last_used, 
                     total_cost, total_turns, message_count)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """,
                    (
                        session_model.session_id,
                        session_model.user_id,
                        session_model.project_path,
                        session_model.created_at,
                        session_model.last_used,
                        session_model.total_cost,
                        session_model.total_turns,
                        session_model.message_count,
                    ),
                )

            await conn.commit()

        logger.debug(
            "Session saved to database",
            session_id=session.session_id,
            user_id=session.user_id,
        )

    async def load_session(self, session_id: str) -> Optional[ClaudeSession]:
        """Load session from database."""
        async with self.db_manager.get_connection() as conn:
            cursor = await conn.execute(
                "SELECT * FROM sessions WHERE session_id = ?", (session_id,)
            )
            row = await cursor.fetchone()

            if not row:
                return None

            session_model = SessionModel.from_row(row)

            # Convert to ClaudeSession
            claude_session = ClaudeSession(
                session_id=session_model.session_id,
                user_id=session_model.user_id,
                project_path=Path(session_model.project_path),
                created_at=session_model.created_at,
                last_used=session_model.last_used,
                total_cost=session_model.total_cost,
                total_turns=session_model.total_turns,
                message_count=session_model.message_count,
                tools_used=[],  # Tools are tracked separately in tool_usage table
            )

            logger.debug(
                "Session loaded from database",
                session_id=session_id,
                user_id=claude_session.user_id,
            )

            return claude_session

    async def delete_session(self, session_id: str) -> None:
        """Delete session from database."""
        async with self.db_manager.get_connection() as conn:
            await conn.execute(
                "UPDATE sessions SET is_active = FALSE WHERE session_id = ?",
                (session_id,),
            )
            await conn.commit()

        logger.debug("Session marked as inactive", session_id=session_id)

    async def update_session_id(self, old_session_id: str, new_session_id: str) -> None:
        """Update session ID when it changes from temporary to Claude session ID."""
        async with self.db_manager.get_connection() as conn:
            # Update session_id in sessions table
            await conn.execute(
                "UPDATE sessions SET session_id = ? WHERE session_id = ?",
                (new_session_id, old_session_id)
            )
            
            # Update foreign key references in other tables
            await conn.execute(
                "UPDATE messages SET session_id = ? WHERE session_id = ?", 
                (new_session_id, old_session_id)
            )
            await conn.execute(
                "UPDATE tool_usage SET session_id = ? WHERE session_id = ?",
                (new_session_id, old_session_id)  
            )
            
            await conn.commit()

        logger.info(
            "Session ID updated in database",
            old_session_id=old_session_id,
            new_session_id=new_session_id,
        )

    async def get_user_sessions(self, user_id: int) -> List[ClaudeSession]:
        """Get all active sessions for a user."""
        async with self.db_manager.get_connection() as conn:
            cursor = await conn.execute(
                """
                SELECT * FROM sessions 
                WHERE user_id = ? AND is_active = TRUE
                ORDER BY last_used DESC
            """,
                (user_id,),
            )
            rows = await cursor.fetchall()

            sessions = []
            for row in rows:
                session_model = SessionModel.from_row(row)
                claude_session = ClaudeSession(
                    session_id=session_model.session_id,
                    user_id=session_model.user_id,
                    project_path=Path(session_model.project_path),
                    created_at=session_model.created_at,
                    last_used=session_model.last_used,
                    total_cost=session_model.total_cost,
                    total_turns=session_model.total_turns,
                    message_count=session_model.message_count,
                    tools_used=[],  # Tools are tracked separately
                )
                sessions.append(claude_session)

            return sessions

    async def get_all_sessions(self) -> List[ClaudeSession]:
        """Get all active sessions."""
        async with self.db_manager.get_connection() as conn:
            cursor = await conn.execute(
                "SELECT * FROM sessions WHERE is_active = TRUE ORDER BY last_used DESC"
            )
            rows = await cursor.fetchall()

            sessions = []
            for row in rows:
                session_model = SessionModel.from_row(row)
                claude_session = ClaudeSession(
                    session_id=session_model.session_id,
                    user_id=session_model.user_id,
                    project_path=Path(session_model.project_path),
                    created_at=session_model.created_at,
                    last_used=session_model.last_used,
                    total_cost=session_model.total_cost,
                    total_turns=session_model.total_turns,
                    message_count=session_model.message_count,
                    tools_used=[],  # Tools are tracked separately
                )
                sessions.append(claude_session)

            return sessions

    async def cleanup_expired_sessions(self, timeout_hours: int) -> int:
        """Mark expired sessions as inactive."""
        async with self.db_manager.get_connection() as conn:
            cursor = await conn.execute(
                """
                UPDATE sessions 
                SET is_active = FALSE 
                WHERE last_used < datetime('now', '-' || ? || ' hours')
                  AND is_active = TRUE
            """,
                (timeout_hours,),
            )
            await conn.commit()

            affected = cursor.rowcount
            logger.info(
                "Cleaned up expired sessions",
                count=affected,
                timeout_hours=timeout_hours,
            )
            return affected

```

### storage/database.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 18,209 Ð±Ð°Ð¹Ñ‚

```python
"""Database connection and initialization.

Features:
- Connection pooling
- Automatic migrations
- Health checks
- Schema versioning
"""

import asyncio
from contextlib import asynccontextmanager
from pathlib import Path
from typing import AsyncIterator, List, Tuple

import aiosqlite
import structlog

logger = structlog.get_logger()

# Initial schema migration
INITIAL_SCHEMA = """
-- Core Tables

-- Users table
CREATE TABLE users (
    user_id INTEGER PRIMARY KEY,
    telegram_username TEXT,
    first_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_active TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    is_allowed BOOLEAN DEFAULT FALSE,
    total_cost REAL DEFAULT 0.0,
    message_count INTEGER DEFAULT 0,
    session_count INTEGER DEFAULT 0
);

-- Sessions table
CREATE TABLE sessions (
    session_id TEXT PRIMARY KEY,
    user_id INTEGER NOT NULL,
    project_path TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_used TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    total_cost REAL DEFAULT 0.0,
    total_turns INTEGER DEFAULT 0,
    message_count INTEGER DEFAULT 0,
    is_active BOOLEAN DEFAULT TRUE,
    FOREIGN KEY (user_id) REFERENCES users(user_id)
);

-- Messages table
CREATE TABLE messages (
    message_id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL,
    user_id INTEGER NOT NULL,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    prompt TEXT NOT NULL,
    response TEXT,
    cost REAL DEFAULT 0.0,
    duration_ms INTEGER,
    error TEXT,
    FOREIGN KEY (session_id) REFERENCES sessions(session_id),
    FOREIGN KEY (user_id) REFERENCES users(user_id)
);

-- Tool usage table
CREATE TABLE tool_usage (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL,
    message_id INTEGER,
    tool_name TEXT NOT NULL,
    tool_input JSON,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    success BOOLEAN DEFAULT TRUE,
    error_message TEXT,
    FOREIGN KEY (session_id) REFERENCES sessions(session_id),
    FOREIGN KEY (message_id) REFERENCES messages(message_id)
);

-- Audit log table
CREATE TABLE audit_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    event_type TEXT NOT NULL,
    event_data JSON,
    success BOOLEAN DEFAULT TRUE,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    ip_address TEXT,
    FOREIGN KEY (user_id) REFERENCES users(user_id)
);

-- User tokens table (for token auth)
CREATE TABLE user_tokens (
    token_id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    token_hash TEXT NOT NULL UNIQUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    expires_at TIMESTAMP,
    last_used TIMESTAMP,
    is_active BOOLEAN DEFAULT TRUE,
    FOREIGN KEY (user_id) REFERENCES users(user_id)
);

-- Cost tracking table
CREATE TABLE cost_tracking (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    date DATE NOT NULL,
    daily_cost REAL DEFAULT 0.0,
    request_count INTEGER DEFAULT 0,
    UNIQUE(user_id, date),
    FOREIGN KEY (user_id) REFERENCES users(user_id)
);

-- Indexes for performance
CREATE INDEX idx_sessions_user_id ON sessions(user_id);
CREATE INDEX idx_sessions_project_path ON sessions(project_path);
CREATE INDEX idx_messages_session_id ON messages(session_id);
CREATE INDEX idx_messages_timestamp ON messages(timestamp);
CREATE INDEX idx_audit_log_user_id ON audit_log(user_id);
CREATE INDEX idx_audit_log_timestamp ON audit_log(timestamp);
CREATE INDEX idx_cost_tracking_user_date ON cost_tracking(user_id, date);
"""


class DatabaseManager:
    """Manage database connections and initialization."""

    def __init__(self, database_url: str):
        """Initialize database manager."""
        self.database_path = self._parse_database_url(database_url)
        self._connection_pool = []
        self._pool_size = 5
        self._pool_lock = asyncio.Lock()

    def _parse_database_url(self, database_url: str) -> Path:
        """Parse database URL to path."""
        if database_url.startswith("sqlite:///"):
            return Path(database_url[10:])
        elif database_url.startswith("sqlite://"):
            return Path(database_url[9:])
        else:
            return Path(database_url)

    async def initialize(self):
        """Initialize database and run migrations."""
        logger.info("Initializing database", path=str(self.database_path))

        # Ensure directory exists
        self.database_path.parent.mkdir(parents=True, exist_ok=True)

        # Run migrations
        await self._run_migrations()

        # Initialize connection pool
        await self._init_pool()

        logger.info("Database initialization complete")

    async def _run_migrations(self):
        """Run database migrations."""
        async with aiosqlite.connect(self.database_path) as conn:
            conn.row_factory = aiosqlite.Row

            # Enable foreign keys
            await conn.execute("PRAGMA foreign_keys = ON")

            # Get current version
            current_version = await self._get_schema_version(conn)
            logger.info("Current schema version", version=current_version)

            # Run migrations
            migrations = self._get_migrations()
            for version, migration in migrations:
                if version > current_version:
                    logger.info("Running migration", version=version)
                    await conn.executescript(migration)
                    await self._set_schema_version(conn, version)

            await conn.commit()

    async def _get_schema_version(self, conn: aiosqlite.Connection) -> int:
        """Get current schema version."""
        await conn.execute(
            """
            CREATE TABLE IF NOT EXISTS schema_version (
                version INTEGER PRIMARY KEY
            )
        """
        )

        cursor = await conn.execute("SELECT MAX(version) FROM schema_version")
        row = await cursor.fetchone()
        return row[0] if row and row[0] else 0

    async def _set_schema_version(self, conn: aiosqlite.Connection, version: int):
        """Set schema version."""
        await conn.execute(
            "INSERT INTO schema_version (version) VALUES (?)", (version,)
        )

    def _get_migrations(self) -> List[Tuple[int, str]]:
        """Get migration scripts."""
        return [
            (1, INITIAL_SCHEMA),
            (
                2,
                """
                -- Add MCP Management System
                CREATE TABLE IF NOT EXISTS mcp_server_templates (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    server_type TEXT UNIQUE NOT NULL,
                    display_name TEXT NOT NULL,
                    description TEXT,
                    command_template TEXT NOT NULL,
                    args_template TEXT,
                    env_template TEXT,
                    config_schema TEXT,
                    setup_instructions TEXT,
                    is_active BOOLEAN DEFAULT 1,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );

                CREATE TABLE IF NOT EXISTS user_mcp_servers (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    server_name TEXT NOT NULL,
                    server_type TEXT NOT NULL,
                    server_command TEXT NOT NULL,
                    server_args TEXT,
                    server_env TEXT,
                    config TEXT,
                    is_active BOOLEAN DEFAULT 1,
                    is_enabled BOOLEAN DEFAULT 1,
                    status TEXT DEFAULT 'inactive',
                    last_used TIMESTAMP,
                    last_status_check TIMESTAMP,
                    error_message TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(user_id, server_name),
                    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE
                );

                CREATE TABLE IF NOT EXISTS user_active_context (
                    user_id INTEGER PRIMARY KEY,
                    selected_server TEXT,
                    context_settings TEXT,
                    selected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE
                );

                CREATE TABLE IF NOT EXISTS mcp_usage_log (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER,
                    server_name TEXT,
                    query TEXT,
                    response_time INTEGER,
                    success BOOLEAN,
                    error_message TEXT,
                    cost REAL DEFAULT 0.0,
                    session_id TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE
                );

                CREATE INDEX IF NOT EXISTS idx_user_mcp_servers_user_id ON user_mcp_servers(user_id);
                CREATE INDEX IF NOT EXISTS idx_user_mcp_servers_status ON user_mcp_servers(status);
                CREATE INDEX IF NOT EXISTS idx_user_mcp_servers_type ON user_mcp_servers(server_type);
                CREATE INDEX IF NOT EXISTS idx_mcp_usage_log_user_id ON mcp_usage_log(user_id);
                CREATE INDEX IF NOT EXISTS idx_mcp_usage_log_created_at ON mcp_usage_log(created_at);

                INSERT OR IGNORE INTO mcp_server_templates (server_type, display_name, description, command_template, args_template, env_template, config_schema, setup_instructions) VALUES
                ('github', 'GitHub Integration', 'Ð”Ð¾ÑÑ‚ÑƒÐ¿ Ð´Ð¾ GitHub Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ñ—Ð², issues, pull requests Ñ‚Ð° Ñ–Ð½ÑˆÐ¾Ð³Ð¾', 'npx', '["-y", "@modelcontextprotocol/server-github"]', '{"GITHUB_PERSONAL_ACCESS_TOKEN": "${input:github_token}"}', '{"type": "object", "properties": {"github_token": {"type": "string", "description": "GitHub Personal Access Token", "required": true}}}', '1. ÐŸÐµÑ€ÐµÐ¹Ð´Ñ–Ñ‚ÑŒ Ð´Ð¾ GitHub Settings > Developer settings > Personal access tokens\n2. Ð¡Ñ‚Ð²Ð¾Ñ€Ñ–Ñ‚ÑŒ Ð½Ð¾Ð²Ð¸Ð¹ Ñ‚Ð¾ÐºÐµÐ½ Ð· Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð¾Ð¼ Ð´Ð¾ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–Ñ—Ð²\n3. Ð¡ÐºÐ¾Ð¿Ñ–ÑŽÐ¹Ñ‚Ðµ Ñ‚Ð¾ÐºÐµÐ½'),
                ('filesystem', 'File System Access', 'Ð§Ð¸Ñ‚Ð°Ð½Ð½Ñ Ñ‚Ð° Ð·Ð°Ð¿Ð¸Ñ Ñ„Ð°Ð¹Ð»Ñ–Ð² Ñƒ Ð²ÐºÐ°Ð·Ð°Ð½Ð¸Ñ… Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–ÑÑ…', 'npx', '["-y", "@modelcontextprotocol/server-filesystem", "${config:allowed_path}"]', '{}', '{"type": "object", "properties": {"allowed_path": {"type": "string", "description": "Ð¨Ð»ÑÑ… Ð´Ð¾ Ð´Ð¾Ð·Ð²Ð¾Ð»ÐµÐ½Ð¾Ñ— Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—", "required": true}}}', 'Ð’ÐºÐ°Ð¶Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ð½Ð¸Ð¹ ÑˆÐ»ÑÑ… Ð´Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ—, Ð´Ðµ Claude Ð¼Ð¾Ð¶Ðµ Ñ‡Ð¸Ñ‚Ð°Ñ‚Ð¸/Ð¿Ð¸ÑÐ°Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ð¸'),
                ('postgres', 'PostgreSQL Database', 'Ð—Ð°Ð¿Ð¸Ñ‚Ð¸ Ñ‚Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ PostgreSQL Ð±Ð°Ð·Ð°Ð¼Ð¸ Ð´Ð°Ð½Ð¸Ñ…', 'npx', '["-y", "@modelcontextprotocol/server-postgres", "${config:connection_string}"]', '{}', '{"type": "object", "properties": {"connection_string": {"type": "string", "description": "Ð ÑÐ´Ð¾Ðº Ð¿Ñ–Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ñ PostgreSQL", "required": true}}}', 'Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚: postgresql://username:password@host:port/database'),
                ('sqlite', 'SQLite Database', 'Ð—Ð°Ð¿Ð¸Ñ‚Ð¸ Ñ‚Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ SQLite Ð±Ð°Ð·Ð°Ð¼Ð¸ Ð´Ð°Ð½Ð¸Ñ…', 'npx', '["-y", "@modelcontextprotocol/server-sqlite", "${config:database_path}"]', '{}', '{"type": "object", "properties": {"database_path": {"type": "string", "description": "Ð¨Ð»ÑÑ… Ð´Ð¾ Ñ„Ð°Ð¹Ð»Ñƒ SQLite Ð±Ð°Ð·Ð¸ Ð´Ð°Ð½Ð¸Ñ…", "required": true}}}', 'Ð’ÐºÐ°Ð¶Ñ–Ñ‚ÑŒ Ð¿Ð¾Ð²Ð½Ð¸Ð¹ ÑˆÐ»ÑÑ… Ð´Ð¾ Ñ„Ð°Ð¹Ð»Ñƒ Ð²Ð°ÑˆÐ¾Ñ— SQLite Ð±Ð°Ð·Ð¸ Ð´Ð°Ð½Ð¸Ñ…'),
                ('git', 'Git Repository Tools', 'Git Ð¾Ð¿ÐµÑ€Ð°Ñ†Ñ–Ñ— Ñ‚Ð° ÑƒÐ¿Ñ€Ð°Ð²Ð»Ñ–Ð½Ð½Ñ Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–ÑÐ¼Ð¸', 'uvx', '["mcp-server-git", "--repository", "${config:repo_path}"]', '{}', '{"type": "object", "properties": {"repo_path": {"type": "string", "description": "Ð¨Ð»ÑÑ… Ð´Ð¾ git Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–ÑŽ", "required": true}}}', 'Ð’ÐºÐ°Ð¶Ñ–Ñ‚ÑŒ ÑˆÐ»ÑÑ… Ð´Ð¾ Ð²Ð°ÑˆÐ¾Ð³Ð¾ git Ñ€ÐµÐ¿Ð¾Ð·Ð¸Ñ‚Ð¾Ñ€Ñ–ÑŽ'),
                ('playwright', 'Web Automation', 'ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°Ñ†Ñ–Ñ Ð±Ñ€Ð°ÑƒÐ·ÐµÑ€Ð° Ñ‚Ð° Ð²ÐµÐ±-ÑÐºÑ€Ð°Ð¿Ñ–Ð½Ð³', 'npx', '["-y", "@modelcontextprotocol/server-playwright"]', '{}', '{"type": "object", "properties": {}}', 'Ð”Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ð° ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ Ð½Ðµ Ð¿Ð¾Ñ‚Ñ€Ñ–Ð±Ð½Ð°');
                """
            ),
            (
                3,
                """
                -- Add analytics views
                CREATE VIEW IF NOT EXISTS daily_stats AS
                SELECT 
                    date(timestamp) as date,
                    COUNT(DISTINCT user_id) as active_users,
                    COUNT(*) as total_messages,
                    SUM(cost) as total_cost,
                    AVG(duration_ms) as avg_duration
                FROM messages
                GROUP BY date(timestamp);

                CREATE VIEW IF NOT EXISTS user_stats AS
                SELECT 
                    u.user_id,
                    u.telegram_username,
                    COUNT(DISTINCT s.session_id) as total_sessions,
                    COUNT(m.message_id) as total_messages,
                    SUM(m.cost) as total_cost,
                    MAX(m.timestamp) as last_activity
                FROM users u
                LEFT JOIN sessions s ON u.user_id = s.user_id
                LEFT JOIN messages m ON u.user_id = m.user_id
                GROUP BY u.user_id;
                """,
            ),
            (
                4,
                """
                -- Add image processing tables
                CREATE TABLE IF NOT EXISTS image_uploads (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    session_id TEXT,
                    message_id INTEGER,
                    filename TEXT NOT NULL,
                    original_filename TEXT,
                    file_size INTEGER NOT NULL,
                    format TEXT NOT NULL,
                    width INTEGER NOT NULL,
                    height INTEGER NOT NULL,
                    file_hash TEXT NOT NULL,
                    caption TEXT,
                    uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    processed_at TIMESTAMP,
                    processing_status TEXT DEFAULT 'uploaded',
                    processing_error TEXT,
                    metadata TEXT,
                    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE,
                    FOREIGN KEY (session_id) REFERENCES sessions(session_id) ON DELETE SET NULL,
                    FOREIGN KEY (message_id) REFERENCES messages(message_id) ON DELETE SET NULL
                );

                CREATE TABLE IF NOT EXISTS image_sessions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT UNIQUE NOT NULL,
                    user_id INTEGER NOT NULL,
                    instruction TEXT,
                    status TEXT DEFAULT 'active',
                    images_count INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    expires_at TIMESTAMP,
                    completed_at TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE
                );

                -- Indexes for performance
                CREATE INDEX IF NOT EXISTS idx_image_uploads_user_id ON image_uploads(user_id);
                CREATE INDEX IF NOT EXISTS idx_image_uploads_session_id ON image_uploads(session_id);  
                CREATE INDEX IF NOT EXISTS idx_image_uploads_hash ON image_uploads(file_hash);
                CREATE INDEX IF NOT EXISTS idx_image_uploads_status ON image_uploads(processing_status);
                CREATE INDEX IF NOT EXISTS idx_image_sessions_user_id ON image_sessions(user_id);
                CREATE INDEX IF NOT EXISTS idx_image_sessions_status ON image_sessions(status);
                CREATE INDEX IF NOT EXISTS idx_image_sessions_expires_at ON image_sessions(expires_at);
                """,
            ),
        ]

    async def _init_pool(self):
        """Initialize connection pool."""
        logger.info("Initializing connection pool", size=self._pool_size)

        async with self._pool_lock:
            for _ in range(self._pool_size):
                conn = await aiosqlite.connect(self.database_path)
                conn.row_factory = aiosqlite.Row
                await conn.execute("PRAGMA foreign_keys = ON")
                self._connection_pool.append(conn)

    @asynccontextmanager
    async def get_connection(self) -> AsyncIterator[aiosqlite.Connection]:
        """Get database connection from pool."""
        async with self._pool_lock:
            if self._connection_pool:
                conn = self._connection_pool.pop()
            else:
                conn = await aiosqlite.connect(self.database_path)
                conn.row_factory = aiosqlite.Row
                await conn.execute("PRAGMA foreign_keys = ON")

        try:
            yield conn
        finally:
            async with self._pool_lock:
                if len(self._connection_pool) < self._pool_size:
                    self._connection_pool.append(conn)
                else:
                    await conn.close()

    async def close(self):
        """Close all connections in pool."""
        logger.info("Closing database connections")

        async with self._pool_lock:
            for conn in self._connection_pool:
                await conn.close()
            self._connection_pool.clear()

    async def health_check(self) -> bool:
        """Check database health."""
        try:
            async with self.get_connection() as conn:
                await conn.execute("SELECT 1")
                return True
        except Exception as e:
            logger.error("Database health check failed", error=str(e))
            return False

```

### storage/models.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 10,504 Ð±Ð°Ð¹Ñ‚

```python
"""Data models for storage.

Using dataclasses for simplicity and type safety.
"""

import json
from dataclasses import asdict, dataclass
from datetime import datetime
from typing import Any, Dict, Optional

import aiosqlite


@dataclass
class UserModel:
    """User data model."""

    user_id: int
    telegram_username: Optional[str] = None
    first_seen: Optional[datetime] = None
    last_active: Optional[datetime] = None
    is_allowed: bool = False
    total_cost: float = 0.0
    message_count: int = 0
    session_count: int = 0

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        data = asdict(self)
        # Convert datetime to ISO format
        for key in ["first_seen", "last_active"]:
            if data[key]:
                data[key] = data[key].isoformat()
        return data

    @classmethod
    def from_row(cls, row: aiosqlite.Row) -> "UserModel":
        """Create from database row."""
        data = dict(row)

        # Parse datetime fields
        for field in ["first_seen", "last_active"]:
            if data.get(field):
                data[field] = datetime.fromisoformat(data[field])

        return cls(**data)


@dataclass
class SessionModel:
    """Session data model."""

    session_id: str
    user_id: int
    project_path: str
    created_at: datetime
    last_used: datetime
    total_cost: float = 0.0
    total_turns: int = 0
    message_count: int = 0
    is_active: bool = True

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        data = asdict(self)
        # Convert datetime to ISO format
        for key in ["created_at", "last_used"]:
            if data[key]:
                data[key] = data[key].isoformat()
        return data

    @classmethod
    def from_row(cls, row: aiosqlite.Row) -> "SessionModel":
        """Create from database row."""
        data = dict(row)

        # Parse datetime fields
        for field in ["created_at", "last_used"]:
            if data.get(field):
                data[field] = datetime.fromisoformat(data[field])

        return cls(**data)

    def is_expired(self, timeout_hours: int) -> bool:
        """Check if session has expired."""
        if not self.last_used:
            return True

        age = datetime.utcnow() - self.last_used
        return age.total_seconds() > (timeout_hours * 3600)


@dataclass
class MessageModel:
    """Message data model."""

    session_id: str
    user_id: int
    timestamp: datetime
    prompt: str
    message_id: Optional[int] = None
    response: Optional[str] = None
    cost: float = 0.0
    duration_ms: Optional[int] = None
    error: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        data = asdict(self)
        # Convert datetime to ISO format
        if data["timestamp"]:
            data["timestamp"] = data["timestamp"].isoformat()
        return data

    @classmethod
    def from_row(cls, row: aiosqlite.Row) -> "MessageModel":
        """Create from database row."""
        data = dict(row)

        # Parse datetime fields
        if data.get("timestamp"):
            data["timestamp"] = datetime.fromisoformat(data["timestamp"])

        return cls(**data)


@dataclass
class ToolUsageModel:
    """Tool usage data model."""

    session_id: str
    tool_name: str
    timestamp: datetime
    id: Optional[int] = None
    message_id: Optional[int] = None
    tool_input: Optional[Dict[str, Any]] = None
    success: bool = True
    error_message: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        data = asdict(self)
        # Convert datetime to ISO format
        if data["timestamp"]:
            data["timestamp"] = data["timestamp"].isoformat()
        # Convert tool_input to JSON string if present
        if data["tool_input"]:
            data["tool_input"] = json.dumps(data["tool_input"])
        return data

    @classmethod
    def from_row(cls, row: aiosqlite.Row) -> "ToolUsageModel":
        """Create from database row."""
        data = dict(row)

        # Parse datetime fields
        if data.get("timestamp"):
            data["timestamp"] = datetime.fromisoformat(data["timestamp"])

        # Parse JSON fields
        if data.get("tool_input"):
            try:
                data["tool_input"] = json.loads(data["tool_input"])
            except (json.JSONDecodeError, TypeError):
                data["tool_input"] = {}

        return cls(**data)


@dataclass
class AuditLogModel:
    """Audit log data model."""

    user_id: int
    event_type: str
    timestamp: datetime
    id: Optional[int] = None
    event_data: Optional[Dict[str, Any]] = None
    success: bool = True
    ip_address: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        data = asdict(self)
        # Convert datetime to ISO format
        if data["timestamp"]:
            data["timestamp"] = data["timestamp"].isoformat()
        # Convert event_data to JSON string if present
        if data["event_data"]:
            data["event_data"] = json.dumps(data["event_data"])
        return data

    @classmethod
    def from_row(cls, row: aiosqlite.Row) -> "AuditLogModel":
        """Create from database row."""
        data = dict(row)

        # Parse datetime fields
        if data.get("timestamp"):
            data["timestamp"] = datetime.fromisoformat(data["timestamp"])

        # Parse JSON fields
        if data.get("event_data"):
            try:
                data["event_data"] = json.loads(data["event_data"])
            except (json.JSONDecodeError, TypeError):
                data["event_data"] = {}

        return cls(**data)


@dataclass
class CostTrackingModel:
    """Cost tracking data model."""

    user_id: int
    date: str  # ISO date format (YYYY-MM-DD)
    daily_cost: float = 0.0
    request_count: int = 0
    id: Optional[int] = None

    @classmethod
    def from_row(cls, row: aiosqlite.Row) -> "CostTrackingModel":
        """Create from database row."""
        return cls(**dict(row))

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return asdict(self)


@dataclass
class UserTokenModel:
    """User token data model."""

    user_id: int
    token_hash: str
    created_at: datetime
    token_id: Optional[int] = None
    expires_at: Optional[datetime] = None
    last_used: Optional[datetime] = None
    is_active: bool = True

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        data = asdict(self)
        # Convert datetime to ISO format
        for key in ["created_at", "expires_at", "last_used"]:
            if data[key]:
                data[key] = data[key].isoformat()
        return data

    @classmethod
    def from_row(cls, row: aiosqlite.Row) -> "UserTokenModel":
        """Create from database row."""
        data = dict(row)

        # Parse datetime fields
        for field in ["created_at", "expires_at", "last_used"]:
            if data.get(field):
                data[field] = datetime.fromisoformat(data[field])

        return cls(**data)

    def is_expired(self) -> bool:
        """Check if token has expired."""
        if not self.expires_at:
            return False
        return datetime.utcnow() > self.expires_at


@dataclass
class ScheduledTaskModel:
    """Scheduled task data model for automated execution."""

    user_id: int
    task_type: str
    prompt: str
    created_at: datetime
    task_id: Optional[int] = None
    scheduled_for: Optional[datetime] = None
    auto_execute: bool = True
    auto_respond: bool = True
    status: str = "pending"  # pending, running, completed, failed, cancelled
    result: Optional[str] = None
    error_message: Optional[str] = None
    executed_at: Optional[datetime] = None
    execution_duration_ms: Optional[int] = None
    retry_count: int = 0
    max_retries: int = 3
    priority: int = 1  # 1=high, 2=medium, 3=low
    metadata: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        data = asdict(self)
        # Convert datetime to ISO format
        for key in ["created_at", "scheduled_for", "executed_at"]:
            if data[key]:
                data[key] = data[key].isoformat()
        # Convert metadata to JSON string if present
        if data["metadata"]:
            data["metadata"] = json.dumps(data["metadata"])
        return data

    @classmethod
    def from_row(cls, row: aiosqlite.Row) -> "ScheduledTaskModel":
        """Create from database row."""
        data = dict(row)

        # Parse datetime fields
        for field in ["created_at", "scheduled_for", "executed_at"]:
            if data.get(field):
                data[field] = datetime.fromisoformat(data[field])

        # Parse JSON fields
        if data.get("metadata"):
            try:
                data["metadata"] = json.loads(data["metadata"])
            except (json.JSONDecodeError, TypeError):
                data["metadata"] = {}

        return cls(**data)

    def is_ready_for_execution(self) -> bool:
        """Check if task is ready for execution."""
        if self.status != "pending":
            return False

        if self.scheduled_for:
            return datetime.utcnow() >= self.scheduled_for

        return True

    def is_failed_with_retries(self) -> bool:
        """Check if task has failed and exhausted retries."""
        return self.status == "failed" and self.retry_count >= self.max_retries

    def can_retry(self) -> bool:
        """Check if task can be retried."""
        return self.status == "failed" and self.retry_count < self.max_retries

    def mark_running(self) -> None:
        """Mark task as running."""
        self.status = "running"

    def mark_completed(self, result: str, duration_ms: Optional[int] = None) -> None:
        """Mark task as completed."""
        self.status = "completed"
        self.result = result
        self.executed_at = datetime.utcnow()
        if duration_ms:
            self.execution_duration_ms = duration_ms

    def mark_failed(self, error: str) -> None:
        """Mark task as failed and increment retry count."""
        self.status = "failed"
        self.error_message = error
        self.retry_count += 1
        self.executed_at = datetime.utcnow()


__all__ = ["UserModel", "SessionModel", "ScheduledTaskModel"]

```

### storage/facade.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 11,038 Ð±Ð°Ð¹Ñ‚

```python
"""Unified storage interface.

Provides simple API for the rest of the application.
"""

from datetime import datetime
from typing import Any, Dict, Optional

import structlog

from ..claude.integration import ClaudeResponse
from .database import DatabaseManager
from .models import (
    AuditLogModel,
    MessageModel,
    SessionModel,
    ToolUsageModel,
    UserModel,
)
from .repositories import (
    AnalyticsRepository,
    AuditLogRepository,
    CostTrackingRepository,
    MessageRepository,
    SessionRepository,
    ToolUsageRepository,
    UserRepository,
)

logger = structlog.get_logger()


class Storage:
    """Main storage interface."""

    def __init__(self, database_url: str):
        """Initialize storage with database URL."""
        self.db_manager = DatabaseManager(database_url)
        self.users = UserRepository(self.db_manager)
        self.sessions = SessionRepository(self.db_manager)
        self.messages = MessageRepository(self.db_manager)
        self.tools = ToolUsageRepository(self.db_manager)
        self.audit = AuditLogRepository(self.db_manager)
        self.costs = CostTrackingRepository(self.db_manager)
        self.analytics = AnalyticsRepository(self.db_manager)

    async def initialize(self):
        """Initialize storage system."""
        logger.info("Initializing storage system")
        await self.db_manager.initialize()
        logger.info("Storage system initialized")

    async def close(self):
        """Close storage connections."""
        logger.info("Closing storage system")
        await self.db_manager.close()

    async def health_check(self) -> bool:
        """Check storage system health."""
        return await self.db_manager.health_check()

    # High-level operations

    async def save_claude_interaction(
        self,
        user_id: int,
        session_id: str,
        prompt: str,
        response: ClaudeResponse,
        ip_address: Optional[str] = None,
    ):
        """Save complete Claude interaction."""
        logger.info(
            "Saving Claude interaction",
            user_id=user_id,
            session_id=session_id,
            cost=response.cost,
        )

        # Save message
        message = MessageModel(
            message_id=None,
            session_id=session_id,
            user_id=user_id,
            timestamp=datetime.utcnow(),
            prompt=prompt,
            response=response.content,
            cost=response.cost,
            duration_ms=response.duration_ms,
            error=response.error_type if response.is_error else None,
        )

        message_id = await self.messages.save_message(message)

        # Save tool usage
        if response.tools_used:
            for tool in response.tools_used:
                tool_usage = ToolUsageModel(
                    id=None,
                    session_id=session_id,
                    message_id=message_id,
                    tool_name=tool["name"],
                    tool_input=tool.get("input", {}),
                    timestamp=datetime.utcnow(),
                    success=not response.is_error,
                    error_message=response.error_type if response.is_error else None,
                )
                await self.tools.save_tool_usage(tool_usage)

        # Update cost tracking
        await self.costs.update_daily_cost(user_id, response.cost)

        # Update user stats
        user = await self.users.get_user(user_id)
        if user:
            user.total_cost += response.cost
            user.message_count += 1
            user.last_active = datetime.utcnow()
            await self.users.update_user(user)

        # Update session stats
        session = await self.sessions.get_session(session_id)
        if session:
            session.total_cost += response.cost
            session.total_turns += response.num_turns
            session.message_count += 1
            session.last_used = datetime.utcnow()
            await self.sessions.update_session(session)

        # Log audit event
        audit_event = AuditLogModel(
            id=None,
            user_id=user_id,
            event_type="claude_interaction",
            event_data={
                "session_id": session_id,
                "cost": response.cost,
                "duration_ms": response.duration_ms,
                "num_turns": response.num_turns,
                "is_error": response.is_error,
                "tools_used": [t["name"] for t in response.tools_used],
            },
            success=not response.is_error,
            timestamp=datetime.utcnow(),
            ip_address=ip_address,
        )
        await self.audit.log_event(audit_event)

    async def get_or_create_user(
        self, user_id: int, username: Optional[str] = None
    ) -> UserModel:
        """Get or create user."""
        user = await self.users.get_user(user_id)

        if not user:
            logger.info("Creating new user", user_id=user_id, username=username)
            user = UserModel(
                user_id=user_id,
                telegram_username=username,
                first_seen=datetime.utcnow(),
                last_active=datetime.utcnow(),
                is_allowed=False,  # Default to not allowed
            )
            await self.users.create_user(user)

        return user

    async def create_session(
        self, user_id: int, project_path: str, session_id: str
    ) -> SessionModel:
        """Create new session."""
        session = SessionModel(
            session_id=session_id,
            user_id=user_id,
            project_path=project_path,
            created_at=datetime.utcnow(),
            last_used=datetime.utcnow(),
        )

        await self.sessions.create_session(session)

        # Update user session count
        user = await self.users.get_user(user_id)
        if user:
            user.session_count += 1
            await self.users.update_user(user)

        return session

    async def log_security_event(
        self,
        user_id: int,
        event_type: str,
        event_data: Dict[str, Any],
        success: bool = True,
        ip_address: Optional[str] = None,
    ):
        """Log security-related event."""
        audit_event = AuditLogModel(
            id=None,
            user_id=user_id,
            event_type=event_type,
            event_data=event_data,
            success=success,
            timestamp=datetime.utcnow(),
            ip_address=ip_address,
        )
        await self.audit.log_event(audit_event)

    async def log_bot_event(
        self,
        user_id: int,
        event_type: str,
        event_data: Dict[str, Any],
        success: bool = True,
    ):
        """Log bot-related event."""
        audit_event = AuditLogModel(
            id=None,
            user_id=user_id,
            event_type=event_type,
            event_data=event_data,
            success=success,
            timestamp=datetime.utcnow(),
        )
        await self.audit.log_event(audit_event)

    # Convenience methods

    async def is_user_allowed(self, user_id: int) -> bool:
        """Check if user is allowed."""
        user = await self.users.get_user(user_id)
        return user.is_allowed if user else False

    async def get_user_session_summary(self, user_id: int) -> Dict[str, Any]:
        """Get user session summary."""
        sessions = await self.sessions.get_user_sessions(user_id, active_only=False)
        active_sessions = [s for s in sessions if s.is_active]

        return {
            "total_sessions": len(sessions),
            "active_sessions": len(active_sessions),
            "total_cost": sum(s.total_cost for s in sessions),
            "total_messages": sum(s.message_count for s in sessions),
            "projects": list(set(s.project_path for s in sessions)),
        }

    async def update_session_id(self, old_session_id: str, new_session_id: str):
        """Update session ID when it changes from temporary to Claude session ID."""
        await self.sessions.update_session_id(old_session_id, new_session_id)

    async def get_session_history(
        self, session_id: str, limit: int = 50
    ) -> Dict[str, Any]:
        """Get session history with messages and tools."""
        session = await self.sessions.get_session(session_id)
        if not session:
            return None

        messages = await self.messages.get_session_messages(session_id, limit)
        tools = await self.tools.get_session_tool_usage(session_id)

        return {
            "session": session.to_dict(),
            "messages": [m.to_dict() for m in messages],
            "tool_usage": [t.to_dict() for t in tools],
        }

    async def cleanup_old_data(self, days: int = 30) -> Dict[str, int]:
        """Cleanup old data."""
        logger.info("Starting data cleanup", days=days)

        # Cleanup old sessions
        sessions_cleaned = await self.sessions.cleanup_old_sessions(days)

        logger.info("Data cleanup complete", sessions_cleaned=sessions_cleaned)

        return {"sessions_cleaned": sessions_cleaned}

    async def get_user_dashboard(self, user_id: int) -> Dict[str, Any]:
        """Get comprehensive user dashboard data."""
        # Get user info
        user = await self.users.get_user(user_id)
        if not user:
            return None

        # Get user stats
        stats = await self.analytics.get_user_stats(user_id)

        # Get recent sessions
        sessions = await self.sessions.get_user_sessions(user_id, active_only=True)

        # Get recent messages
        messages = await self.messages.get_user_messages(user_id, limit=10)

        # Get recent audit log
        audit_logs = await self.audit.get_user_audit_log(user_id, limit=20)

        # Get daily costs
        daily_costs = await self.costs.get_user_daily_costs(user_id, days=30)

        return {
            "user": user.to_dict(),
            "stats": stats,
            "recent_sessions": [s.to_dict() for s in sessions[:5]],
            "recent_messages": [m.to_dict() for m in messages],
            "recent_audit": [a.to_dict() for a in audit_logs],
            "daily_costs": [c.to_dict() for c in daily_costs],
        }

    async def get_admin_dashboard(self) -> Dict[str, Any]:
        """Get admin dashboard data."""
        # Get system stats
        system_stats = await self.analytics.get_system_stats()

        # Get all users
        users = await self.users.get_all_users()

        # Get recent audit log
        recent_audit = await self.audit.get_recent_audit_log(hours=24)

        # Get total costs
        total_costs = await self.costs.get_total_costs(days=30)

        # Get tool stats
        tool_stats = await self.tools.get_tool_stats()

        return {
            "system_stats": system_stats,
            "users": [u.to_dict() for u in users],
            "recent_audit": [a.to_dict() for a in recent_audit],
            "total_costs": total_costs,
            "tool_stats": tool_stats,
        }

```

### storage/repositories.py

**Ð Ð¾Ð·Ð¼Ñ–Ñ€:** 23,988 Ð±Ð°Ð¹Ñ‚

```python
"""Data access layer using repository pattern.

Features:
- Clean data access API
- Query optimization
- Error handling
"""

import json
from datetime import datetime
from typing import Dict, List, Optional

import structlog

from .database import DatabaseManager
from .models import (
    AuditLogModel,
    CostTrackingModel,
    MessageModel,
    SessionModel,
    ToolUsageModel,
    UserModel,
)

logger = structlog.get_logger()


class UserRepository:
    """User data access."""

    def __init__(self, db_manager: DatabaseManager):
        """Initialize repository."""
        self.db = db_manager

    async def get_user(self, user_id: int) -> Optional[UserModel]:
        """Get user by ID."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                "SELECT * FROM users WHERE user_id = ?", (user_id,)
            )
            row = await cursor.fetchone()
            return UserModel.from_row(row) if row else None

    async def create_user(self, user: UserModel) -> UserModel:
        """Create new user."""
        async with self.db.get_connection() as conn:
            await conn.execute(
                """
                INSERT INTO users (user_id, telegram_username, first_seen, last_active, is_allowed)
                VALUES (?, ?, ?, ?, ?)
            """,
                (
                    user.user_id,
                    user.telegram_username,
                    user.first_seen or datetime.utcnow(),
                    user.last_active or datetime.utcnow(),
                    user.is_allowed,
                ),
            )
            await conn.commit()

            logger.info(
                "Created user", user_id=user.user_id, username=user.telegram_username
            )
            return user

    async def update_user(self, user: UserModel):
        """Update user data."""
        async with self.db.get_connection() as conn:
            await conn.execute(
                """
                UPDATE users 
                SET telegram_username = ?, last_active = ?, 
                    total_cost = ?, message_count = ?, session_count = ?
                WHERE user_id = ?
            """,
                (
                    user.telegram_username,
                    user.last_active or datetime.utcnow(),
                    user.total_cost,
                    user.message_count,
                    user.session_count,
                    user.user_id,
                ),
            )
            await conn.commit()

    async def get_allowed_users(self) -> List[int]:
        """Get list of allowed user IDs."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                "SELECT user_id FROM users WHERE is_allowed = TRUE"
            )
            rows = await cursor.fetchall()
            return [row[0] for row in rows]

    async def set_user_allowed(self, user_id: int, allowed: bool):
        """Set user allowed status."""
        async with self.db.get_connection() as conn:
            await conn.execute(
                "UPDATE users SET is_allowed = ? WHERE user_id = ?", (allowed, user_id)
            )
            await conn.commit()

            logger.info("Updated user permissions", user_id=user_id, allowed=allowed)

    async def get_all_users(self) -> List[UserModel]:
        """Get all users."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute("SELECT * FROM users ORDER BY first_seen DESC")
            rows = await cursor.fetchall()
            return [UserModel.from_row(row) for row in rows]


class SessionRepository:
    """Session data access."""

    def __init__(self, db_manager: DatabaseManager):
        """Initialize repository."""
        self.db = db_manager

    async def get_session(self, session_id: str) -> Optional[SessionModel]:
        """Get session by ID."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                "SELECT * FROM sessions WHERE session_id = ?", (session_id,)
            )
            row = await cursor.fetchone()
            return SessionModel.from_row(row) if row else None

    async def create_session(self, session: SessionModel) -> SessionModel:
        """Create new session."""
        async with self.db.get_connection() as conn:
            await conn.execute(
                """
                INSERT INTO sessions 
                (session_id, user_id, project_path, created_at, last_used)
                VALUES (?, ?, ?, ?, ?)
            """,
                (
                    session.session_id,
                    session.user_id,
                    session.project_path,
                    session.created_at,
                    session.last_used,
                ),
            )
            await conn.commit()

            logger.info(
                "Created session",
                session_id=session.session_id,
                user_id=session.user_id,
            )
            return session

    async def update_session(self, session: SessionModel):
        """Update session data."""
        async with self.db.get_connection() as conn:
            await conn.execute(
                """
                UPDATE sessions 
                SET last_used = ?, total_cost = ?, total_turns = ?, 
                    message_count = ?, is_active = ?
                WHERE session_id = ?
            """,
                (
                    session.last_used,
                    session.total_cost,
                    session.total_turns,
                    session.message_count,
                    session.is_active,
                    session.session_id,
                ),
            )
            await conn.commit()

    async def update_session_id(self, old_session_id: str, new_session_id: str):
        """Update session ID when it changes from temporary to Claude session ID."""
        async with self.db.get_connection() as conn:
            # Update session_id in sessions table
            await conn.execute(
                "UPDATE sessions SET session_id = ? WHERE session_id = ?",
                (new_session_id, old_session_id)
            )
            
            # Update foreign key references in other tables
            await conn.execute(
                "UPDATE messages SET session_id = ? WHERE session_id = ?", 
                (new_session_id, old_session_id)
            )
            await conn.execute(
                "UPDATE tool_usage SET session_id = ? WHERE session_id = ?",
                (new_session_id, old_session_id)  
            )
            
            await conn.commit()

    async def get_user_sessions(
        self, user_id: int, active_only: bool = True
    ) -> List[SessionModel]:
        """Get sessions for user."""
        async with self.db.get_connection() as conn:
            query = "SELECT * FROM sessions WHERE user_id = ?"
            params = [user_id]

            if active_only:
                query += " AND is_active = TRUE"

            query += " ORDER BY last_used DESC"

            cursor = await conn.execute(query, params)
            rows = await cursor.fetchall()
            return [SessionModel.from_row(row) for row in rows]

    async def cleanup_old_sessions(self, days: int = 30) -> int:
        """Mark old sessions as inactive."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                UPDATE sessions 
                SET is_active = FALSE 
                WHERE last_used < datetime('now', '-' || ? || ' days')
                  AND is_active = TRUE
            """,
                (days,),
            )
            await conn.commit()

            affected = cursor.rowcount
            logger.info("Cleaned up old sessions", count=affected, days=days)
            return affected

    async def get_sessions_by_project(self, project_path: str) -> List[SessionModel]:
        """Get sessions for a specific project."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                SELECT * FROM sessions 
                WHERE project_path = ? AND is_active = TRUE
                ORDER BY last_used DESC
            """,
                (project_path,),
            )
            rows = await cursor.fetchall()
            return [SessionModel.from_row(row) for row in rows]


class MessageRepository:
    """Message data access."""

    def __init__(self, db_manager: DatabaseManager):
        """Initialize repository."""
        self.db = db_manager

    async def save_message(self, message: MessageModel) -> int:
        """Save message and return ID."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                INSERT INTO messages 
                (session_id, user_id, timestamp, prompt, response, cost, duration_ms, error)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    message.session_id,
                    message.user_id,
                    message.timestamp,
                    message.prompt,
                    message.response,
                    message.cost,
                    message.duration_ms,
                    message.error,
                ),
            )
            await conn.commit()
            return cursor.lastrowid

    async def get_session_messages(
        self, session_id: str, limit: int = 50
    ) -> List[MessageModel]:
        """Get messages for session."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                SELECT * FROM messages 
                WHERE session_id = ? 
                ORDER BY timestamp DESC 
                LIMIT ?
            """,
                (session_id, limit),
            )
            rows = await cursor.fetchall()
            return [MessageModel.from_row(row) for row in rows]

    async def get_user_messages(
        self, user_id: int, limit: int = 100
    ) -> List[MessageModel]:
        """Get messages for user."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                SELECT * FROM messages 
                WHERE user_id = ? 
                ORDER BY timestamp DESC 
                LIMIT ?
            """,
                (user_id, limit),
            )
            rows = await cursor.fetchall()
            return [MessageModel.from_row(row) for row in rows]

    async def get_recent_messages(self, hours: int = 24) -> List[MessageModel]:
        """Get recent messages."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                SELECT * FROM messages 
                WHERE timestamp > datetime('now', '-' || ? || ' hours')
                ORDER BY timestamp DESC
            """,
                (hours,),
            )
            rows = await cursor.fetchall()
            return [MessageModel.from_row(row) for row in rows]


class ToolUsageRepository:
    """Tool usage data access."""

    def __init__(self, db_manager: DatabaseManager):
        """Initialize repository."""
        self.db = db_manager

    async def save_tool_usage(self, tool_usage: ToolUsageModel) -> int:
        """Save tool usage and return ID."""
        async with self.db.get_connection() as conn:
            tool_input_json = (
                json.dumps(tool_usage.tool_input) if tool_usage.tool_input else None
            )

            cursor = await conn.execute(
                """
                INSERT INTO tool_usage 
                (session_id, message_id, tool_name, tool_input, timestamp, success, error_message)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    tool_usage.session_id,
                    tool_usage.message_id,
                    tool_usage.tool_name,
                    tool_input_json,
                    tool_usage.timestamp,
                    tool_usage.success,
                    tool_usage.error_message,
                ),
            )
            await conn.commit()
            return cursor.lastrowid

    async def get_session_tool_usage(self, session_id: str) -> List[ToolUsageModel]:
        """Get tool usage for session."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                SELECT * FROM tool_usage 
                WHERE session_id = ? 
                ORDER BY timestamp DESC
            """,
                (session_id,),
            )
            rows = await cursor.fetchall()
            return [ToolUsageModel.from_row(row) for row in rows]

    async def get_user_tool_usage(self, user_id: int) -> List[ToolUsageModel]:
        """Get tool usage for user."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                SELECT tu.* FROM tool_usage tu
                JOIN sessions s ON tu.session_id = s.session_id
                WHERE s.user_id = ?
                ORDER BY tu.timestamp DESC
            """,
                (user_id,),
            )
            rows = await cursor.fetchall()
            return [ToolUsageModel.from_row(row) for row in rows]

    async def get_tool_stats(self) -> List[Dict[str, any]]:
        """Get tool usage statistics."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                SELECT 
                    tool_name,
                    COUNT(*) as usage_count,
                    COUNT(DISTINCT session_id) as sessions_used,
                    SUM(CASE WHEN success = TRUE THEN 1 ELSE 0 END) as success_count,
                    SUM(CASE WHEN success = FALSE THEN 1 ELSE 0 END) as error_count
                FROM tool_usage
                GROUP BY tool_name
                ORDER BY usage_count DESC
            """
            )
            rows = await cursor.fetchall()
            return [dict(row) for row in rows]


class AuditLogRepository:
    """Audit log data access."""

    def __init__(self, db_manager: DatabaseManager):
        """Initialize repository."""
        self.db = db_manager

    async def log_event(self, audit_log: AuditLogModel) -> int:
        """Log audit event and return ID."""
        async with self.db.get_connection() as conn:
            event_data_json = (
                json.dumps(audit_log.event_data) if audit_log.event_data else None
            )

            cursor = await conn.execute(
                """
                INSERT INTO audit_log 
                (user_id, event_type, event_data, success, timestamp, ip_address)
                VALUES (?, ?, ?, ?, ?, ?)
            """,
                (
                    audit_log.user_id,
                    audit_log.event_type,
                    event_data_json,
                    audit_log.success,
                    audit_log.timestamp,
                    audit_log.ip_address,
                ),
            )
            await conn.commit()
            return cursor.lastrowid

    async def get_user_audit_log(
        self, user_id: int, limit: int = 100
    ) -> List[AuditLogModel]:
        """Get audit log for user."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                SELECT * FROM audit_log 
                WHERE user_id = ? 
                ORDER BY timestamp DESC 
                LIMIT ?
            """,
                (user_id, limit),
            )
            rows = await cursor.fetchall()
            return [AuditLogModel.from_row(row) for row in rows]

    async def get_recent_audit_log(self, hours: int = 24) -> List[AuditLogModel]:
        """Get recent audit log entries."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                SELECT * FROM audit_log 
                WHERE timestamp > datetime('now', '-' || ? || ' hours')
                ORDER BY timestamp DESC
            """,
                (hours,),
            )
            rows = await cursor.fetchall()
            return [AuditLogModel.from_row(row) for row in rows]


class CostTrackingRepository:
    """Cost tracking data access."""

    def __init__(self, db_manager: DatabaseManager):
        """Initialize repository."""
        self.db = db_manager

    async def update_daily_cost(self, user_id: int, cost: float, date: str = None):
        """Update daily cost for user."""
        if not date:
            date = datetime.utcnow().strftime("%Y-%m-%d")

        async with self.db.get_connection() as conn:
            await conn.execute(
                """
                INSERT INTO cost_tracking (user_id, date, daily_cost, request_count)
                VALUES (?, ?, ?, 1)
                ON CONFLICT(user_id, date) 
                DO UPDATE SET 
                    daily_cost = daily_cost + ?,
                    request_count = request_count + 1
            """,
                (user_id, date, cost, cost),
            )
            await conn.commit()

    async def get_user_daily_costs(
        self, user_id: int, days: int = 30
    ) -> List[CostTrackingModel]:
        """Get user's daily costs."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                SELECT * FROM cost_tracking 
                WHERE user_id = ? AND date >= date('now', '-' || ? || ' days')
                ORDER BY date DESC
            """,
                (user_id, days),
            )
            rows = await cursor.fetchall()
            return [CostTrackingModel.from_row(row) for row in rows]

    async def get_total_costs(self, days: int = 30) -> List[Dict[str, any]]:
        """Get total costs by day."""
        async with self.db.get_connection() as conn:
            cursor = await conn.execute(
                """
                SELECT 
                    date,
                    SUM(daily_cost) as total_cost,
                    SUM(request_count) as total_requests,
                    COUNT(DISTINCT user_id) as active_users
                FROM cost_tracking 
                WHERE date >= date('now', '-' || ? || ' days')
                GROUP BY date
                ORDER BY date DESC
            """,
                (days,),
            )
            rows = await cursor.fetchall()
            return [dict(row) for row in rows]


class AnalyticsRepository:
    """Analytics and reporting."""

    def __init__(self, db_manager: DatabaseManager):
        """Initialize repository."""
        self.db = db_manager

    async def get_user_stats(self, user_id: int) -> Dict[str, any]:
        """Get user statistics."""
        async with self.db.get_connection() as conn:
            # User summary
            cursor = await conn.execute(
                """
                SELECT 
                    COUNT(DISTINCT session_id) as total_sessions,
                    COUNT(*) as total_messages,
                    SUM(cost) as total_cost,
                    AVG(cost) as avg_cost,
                    MAX(timestamp) as last_activity,
                    AVG(duration_ms) as avg_duration
                FROM messages
                WHERE user_id = ?
            """,
                (user_id,),
            )

            summary = dict(await cursor.fetchone())

            # Daily usage (last 30 days)
            cursor = await conn.execute(
                """
                SELECT 
                    date(timestamp) as date,
                    COUNT(*) as messages,
                    SUM(cost) as cost,
                    COUNT(DISTINCT session_id) as sessions
                FROM messages
                WHERE user_id = ? AND timestamp >= datetime('now', '-30 days')
                GROUP BY date(timestamp)
                ORDER BY date DESC
            """,
                (user_id,),
            )

            daily_usage = [dict(row) for row in await cursor.fetchall()]

            # Most used tools
            cursor = await conn.execute(
                """
                SELECT 
                    tu.tool_name,
                    COUNT(*) as usage_count
                FROM tool_usage tu
                JOIN sessions s ON tu.session_id = s.session_id
                WHERE s.user_id = ?
                GROUP BY tu.tool_name
                ORDER BY usage_count DESC
                LIMIT 10
            """,
                (user_id,),
            )

            top_tools = [dict(row) for row in await cursor.fetchall()]

            return {
                "summary": summary,
                "daily_usage": daily_usage,
                "top_tools": top_tools,
            }

    async def get_system_stats(self) -> Dict[str, any]:
        """Get system-wide statistics."""
        async with self.db.get_connection() as conn:
            # Overall stats
            cursor = await conn.execute(
                """
                SELECT 
                    COUNT(DISTINCT user_id) as total_users,
                    COUNT(DISTINCT session_id) as total_sessions,
                    COUNT(*) as total_messages,
                    SUM(cost) as total_cost,
                    AVG(duration_ms) as avg_duration
                FROM messages
            """
            )

            overall = dict(await cursor.fetchone())

            # Active users (last 7 days)
            cursor = await conn.execute(
                """
                SELECT COUNT(DISTINCT user_id) as active_users
                FROM messages
                WHERE timestamp > datetime('now', '-7 days')
            """
            )

            active_users = (await cursor.fetchone())[0]
            overall["active_users_7d"] = active_users

            # Top users by cost
            cursor = await conn.execute(
                """
                SELECT 
                    u.user_id,
                    u.telegram_username,
                    SUM(m.cost) as total_cost,
                    COUNT(m.message_id) as total_messages
                FROM messages m
                JOIN users u ON m.user_id = u.user_id
                GROUP BY u.user_id
                ORDER BY total_cost DESC
                LIMIT 10
            """
            )

            top_users = [dict(row) for row in await cursor.fetchall()]

            # Tool usage stats
            cursor = await conn.execute(
                """
                SELECT 
                    tool_name,
                    COUNT(*) as usage_count,
                    COUNT(DISTINCT session_id) as sessions_used
                FROM tool_usage
                GROUP BY tool_name
                ORDER BY usage_count DESC
                LIMIT 10
            """
            )

            tool_stats = [dict(row) for row in await cursor.fetchall()]

            # Daily activity (last 30 days)
            cursor = await conn.execute(
                """
                SELECT 
                    date(timestamp) as date,
                    COUNT(DISTINCT user_id) as active_users,
                    COUNT(*) as total_messages,
                    SUM(cost) as total_cost
                FROM messages
                WHERE timestamp >= datetime('now', '-30 days')
                GROUP BY date(timestamp)
                ORDER BY date DESC
            """
            )

            daily_activity = [dict(row) for row in await cursor.fetchall()]

            return {
                "overall": overall,
                "top_users": top_users,
                "tool_stats": tool_stats,
                "daily_activity": daily_activity,
            }

```

---

## Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°

- **ÐžÐ±Ñ€Ð¾Ð±Ð»ÐµÐ½Ð¾ Ñ„Ð°Ð¹Ð»Ñ–Ð²:** 87
- **ÐŸÑ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾ ÑÐµÑ€Ð²Ñ–ÑÐ½Ð¸Ñ… Ñ„Ð°Ð¹Ð»Ñ–Ð²:** 1
- **Ð—Ð°Ð³Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€:** 1,334,007 Ð±Ð°Ð¹Ñ‚ (1302.7 KB)
- **Ð”Ð°Ñ‚Ð° ÑÑ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ:** 2025-09-21 07:24:59
